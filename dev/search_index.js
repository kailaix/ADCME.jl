var documenterSearchIndex = {"docs":
[{"location":"nn/#Neural-Networks","page":"Neural Networks","title":"Neural Networks","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"A neural network can be viewed as a computational graph where each operator in the computational graph is composed of linear transformation or simple explicit nonlinear mapping (called activation functions). There are essential components of the neural network ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"Input: the input to the neural network, which is a real or complex valued vector; the input is often called features in machine learning. To leverage dense linear algebra, features are usually aggregated into a matrix and fed to the neural network. \nOutput: the output of the neural network is also a real or complex valued vectors. The vector can be tranformed to categorical values (labels) based on the specific application. ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"The common activations functions include ReLU (Rectified linear unit), tanh, leaky ReLU, SELU, ELU, etc. In general, for inverse modeling in scientific computing, tanh usually outperms the others due to its smoothness and boundedness, and forms a solid choice at the first try. ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"A common limitation of the neural network is overfitting. The neural network contains plenty of free parameters, which makes the neural network \"memorize\" the training data easily. Therefore, you may see very a small training error, but have large test errors. Regularization methods have been proposed to alleviate this problem; to name a few, restricting network sizes, imposing weight regulization (Lasso or Ridge), using Dropout and batch normalization, etc. ","category":"page"},{"location":"nn/#Constructing-a-Neural-Network","page":"Neural Networks","title":"Constructing a Neural Network","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"ADCME provides a very simple way to specify a fully connected neural network, fc (short for autoencoder)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"x = constant(rand(10,2)) # input\nconfig = [20,20,20,3] # hidden layers\nθ = fc_init([2;config]) # getting an initial weight-and-biases vector. \n\ny1 = fc(x, config)\ny2 = fc(x, config, θ)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"note: Note\nWhen you construct a neural network using fc(x, config) syntax, ADCME will construct the weights and biases automatically for you and label the parameters (the default is default). In some cases, you may have multiple neural networks, and you can label the neural network manually using fc(x1, config1, \"label1\")\nfc(x2, config2, \"label2\")\n...","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"In scientific computing, sometimes we not only want to evaluate the neural network output, but also the sensitivity. Specifically, if ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"y = NN_theta(x)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"We also want to compute nabla_x NN_theta(x). ADCME provides a function fcx (short for fully-connected)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"y3, dy3 = fcx(x, config, θ)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"Here dy3 will be a 10times 3 times 2 tensor, where dy3[i,:,:] is the Jacobian matrix of the i-th output with respect to the i-th input (Note the i-th output is independent of j-th input, whenever ineq j).","category":"page"},{"location":"nn/#Prediction","page":"Neural Networks","title":"Prediction","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"After training a neural network, we can use the trained neural network for prediction. Here is an example","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"using ADCME\nx_train = rand(10,2)\nx_test = rand(20,2)\ny = fc(x_train, [20,20,10])\ny_obs = rand(10,10)\nloss = sum((y-y_obs)^2)\nsess = Session(); init(sess)\nBFGS!(sess, loss)\n# prediction\nrun(sess, fc(x_test, [20,20,10]))","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"Note that the second fc does not create a new neural network, but instead searches for a neural network with the label default because the default label is default. If you constructed a neural network with label mylabel: fc(x_train, [20,20,10], \"mylabel\"), you can predict using ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"run(sess, fc(x_test, [20,20,10], \"mylabel\"))","category":"page"},{"location":"nn/#Save-the-Neural-Network","page":"Neural Networks","title":"Save the Neural Network","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"To save the trained neural network in the Session sess, we can use","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"ADCME.save(sess, \"filename.mat\")","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"This will create a .mat file that contains all the labeled weights and biases. If there are other variables besides neural network parameters, these variables will also be saved. ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"To load the weights and biases to the current session, create a neural network with the same label and run","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"ADCME.load(sess, \"filename.mat\")","category":"page"},{"location":"nn/#Convert-Neural-Network-to-Codes","page":"Neural Networks","title":"Convert Neural Network to Codes","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"Sometimes we may also want to convert a fully-connected neural network to pure Julia codes. This can be done via fc_to_code. ","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"After saving the neural network to a mat file via ADCME.save, we can call","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"ae_to_code(\"filename.mat\", \"mylabel\")","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"If the second argument is missing, the default is default. For example,","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"julia> ae_to_code(\"filename.mat\", \"default\")|>println\nlet aedictdefault = matread(\"filename.mat\")\n  global nndefault\n  function nndefault(net)\n    W0 = aedictdefault[\"defaultbackslashfully_connectedbackslashweightscolon0\"]\n    b0 = aedictdefault[\"defaultbackslashfully_connectedbackslashbiasescolon0\"];\n    isa(net, Array) ? (net = net * W0 .+ b0') : (net = net *W0 + b0)\n    isa(net, Array) ? (net = tanh.(net)) : (net=tanh(net))\n    #-------------------------------------------------------------------\n    W1 = aedictdefault[\"defaultbackslashfully_connected_1backslashweightscolon0\"]\n    b1 = aedictdefault[\"defaultbackslashfully_connected_1backslashbiasescolon0\"];\n    isa(net, Array) ? (net = net * W1 .+ b1') : (net = net *W1 + b1)\n    isa(net, Array) ? (net = tanh.(net)) : (net=tanh(net))\n    #-------------------------------------------------------------------\n    W2 = aedictdefault[\"defaultbackslashfully_connected_2backslashweightscolon0\"]\n    b2 = aedictdefault[\"defaultbackslashfully_connected_2backslashbiasescolon0\"];\n    isa(net, Array) ? (net = net * W2 .+ b2') : (net = net *W2 + b2)\n    return net\n  end\nend","category":"page"},{"location":"nn/#Advance:-Use-Neural-Network-Implementations-from-Python-Script/Modules","page":"Neural Networks","title":"Advance: Use Neural Network Implementations from Python Script/Modules","text":"","category":"section"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"If you have a Python implementation of a neural network architecture and want to use that architecture, we do not need to reimplement it in ADCME. Instead, we can use the PyCall.jl package and import the functionalities. For example, if you have a Python package nnpy and it has a function magic_neural_network. We can use the following code to call magic_neural_network","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"using PyCall\nusing ADCME\n\nnnpy = pyimport(\"nnpy\")\n\nx = constant(rand(100,2))\ny = nnpy.magic_neural_network(x)","category":"page"},{"location":"nn/","page":"Neural Networks","title":"Neural Networks","text":"Because all the runtime computation are conducted in C++, there is no harm to performance using this mechanism.  ","category":"page"},{"location":"toolchain/#Built-in-Toolchain-for-Third-party-Libraries","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"","category":"section"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"Using third-party libraries, especially binaries with operation system and runtime dependencies, is troublesome and painful. ADCME has a built-in set of tools for downloading, uncompressing, and compiling third-party libraries. Therefore, we can compile external libraries from source and ensure that the products are compatible within the ADCME ecosystem. ","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"The toolchain uses the same set of C/C++ compilers that were used to compile the tensorflow dynamic library. Additionally, the toolchain provide essential building  tools such as cmake and ninja. This section will be a short introduction to the toolchain. ","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"The best way to introduce the toolchain is through an example. Let us consider compiling a C++ library for use in ADCME. The library LibHelloWorld is hosted on GitHub and the repository contains a CMakeLists.txt and HelloWorld.cpp. Our goal is to download the repository into ADCME private workspace (ADCME.PREFIXDIR) and compile the library to the library path (ADCME.LIBDIR). The following code will do the job:","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"using ADCME\n\nPWD = pwd()\nchange_directory(ADCME.PREFIXDIR)\ngit_repository(\"https://github.com/kailaix/LibHelloWorld\", \"LibHelloWorld\")\nchange_directory(\"LibHelloWorld\")\nmake_directory(\"build\")\nchange_directory(\"build\")\nlib = get_library(\"hello_world\")\nrequire_file(lib) do \n    ADCME.cmake()\n    ADCME.make()\nend\n_, libname = splitdir(lib)\nmv(lib, joinpath(ADCME.LIBDIR, libname), force=true)\nchange_directory(PWD)","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"Here change_directory, git_repository, and others are ADCME toolchain functions. Note we have used ADCME.cmake() and ADCME.make() to ensure that the codes are compiled with a compatible compiler. The toolchain will cache all the intermediate files and therefore will not recompile as long as the files exist. To force recompiling, users need to delete the local repository, i.e., LibHelloWorld in ADCME.PREFIXDIR. The following is an exemplary output of the program:","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"[ Info: Changed to directory /home/darve/kailaix/.julia/adcme/lib/Libraries\n[ Info: Cloning from https://github.com/kailaix/LibHelloWorld to LibHelloWorld...\n[ Info: Cloned https://github.com/kailaix/LibHelloWorld to LibHelloWorld\n[ Info: Changed to directory LibHelloWorld\n[ Info: Made directory directory\n[ Info: Changed to directory build\n-- The C compiler identification is GNU 5.4.0\n-- The CXX compiler identification is GNU 5.4.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: /home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: /home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\nJULIA=/home/darve/kailaix/julia-1.3.1/bin/julia\n...\nPython path=/home/darve/kailaix/.julia/adcme/bin/python\nPREFIXDIR=/home/darve/kailaix/.julia/adcme/lib/Libraries\nTF_INC=/home/darve/kailaix/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/include\nTF_ABI=1\nTF_LIB_FILE=/home/darve/kailaix/.julia/adcme/lib/python3.7/site-packages/tensorflow_core/libtensorflow_framework.so.1\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/darve/kailaix/.julia/adcme/lib/Libraries/LibHelloWorld/build\n[2/2] Linking CXX shared library libhello_world.so\n[ Info: Changed to directory /home/darve/kailaix/project/MPI_Project/LibHelloWorld","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"To use the compiled library, we can write ","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"using ADCME\nlibdir = joinpath(ADCME.LIBDIR, \"libhello_world.so\")\n@eval ccall((:helloworld, $libdir), Cvoid, ())","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"Then we get the expected output: ","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"Hello World!","category":"page"},{"location":"toolchain/","page":"Built-in Toolchain for Third-party Libraries","title":"Built-in Toolchain for Third-party Libraries","text":"The design idea for ADCME toolchains is that users can write an install script. Then ADCME will guarantee that the runtime and compilation eco-system are compatible. ","category":"page"},{"location":"apps/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"apps/","page":"Overview","title":"Overview","text":"In this section, we present some applications of ADCME to physics based machine learning.  We design data-driven algorithms for estimating unknown parameters, functions, functionals, and stochastic processes to physical or statistical models. One highlight of the applications is using neural networks to approximate the unknowns, and at the same time preserving the physical constraints such as conservation laws. We believe that as deep learning technology continues to grow, building an AD tool based on the deep learning framework will benefit scientific computing and helps solve long standing challenging inverse problems. Meanwhile, we can leverage the knowledge of physical laws to reduce the amount of data required for training deep neural networks.  This goal is achieved by the insights into the connection between deep learning algorithms and inverse modeling algorithm via automatic differentiation.","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Sample Applications","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Adversarial Numerical Analysis","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Intelligent Automatic Differentiation ","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Calibrating Multivariate Lévy Processes with Neural Networks","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"General Seismic Inversion using Automatic Differentiation","category":"page"},{"location":"apps/","page":"Overview","title":"Overview","text":"Symmetric Positive Definite Neural Networks (SPD-NN)","category":"page"},{"location":"apps_ana/#Adversarial-Numerical-Analysis","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"","category":"section"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Kailai Xu, and Eric Darve. \"Adversarial Numerical Analysis for Inverse Problems\"","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Project Website","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Many scientific and engineering applications are formulated as inverse problems associated with stochastic models. In such cases the unknown quantities are distributions. The applicability of traditional methods is limited because of their demanding assumptions or prohibitive computational consumptions; for example, maximum likelihood methods require closed-form density functions, and Markov Chain Monte Carlo needs a large number of simulations. ","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Consider the forward model","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"x = F(w theta)","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Here w is a known stochastic process such as Gaussian processes, theta is an unknown parameter, distribution or stochastic processes. Consequently, the output of the model x is also a stochastic process. F can be a very complicated model such as a system of partial differential equations. Many models fall into this category; here  we solve an inverse modeling problem of boundary value Poisson equations","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"begincases\n    -nabla cdot (a(x)nabla u(x)) = 1  xin(01)\n    u(0) = u(1) = 0  textotherwise\nendcases","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"a(x) = 1-09expleft( -frac(x-mu)^22sigma^2 right)","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"Here (mu, sigma) is subject to unknown distribution (theta in the forward model). w=emptyset and x is the solution to the equation, u. Assume we have observed a set of solutions u_i, and we want to estimate the distribution of (mu, sigma). Adversarial numerical analysis works as follows","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"The distribution (mu, sigma) is parametrized by a deep neural network G_eta.\nFor each instance of (mu, sigma) sampled from the neural network parametrized distribution, we can compute a solution u_mu sigma using the finite difference method. \nWe compute a metric between the distribution u_mu sigma and u_i with a discriminative neural network D_xi.\nMinimize the metric by adjusting the weights of G_eta and D_xi. ","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"The distribution of (mu, sigma) is given by G_eta. The following plots show the workflow of adversarial numerical analysis and a sample result for the Dirichlet distribution. ","category":"page"},{"location":"apps_ana/","page":"Adversarial Numerical Analysis","title":"Adversarial Numerical Analysis","text":"(Image: )","category":"page"},{"location":"tu_customop/#Advanced:-Custom-Operators","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"note: Note\nAs a reminder, there are many built-in custom operators in deps/CustomOps and they are good resources for understanding custom operators. The following is a step-by-step instruction on how custom operators are implemented. ","category":"page"},{"location":"tu_customop/#The-Need-for-Custom-Operators","page":"Advanced: Custom Operators","title":"The Need for Custom Operators","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Custom operators are ways to add missing features or improve performance critical components in ADCME. Typically users do not have to worry about custom operators. However, in the following situation custom opreators might be very useful","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Direct implementation in ADCME is inefficient, e.g., vectorizing some codes is difficult. \nThere are legacy codes users want to reuse, such as Fortran libraries or adjoint-state method solvers.  \nSpecial acceleration techniques, such as checkpointing scheme, MPI-enabled linear solvers, and FPGA/GPU-accelerated codes. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"(Image: )","category":"page"},{"location":"tu_customop/#The-Philosophy-of-Implementing-Custom-Operators","page":"Advanced: Custom Operators","title":"The Philosophy of Implementing Custom Operators","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Usually the motivation for implementing custom operators is to enable gradient backpropagation for some performance critical operators. However, not all performance critical operators participate the automatic differentiation. Using terminologies from programming, these computations are \"constant expressions\", which can be evaluated at compilation time (constant folding). Therefore, before we devote ourselves to implementating custom operators, we need to identify which operators need to be implemented as custom operators. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"(Image: forwardbackward)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"This identification task can be done by sketching out the computational graph of your program. Assume your optimization outer loops update x repeatly, then we can track all downstream the operators that depend on this parameter x. We call the dependent operators \"tensor operations\", because they are essentially TensorFlow operators that consume and output tensors. The dependent variables are called \"tensors\". The counterpart of tensors and tensor operations are \"numerical arrays\" and \"numerical operations\", respectively. The names seem a bit vague here but the essence is that numerical operations/arrays do no participate automatic differentiation during the optimization, so the values can be precomputed only once during the entire optimization process. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"In ADCME, we can precompute all numerical quantities of numerical arrays using Julia. No TensorFlow operators or custom operators are needed. This procedure combines the best of the two worlds: the simple syntax and high performance computing environment provided by Julia, and the efficient AD capability provided by TensorFlow. The high performance computing for precomputing cannot be provided by Python, the main scripting language that TensorFlow or PyTorch supports. Readers migh suspect that such precomputing may not be significant in many tasks. Actually, the precomputing constitutes a large portion in scientific computing. For example, researchers assemble matrices, prepare geometries and construct preconditioners in a finite element program. These tasks are by no means trivial and cheap. The consideration for  performance in scientific computing actually forms the major motivation behind adopting Julia for the major language for ADCME. ","category":"page"},{"location":"tu_customop/#Build-Custom-Operators","page":"Advanced: Custom Operators","title":"Build Custom Operators","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"In the following, we present an example of implementing a sparse solver for Au=b as a custom operator.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Input: row vector ii, column vectorjj and value vector vv for the sparse coefficient matrix A; row vector kk and value vector ff for the right hand side b; the coefficient matrix dimension is dtimes d","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Output: solution vector uin mathbbR^d","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Step 1: Create and modify the template file","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The following command helps create the wrapper","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"customop()","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"There will be a custom_op.txt in the current directory. Modify the template file ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"MySparseSolver\nint32 ii(?)\nint32 jj(?)\ndouble vv(?)\nint32 kk(?)\ndouble ff(?)\nint32 d()\ndouble u(?) -> output","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The first line is the name of the operator. It should always be in the camel case. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The 2nd to the 7th lines specify the input arguments, the signature is type+variable name+shape. For the shape, () corresponds to a scalar, (?) to a vector and (?,?) to a matrix. The variable names must be in lower cases. Additionally, the supported types are: int32, int64, float, double, bool and string. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The last line is the output, denoted by -> output (do not forget the whitespace before and after ->).  ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"note: Note\nIf there are non-real type outputs, the corresponding top gradients input to the gradient kernel should be removed. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Step 2: Implement the kernels","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Run customop() again and there will be CMakeLists.txt, gradtest.jl, MySparseSolver.cpp appearing in the current directory. MySparseSolver.cpp is the main wrapper for the codes and gradtest.jl is used for testing the operator and its gradients. CMakeLists.txt is the file for compilation. In the gradient back-propagation (backward below), we want to back-propagate the gradients from the output to the inputs, and the associated rule can be derived using adjoint-state methods. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Create a new file MySparseSolver.h and implement both the forward simulation and backward simulation (gradients)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"#include <eigen3/Eigen/Sparse>\n#include <eigen3/Eigen/SparseLU>\n#include <vector>\n#include <iostream>\nusing namespace std;\ntypedef Eigen::SparseMatrix<double> SpMat; // declares a column-major sparse matrix type of double\ntypedef Eigen::Triplet<double> T;\n\nSpMat A;\n\nvoid forward(double *u, const int *ii, const int *jj, const double *vv, int nv, const int *kk, const double *ff,int nf,  int d){\n    vector<T> triplets;\n    Eigen::VectorXd rhs(d); rhs.setZero();\n    for(int i=0;i<nv;i++){\n      triplets.push_back(T(ii[i]-1,jj[i]-1,vv[i]));\n    }\n    for(int i=0;i<nf;i++){\n      rhs[kk[i]-1] += ff[i];\n    }\n    A.resize(d, d);\n    A.setFromTriplets(triplets.begin(), triplets.end());\n    auto C = Eigen::MatrixXd(A);\n    Eigen::SparseLU<SpMat> solver;\n    solver.analyzePattern(A);\n    solver.factorize(A);\n    auto x = solver.solve(rhs);\n    for(int i=0;i<d;i++) u[i] = x[i];\n}\n\nvoid backward(double *grad_vv, const double *grad_u, const int *ii, const int *jj, const double *u, int nv, int d){\n    Eigen::VectorXd g(d);\n    for(int i=0;i<d;i++) g[i] = grad_u[i];\n    auto B = A.transpose();\n    Eigen::SparseLU<SpMat> solver;\n    solver.analyzePattern(B);\n    solver.factorize(B);\n    auto x = solver.solve(g);\n    // cout << x << endl;\n    for(int i=0;i<nv;i++) grad_vv[i] = 0.0;\n    for(int i=0;i<nv;i++){\n      grad_vv[i] -= x[ii[i]-1]*u[jj[i]-1];\n    }\n}","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"note: Note\nIn this implementation we have used Eigen library for solving sparse matrix. Other choices are also possible, such as algebraic multigrid methods. Note here for convenience we have created a global variable SpMat A;. This is not recommend if you want to run the code concurrently, since the variable A must be overwritten by another concurrent thread. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Step 3: Compile","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"You should always compile your custom operator using the built-in toolchain ADCME.make and ADCME.cmake to ensure compatibility such as ABIs. The built-in toolchain uses exactly the same compiler that has been used to compile your tensorflow shared library. For example, some of the toolchain variables are:","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Variable Description\nADCME.CXX C++ Compiler\nADCME.CC C Compiler\nADCME.TF_LIB_FILE libtensorflow_framework.so location\nADCME.CMAKE Cmake binary location\nADCME.MAKE Make (Ninja for Unix systems) binary location","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"ADCME will properly handle the environment variable for you. So we always recommend you to compile custom operators using ADCME functions:","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"First cd into your custom operator director (where CMakeLists.txt is located), create a directory build if it doesn't exist, cd into build, and do ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"julia> using ADCME\njulia> ADCME.cmake()\njulia> ADCME.make()","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Based on your operation system, you will create libMySparseSolver.{so,dylib,dll}. This will be the dynamic library to link in TensorFlow. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Step 4: Test","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Finally, you could use gradtest.jl to test the operator and its gradients (specify appropriate data in gradtest.jl first). If you implement the gradients correctly, you will be able to obtain first order convergence for finite difference and second order convergence for automatic differentiation. Note you need to modify this file first, e.g., creating data and modifying the function scalar_function. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"(Image: custom_op)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"info: Info\nIf the process fails, it is most probable the GCC compiler is not compatible with which was used to compile libtensorflow_framework.{so,dylib}. ADCME downloads a  GCC compiler via Conda for you. However, if you follow the above steps but encounter some problems, we are happy to resolve the compatibility issue and improve the robustness of ADCME. Submitting an issue is welcome.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Please see this repository for an extra example. ","category":"page"},{"location":"tu_customop/#Build-GPU-Custom-Operators","page":"Advanced: Custom Operators","title":"Build GPU Custom Operators","text":"","category":"section"},{"location":"tu_customop/#Install-GPU-enabled-TensorFlow-(Linux-and-Windows)","page":"Advanced: Custom Operators","title":"Install GPU-enabled TensorFlow (Linux and Windows)","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"To use  CUDA in ADCME, we need to install a GPU-enabled version of TensorFlow. In ADCME, this is achieved by simply rebuilding ADCME with GPU environment variabe. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"using Pkg\nENV[\"GPU\"] = 1\nPkg.build(\"ADCME\")","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"This will install all GPU dependencies.","category":"page"},{"location":"tu_customop/#Building-a-GPU-custom-operator","page":"Advanced: Custom Operators","title":"Building a GPU custom operator","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"We consider a toy example where the custom operator is a function f xrightarrow 2x. To begin with, we create a custom_op.txt via customop","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"GpuTest\ndouble a(?)\ndouble b(?) -> output","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Next, by running customop() again several template files are generated. We can then do the implementation in those files","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"GpuTest.cpp","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/default/logging.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include<cmath>\n\n// Signatures for GPU kernels here \nvoid return_double(int n, double *b, const double*a);\nusing namespace tensorflow;\n\n\nREGISTER_OP(\"GpuTest\")\n\n.Input(\"a : double\")\n.Output(\"b : double\")\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    \n        shape_inference::ShapeHandle a_shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &a_shape));\n\n        c->set_output(0, c->input(0));\n    return Status::OK();\n  });\n\nREGISTER_OP(\"GpuTestGrad\")\n\n.Input(\"grad_b : double\")\n.Input(\"b : double\")\n.Input(\"a : double\")\n.Output(\"grad_a : double\");\n\n\nclass GpuTestOpGPU : public OpKernel {\nprivate:\n  \npublic:\n  explicit GpuTestOpGPU(OpKernelConstruction* context) : OpKernel(context) {\n\n  }\n\n  void Compute(OpKernelContext* context) override {    \n    DCHECK_EQ(1, context->num_inputs());\n    \n    \n    const Tensor& a = context->input(0);\n    \n    \n    const TensorShape& a_shape = a.shape();\n    \n    \n    DCHECK_EQ(a_shape.dims(), 1);\n\n    // extra check\n        \n    // create output shape\n    int n = a_shape.dim_size(0);\n    TensorShape b_shape({n});\n            \n    // create output tensor\n    \n    Tensor* b = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, b_shape, &b));\n    \n    // get the corresponding Eigen tensors for data access\n    \n    auto a_tensor = a.flat<double>().data();\n    auto b_tensor = b->flat<double>().data();   \n\n    // implement your forward function here \n\n    // TODO:\n    return_double(n, b_tensor, a_tensor);\n\n  }\n};\nREGISTER_KERNEL_BUILDER(Name(\"GpuTest\").Device(DEVICE_GPU), GpuTestOpGPU);","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"GpuTest.cu","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"#include \"cuda.h\"\n\n__global__ void return_double_(int n, double *b, const double*a){\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i<n) b[i] = 2*a[i];\n}\n\nvoid return_double(int n, double *b, const double*a){\n    return_double_<<<(n+255)/256, 256>>>(n, b, a);\n}","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"CMakeLists.txt","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"cmake_minimum_required(VERSION 3.5)\nproject(TF_CUSTOM_OP)\nset (CMAKE_CXX_STANDARD 11)\n\nmessage(\"JULIA=${JULIA}\")\nexecute_process(COMMAND ${JULIA} -e \"import ADCME; print(ADCME.__STR__)\" OUTPUT_VARIABLE JL_OUT)\n\n\n\nlist(GET JL_OUT 0 BINDIR)\nlist(GET JL_OUT 1 LIBDIR)\nlist(GET JL_OUT 2 TF_INC)\nlist(GET JL_OUT 3 TF_ABI)\nlist(GET JL_OUT 4 PREFIXDIR)\nlist(GET JL_OUT 5 CC)\nlist(GET JL_OUT 6 CXX)\nlist(GET JL_OUT 7 CMAKE)\nlist(GET JL_OUT 8 MAKE)\nlist(GET JL_OUT 9 GIT)\nlist(GET JL_OUT 10 PYTHON)\nlist(GET JL_OUT 11 TF_LIB_FILE)\nlist(GET JL_OUT 12 LIBCUDA)\nlist(GET JL_OUT 13 CUDA_INC)\n\nmessage(\"Python path=${PYTHON}\")\nmessage(\"PREFIXDIR=${PREFIXDIR}\")\nmessage(\"TF_INC=${TF_INC}\")\nmessage(\"TF_ABI=${TF_ABI}\")\nmessage(\"TF_LIB_FILE=${TF_LIB_FILE}\")\n\n\nif (CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 5.0 OR CMAKE_CXX_COMPILER_VERSION VERSION_EQUAL 5.0)\n  set(CMAKE_CXX_FLAGS \"-D_GLIBCXX_USE_CXX11_ABI=${TF_ABI} ${CMAKE_CXX_FLAGS}\")\nendif()\n\nset(CMAKE_BUILD_TYPE Release)\nif(MSVC)\nset(CMAKE_CXX_FLAGS_RELEASE \"-DNDEBUG\")\nelse()\nset(CMAKE_CXX_FLAGS_RELEASE \"-O3 -DNDEBUG\")\nendif()\ninclude_directories(${TF_INC} ${PREFIXDIR} ${CUDA_INC})\n\n\nfind_package(CUDA QUIET REQUIRED)\nset(CMAKE_CXX_FLAGS \"-std=c++11 ${CMAKE_CXX_FLAGS}\")\nset(CMAKE_CXX_FLAGS \"-O3 ${CMAKE_CXX_FLAGS}\")\nset(CMAKE_CXX_FLAGS \"-shared ${CMAKE_CXX_FLAGS}\")\nset(CMAKE_CXX_FLAGS \"-fPIC ${CMAKE_CXX_FLAGS}\")\nset(CUDA_NVCC_FLAGS ${CUDA_NVCC_FLAGS};--expt-relaxed-constexpr)\nSET(CUDA_PROPAGATE_HOST_FLAGS ON)\n\nadd_definitions(-DGOOGLE_CUDA)\nmessage(\"Compiling GPU-compatible custom operator!\")\ncuda_add_library(GpuTest SHARED GpuTest.cpp GpuTest.cu)\n\n\nset_property(TARGET GpuTest PROPERTY POSITION_INDEPENDENT_CODE ON)\ntarget_link_libraries(GpuTest ${TF_LIB_FILE})\nfile(MAKE_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/build)\nset_target_properties(GpuTest PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/build RUNTIME_OUTPUT_DIRECTORY_RELEASE ${CMAKE_CURRENT_SOURCE_DIR}/build)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"We can then compile the operator on a system where nvcc is available:","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"change_directory(\"build\")\nADCME.cmake()\nADCME.make()","category":"page"},{"location":"tu_customop/#Running-a-GPU-custom-operator","page":"Advanced: Custom Operators","title":"Running a GPU custom operator","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"We can now run a GPU operator by loading the shared library","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"using ADCME\n\nfunction gpu_test(a)\n    gpu_test_ = load_op_and_grad(\"$(@__DIR__)/build/libGpuTest\",\"gpu_test\")\n    a = convert_to_tensor([a], [Float64]); a = a[1]\n    gpu_test_(a)\nend\n\n# TODO: specify your input parameters\na = [1.0;3.0;-1.0]\nu = gpu_test(a)\nsess = Session(); init(sess)\nrun(sess, u)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"If we run the file on a system without GPU resources, we will get the following error ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":" <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"If we have GPU resources, the kernel will run correctly with the output","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"2.0\n6.0\n-2.0","category":"page"},{"location":"tu_customop/#Batch-Build","page":"Advanced: Custom Operators","title":"Batch Build","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"At some point, you might have a lot of custom operators. Building one-by-one will take up too much time. To reduce the building time, you might want to build all the operators all at once concurrently. To this end, you can consider batch build by using a common CMakeLists.txt. The commands in the CMakeLists.txt are the same as a typical custom operator, except that the designated libraries are different","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"# ... The same as a typical CMake script ...\n\n# Specify all the library paths and library names. \nset(LIBDIR_NAME VolumetricStrain ComputeVel DirichletBd\n    FemStiffness FemStiffness1 SpatialFemStiffness\n    SpatialVaryingTangentElastic Strain Strain1\n    StrainEnergy StrainEnergy1)\nset(LIB_NAME VolumetricStrain ComputeVel DirichletBd\n    FemStiffness UnivariateFemStiffness SpatialFemStiffness\n    SpatialVaryingTangentElastic StrainOp StrainOpUnivariate\n    StrainEnergy StrainEnergyUnivariate)\n\n# Copy and paste the following lines (no modification is required)\nlist(LENGTH \"LIBDIR_NAME\" LIBLENGTH)\nmessage(\"Total number of libraries to make: ${LIBLENGTH}\")\nMATH(EXPR LIBLENGTH \"${LIBLENGTH}-1\")\nforeach(IDX RANGE 0 ${LIBLENGTH})\n  list(GET LIBDIR_NAME ${IDX} _LIB_DIR)\n  list(GET LIB_NAME ${IDX} _LIB_NAME)\n  message(\"Compiling ${IDX}th library: ${_LIB_DIR}==>${_LIB_NAME}\")\n  file(MAKE_DIRECTORY ${_LIB_DIR}/build)\n  add_library(${_LIB_NAME} SHARED ${_LIB_DIR}/${_LIB_NAME}.cpp)\n  set_property(TARGET ${_LIB_NAME} PROPERTY POSITION_INDEPENDENT_CODE ON)\n  set_target_properties(${_LIB_NAME} PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/${_LIB_DIR}/build)\n  target_link_libraries(${_LIB_NAME} ${TF_LIB_FILE})\nendforeach(IDX)","category":"page"},{"location":"tu_customop/#Loading-Order","page":"Advanced: Custom Operators","title":"Loading Order","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"To ensure that TensorFlow can find all the registered symbols, it is recommended that you should always load the shared libraries first if you also run ccall on the shared library. This can be done using load_library to obtain a handle to the shared library. Then you can use the handle in load_op_and_grad or load_op. For example","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"lib = load_library(\"path/to/my/library\")\nmy_custom_op = load_op_and_grad(lib, \"my_custom_op\")","category":"page"},{"location":"tu_customop/#Error-Handling","page":"Advanced: Custom Operators","title":"Error Handling","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Sometimes we might encounter error in C++ kernels and we want to propagate the error to the Julia interface. This is done by OP_REQUIRES_OK. Its syntax is","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"OP_REQUIRES_OK(context, status)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"where context is either a OpKernelConstruction or a OpKernelContext, and status can be created using ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Status(error::Code::ERROR_CODE, message)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Here ERROR_CODE is one of the following:","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"OK = 0,\nCANCELLED = 1,\nUNKNOWN = 2,\nINVALID_ARGUMENT = 3,\nDEADLINE_EXCEEDED = 4,\nNOT_FOUND = 5,\nALREADY_EXISTS = 6,\nPERMISSION_DENIED = 7,\nUNAUTHENTICATED = 16,\nRESOURCE_EXHAUSTED = 8,\nFAILED_PRECONDITION = 9,\nABORTED = 10,\nOUT_OF_RANGE = 11,\nUNIMPLEMENTED = 12,\nINTERNAL = 13,\nUNAVAILABLE = 14,\nDATA_LOSS = 15,\nDO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_ = 20,\nCode_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<::PROTOBUF_NAMESPACE_ID::int32>::min(),\nCode_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<::PROTOBUF_NAMESPACE_ID::int32>::max()","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"message is a string. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"For example, ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"OP_REQUIRES_OK(context, \n        Status(error::Code::UNAVAILABLE, \"Sparse solver type not supported.\"));","category":"page"},{"location":"tu_customop/#Logging","page":"Advanced: Custom Operators","title":"Logging","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"TensorFlow has a C++ level logging system. We can conveniently log messages to specific streams using the folloing syntax","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"VLOG(INFO) << message;\nVLOG(WARNING) << message;\nVLOG(ERROR) << message;\nVLOG(FATAL) << message;\nVLOG(NUM_SEVERITIES) << message;","category":"page"},{"location":"tu_customop/#Windows:-Load-Shared-Library","page":"Advanced: Custom Operators","title":"Windows: Load Shared Library","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Sometimes you might encounter NotFoundError() when using tf.load_op_library on Windows system, despite that the library you referred does exist. You can then check using Libdl","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"using Libdl\ndlopen(<MySharedLibrary.dll>)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"and you still get an error","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"ERROR: could not load library \"MySharedLibrary.dll\"\nThe specified module could not be found. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"This is annoying. The reason is that when you load this shared library on windows, the system looks for all its dependencies. If at least one of the dependent library is not in the path, then the error occurs. To solve this problem, you need a dependency walker, such as die.exe. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"For example, in the following right panel we see a lot of dynamic libraries. They must be in the system path so that we can load the current dynamic library (dlopen(...)). ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Main Window Import Window\n(Image: ) (Image: )","category":"page"},{"location":"tu_customop/#Miscellany","page":"Advanced: Custom Operators","title":"Miscellany","text":"","category":"section"},{"location":"tu_customop/#Mutable-Inputs","page":"Advanced: Custom Operators","title":"Mutable Inputs","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Sometimes we want to modify tensors in place. In this case we can use mutable inputs. Mutable inputs must be Variable and it must be forwarded to one of the output. We consider implement a my_assign operator, with signature","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"my_assign(u::PyObject, v::PyObject)::PyObject","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Here u is a Variable and we copy the data from v to u. In the MyAssign.cpp file, we modify the input and output specifications to ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":".Input(\"u : Ref(double)\")\n.Input(\"v : double\")\n.Output(\"w : Ref(double)\")","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"In addition, the input tensor is obtained through","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Tensor u = context->mutable_input(0, true);","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The second argument lock_held specifies whether the input mutex is acquired (false) before the operation. Note the output must be a Tensor instead of a reference. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"To forward the input, use","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"context->forward_ref_input_to_ref_output(0,0);","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"We use the following code snippet to test the program","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"my_assign = load_op(\"./build/libMyAssign\",\"my_assign\")\nu = Variable([0.1,0.2,0.3])\nv = constant(Array{Float64}(1:3))\nu2 = u^2\nw = my_assign(u,v)\nsess = tf.Session()\ninit(sess)\n@show run(sess, u)\n@show run(sess, u2)\n@show run(sess, w)\n@show run(sess, u2)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"The output is ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"[0.1,0.2,0.3]\n[0.1,0.04,0.09]\n[1.0,2.0,3.0]\n[1.0,4.0,9.0]","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"We can see that the tensors depending on u are also aware of the assign operator. The complete programs can be downloaded here: CMakeLists.txt, MyAssign.cpp, gradtest.jl.","category":"page"},{"location":"tu_customop/#Third-party-Plugins","page":"Advanced: Custom Operators","title":"Third-party Plugins","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"ADCME also allows third-party custom operators hosted on Github. To build your own custom operators, implement your own custom operators in a Github repository. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Users are free to arrange other source files or other third-party libraries. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Upon using those libraries in ADCME, users first download those libraries to deps directory via","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"pth = install(\"OTNetwork\")","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"pth is the dynamic library product generated with source codes in OTNetwork. The official plugins are hosted on https://github.com/ADCMEMarket. To get access to the custom operators in ADCME, use","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"op = load_op_and_grad(pth, \"ot_network\"; multiple=true)","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"https://on-demand.gputechconf.com/ai-conference-2019/T1-3Minseok%20LeeAdding%20custom%20CUDA%20C++%20Operations%20in%20Tensorflow%20for%20boosting%20BERT%20Inference.pdf)","category":"page"},{"location":"tu_customop/#Troubleshooting","page":"Advanced: Custom Operators","title":"Troubleshooting","text":"","category":"section"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Here are some common errors you might encounter during custom operator compilation:","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Q: The cmake output for the Julia path is empty.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Julia=","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"A: Check whether which julia outputs the Julia location you are using. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Q: The cmake output for Python path, Eigen path, etc., is empty.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Python path=\nPREFIXDIR=\nTF_INC=\nTF_ABI=\nTF_LIB_FILE=","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"A: Update ADCME to the latest version and check whether or not the ADCME compiler string is empty","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"using ADCME\nADCME.__STR__","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Q: Julia package precompilation errors that seem not linked to ADCME.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"A: Remove the corresponding packages using using Pkg; Pkg.rm(XXX) and reinstall those packages. ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Q: Precompilation error linked to ADCME","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"ERROR: LoadError: ADCME is not properly built; run `Pkg.build(\"ADCME\")` to fix the problem.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"A: Build ADCME using Pkg.build(\"ADCME\"). Exit Julia and open Julia again. Check whether deps.jl exists in the deps directory of your Julia package (optional).","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"Q: On Mac, the PyPlot package gives the warning: PyPlot is using tkagg backend, which is known to cause crashes on MacOS (#410); use the MPLBACKEND environment variable to request a different backend.","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"A: ","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"using ADCME\nusing Pkg\nCONDA = get_conda()\nrun(`$CONDA install -y pyqt`)\nPkg.build(\"PyPlot\")","category":"page"},{"location":"tu_customop/","page":"Advanced: Custom Operators","title":"Advanced: Custom Operators","text":"This will install a working backend for PyPlot. ","category":"page"},{"location":"apps_levy/#Calibrating-Multivariate-Lévy-Processes-with-Neural-Networks","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"","category":"section"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Kailai Xu and Eric Darve. \"Calibrating Multivariate Lévy Processes with Neural Networks\" ","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Project Website","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Calibrating a Lévy process usually requires characterizing its jump distribution. Traditionally this problem can be solved with nonparametric estimation using the empirical characteristic functions (ECF), assuming certain regularity, and results to date are mostly in 1D. For multivariate Lévy processes and less smooth Lévy densities, the problem becomes challenging as ECFs decay slowly and have large uncertainty because of limited observations. We solve this problem by approximating the Lévy density with a parametrized functional form; the characteristic function is then estimated using numerical integration. In our benchmarks, we used deep neural networks and found that they are robust and can capture sharp transitions in the Lévy density. They perform favorably compared to piecewise linear functions and radial basis functions. The methods and techniques developed here apply to many other problems that involve nonparametric estimation of functions embedded in a system model.","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"The Lévy process can be described by the Lévy-Khintchine formula","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"phi(xi) = mathbbEe^mathrmi langle xi mathbfX_t rangle =explefttleft( mathrmi langle mathbfb xi rangle - frac12langle xi mathbfAxirangle  +int_mathbbR^d left( e^mathrmi langle xi mathbfxrangle - 1 - mathrmi langle xi mathbfxrangle mathbf1_mathbfxleq 1right)nu(dmathbfx)right) right","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Here the multivariate Lévy process is described by three parameters: a positive semi-definite matrix mathbfA = SigmaSigma^T in mathbbR^dtimes d, where Sigmain mathbbR^dtimes d; a vector mathbfbin mathbbR^d; and a measure nuin mathbbR^dbackslashmathbf0. ","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Given a sample path mathbfX_iDelta t, i=123ldots, we focus on estimating mathbfb, mathbfA and nu. In this work, we focus on the functional inverse problem–estimate nu–and assume mathbfb=0mathbfA=0. The idea is","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"The Lévy density is approximated by a parametric functional form–-such as piecewise linear functions–-with parameters theta,","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"    nu(mathbfx) approx nu_theta(mathbfx)","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"The characteristic function is approximated by numerical integration ","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"phi(xi)approx    phi_theta(xi) = expleft Delta t sum_i=1^n_q left(e^mathrmi langlexi mathbfx_i rangle-1-mathrmilanglexi mathbfx_i ranglemathbf1_mathbfx_ileq 1  right)nu_theta(mathbfx_i) w_i right","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"where (mathbfx_i w_i)_i=1^n_q are quadrature nodes and weights.","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"The empirical characteristic functions are computed given observations mathbfX_iDelta t_i=0^n","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"hatphi_n(xi) = frac1nsum_i=1^n exp(mathrmilangle xi mathbfX_iDelta t-mathbfX_(i-1)Delta trangle )  xi in mathbbR^d","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"Solve the following optimization problem with a gradient based method. Here xi_i _i=1^m are collocation points depending on the data. ","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"min_thetafrac1m sum_i=1^m hatphi_n(xi_i)-phi_theta(xi_i)  ^2","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"We show the schematic description of the method and some results on calibrating a discontinuous Lévy density function nu. ","category":"page"},{"location":"apps_levy/","page":"Calibrating Multivariate Lévy Processes with Neural Networks","title":"Calibrating Multivariate Lévy Processes with Neural Networks","text":"(Image: image-20191031200808697)","category":"page"},{"location":"optimizers/#Optimizers","page":"Optimizers","title":"Optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"ADCME provides a rich class of optimizers and acceleration techniques for conducting inverse modeling. The programming model also allows for easily extending ADCME with customer optimizers. In this section, we show how to take advantage of the built-in optimization library by showing how to solve an inverse problem–estimating the diffusivity coefficient of a Poisson equation from sparse observations–using different kinds of optimization techniques.    ","category":"page"},{"location":"optimizers/#Solving-an-Inverse-Problem-using-L-BFGS-optimizer","page":"Optimizers","title":"Solving an Inverse Problem using L-BFGS optimizer","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Consider the Poisson equation in 2D:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"beginaligned\nnabla  cdot (kappa (xy)nabla u(xy)) = f(x)  (xy) in Omega \nu(xy) =0  (xy)in partial Omega\nendalignedtag1","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Here Omega is a L-shaped domain, which can be loaded using meshread. ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"f(xy) = -sinleft(20pi y+fracpi8right)","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"and the diffusivity coefficient kappa(xy) is given by ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"kappa(xy) = 2+e^10x - (10y)^2","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We can solve Equation 1 using a standard finite element method. Here, we use AdFem.jl to solve the PDE.","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"using AdFem\nusing ADCME\nusing PyPlot \n\nfunction kappa(x, y)\n    return 2 + exp(10x) - (10y)^2\nend\n\nfunction f(x, y)\n    return sin(2π*10y+π/8)\nend\n\nmmesh = Mesh(joinpath(PDATA, \"twoholes_large.stl\"))\n\nKappa = eval_f_on_gauss_pts(kappa, mmesh)\nF = eval_f_on_gauss_pts(f, mmesh)\nL = compute_fem_laplace_matrix1(Kappa, mmesh)\nRHS = compute_fem_source_term1(F, mmesh)\n\nbd = bcnode(mmesh)\nL, RHS = impose_Dirichlet_boundary_conditions(L, RHS, bd, zeros(length(bd)))\n\nSOL = L\\RHS \nclose(\"all\")\nfigure(figsize = (10, 4))\nsubplot(121)\nvisualize_scalar_on_gauss_points(Kappa, mmesh)\ntitle(\"\\$\\\\kappa\\$\")\nsubplot(122)\nvisualize_scalar_on_fem_points(SOL, mmesh)\ntitle(\"Solution\")\nsavefig(\"optimizers_poisson.png\")","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"(Image: )","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Now we approximate kappa(xy) using a deep neural network (fc in ADCME). The script is nearly the same as the forward computation","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"using AdFem\nusing ADCME\nusing PyPlot \n\nfunction f(x, y)\n    return sin(2π*10y+π/8)\nend\n\nmmesh = Mesh(joinpath(PDATA, \"twoholes_large.stl\"))\n\nxy = gauss_nodes(mmesh)\nKappa = squeeze(fc(xy, [20, 20, 20, 1])) + 1.0\nF = eval_f_on_gauss_pts(f, mmesh)\nL = compute_fem_laplace_matrix1(Kappa, mmesh)\nRHS = compute_fem_source_term1(F, mmesh)\n\nbd = bcnode(mmesh)\nL, RHS = impose_Dirichlet_boundary_conditions(L, RHS, bd, zeros(length(bd)))\n\nsol = L\\RHS ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We want to find a deep neural network such that sol and SOL match. We can train the neural network by minimizing a loss function. ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"loss = sum((sol - SOL)^2)*1e10","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Here we multiply the loss function by 1e10 because the scale of SOL is 10^-5. We want the initial value of loss to have a scale of O(1). ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We can minimize the loss function by ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"sess = Session(); init(sess)\nlosses = BFGS!(sess, loss)","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We can visualize the result:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"figure(figsize = (10, 4))\nsubplot(121)\nsemilogy(losses)\nxlabel(\"Iterations\"); ylabel(\"Loss\")\nsubplot(122)\nvisualize_scalar_on_gauss_points(run(sess, Kappa), mmesh)\nsavefig(\"optimizer_bfgs.png\")","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"(Image: )","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We see that the estimated kappa(xy) is quite similar to the reference one. ","category":"page"},{"location":"optimizers/#Use-the-optimizer-from-Optim.jl","page":"Optimizers","title":"Use the optimizer from Optim.jl","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"We have used the built-in optimizer L-BFGS. What if we want to try out other options? Optimize! is an API that allows you to try out custom optimizers. For convenience, it also supports optimizers from the Optim.jl package. ","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Let's consider using BFGS to solve the above problem:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"import Optim\nsess = Session(); init(sess)\nlosses = Optimize!(sess, loss, optimizer = Optim.BFGS())\n\nfigure(figsize = (10, 4))\nsubplot(121)\nsemilogy(losses)\nxlabel(\"Iterations\"); ylabel(\"Loss\")\nsubplot(122)\nvisualize_scalar_on_gauss_points(run(sess, Kappa), mmesh)\nsavefig(\"optimizer_bfgs2.png\")","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"(Image: )","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Unfortunately, it got stuck after several iterations. ","category":"page"},{"location":"optimizers/#Build-Your-Own-Optimizer","page":"Optimizers","title":"Build Your Own Optimizer","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Sometimes we might want to build our own optimizer. This can be done using Optimize!. To this end, we want to supply the function with the following arguments:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"sess: Session \nloss: Loss function to minimize \noptimizer: a keyword argument that specifies the optimizer function. The function takes f, fprime, and f_fprime (outputs both loss and gradients), initial value x0 as input. The output is redirected to the output of Optimize!.","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Let us consider minimizing the Rosenbrock function using an optimizer from Ipopt","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"import Ipopt\nx = Variable(rand(2))\nloss = (1-x[1])^2 + 100(x[2]-x[1]^2)^2\n\nfunction opt(f, g, fg, x0)\n    prob = createProblem(2, -100ones(2), 100ones(2), 0, Float64[], Float64[], 0, 0,\n                     f, (x,g)->nothing, (x,G)->g(G, x), (x, mode, rows, cols, values)->nothing, nothing)\n    prob.x = x0 \n    Ipopt.addOption(prob, \"hessian_approximation\", \"limited-memory\")\n    status = Ipopt.solveProblem(prob)\n    println(Ipopt.ApplicationReturnStatus[status])\n    println(prob.x)\n    Ipopt.freeProblem(prob)\n    nothing\nend\n\nsess = Session(); init(sess)\nOptimize!(sess, loss, optimizer = opt)","category":"page"},{"location":"mpi_benchmark/#MPI-Benchmarks","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The purpose of this section is to present the distributed computing capability of ADCME via MPI. With the MPI operators, ADCME is well suited to parallel implementations on clusters with very large numbers of cores. We benchmark individual operators as well as the gradient calculation as a whole. Particularly, we use two metrics for measuring the scaling of the implementation:","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"weak scaling, i.e., how the solution time varies with the number of processors for a fixed problem size per processor. \nstrong scaling, i.e., the speedup for a fixed problem size with respect to the number of processors, and is governed by Amdahl's law.","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"For most operators, ADCME is just a wrapper of existing third-party parallel computing software (e.g., Hypre). However, for gradient back-propagation, some functions may be missing and are implemented at our own discretion. For example, in Hypre, distributed sparse matrices split into multiple stripes, where each MPI rank owns a stripe with continuous row indices. In gradient back-propagation, the transpose of the original matrix is usually needed and such functionalities are missing in Hypre as of September 2020. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The MPI programs are verified with serial programs. Note that ADCME uses hybrid parallel computing models, i.e., a mixture of multithreading programs and MPI communication; therefore, one MPI processor may be allocated multiple cores. ","category":"page"},{"location":"mpi_benchmark/#Transposition","page":"MPI Benchmarks","title":"Transposition","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Matrix transposition is an operator that are common in gradient back-propagation. For example, assume the forward computation is (x is the input, y is the output, and A is a matrix) ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"y(theta) = Ax(theta) tag1","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Given a loss function L(y), we have","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"fracpartial L(y(x))partial x = fracpartial L(y)partial yfracpartial y(x)partial x = fracpartial L(y)partial y A","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Note that fracpartial L(y)partial y is a row vector, and therefore, ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"left(fracpartial L(y(x))partial xright)^T = A^T left(fracpartial L(y)partial y right)^T","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"requires a matrix vector multiplication, where the matrix is A^T. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Given that Equation 1 is ubiquitous in numerical PDE schemes, a distributed implementation of parallel transposition is very important. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"ADCME uses the same distributed sparse matrix representation as Hypre. In Hypre, each MPI processor own a set of rows of the whole sparse matrix. The rows have continuous indices. To transpose the sparse matrix in a parallel environment, we first split the matrices in each MPI processor into blocks and then use MPI_Isend/MPI_Irecv to exchange data. Finally, we transpose the matrices in place for each block. Using this method, we obtained a CSR representation of the transposed matrix. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The following results shows the scalability of the transposition operator of mpi_SparseTensor. In the plots, we show the strong scaling for a fixed matrix size of 25textM times 25textM as well as the weak scaling, where each MPI processor owns 300^2=90000 rows. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Strong Scaling Weak Scaling\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/#Poisson's-Equation","page":"MPI Benchmarks","title":"Poisson's Equation","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"This example presents the overhead of ADCME MPI operators when the main computation is carried out through a third-party library (Hypre). We solve the Poisson's equation ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"nabla cdot (kappa(x y) nabla u(xy)) = f(x y) (xy) in Omega quad u(xy) = 0 (xy) in partial Omega","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Here kappa(x y) is approximated by a neural network kappa_theta(xy) = mathcalNN_theta(xy), and the weights and biases theta are broadcasted from the root processor. We express the numerical scheme as a computational graph is:","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: ) ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The domain decomposition is as follows:","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: ) ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The domain 01^2 is divided into Ntimes N blocks, and each block contains ntimes n degrees of freedom. The domain is padded with boundary nodes, which are eliminated from the discretized equation. The grid size is ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"h = frac1Nn+1","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We use a finite difference method for discretizing the Poisson's equation, which has the following form","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"beginaligned(kappa_i+1 j+kappa_ij)u_i+1j + (kappa_i-1 j+kappa_ij)u_i-1j  \n+ (kappa_ij+1+kappa_ij)u_ij+1 + (kappa_i j-1+kappa_ij)u_ij-1  \n-(kappa_i+1 j+kappa_i-1 j+kappa_ij+1+kappa_i j-1+4kappa_ij)u_ij  \n= 2h^2f_ij\nendaligned","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We show the strong scaling with a fixed problem size 1800 times 1800 (mesh size, which implies the matrix size is around 32 million). We also show the weak scaling where each MPI processor owns a 300times 300 block. For example, a problem with 3600 processors has the problem size 90000times 3600 approx 03 billion.","category":"page"},{"location":"mpi_benchmark/#Weak-Scaling","page":"MPI Benchmarks","title":"Weak Scaling","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We first consider the weak scaling. The following plots shows the runtime for forward computation as well as gradient back-propagation. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Speedup Efficiency\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"There are several important observations:","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"By using more cores per processor, the runtime is reduced significantly. For example, the runtime for the backward is reduced to around 10 seconds from 30 seconds by switching from 1 core to 4 cores per processor. \nThe runtime for the backward is typically less than twice the forward computation. Although the backward requires solve two linear systems (one of them is in the forward computation), the AMG linear solver in the back-propagation may converge faster, and therefore costs less than the forward. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Additionally, we show the overhead, which is defined as the difference between total runtime and Hypre linear solver time, of both the forward and backward calculation. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"1 Core 4 Cores\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We see that the overhead is quite small compared to the total time, especially when the problem size is large. This indicates that the ADCME MPI implementation is very effective. ","category":"page"},{"location":"mpi_benchmark/#Strong-Scaling","page":"MPI Benchmarks","title":"Strong Scaling","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Now we consider the strong scaling. In this case, we fixed the whole problem size and split the mesh onto different MPI processors. The following plots show the runtime for the forward computation and the gradient back-propagation","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Forward Bckward\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The following plots show the speedup and efficiency ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"1 Core 4 Cores\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We can see that the 4 cores have smaller runtime compared to 1 core. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Interested readers can go to here for implementations. To compile the codes, make sure that MPI and Hypre is available (see install_openmpi and install_hypre) and run the following script:","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"using ADCME \nchange_directory(\"ccode/build\")\nADCME.cmake()\nADCME.make()","category":"page"},{"location":"mpi_benchmark/#Acoustic-Seismic-Inversion","page":"MPI Benchmarks","title":"Acoustic Seismic Inversion","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"In this example, we consider the acoustic wave equation with perfectly matched layer (PML). The governing equation for the acoustic equation is","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"fracpartial^2 upartial t^2 = nabla cdot (c^2 nabla u)","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"where u is the displacement, f is the source term, and c is the spatially varying acoustic velocity. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"In the inverse problem, only the wavefield u on the surface is observable, and we want to use this information to estimate c. The problem is usually ill-posed, so regularization techniques are usually used to constrain c. One approach is to represent c by a deep neural network","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"c(xy) = mathcalNN_theta(xy)","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"where theta is the neural network weights and biases. The loss function is formulated by the square loss for the wavefield on the surface. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Model c Wavefield\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"To implement an MPI version of the acoustic wave equation propagator, we use mpi_halo_exchange, which is implemented using MPI and performs the halo exchange mentioned in the last example for both wavefields and axilliary fields. This function communicates the boundary information for each block of the mesh. The following plot shows the computational graph for the numerical simulation of the acoustic wave equation","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The following plot shows the strong scaling and weak scaling of our implementation. Each processor consists of 32 processors, which are used at the discretion of ADCME's backend, i.e., TensorFlow. The strong scaling result is obtained by using a 1000times 1000 grid and 100 times steps. For the weak scaling result, each MPI processor owns a 100times 100 grid, and the total number of steps is 2000. It is remarkable that even though we increase the number of processors from 1 to 100, the total time only increases 2 times in the weak scaling. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Strong Scaling Weak Scaling\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We also show the speedup and efficiency for the strong scaling case. We can achieve more than 20 times acceleration by using 100 processors (3200 cores in total) and the trend is not slowing down at this scale. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: ) ","category":"page"},{"location":"mpi_benchmark/#Elastic-Seismic-Inversion","page":"MPI Benchmarks","title":"Elastic Seismic Inversion","text":"","category":"section"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"In the last example, we consider the elastic wave equation","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"beginaligned\nrho fracpartial v_ipartial t = sigma_ijj + rho f_i  \nfracpartial sigma_ijpartial t = lambda v_k k + mu (v_ij+v_ji)\nendalignedtag2","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"where v is the velocity, sigma is the stress tensor, rho is the density, and lambda and mu are the Lamé constants. Similar to the acoustic equation, we use the PML boundary conditions and have observations on the surface. However, the inversion parameters are now spatially varying rho, lambda and mu. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"(Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"As an example, we approximate lambda by a deep neural network","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"lambda(xy) = mathcalNN_theta(xy)","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"and the other two parameters are kept fixed. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"We use the same geometry settings as the acoustic wave equation case. Note that elastic wave equation has more state variables as well as auxilliary fields, and thus is more memory demanding. The huge memory cost calls for a  distributed framework, especially for large-scale problems. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Additionally, we use fourth-order finite difference scheme for discretizing Equation 2. This scheme requires us to exchange two layers on the boundaries for each block in the mesh. This data communication is implemented using MPI, i.e., mpi_halo_exchange2.","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The following plots show the strong and weak scaling. Again, we see that the weak scaling of the implementation is quite effective because the runtime increases mildly even if we increase the number of processors from 1 to 100. ","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"Strong Scaling Weak Scaling\n(Image: ) (Image: )","category":"page"},{"location":"mpi_benchmark/","page":"MPI Benchmarks","title":"MPI Benchmarks","text":"The following plots show the speedup and efficiency for the strong scaling. We can achieve more than 20 times speedup when using 100 processors. (Image: ) ","category":"page"},{"location":"tu_recipe/#Inverse-Modeling-Recipe","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Here is a tip for inverse modeling using ADCME. ","category":"page"},{"location":"tu_recipe/#Forward-Modeling","page":"Inverse Modeling Recipe","title":"Forward Modeling","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"The first step is to implement your forward computation in ADCME. Let's consider a simple example. Assume that we want to compute a transformation from x_1x_2 ldots x_n to f_theta(x_1) f_theta(x_2) ldots f_theta(x_n), where ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"f_theta(x) = a_2sigma(a_1x+b_1)+b_2quad theta=(a_1b_2a_2b_2)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"The value theta=(1234). We can code the forward computation as follows","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nθ = constant([1.;2.;3.;4.])\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]\n\nsess = Session(); init(sess)\nf0 = run(sess, f)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"We obtained","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"10-element Array{Float64,1}:\n 6.6423912339336475\n 6.675935315969742\n 6.706682200447601\n 6.734800968378825\n 6.7604627001561575\n 6.783837569144308\n 6.805092492614008\n 6.824389291376896\n 6.841883301751329\n 6.8577223804673","category":"page"},{"location":"tu_recipe/#Inverse-Modeling","page":"Inverse Modeling Recipe","title":"Inverse Modeling","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Assume that we want to estimate the target variable theta from observations f_theta(x_1) f_theta(x_2) ldots f_theta(x_n). The inverse modeling is split into 6 steps. Follow the steps one by one","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Step 1: Mark the target variable as placeholder. That is, we replace θ = constant([1.;2.;3.;4.]) by θ = placeholder([1.;2.;3.;4.]).\nStep 2: Check that the loss is zero given true values. The loss function is usually formulated so that it equals zero when we plug the true value to the target variable. \nYou should expect 0.0 using the following codes. ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nθ = placeholder([1.;2.;3.;4.])\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]\nloss = sum((f - f0)^2)\nsess = Session(); init(sess)\n@show run(sess, loss)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Step 3: Use lineview to visualize the landscape. Assume the initial guess is theta_0, we can use the lineview function from ADCMEKit.jl package to visualize the landscape from theta_0=0000 to theta^* (true value). This gives us  early confidence  on the correctness of the implementation as well as the difficulty of the optimization problem. You can also use meshview, which shows a 2D landscape but is more expensive to evaluate. ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nusing ADCMEKit\nθ = placeholder([1.;2.;3.;4.])\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]\nloss = sum((f - f0)^2)\nsess = Session(); init(sess)\n@show run(sess, loss)\nlineview(sess, θ, loss, [1.;2.;3.;4.], zeros(4)) # or meshview(sess, θ, loss, [1.;2.;3.;4.])","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"(Image: image-20200227233902747)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"The landscape is very nice (convex and smooth)! That means the optimization should be very easy. ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Step 4: Use gradview to check the gradients. ADCMEKit.jl also provides gradview which visualizes the gradients at arbitrary points. This helps us to check whether the gradient is implemented correctly. ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nusing ADCMEKit\nθ = placeholder([1.;2.;3.;4.])\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]\nloss = sum((f - f0)^2)\nsess = Session(); init(sess)\n@show run(sess, loss)\nlineview(sess, θ, loss, [1.;2.;3.;4.], zeros(4)) # or meshview(sess, θ, loss, [1.;2.;3.;4.])\ngradview(sess, θ, loss, zeros(4))","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"​\t\tYou should get something like this:","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"(Image: )","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Step 5: Change placeholder to Variable and perform optimization! We use L-BFGS-B optimizer to solve the minimization problem. A useful trick is to multiply the loss function by a large scalar so that the optimizer does not stop early (or reduce the tolerance). ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nusing ADCMEKit\nθ = Variable(zeros(4))\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2])+θ[4]\nloss = 1e10*sum((f - f0)^2)\nsess = Session(); init(sess)\nBFGS!(sess, loss)\nrun(sess, θ)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"You should get ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"4-element Array{Float64,1}:\n 1.0000000000008975\n 2.0000000000028235\n 3.0000000000056493\n 3.999999999994123","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"That's exact what we want. ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Step 6: Last but not least, repeat step 3 and step 4 if you get stuck in a local minimum. Scrutinizing the landscape at the local minimum will give you useful information so you can make educated next step!","category":"page"},{"location":"tu_recipe/#Debugging","page":"Inverse Modeling Recipe","title":"Debugging","text":"","category":"section"},{"location":"tu_recipe/#Sensitivity-Analysis","page":"Inverse Modeling Recipe","title":"Sensitivity Analysis","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"When the gradient test fails, we can perform unit sensitivity analysis. The idea is that given a function y = f(x_1 x_2 ldots x_n), if we want to confirm that the gradients fracpartial fpartial x_i is correctly implemented, we can perform 1D gradient test with respect to a small perturbation varepsilon_i: ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"y(varepsilon_i) = f(x_1 x_2 ldots x_i + varepsilon_i ldots x_n)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"or in the case you are not sure about the scale of x_i, ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"y(varepsilon_i) = f(x_1 x_2 ldots x_i (1 + varepsilon_i) ldots x_n)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"As an example, if we want to check whether the gradients for sigmoid is correctly backpropagated in the above code, we have ","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"using ADCME\nusing ADCMEKit\nε = placeholder(1.0)\nθ = constant([1.;2.;3.;4.])\nx = collect(LinRange(0.0,1.0,10))\nf = θ[3]*sigmoid(θ[1]*x+θ[2] + ε)+θ[4]\nloss = sum((f - f0)^2)\nsess = Session(); init(sess)\ngradview(sess, ε, loss, 0.01)","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"We will see a second order convergence for the automatic differentiation method while a first order convergence for the finite difference method. The principle for identifying problematic operator is to go from downstream operators to top stream operators in the computational graph. For example, given the computational graph","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"f_1rightarrow f_2 rightarrow cdots rightarrow f_i rightarrow f_i+1 rightarrow ldots rightarrow f_n","category":"page"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"If we conduct sensitivity analysis for f_io_i mapsto o_i+1, and find that the gradient is wrong, then we can infer that at least one of the operators in the downstream f_i rightarrow f_i+1 rightarrow ldots rightarrow f_n has problematic gradients. ","category":"page"},{"location":"tu_recipe/#Check-Your-Training-Data","page":"Inverse Modeling Recipe","title":"Check Your Training Data","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"Sometimes it is also useful to check your training data. For example, if you are working with numerical schemes, check whether your training data are generated from reasonable physical parameters, and whether or not the numerical schemes are stable. ","category":"page"},{"location":"tu_recipe/#Local-Minimum","page":"Inverse Modeling Recipe","title":"Local Minimum","text":"","category":"section"},{"location":"tu_recipe/","page":"Inverse Modeling Recipe","title":"Inverse Modeling Recipe","text":"To check whether or not the optimization converged to a local minimum, you can either check meshview or lineview. However, these functions only give you some hints and you should only rely solely on their results. A more reliable check is to consider gradview. In principle, if you have a local minimum, the gradient at the local minimum should be zero, and therefore the finite difference curve should also have second order convergence. ","category":"page"},{"location":"vae/#Variational-Autoencoder","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"","category":"section"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Let's see how to implement an autoencoder for generating MNIST images in ADCME. The mathematics underlying autoencoder is the Bayes formula","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"p(zx) = fracp(xz)p(z)p(x)","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"where x a sample from the data distribution and z is latent variables. To model the data distribution given the latent variable, p(xz), we use a deep generative neural network g_phi that takees z as the input and outputs x. This gives us the approximate p_phi(xz) approx p(xz). ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"However, computing p(zx) directly can be intractable. To this end, we approximate the posterior using zsim mathcalN(mu_x sigma_x^2I), where mu_x and sigma_x are both encoded using neural networks, where x is the input to the neural network. In this way, we obtain an approximate posterior ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"p_w(zx) = frac1(sqrt2pi sigma_x^2)^dexpleft( -fracz-mu_x)^22sigma_x^2 right) tag1","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"How can we choose the correct weights and biases phi and w? The idea is to minimize the discrepancy between the true posterior and the approximate posterior Equation (1). We can use the KL divergence, which is a metric for measuring the discrepancy between two distributions","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"mathrmKL(p_w(zx) p(zx)) = mathbbE_p_w(log p_w(zx) - log p(zx)) tag2","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"However, computing Equation 2 is still intractable since we do not know log p(zx). Instead, we seek to minimize a maximize bound of the KL divergence ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"beginaligned\nmathrmELBO =  log p(x) - mathrmKL(p_w(zx) p(zx))\n = mathbbE_p_w( log p(zx) - log p_w(zx))  \n = mathbbE_p_w(zx)log p_phi(xz) - mathrmKL(p_w(zx)  p(z))\nendaligned","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Note that we assumed that the generative neural network g_phi is sufficiently expressive so p_phi(yz)approx p(yz). Additionally, because KL divergence is always positive","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"mathrmELBO leq log p(x)tag3","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Equation (3) justifies the name \"evidence lower bound\". ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Let's consider how to compute ELBO for our autoencoder. For the marginal likelihood term mathbbE_p_w(zx)log p_phi(xz), for each given sample y, we can calculate the mean and covariance of z, namely mu_x and sigma_x^2I. We sample z_isim mathcalN(mu_x sigma_x^2I) and plug them into g_phi and obtain the outputs x_i = g_phi(z_i). If we assume that the decoder model is subject to Bernoulli distribution x sim Ber(g_phi(z)) (in this case we have g_phi(z)in 01), we have the approximation ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"mathbbE_p_w(zx)log p_phi(xz) approx frac1nsum_i=1^n leftx_ilog (g_phi(z_i)) + (1-x_i) log(1-g_phi(z_i))righttag4","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Now let us consider the second term mathrmKL(p_w(zx)  p(z)). If we assign a unit Gaussian prior on z, we have","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"beginaligned\nmathrmKL(p_w(zx)  p(z)) = mathbbE_p_wlog(p_w(zx)) - log(p(z))  \n =  mathbbE_p_wleft-fracz-mu_x^22sigma_x^2 - dlog(sigma_x) + fracz^22 right\n = -d - dlog(sigma_x) +frac12 mu_x^2 + fracd2sigma_x^2 \nendaligned tag5","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"Using Equation 4 and 5 we can formulate a loss function, which we can use a stochastic gradient descent method to minimize. ","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"The following code is an example of applying the autoencoder to learn a data distribution from MNIST dataset. Here is the result using this script:","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"(Image: )","category":"page"},{"location":"vae/","page":"Variational Autoencoder","title":"Variational Autoencoder","text":"using ADCME\nusing PyPlot\nusing MLDatasets\nusing ProgressMeter\n\n\nfunction encoder(x, n_hidden, n_output, rate)\n    local μ, σ\n    variable_scope(\"encoder\") do \n        y = dense(x, n_hidden, activation = \"elu\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, n_hidden, activation = \"tanh\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, 2n_output)\n        μ = y[:, 1:n_output]\n        σ = 1e-6 + softplus(y[:,n_output+1:end])\n    end\n    return μ, σ\nend\n\nfunction decoder(z, n_hidden, n_output, rate)\n    local y \n    variable_scope(\"decoder\") do \n        y = dense(z, n_hidden, activation=\"tanh\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, n_hidden, activation=\"elu\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, n_output, activation=\"sigmoid\")\n    end\n    return y \nend\n\nfunction autoencoder(xh, x, dim_img, dim_z, n_hidden, rate)\n    μ, σ = encoder(xh, n_hidden, dim_z, rate)\n    z = μ + σ .* tf.random_normal(size(μ), 0, 1, dtype=tf.float64)\n    y = decoder(z, n_hidden, dim_img, rate)\n    y = clip(y, 1e-8, 1-1e-8)\n\n    marginal_likelihood = sum(x .* log(y) + (1-x).*log(1-y), dims=2)\n    KL_divergence = 0.5 * sum(μ^2 + σ^2 - log(1e-8 + σ^2) - 1, dims=2)\n\n    marginal_likelihood = mean(marginal_likelihood)\n    KL_divergence = mean(KL_divergence)\n\n    ELBO = marginal_likelihood - KL_divergence\n    loss = -ELBO \n    return y, loss, -marginal_likelihood, KL_divergence\nend\n\nfunction step(epoch)\n    tx = train_x[1:batch_size,:]\n    @showprogress for i = 1:div(60000, batch_size)\n        idx = Array((i-1)*batch_size+1:i*batch_size)\n        run(sess, opt, x=>train_x[idx,:])\n    end\n    y_, loss_, ml_, kl_ = run(sess, [y, loss, ml, KL_divergence],\n            feed_dict = Dict(\n                ADCME.options.training.training=>false, \n                x => tx\n            ))\n    println(\"epoch $epoch: L_tot = $(loss_), L_likelihood = $(ml_), L_KL = $(kl_)\")\n\n    close(\"all\")\n    for i = 1:3\n        for j = 1:3\n            k = (i-1)*3 + j \n            img = reshape(y_[k,:], 28, 28)'|>Array\n            subplot(3,3,k)\n            imshow(img)\n        end\n    end\n    savefig(\"result$epoch.png\")\nend\n\n\n\nn_hidden = 500\nrate = 0.1\ndim_z = 20\ndim_img = 28^2\nbatch_size = 128\nADCME.options.training.training = placeholder(true)\nx = placeholder(Float64, shape = [128, 28^2])\nxh = x\ny, loss, ml, KL_divergence = autoencoder(xh, x, dim_img, dim_z, n_hidden, rate)\nopt = AdamOptimizer(1e-3).minimize(loss)\n\ntrain_x = MNIST.traintensor(Float64);\ntrain_x = Array(reshape(train_x, :, 60000)');\n\nsess = Session(); init(sess)\nfor i = 1:100\n    step(i)\nend","category":"page"},{"location":"tu_fd/#Numerical-Scheme-in-ADCME:-Finite-Difference-Example","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"","category":"section"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"ADCME provides convenient tools to implement numerical schemes. In this tutorial, we will implement a finite difference program and conduct inverse modeling. In the first part, we consider a toy example of estimating parameters in a partial differential equation. In the second part, we showcase a real world application of ADCME to geophysical inversion.","category":"page"},{"location":"tu_fd/#Estimating-a-scalar-unknown-in-the-PDE","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Estimating a scalar unknown in the PDE","text":"","category":"section"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"Consider the following partial differential equation","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"-bu(x)+u(x)=f(x)quad xin01 u(0)=u(1)=0","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"where ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"f(x) = 8 + 4x - 4x^2","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"Assume that we have observed u(05)=1, we want to estimate b. The true value in this case should be b=1. We can discretize the system using finite difference method, and the resultant linear system will be","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"(bA+I)mathbfu = mathbff","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"where","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"A = beginbmatrix\n        frac2h^2  -frac1h^2  dots  0\n         -frac1h^2  frac2h^2  dots  0\n         dots \n         0  0  dots  frac2h^2\n    endbmatrix quad mathbfu = beginbmatrix\n        u_2\n        u_3\n        vdots\n        u_n\n    endbmatrix quad mathbff = beginbmatrix\n        f(x_2)\n        f(x_3)\n        vdots\n        f(x_n)\n    endbmatrix","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"The idea for implementing the inverse modeling method in ADCME is that we make the unknown b a Variable and then solve the forward problem pretending b is known. The following code snippet shows the implementation","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"using LinearAlgebra\nusing ADCME             # (1)\n\nn = 101 # number of grid nodes in [0,1]\nh = 1/(n-1)\nx = LinRange(0,1,n)[2:end-1]       # (2)\n\nb = Variable(10.0) # we use Variable keyword to mark the unknowns    # (3)\nA = diagm(0=>2/h^2*ones(n-2), -1=>-1/h^2*ones(n-3), 1=>-1/h^2*ones(n-3)) \nB = b*A + I  # I stands for the identity matrix\nf = @. 4*(2 + x - x^2) \nu = B\\f # solve the equation using built-in linear solver\nue = u[div(n+1,2)] # extract values at x=0.5\t\t\t\t\t\t\t\t# (4)\n\nloss = (ue-1.0)^2    # (5)\n\n# Optimization\nsess = Session(); init(sess) # (6) \nBFGS!(sess, loss)\t\t\t# (7)\n\nprintln(\"Estimated b = \", run(sess, b)) ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"The expected output is","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"Estimated b = 0.9995582304494237","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"The detailed explaination is as follow: (1) The first two lines load necessary packages; (2) We split the interval 01 into 100 equal length subintervals; (3) Since b is unknown and needs to be updated during optimization, we mark it as trainable using the Variable keyword; (4) Solve the linear system and extract the value at x=05. here I stands for the identity matrix and @. denotes element-wise operation. They are Julia-style syntax but are also compatible with tensors by overloading; (5) Formulate the loss function; (6) Create and initialize a TensorFlow session, which analyzes the computational graph and initializes the tensor values; (7) Finally, we trigger the optimization by invoking BFGS!, which wraps the L-BFGS-B algorithm. ","category":"page"},{"location":"tu_fd/#ADSeismic.jl:-A-General-Approach-to-Seismic-Inversion","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"ADSeismic.jl: A General Approach to Seismic Inversion","text":"","category":"section"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"ADSeismic is a software package for solving seismic inversion problems, such as velocity model estimation, rupture imaging, earthquake location, and source time function retrieval. The governing equation for the acoustic wave equation is  ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"$ \\frac{\\partial^2 u}{\\partial t^2} = \\nabla\\cdot(c^2 \\nabla u) +  f$","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"where u is displacement, f is the source term, and c is the spatially varying acoustic velocity. The inversion parameters of interest are c or f. The governing equation for the elastic wave equation is ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"beginaligned\n    rho fracpartial v_ipartial t = sigma_ij j + rho f_i  \n    fracpartial sigma_ijpartial t = lambda v_kk + mu(v_ij + v_ji)\nendaligned","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"where v is velocity, sigma is stress tensor, rho is density, and lambda and mu are the Lam\\'e's constants. The inversion parameters in the elastic wave equation case are lambda, mu, rho or f.","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"The idea is to substitute the unknowns such as the c and f using mutable tensors (with the Variable keyword) and implement the finite difference method. The implementation detail is beyond the scope of this tutorial. Basically, when explicit schemes are used, the finite difference scheme can be expressed by a computational graph as follows, where U is the discretization of u, A(theta) is the fintie difference coefficient matrix and theta is the unknown (in this case, the entries in the coefficient matrix depends on theta ). The loss function is formulated by matching the predicted wavefield U_i and the observed wavefield U_i^mathrmobs. ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"(Image: adg)","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"The unknown theta is sought by solving a minimization problem using L-BFGS-B, using gradients computed in AD. Besides the simplification of implementation, a direct benefit of implementing the numerical in ADCME is that we can leverage multi-GPU computing resources. We distribute the loss function for each scenario (in practice, we can collect many U_i^mathbfobs corresponding to different source functions f) onto different GPUs and compute the gradients separately. Using this strategy, we can achieve more than 20 times and 60 times acceleration for acoustic and elastic wave equations respectively.","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"(Image: )","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"Here we show a case in locating the centroid of an earthquake. The red star denotes the location where the earthquake happens and the triangles denote the seismic stations. The subsurface constitutes layers of different properties (the values of c are different), affecting the propagation of the seismic waves. ","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"Source/Receiver Location Forward Simulation\n(Image: ) (Image: )","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"By running the optimization problem by specifying the earthquake location as Variable [delta], we can locate the centroid of an earthquake. The result is amazingly good. It is worth noting that it requires substantial effort to implement the traditional adjoint-state solver for this problem (e.g., it takes time to manually deriving and implementing the gradients). However, in view of ADCME, the inversion functionality is merely a by-product of the forward simulation codes, which can be reused in many other inversion problems.","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"(Image: fwi_source)","category":"page"},{"location":"tu_fd/","page":"Numerical Scheme in ADCME: Finite Difference Example","title":"Numerical Scheme in ADCME: Finite Difference Example","text":"[delta]: Mathematically, f(t mathbfx) is a Delta function in mathbfx; to make the inversion problem continuous, we use f_theta(t mathbfx) = g(t) frac12pisigma^2exp(-fracmathbfx-theta^22sigma^2) to approximate f(t mathbfx); here thetainmathbbR^2 and g(t) are unknown.","category":"page"},{"location":"tu_nn/#Combining-Neural-Networks-with-Numerical-Schemes","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Modeling unknown componenets in a physical models using a neural networks is an important method for function inverse problem. This approach includes a wide variety of applications, including","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Koopman operator in dynamical systems\nConstitutive relations in solid mechanics.\nTurbulent closure relations in fluid mechanics.\n...... ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"To use the known physics to the largest extent, we couple the neural networks and numerical schemes (e.g., finite difference, finite element, or finite volumn method) for partial differential equations. Based on the nature of the observation data, we present three methods to train the neural networks using gradient-based optimization method: the residual minimization method, the penalty method, and the physics constrained learning. We discuss the pros and cons for each method and show how the gradients can be computed using automatic differentiation in ADCME. ","category":"page"},{"location":"tu_nn/#Introduction","page":"Combining Neural Networks with Numerical Schemes","title":"Introduction","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Many science and engineering problems use models to describe the physical processes. These physical processes are usually derived from first principles or based on empirical relations. Neural networks have shown to be effective to model complex and high dimensional functions, and can be used to model the unknown mapping within a physical model. The known part of the model, such as conservation laws and boundary conditions, are preserved to obey the physics. Basically, we substutite unknown part of the model using neural networks in a physical system. As an example, consider a simple 1D heat equation","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"beginaligned\nfracpartialpartial xleft(kappa(u)fracpartial upartial xright) = f(x) xin Omega\nu(0) = u(1) = 0\nendaligned","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"The diffusivity coefficient kappa(u) is a function of the temperature u, and is an unknown function to be calibrated. We consider a data-driven approach to discover kappa(u)  using only the temperature data set mathcalT. In the case where we do not know the constitutive relation, it can be modeled using a neural network  kappa_theta (u), where theta is the weights and biases of the neural network. ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"In the following, we will discuss three methods based on the nature of the observation data set mathcalT to train the neural network. ","category":"page"},{"location":"tu_nn/#Residual-Minimization-for-Full-Field-Data","page":"Combining Neural Networks with Numerical Schemes","title":"Residual Minimization for Full Field Data","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"In the case mathcalT consist of full-field data, i.e., the values of u(x) on a very fine grid, we can use the residual minimization to learn the neural network. Specifically, we can discretize the PDE using a numerical scheme, such as finite element method (FEM), and obtain the residual term ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"R_j(theta) =sum_i u(x_i)int_0^1  kappa_theta(sum_i c_i phi_i) phi_i(x) phi_j(x) dx - int_0^1 f(x)phi_j(x)dx","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"where phi_i are the basis functions in FEM. To find the optimal values for theta, we can perform a residual minimization ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"min_theta sum_j R_j(theta)^2","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"The residual minimization method avoids solving the PDE system, which can be expensive. The implication is straightforward using ADCME: all we need is to evaluate R_j(theta) and fracpartial R_j(theta)partial theta (using automatic differention). However, the limitation is that this method is only applicable when full-field data are available. ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"In the following two references, we explore the applications of the residual minimization method to constitutive modeling","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"DZ Huang, K Xu, C Farhat, E Darve. Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"K Xu, DZ Huang, E Darve. Learning Constitutive Relations using Symmetric Positive Definite Neural Networks","category":"page"},{"location":"tu_nn/#Penalty-Method-for-Sparse-Observations","page":"Combining Neural Networks with Numerical Schemes","title":"Penalty Method for Sparse Observations","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"In the case where mathcalT only consists of sparse observations, i.e., u_o(x_i) (observation of u(x_i)) at only a few locations x_i, we can formulate the problem as a PDE-constrained optimization problem","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"beginaligned\nmin_theta sum_i (u(x_i) - u_o(x_i))^2\ntextst  fracpartialpartial xleft(kappa_theta(u)fracpartial upartial xright) = f(x) xin Omega\n u(0) = u(1) = 0\nendalignedtag1","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"As pointed in this article, we can apply the penalty method to solve the contrained optimization problem, ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"min_thetau sum_i (u(x_i) - u_o(x_i))^2 + rho F(u theta)^2_2","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Here rho is the penalty parameter and F(u theta) is the discretized form of the PDE. For example, F(utheta)_i can be R_i(theta) in the residual minimization problem. ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"The penalty method is conceptually simple and easy to implement. Like the residual minimization method, the penalty method requires limited insights into the numerical simulator to evaluate the gradients with respect to u and theta. The method does not require solving the PDE.","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"However, the penalty method treats u as optimization variable and therefore typically has much more degrees of freedom than the original constrained optimization problem. Mathematically, the penalty method suffers from worse conditioning than the constrained one, making it unfavorable in many scenarios. ","category":"page"},{"location":"tu_nn/#Physics-Constrained-Learning","page":"Combining Neural Networks with Numerical Schemes","title":"Physics Constrained Learning","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"An alternative approach to the penalty method in the context of sparse observations is the physics constrained learning (PCL). The physics constrained learning reduces Equation 1 to an unconstrained optimization problem by two steps:","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Solve for u from the PDE constraint, given a candidate neural network;\nPlug the solution u(theta) into the objective function and obtain a reduced loss function","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"The reduced loss function only depends on theta and therefore we can perform the unconstrained optimization, in which case a wide variety of off-the-shelf optimizers are available. The advantage of this approach is that PCL enforces the physics constraints, which can be crucial for some applications and are essential for numerical solvers. Additionally, PCL typically exhibits high efficiency and fast convergence compared to the other two methods. However, PCL requires deep insights into the numerical simulator since an analytical form of u(theta) is not always tractable. It requires automatic differentiation through implict numerical solvers as well as iterative algorithms, which are usually not supported in AD frameworks. In the references below, we provide the key techniques for solving these problems. A final limitation of PCL is that it consumes much more memory and runtime per iteration than the other two methods. ","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"For more details on PCL, and comparison between the penalty method and PCL, see the following reference","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"K Xu, E Darve. Physics Constrained Learning for Data-driven Inverse Modeling from Sparse Observations","category":"page"},{"location":"tu_nn/#Summary","page":"Combining Neural Networks with Numerical Schemes","title":"Summary","text":"","category":"section"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Using physics based machine learning  to solve inverse problems requires techniques from different areas, deep learning, automatic differentiation, numerical PDEs, and physical modeling. By a combination of the best from all worlds, we can leverage the power of modern high performance computing environments to solve long standing inverse problems in physical modeling. Specially, in this article we review three methods for training a neural network in a physical model using automatic differentiation. These methods can be readily implemented in ADCME. We conclude this article by a direct comparison of the three methods","category":"page"},{"location":"tu_nn/","page":"Combining Neural Networks with Numerical Schemes","title":"Combining Neural Networks with Numerical Schemes","text":"Method Residual Minimization Penalty Method Physics Constrained Learning\nSparse Observations ❌ ✔️ ✔️\nEasy-to-implement ✔️ ✔️ ❌\nEnforcing Physical Constraints ❌ ❌ ✔️\nFast Convergence ❌ ❌ ✔️\nMinimal Optimization Variables ✔️ ❌ ✔️","category":"page"},{"location":"tu_optimization/#PDE-Constrained-Optimization","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"In the broad context, the physics based machine learning can be formulated as a PDE-constrained optimization problem. The PDE-constrained optimization problem aims at finding the optimal design variables such that the objective function is minimized and the constraints–-usually described by PDEs–-are satisfied. PDE-contrained optimization has a large variety of applications, such as optimal control and inverse problem. The topic is at the intersection of numerical PDE discretization, mathematical optimization, software design, and physics modeling. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Mathematically, a PDE-constrained optimization can be formulated as ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nmin_yin mathcalY uin mathcalU J(y u)\ntextst F(y u)=0  textthe governing PDEs\n c(yu)=0textadditional equality constraints\n h(y u)geq 0textadditional inequality constraints\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Here J is the objective function, y is the design variable, u is the state variable. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"In this section, we will focus on the PDE-constrained optimization with only the governing PDE constraints, and we consider a discretize-then-optimize and gradient-based optimization approach. Specifically, the objective function and the PDEs are first discretized numerically, leading to a constrained optimization problem with  a finite dimensional optimization variable. We use gradient-based optimization because it provides fast convergence and an efficient way to integrate optimization and simulation. However, this approach requires insight into the simulator and can be quite all-consuming to obtain the gradients. ","category":"page"},{"location":"tu_optimization/#Example","page":"PDE Constrained Optimization","title":"Example","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"We consider an exemplary PDE-constrained optimization problem: assume we want to have a specific temperature distribution on a metal bar bar u(x) by imposing a heat source y(x) on the bar","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nmin_yin mathcalY uin mathcalU L(y u) = frac12int_0^1 u(x) - bar u(x)^2 dx + fracrho2int_0^1 y(x)^2 dx \ntextst f(y u)=0 \nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Here f(yu)=0 is the static heat equation with the boundary conditions. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"c(x)u_xx(x) = y(x)quad xin (01) quad u(0)=u_0 u(1)=u_1","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"where c(x) is the diffusivity coefficient, u_0 and u_1 are fixed boundaries. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"After discretization, the optimization problem becomes","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nmin_y u J(y u) = frac12u-bar u_2 + fracrho2y^2\ntextst F(y u)= Ku - y = 0\nendalignedtag1","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"where K is the stiffness matrix, taking into account of the boundary conditions, u, bar u, and y are vectors.","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"In what follows, we basically apply common optimization method to the constrained optimization problem Equation 1.  ","category":"page"},{"location":"tu_optimization/#Method-1:-Penalty-Method","page":"PDE Constrained Optimization","title":"Method 1: Penalty Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The simplest method for solving the unconstrained optimization problem Equation 1 is via the penalty method. Specifically, instead of solving the original constrained optimization problem, we solve ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"min_y u frac12u-bar u_2 + fracrho2y^2 + lambda f(y u)^2_2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"where lambda is the penalty parameter. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The penalty method is conceptually simple  and is also easy-to-implement. Additionally, it does not require solving the PDE constraint f(yu)=0 and thus the comptuational cost for each iteration can be small. However, avoid solving the PDE constraint is also a disadvantage since it means the penalty method does not eventually enforce the physical constraint. The solution from the penalty method only converges to the the true solution when lambdarightarrow infty, which is not computationally feasible. Additionally, despite less cost per iteration, the total number of iterations can be huge when the PDE constraint is \"stiff\". To gain some intuition, consider the following problem","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nmin_u 0\ntextst  Ku - y = 0\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The optimal value is u = K^-1y and the cost by solving the linear system is usually propertional to mathrmcond(K). However, if we were to solve the problem using the penalty method ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"min_u Ku-y^2_2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The condition number for solving the least square problem (e.g., by solving the normal equation K^TK u = K^Ty) is usually propertional to mathrmcond(K)^2. When the problem is stiff, i.e., mathrmcond(K) is large, the penaty formulation can be much more ill-conditioned than the original problem. ","category":"page"},{"location":"tu_optimization/#Method-2:-Primal-and-Primal-Dual-Method","page":"PDE Constrained Optimization","title":"Method 2: Primal and Primal-Dual Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"A classical theory regarding constrained optimization is the Karush-Kuhn-Tucker (KKT) Theorm. It states a necessary and sufficient condition for a value to be optimal under certain assumptions. To formulate the KKT condition, consider the Lagrangian function ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"L(u y lambda) = frac12u-bar u_2 + fracrho2y^2 + lambda^T(Ku - y)","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"where lambda is the adjoint variable. The corresponding KKT condition is ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nfracpartial Lpartial u = u - bar u + K^Tlambda = 0 \nfracpartial Lpartial y = rho y - lambda = 0 \nfracpartial Lpartial lambda = Ku - y = 0\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The primal-dual method solves for (u y lambda) simultaneously from the linear system","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginbmatrix 1  0  K^T 0  rho  -1K  -1  0 endbmatrixbeginbmatrixu y lambdaendbmatrix = beginbmatrixbar u 0  0endbmatrix","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"In contrast, the dual method eliminates the state variables u and y and solves for lambda","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"(1+rho KK^T)lambda = rho Kbar u","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The primal-dual and dual method have some advantages. For example, we reduce finding the minimum of a constrained optimization method to solving a nonlinear equation, where certain tools are available. For the primal-dual method, the limitation is that the system of equations can be very large and difficult to solve. The dual method requires analytical derivation and is not always obvious in practice, especially for nonlinear problems. ","category":"page"},{"location":"tu_optimization/#Method-3:-Primal-Method","page":"PDE Constrained Optimization","title":"Method 3: Primal Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The primal method reduces the constrained optimization problem to an unconstrained optimization problem by \"solving\" the numerical PDE first. In the previous example, we have u(y) = K^-1y and therefore we have","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"min_y frac12K^-1y-bar u_2 + fracrho2y^2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The advantage is three-folds","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Dimension reduction. The optimization variables are reduced from (uy) to the design variables y only. \nEnforced physical constraints. The physical constraints are enforced numerically. \nUnconstrained optimization. The reduced problem is a constrained optimization problem and many off-the-shelf optimizers (gradient descent, BFGS, CG, etc.) are available. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"However, to compute the gradients, the primal method requires deep insights into the numerical solver, which may be highly nonlinear and implicit. The usual automatic differentiation (AD) framework are in general not applicable to this type of operators (nodes in the computational graph) and we need special algorithms.","category":"page"},{"location":"tu_optimization/#Link-to-Adjoint-State-Method","page":"PDE Constrained Optimization","title":"Link to Adjoint-State Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The adjoint state method is a standard method for computing the gradients of the objective function with respect to design variables in PDE-constrained optimization. Consider ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nmin_y u J(y u)\ntextst F(y u)=0 \nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Let u be the state variable and y be the design variable. Assume we solve for u=u(y) from the PDE constraint, then we have the reduced objective function ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"hat J(y) = J(y u(y))","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"To conduct gradient-based optimization, we need to compute the gradient ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracd hat J(y)d y =nabla_y J(y u(y)) +nabla_u J(y u(y))fracdu(y)dy tag2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"To compute the fracdu(y)dy we have","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"F(y u(y))=0 Rightarrow nabla_y F + nabla_u F fracdudy = 0 tag3","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Therefore we can use Equations 2 and 3 to evaluate the gradient of the objective function","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracd hat J(y)d y = nabla_y J(y u(y)) - nabla_u J(y u(y)) (nabla_u F(yu(y)))^-1 nabla_y F(y u(y))tag4","category":"page"},{"location":"tu_optimization/#Link-to-the-Lagrange-Function","page":"PDE Constrained Optimization","title":"Link to the Lagrange Function","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"There is a nice interpretation of Equations 2 and 3 using the Lagrange function. Consider the langrange function ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"L(y u lambda) = J(y u) + lambda^T F(y u) tag5","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The KKT condition says","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\nfracpartial Lpartial lambda = F(y u) = 0\nfracpartial Lpartial u = nabla_u J + lambda^T nabla_u F(y u) = 0\nfracpartial Lpartial y = nabla_y J + lambda^T nabla_y F(y u) = 0\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Now we relax the third equation: given a fixed y (not necessarily optimal), we can solve for (ulambda) from the first two equations. We plug the solutions into the third equation and obtain (note u satisfies F(y u)=0)","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracpartial Lpartial y = nabla_y J(y u) - nabla_u J(y u) (nabla_u F(yu))^-1 nabla_y F(y u)","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"which is the same expression as Equation 4. When y is optimal, this expression is equal to zero, i.e., all the KKT conditions are satisfied. The gradient of the unconstrained optimization problem is also zero. Both the primal system and the primal-dual system confirm the optimality. This relation also explains why we call the method above as \"adjoint\" state method. In summary, the adjoint-state method involves a three-step process","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Step 1. Create the Lagrangian Equation 5.\nStep 2. Conduct forward computation and solve for u from ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"F(y u) = 0","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Step 3. Compute the adjoint variable lambda from ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"nabla_u J + lambda^T nabla_u F(y u) = 0","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Step 4. Compute the sensitivity ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracpartial hat Jpartial y = nabla_y J + lambda^T nabla_y F(y u)","category":"page"},{"location":"tu_optimization/#Link-to-Automatic-Differentiation","page":"PDE Constrained Optimization","title":"Link to Automatic Differentiation","text":"","category":"section"},{"location":"tu_optimization/#Computational-Graph","page":"PDE Constrained Optimization","title":"Computational Graph","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The adjoint-state method is also closely related to the reverse-mode automatic differentiation. Consider a concrete PDE-constrained optimization problem","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\n     min_mathbfu_1 theta   J = f_4(mathbfu_1 mathbfu_2 mathbfu_3 mathbfu_4) \n     mathrmst   mathbfu_2 = f_1(mathbfu_1  theta) \n       mathbfu_3 = f_2(mathbfu_2  theta)\n        mathbfu_4 = f_3(mathbfu_3  theta)\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"where f_1, f_2, f_3 are PDE constraints, f_4 is the loss function, mathbfu_1 is the initial condition, and theta is the model parameter.","category":"page"},{"location":"tu_optimization/#Adjoint-State-Method","page":"PDE Constrained Optimization","title":"Adjoint-State Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The Lagrangian function is ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"mathcalL= f_4(mathbfu_1 mathbfu_2 mathbfu_3 mathbfu_4) + lambda^T_2(f_1(mathbfu_1  theta) - mathbfu_2) + lambda^T_3(f_2(mathbfu_2  theta) - mathbfu_3) + lambda^T_4(f_3(mathbfu_3  theta) - mathbfu_4)","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Upon conducting the foward computation we have all mathbfu_i available. To compute the adjoint variable lambda_i, we have ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\n  lambda_4^T = fracpartial f_4partial mathbfu_4  \n lambda_3^T = fracpartial f_4partial  mathbfu_3 + lambda_4^Tfracpartial f_3partial  mathbfu_3  \n  lambda_2^T = fracpartial f_4partial  mathbfu_2 + lambda_3^Tfracpartial f_2partial  mathbfu_2 \nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The gradient of the objective function in the constrained optimization problem is given by ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracpartial mathcalLpartial theta = lambda_2^Tfracpartial f_1partial theta + lambda_3^Tfracpartial f_2partial theta + lambda_4^Tfracpartial f_3partial theta","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"(Image: )","category":"page"},{"location":"tu_optimization/#Automatic-Differentiation","page":"PDE Constrained Optimization","title":"Automatic Differentiation","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Now let's see how the computation is linked to automatic differentiation. As explained in the previous tutorials, when we implement the automatic differentiation operator, we need to backpropagate the \"top\" gradients to its upstreams in the computational graph. Consider the operator f_2, we need to implement two operators ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"beginaligned\ntextForward mathbfu_3 = f_2(mathbfu_2 theta)\ntextBackward fracpartial Jpartial mathbfu_2 fracpartial Jpartial theta = b_2left(fracpartial J^mathrmtotpartial mathbfu_3 mathbfu_2 thetaright)\nendaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Here fracpartial J^mathrmtotpartial mathbfu_3 is the \"total\" gradient mathbfu_3 received from the downstream in the computational graph. ","category":"page"},{"location":"tu_optimization/#Relation-between-AD-and-Adjoint-State-Method","page":"PDE Constrained Optimization","title":"Relation between AD and Adjoint-State Method","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The backward operator is implemented using the chain rule beginaligned \tfracpartial Jpartial mathbfu_2 = fracpartial J^mathrmtotpartial mathbfu_3 fracpartial f_2partial mathbfu_2qquad \tfracpartial Jpartial theta = fracpartial J^mathrmtotpartial mathbfu_3 fracpartial f_2partial theta endaligned","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The total gradient mathbfu_2 received is","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"fracpartial J^mathrmtotpartial mathbfu_2  = fracpartial f_4partial mathbfu_2 + fracpartial Jpartial mathbfu_2 = fracpartial f_4partial mathbfu_2 + fracpartial J^mathrmtotpartial mathbfu_3 fracpartial f_2partial mathbfu_2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"The dual constraint in the KKT condition lambda_2^T = fracpartial f_4partial  mathbfu_2 + lambda_3^Tfracpartial f_2partial  mathbfu_2","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Now we see the important relation ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"boxedlambda_i^T = fracpartial J^mathrmtotpartial mathbfu_i","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"That means, in general, the reverse-mode AD is back-propagating the Lagrange multiplier (adjoint variables). ","category":"page"},{"location":"tu_optimization/#Dicussion-and-Physics-based-Machine-Learning","page":"PDE Constrained Optimization","title":"Dicussion and Physics based Machine Learning","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"However, although the link between AD and adjoint state methods enables us to use AD tools for PDE-constrained optimization, many standard numerical schemes, such as implicit ones, involve an iterative process (e.g., Newton-Raphson) in nature. AD is usually designed for explicit operators. To this end, we can borrow the idea from the adjoint-state methods and enhance the current AD framework to differentiate through iterative solvers or implicit schemes. This is known as physics constrained learning. For more details, see the paper here. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Another ongoing research is the combination of neural networks and physical modeling. One idea is to model the unknown relations in the physical system using neural networks. Those includes ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Koopman operator in dynamical systems\nConstitutive relations in solid mechanics.\nTurbulent closure relations in fluid mechanics.\n......","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"In the context of PDE-constrained optimization, there is no essential difference between learning a neural network and finding the optimal physical parameters, except that the design variables become the weights and biases of neural networks. However, the neural networks raise some questions, for example: does one optimization technique preferable than the others? How to stabilize the numerical solvers when neural networks are present? How to add physical constraints to the neural network? How to scale the algorithm? How is the well-posedness and conditioning of the optimization problem? How much data do we need? How to stabilize the training (e.g., regularization, projected gradients)? Indeed, the application of neural networks in the physics machine learning leave more problems than what have been answered here. ","category":"page"},{"location":"tu_optimization/#Other-Optimization-Techniques","page":"PDE Constrained Optimization","title":"Other Optimization Techniques","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Besides the formulation and optimization techniques  introduced here, there are many other topics, which we have not covered here, on PDE-constrained optimization. It is worthwhile mentioning that we consider the optimize-then-discretize approach. The alternative approach, discretize-then-optimize, derives the optimal condition (KKT condition) on the continuous level and then discretize the dual PDE. In this formulation, we can use the same discretization method for both the primal and dual system, and therefore we may preserve some essential physical properties. However, the gradients derived in this way may deviate from the true gradients of the constrained optimization problem. ","category":"page"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"Another noteworthy ongoing research is to formulate the optimization as an action functional. Just like every PDE can be viewed as a minimization of an energy function, a PDE-constrained optimization problem can also be formulated as a problem of minimizing a functional. These discussions are beyond the scope of the tutorial. ","category":"page"},{"location":"tu_optimization/#Summary","page":"PDE Constrained Optimization","title":"Summary","text":"","category":"section"},{"location":"tu_optimization/","page":"PDE Constrained Optimization","title":"PDE Constrained Optimization","text":"PDE-constrained optimization has a wide variety of applications. Specifically, formulating the physics based machine learning as a PDE-constrained optimization problem lends us a rich toolbox for optimization, discretization, and algorithm design. The combination of neural networks and physics modeling poses a lot of opportunities as well as challenges for solving long standing problems. The gradient based optimization with automatic differentiation has the potential to consolidate the techniques in a single framework.  ","category":"page"},{"location":"tu_sparse/#Sparse-Linear-Algebra","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"ADCME augments TensorFlow APIs by adding sparse linear algebra support. In ADCME, sparse matrices are represented by SparseTensor. This data structure stores indices, rows and cols of the sparse matrices and keep track of relevant information such as whether it is diagonal for performance consideration. The default is row major (due to TensorFlow backend). ","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"When evaluating SparseTensor, the output will be SparseMatrixCSC, the native Julia representation of sparse matrices","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"A = run(sess, s) # A has type SparseMatrixCSC{Float64,Int64}","category":"page"},{"location":"tu_sparse/#Sparse-Matrix-Construction","page":"Sparse Linear Algebra","title":"Sparse Matrix Construction","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"By passing columns (Int64), rows (Int64) and values (Float64) arrays","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"ii = [1;2;3;4]\njj = [1;2;3;4]\nvv = [1.0;1.0;1.0;1.0]\ns = SparseTensor(ii, jj, vv, 4, 4)","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"By passing a SparseMatrixCSC","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"using SparseArrays\ns = SparseTensor(sprand(10,10,0.3))","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"By passing a dense array (tensor or numerical array)","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"D = Array(sprand(10,10,0.3)) # a dense array\nd = constant(D)\ns = dense_to_sparse(d)","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"There are also special constructors. ","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"Description Code\nDiagonal matrix with diagonal v spdiag(v)\nEmpty matrix with size m, n spzero(m, n)\nIdentity matrix with size m spdiag(m)","category":"page"},{"location":"tu_sparse/#Matrix-Traits","page":"Sparse Linear Algebra","title":"Matrix Traits","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"Size of the matrices\nsize(s) # (10,20)\nsize(s,1) # 10\nReturn row, col, val arrays (also known as COO arrays)\nii,jj,vv = find(s)","category":"page"},{"location":"tu_sparse/#Arithmetic-Operations","page":"Sparse Linear Algebra","title":"Arithmetic Operations","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"Add Subtract\ns = s1 + s2\ns = s1 - s2\n\nScalar Product\ns = 2.0 * s1\ns = s1 / 2.0\nSparse Product\ns = s1 * s2\nTransposition\ns = s1'","category":"page"},{"location":"tu_sparse/#Sparse-Solvers","page":"Sparse Linear Algebra","title":"Sparse Solvers","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"Solve a linear system (s is a square matrix)\nsol = s\\rhs\nSolve a least square system (s is a tall matrix)\nsol = s\\rhs","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"note: Note\nThe least square solvers are implemented using Eigen sparse linear packages, and the gradients are also implemented. Thus, the following codes will work as expected (the gradients functions will correctly compute the gradients):ii = [1;2;3;4]\njj = [1;2;3;4]\nvv = constant([1.0;1.0;1.0;1.0])\nrhs = constant(rand(4))\ns = SparseTensor(ii, jj, vv, 4, 4)\nsol = s\\rhs\nrun(sess, sol)\nrun(sess, gradients(sum(sol), rhs))\nrun(sess, gradients(sum(sol), vv))","category":"page"},{"location":"tu_sparse/#Assembling-Sparse-Matrix","page":"Sparse Linear Algebra","title":"Assembling Sparse Matrix","text":"","category":"section"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"In many applications, we want to accumulate row, col and val to assemble a sparse matrix in iterations. For this purpose, we provide the SparseAssembler utilities. ","category":"page"},{"location":"tu_sparse/","page":"Sparse Linear Algebra","title":"Sparse Linear Algebra","text":"SparseAssembler\naccumulate\nassemble","category":"page"},{"location":"tu_sparse/#ADCME.SparseAssembler","page":"Sparse Linear Algebra","title":"ADCME.SparseAssembler","text":"SparseAssembler(handle::Union{PyObject, <:Integer}, n::Union{PyObject, <:Integer}, tol::Union{PyObject, <:Real}=0.0)\n\nCreates a SparseAssembler for accumulating row, col, val for sparse matrices. \n\nhandle: an integer handle for creating a sparse matrix. If the handle already exists, SparseAssembler return the existing sparse matrix handle. If you are creating different sparse matrices, the handles should be different. \nn: Number of rows of the sparse matrix. \ntol (optional): Tolerance. SparseAssembler will treats any values less than tol as zero. \n\nExample 1\n\nhandle = SparseAssembler(100, 5, 1e-8)\nop1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])\nop2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])\nJ = assemble(5, 5, [op1;op2])\n\nJ will be a SparseTensor object. \n\nExample 2\n\nhandle = SparseAssembler(0, 5)\nop1 = accumulate(handle, 1, [1;2;3], ones(3))\nop2 = accumulate(handle, 1, [3], [1.])\nop3 = accumulate(handle, 2, [1;3], ones(2))\nJ = assemble(5, 5, [op1;op2;op3]) # op1, op2, op3 are parallel\nArray(run(sess, J))≈[1.0  1.0  2.0  0.0  0.0\n                1.0  0.0  1.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0]\n\n\n\n\n\n","category":"function"},{"location":"tu_sparse/#Base.accumulate","page":"Sparse Linear Algebra","title":"Base.accumulate","text":"accumulate(handle::PyObject, row::Union{PyObject, <:Integer}, cols::Union{PyObject, Array{<:Integer}}, vals::Union{PyObject, Array{<:Real}})\n\nAccumulates row-th row. It adds the value to the sparse matrix\n\nfor k = 1:length(cols)\n    A[row, cols[k]] += vals[k]\nend\n\nhandle is the handle created by SparseAssembler. \n\nSee SparseAssembler for an example.\n\nnote: Note\nThe function accumulate returns a op::PyObject. Only when op is executed, the nonzero values are populated into the sparse matrix. \n\n\n\n\n\n","category":"function"},{"location":"tu_sparse/#ADCME.assemble","page":"Sparse Linear Algebra","title":"ADCME.assemble","text":"assemble(m::Union{PyObject, <:Integer}, n::Union{PyObject, <:Integer}, ops::PyObject)\n\nAssembles the sparse matrix from the ops created by accumulate. ops is either a single output from accumulate, or concated from several ops\n\nop1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])\nop2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])\nop = [op1;op2] # equivalent to `vcat([op1, op2]...)`\n\nm and n are rows and columns of the sparse matrix. \n\nSee SparseAssembler for an example.\n\n\n\n\n\n","category":"function"},{"location":"flow/#Normalizing-Flows","page":"Normalizing Flows","title":"Normalizing Flows","text":"","category":"section"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"In this article we introduce the ADCME module for flow-based generative models. The flow-based generative models can be used to model the joint distribution of high-dimensional random variables. It constructs a sequence of invertible transformation of distributions","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"x = f(u) quad u sim pi(u)","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"based on the change of variable equation","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"p(x) = pi(f^-1(x)) leftdetleft(fracpartial f^-1(x)partial xright)right","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"example: Example\nConsider the transformation f mathbbRrightarrow 01, s.t. f(x) = mathrmsigmoid(x) = frac11+e^-x. Consider the random variable u sim mathcalN(01)We want to find out the probability density function of p(x), where x=f(u). To this end, we have f^-1(x)=log(x) - log(1-x) Rightarrow fracpartial f^-1(x)partial x = frac1x + frac11-xTherefore, we havebeginaligned\np(x) = pi(f^-1(x))left( frac1x + frac11-xright)  \n= frac1sqrt2piexpleft(-frac(log(x)-log(1-x))^22right)left( frac1x + frac11-xright)\nendaligned","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Compared to other generative models such as variational autoencoder (VAE) and generative neural networks (GAN), the flow-based generative models give us explicit formuas of density functions. For model training, we can directly minimizes the posterier log likelihood in the flow-based generative models, while use approximate likelihood functions in VAE and adversarial training in GAN. In general, the flow-based generative model is easier to train than VAE and GAN. In the following, we give some examples of using flow-based generatives models in ADCME. ","category":"page"},{"location":"flow/#Type-Hierarchy","page":"Normalizing Flows","title":"Type Hierarchy","text":"","category":"section"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"The flow-based generative model is organized as follows, from botton level to top level:","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"FlowOp. This consists of unit invertible transformations, such as AffineConstantFlow and Invertible1x1Conv.\nNormalizingFlow. This is basically a sequence of FlowOp. It is not exposed to users. \nNormalizingFlowModel. This is a container of the sequence of FlowOps and a prior distribution. NormalizingFlowModel is callable and can \"normalize\" the data distribution. We can also sample from NormalizingFlowModel, where the prior distribution is transformed to data distribution. ","category":"page"},{"location":"flow/#A-Simple-Example","page":"Normalizing Flows","title":"A Simple Example","text":"","category":"section"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Let's consider a simple example for transforming the two moons dataset to a univariate Gaussian distribution. First, we adapt a function from here and use it to generate the dataset","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"using Revise\nusing ADCME\nusing PyCall\nusing PyPlot\nusing Random\n\n# `nmoons` is adapted from https://github.com/wildart/nmoons\nfunction nmoons(::Type{T}, n::Int=100, c::Int=2;\n    shuffle::Bool=false, ε::Real=0.1, d::Int = 2,\n    translation::Vector{T}=zeros(T, d),\n    rotations::Dict{Pair{Int,Int},T} = Dict{Pair{Int,Int},T}(),\n    seed::Union{Int,Nothing}=nothing) where {T <: Real}\n    rng = seed === nothing ? Random.GLOBAL_RNG : MersenneTwister(Int(seed))\n    ssize = floor(Int, n/c)\n    ssizes = fill(ssize, c)\n    ssizes[end] += n - ssize*c\n    @assert sum(ssizes) == n \"Incorrect partitioning\"\n    pi = convert(T, π)\n    R(θ) = [cos(θ) -sin(θ); sin(θ) cos(θ)]\n    X = zeros(d,0)\n    for (i, s) in enumerate(ssizes)\n    circ_x = cos.(range(zero(T), pi, length=s)).-1.0\n    circ_y = sin.(range(zero(T), pi, length=s))\n    C = R(-(i-1)*(2*pi/c)) * hcat(circ_x, circ_y)'\n    C = vcat(C, zeros(d-2, s))\n    dir = zeros(d)-C[:,end] # translation direction\n    X = hcat(X, C .+ dir.*translation)\n    end\n    y = vcat([fill(i,s) for (i,s) in enumerate(ssizes)]...)\n    if shuffle\n        idx = randperm(rng, n)\n        X, y = X[:, idx], y[idx]\n    end\n    # Add noise to the dataset\n    if ε > 0.0\n        X += randn(rng, size(X)).*convert(T,ε/d)\n    end\n    # Rotate dataset\n    for ((i,j),θ) in rotations\n        X[[i,j],:] .= R(θ)*view(X,[i,j],:)\n    end\n    return X, y\nend\n\nfunction sample_moons(n)\n    X, _ = nmoons(Float64, n, 2, ε=0.05, d=2, translation=[0.25, -0.25])\n    return Array(X')\nend","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"(Image: )","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Next we construct a flow-based generative model, as follows:","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"prior = ADCME.MultivariateNormalDiag(loc=zeros(2))\nmodel = NormalizingFlowModel(prior, flows)","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"We can print the model by just type model in REPL:","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"( MultivariateNormalDiag )\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow\n        ↓\nAffineHalfFlow","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"Finally, we maximize the log llikelihood function using AdamOptimizer","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"\n\nx = placeholder(rand(128,2))\nzs, prior_logpdf, logdet = model(x)\nlog_pdf = prior_logpdf + logdet\nloss = -sum(log_pdf)\n\nmodel_samples = rand(model, 128*8)\nsess = Session(); init(sess)\nopt = AdamOptimizer(1e-4).minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    _, l = run(sess, [opt, loss], x=>sample_moons(128))\n    if mod(i,100)==0\n        @info i, l \n    end\nend","category":"page"},{"location":"flow/#Models","page":"Normalizing Flows","title":"Models","text":"","category":"section"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"ADCME has implemeted some popular flow-based generative models. For example, AffineConstantFlow, AffineHalfFlow, SlowMAF, MAF, IAF, ActNorm,  Invertible1x1Conv, NormalizingFlow, NormalizingFlowModel, and NeuralCouplingFlow. ","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"The following script shows how to usee those functions:","category":"page"},{"location":"flow/","page":"Normalizing Flows","title":"Normalizing Flows","text":"# Adapted from https://github.com/karpathy/pytorch-normalizing-flows\nusing Revise\nusing ADCME\nusing PyCall\nusing PyPlot\nusing Random\n\n# `nmoons` is adapted from https://github.com/wildart/nmoons\nfunction nmoons(::Type{T}, n::Int=100, c::Int=2;\n    shuffle::Bool=false, ε::Real=0.1, d::Int = 2,\n    translation::Vector{T}=zeros(T, d),\n    rotations::Dict{Pair{Int,Int},T} = Dict{Pair{Int,Int},T}(),\n    seed::Union{Int,Nothing}=nothing) where {T <: Real}\n    rng = seed === nothing ? Random.GLOBAL_RNG : MersenneTwister(Int(seed))\n    ssize = floor(Int, n/c)\n    ssizes = fill(ssize, c)\n    ssizes[end] += n - ssize*c\n    @assert sum(ssizes) == n \"Incorrect partitioning\"\n    pi = convert(T, π)\n    R(θ) = [cos(θ) -sin(θ); sin(θ) cos(θ)]\n    X = zeros(d,0)\n    for (i, s) in enumerate(ssizes)\n    circ_x = cos.(range(zero(T), pi, length=s)).-1.0\n    circ_y = sin.(range(zero(T), pi, length=s))\n    C = R(-(i-1)*(2*pi/c)) * hcat(circ_x, circ_y)'\n    C = vcat(C, zeros(d-2, s))\n    dir = zeros(d)-C[:,end] # translation direction\n    X = hcat(X, C .+ dir.*translation)\n    end\n    y = vcat([fill(i,s) for (i,s) in enumerate(ssizes)]...)\n    if shuffle\n        idx = randperm(rng, n)\n        X, y = X[:, idx], y[idx]\n    end\n    # Add noise to the dataset\n    if ε > 0.0\n        X += randn(rng, size(X)).*convert(T,ε/d)\n    end\n    # Rotate dataset\n    for ((i,j),θ) in rotations\n        X[[i,j],:] .= R(θ)*view(X,[i,j],:)\n    end\n    return X, y\nend\n\nfunction sample_moons(n)\n    X, _ = nmoons(Float64, n, 2, ε=0.05, d=2, translation=[0.25, -0.25])\n    return Array(X')\nend\n\n\n#------------------------------------------------------------------------------------------\n# RealNVP\nfunction mlp(x, k, id)\n    x = constant(x)\n    variable_scope(\"layer$k$id\") do\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 1)\n    end\n    return x\nend\nflows = [AffineHalfFlow(2, mod(i,2)==1, x->mlp(x, i, 0), x->mlp(x, i, 1)) for i = 0:8]\n\n\n#------------------------------------------------------------------------------------------\n# RealNVP\nfunction mlp(x, k, id)\n    x = constant(x)\n    variable_scope(\"layer$k$id\") do\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 24, activation=\"leaky_relu\")\n        x = dense(x, 1)\n    end\n    return x\nend\nflows = [AffineHalfFlow(2, mod(i,2)==1, x->mlp(x, i, 0), x->mlp(x, i, 1)) for i = 0:8]\n\n\n#------------------------------------------------------------------------------------------\n# NICE\n# function mlp(x, k, id)\n#     x = constant(x)\n#     variable_scope(\"layer$k$id\") do\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 1)\n#     end\n#     return x\n# end\n# flow1 = [AffineHalfFlow(2, mod(i,2)==1, missing, x->mlp(x, i, 1)) for i = 0:4]\n# flow2 = [AffineConstantFlow(2, shift=false)]\n# flows = [flow1;flow2]\n\n\n# SlowMAF\n#------------------------------------------------------------------------------------------\n# function mlp(x, k, id)\n#     x = constant(x)\n#     variable_scope(\"layer$k$id\") do\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 2)\n#     end\n#     return x\n# end\n# flows = [SlowMAF(2, mod(i,2)==1, [x->mlp(x, i, 0)]) for i = 0:3]\n\n# MAF\n#------------------------------------------------------------------------------------------ \n# flows = [MAF(2, mod(i,2)==1, [24, 24, 24], name=\"layer$i\") for i = 0:3]\n\n\n\n# IAF \n#------------------------------------------------------------------------------------------ \n# flows = [IAF(2, mod(i,2)==1, [24, 24, 24], name=\"layer$i\") for i = 0:3]\n# prior = ADCME.MultivariateNormalDiag(loc=zeros(2))\n# model = NormalizingFlowModel(prior, flows)\n\n# Insert ActNorm to any of the flows \n#------------------------------------------------------------------------------------------ \n# flow2 = [ActNorm(2, \"ActNorm$i\") for i = 1:length(flows)]\n# flows = permutedims(hcat(flow2, flows))[:]\n# # error()\n# # msample = rand(model,1)\n# # zs, prior_logprob, log_det = model([0.0040 0.4426])\n# # sess = Session(); init(sess)\n# # run(sess, msample)\n# # run(sess,zs)\n\n\n# GLOW\n#------------------------------------------------------------------------------------------ \n# function mlp(x, k, id)\n#     x = constant(x)\n#     variable_scope(\"layer$k$id\") do\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 24, activation=\"leaky_relu\")\n#         x = dense(x, 1)\n#     end\n#     return x\n# end\n# flows = [Invertible1x1Conv(2, \"conv$i\") for i = 0:2]\n# norms = [ActNorm(2, \"ActNorm$i\") for i = 0:2]\n# couplings = [AffineHalfFlow(2, mod(i, 2)==1, x->mlp(x, i, 0), x->mlp(x, i, 1)) for i = 0:length(flows)-1]\n# flows = permutedims(hcat(norms, flows, couplings))[:]\n\n#------------------------------------------------------------------------------------------ \n# Neural Splines Coupling\n# function mlp(x, k, id)\n#     x = constant(x)\n#     variable_scope(\"fc$k$id\") do\n#         x = dense(x, 16, activation=\"leaky_relu\")\n#         x = dense(x, 16, activation=\"leaky_relu\")\n#         x = dense(x, 16, activation=\"leaky_relu\")\n#         x = dense(x, 3K-1)\n#     end\n#     return x\n# end\n# K = 8\n# flows = [NeuralCouplingFlow(2, x->mlp(x, i, 0), x->mlp(x, i, 1), K) for i = 0:2]\n# convs = [Invertible1x1Conv(2, \"conv$i\") for i = 0:2]\n# norms = [ActNorm(2, \"ActNorm$i\") for i = 0:2]\n# flows = permutedims(hcat(norms, convs, flows))[:]\n\n#------------------------------------------------------------------------------------------ \n\n\nprior = ADCME.MultivariateNormalDiag(loc=zeros(2))\nmodel = NormalizingFlowModel(prior, flows)\n\n\nx = placeholder(rand(128,2))\nzs, prior_logpdf, logdet = model(x)\nlog_pdf = prior_logpdf + logdet\nloss = -sum(log_pdf)\n\nmodel_samples = rand(model, 128*8)\nsess = Session(); init(sess)\nopt = AdamOptimizer(1e-4).minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    _, l = run(sess, [opt, loss], x=>sample_moons(128))\n    if mod(i,100)==0\n        @info i, l \n    end\nend\n\nz = run(sess, model_samples[end]) \nx = sample_moons(128*8)\nscatter(x[:,1], x[:,2], c=\"b\", s=5, label=\"data\")\nscatter(z[:,1], z[:,2], c=\"r\", s=5, label=\"prior --> posterior\")\naxis(\"scaled\"); xlabel(\"x\"); ylabel(\"y\")#","category":"page"},{"location":"convnet/#Convolutional-Neural-Network","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"","category":"section"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"The convolutional neural network (CNN) is one of the key building blocks for deep learning. Mathematically, it is a linear operator whose actions are \"local\", in the sense that each output only depends on a small number of inputs. These actions share the same kernel functions, and the sharing reduces the number of parameters significantly. ","category":"page"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"One remarkable feature of CNNs is that they are massively parallelizable. The parallesim makes CNNs very efficient on GPUs, which are good at doing a large number of simple tasks at the same time. ","category":"page"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"In the practical use of CNNs, we can stick to images, which have four dimensions: batch number, height, width, and channel. A CNN transforms the images to another images with the same four dimensions, but possibly with different heights, widths, and channels. In the following script, we use CNNs instead of fully connected neural networks to train a variational autoencoder. Readers can compare the results with this article. ","category":"page"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"You are also encouraged to run the same script on CPUs and GPUs. You might get surprised at the huge performance gap for training CNNs on these two different computing environment. We also observe some CNN artifacts (the dots in the images).","category":"page"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"(Image: )","category":"page"},{"location":"convnet/","page":"Convolutional Neural Network","title":"Convolutional Neural Network","text":"using ADCME\nusing PyPlot\nusing MLDatasets\nusing ProgressMeter\nusing Images\n\nmutable struct Generator\n    dim_z::Int64\n    layers::Array\nend\n\nfunction Generator( dim_z::Int64 = 100, ngf::Int64 = 8)\n    layers = [\n        Conv2DTranspose(ngf*32, 4, 1, use_bias=false)\n        BatchNormalization()\n        relu\n        Conv2DTranspose(ngf*16, 4, 1, padding=\"same\", use_bias=false)\n        BatchNormalization()\n        relu\n        Conv2DTranspose(ngf*8, 4, 1, use_bias=false)\n        x -> pad(x, [\n            0 0 \n            0 1\n            0 1\n            0 0\n        ])\n        BatchNormalization()\n        relu\n        Conv2DTranspose(1, 4, 4, use_bias = false)\n        BatchNormalization()\n        sigmoid\n    ]\n    Generator(dim_z, layers)\nend\n\nfunction (g::Generator)(z)\n    z = constant(z)\n    z = reshape(z, (-1, 1, 1, g.dim_z))\n    @info size(z)\n    for l in g.layers\n        z = l(z)\n        @info size(z)\n    end\n    return z \nend\nfunction encoder(x, n_hidden, n_output, rate)\n    local μ, σ\n    variable_scope(\"encoder\") do \n        y = dense(x, n_hidden, activation = \"elu\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, n_hidden, activation = \"tanh\")\n        y = dropout(y, rate, ADCME.options.training.training)\n        y = dense(y, 2n_output)\n        μ = y[:, 1:n_output]\n        σ = 1e-6 + softplus(y[:,n_output+1:end])\n    end\n    return μ, σ\nend\n\nfunction decoder(z, n_hidden, n_output, rate)\n    Generator(dim_z)(z)\nend\n\nfunction autoencoder(xh, x, dim_img, dim_z, n_hidden, rate)\n    μ, σ = encoder(xh, n_hidden, dim_z, rate)\n    z = μ + σ .* tf.random_normal(size(μ), 0, 1, dtype=tf.float64)\n    y = decoder(z, n_hidden, dim_img, rate)\n    y = clip(y, 1e-8, 1-1e-8)\n    y = tf.reshape(y, (-1,32^2))\n\n    marginal_likelihood = sum(x .* log(y) + (1-x).*log(1-y), dims=2)\n    KL_divergence = 0.5 * sum(μ^2 + σ^2 - log(1e-8 + σ^2) - 1, dims=2)\n\n    marginal_likelihood = mean(marginal_likelihood)\n    KL_divergence = mean(KL_divergence)\n\n    ELBO = marginal_likelihood - KL_divergence\n    loss = -ELBO \n    return y, loss, -marginal_likelihood, KL_divergence\nend\n\nfunction step(epoch)\n    tx = train_x[1:batch_size,:]\n    @showprogress for i = 1:div(60000, batch_size)\n        idx = Array((i-1)*batch_size+1:i*batch_size)\n        run(sess, opt, x=>train_x[idx,:])\n    end\n    y_, loss_, ml_, kl_ = run(sess, [y, loss, ml, KL_divergence],\n            feed_dict = Dict(\n                ADCME.options.training.training=>false, \n                x => tx\n            ))\n    println(\"epoch $epoch: L_tot = $(loss_), L_likelihood = $(ml_), L_KL = $(kl_)\")\n\n    close(\"all\")\n    for i = 1:3\n        for j = 1:3\n            k = (i-1)*3 + j \n            img = reshape(y_[k,:], 32, 32)'|>Array\n            img = imresize(img, 28, 28)\n            subplot(3,3,k)\n            imshow(img)\n        end\n    end\n    savefig(\"result$epoch.png\")\nend\n\n\n\nn_hidden = 500\nrate = 0.1\ndim_z = 100\ndim_img = 32^2\nbatch_size = 32\nADCME.options.training.training = placeholder(true)\nx = placeholder(Float64, shape = [32, 32^2])\nxh = x\ny, loss, ml, KL_divergence = autoencoder(xh, x, dim_img, dim_z, n_hidden, rate)\nopt = AdamOptimizer(1e-3).minimize(loss)\n\ntrain_x_ = MNIST.traintensor(Float64);\ntrain_x = zeros(60000, 32^2)\nfor i = 1:60000\n    train_x[i,:] = imresize(train_x_[:, :, i], 32, 32)[:]\nend\n\nsess = Session(); init(sess)\nfor i = 1:100\n    @info i \n    step(i)\nend","category":"page"},{"location":"parallel/#Parallel-Computing","page":"Parallel Computing","title":"Parallel Computing","text":"","category":"section"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"The ADCME backend, TensorFlow, treats each operator as the smallest computation unit. Users are allowed to manually assign each operator to a specific device (GPU, CPU, or TPU). This is usually done with the @cpu device_id expr or @gpu device_id expr syntax, where device_id is the index of devices you want to place all operators and variables in expr. For example, if we want to create a variable a and compute sin(a) on GPU:0 we can write","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"@cpu 0 begin\n    global a = Variable(1.0)\n    global b = sin(a)\nend","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"If the device_id is missing, 0 is treated as default. ","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"@cpu begin\n    global a = Variable(1.0)\n    global b = sin(a)\nend","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"Custom Device Placement Functions","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"The above placement function is useful and simple for placing operators on certain GPU devices without changing original codes. However, sometimes we want to place certain operators on certain devices. This can be done by implementing a custom assign_to_device function. As an example, we want to place all Variables on CPU:0 while placing all other operators on GPU:0, the code has the following form","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"PS_OPS = [\"Variable\", \"VariableV2\", \"AutoReloadVariable\"]\nfunction assign_to_device(device, ps_device=\"/device:CPU:0\")\n    function _assign(op)\n        node_def = pybuiltin(\"isinstance\")(op, tf.NodeDef) ? op : op.node_def\n        if node_def.op in PS_OPS\n            return ps_device\n        else\n            return device\n        end\n    end\n\n    return _assign\nend","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"Then we can write something like","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"@pywith tf.device(assign_to_device(\"/device:GPU:0\")) begin\n    global a = Variable(1.0)\n    global b = sin(a)\nend","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"We can check the location of a and b by inspecting their device attributes","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"julia> a.device\n\"/device:CPU:0\"\n\njulia> b.device\n\"/device:GPU:0\"","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"Collocate Gradient Operators","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"When we call gradients, TensorFlow actually creates a set of new operators, one for each operator in the forward computation. By default, those operators are placed on the default device (GPU:0 if GPU is available; otherwise it's CPU:0). Sometimes we want to place the operators created by gradients on the same devices as the corresponding forward computation operators. For example, if the operator b (sin) in the last example is on GPU:0, we hope the corresponding gradient computation (cos) is also on GPU:0. This can be done by specifying colocate [colocate] keyword arguments in gradients:","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"@pywith tf.device(assign_to_device(\"/device:GPU:0\")) begin\n    global a = Variable(1.0)\n    global b = sin(a)\nend\n\n@pywith tf.device(\"/CPU:0\") begin\n    global c = cos(b)\nend\n\ng = gradients(c, a, colocate=true)","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"In the following figure, we show the effects of colocate of the above codes. The test code snippet is","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"g = gradients(c, a, colocate=true)\nsess = Session(); init(sess)\nrun_profile(sess, g+c)\nsave_profile(\"true.json\")\n\ng = gradients(c, a, colocate=false)\nsess = Session(); init(sess)\nrun_profile(sess, g+c)\nsave_profile(\"false.json\")","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"(Image: )","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"note: Note\nIf you use bn (batch normalization) on multi-GPUs, you must be careful to update the parameters in batch normalization on CPUs. This can be done by explicitly specify @pywith tf.device(\"/cpu:0\") begin\nglobal update_ops = get_collection(tf.GraphKeys.UPDATE_OPS)\nendand bind update_ops to an active operator (or explictly execute it in run(sess,...)).","category":"page"},{"location":"parallel/","page":"Parallel Computing","title":"Parallel Computing","text":"[colocate]: Unfortunately, in the TensorFlow APIs, \"collocate\" is spelt as \"colocate\". ","category":"page"},{"location":"sqlite3/#Introducing-ADCME-Database-and-SQL-Integration:-an-Efficient-Approach-to-Simulation-Data-Management","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"","category":"section"},{"location":"sqlite3/#Introduction","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introduction","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"If you have a massive number of simulations and results from different simulation parameters, to facilitate the data analysis and improve reproducibility, database and  Structured Query Language (SQL) are convenient and powerful ways for data management. ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Database allows simulation parameters and results to be stored in a permanent storage, and  records can be inserted, queried, updated, and deleted as we proceed in our research. Specifically, databases are usually designed in a way that we can concurrently read and write in a transactional manner, which ensures that the reads are writes are done correctly even in the case of data conflicts. This characteristic is very useful for parallel simulations. Another important feature of databases is \"indexing\". By indexing tables, we can manipute tables in a more efficient way. ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"(Image: )","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"SQL is a standad language for accessing and manipulating databases. The four main operations in SQLs are: create, insert, update, and delete. More advanced commands include where, groupby, join, etc. In ADCME, we implemented an interface to SQLite, a relational database management system contained in a C library. SQLite provides basic SQL engines, which is compliant to the SQL standard. One particular feature of SQLite is that the database is a single file or in-memory. This simplifies the client and server SQL logic, but bears the limitation of scalability. Nevertheless, SQLite is more than sufficient to store and manipulate our simulation parameters and results (typically a link to the data folder). ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"The introduction primarily focuses on some commonly used features of database management in ADCME. ","category":"page"},{"location":"sqlite3/#Database-Structure","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Database Structure","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"In ADCME, a database is created using Database. There are two types of database:","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"db1 = Database() # in-memory \ndb2 = Database(\"simulation.db\") # file ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"If you created a file-based database, whenever you finished operation, you need to commit to the database or close the database to make the changes effective. ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"commit(db2)\nclose(db2)","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"To execute a SQL command in the database, we can use execute command. In the next section, we list some commonly used operations. By default, commit is called after execute. Users can disable this by using ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"db1 = Database(commit_after_execute=false) # in-memory \ndb2 = Database(\"simulation.db\", commit_after_execute=false) # file ","category":"page"},{"location":"sqlite3/#Commonly-Used-Operations","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Commonly Used Operations","text":"","category":"section"},{"location":"sqlite3/#Create-a-Database","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Create a Database","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nCREATE TABLE simulation_parameters (\n    name real primary key,\n    dt real,\n    h real, \n    result text \n)\n\"\"\")","category":"page"},{"location":"sqlite3/#Insert-an-Record","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Insert an Record","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nINSERT INTO simulation_parameters VALUES\n(\"sim1\", 0.1, 0.01, \"file1.png\")\n\"\"\")","category":"page"},{"location":"sqlite3/#Insert-Many-Records","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Insert Many Records","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"params = [\n    (\"sim2\", 0.3, \"file2.png\"),\n    (\"sim3\", 0.5, \"file3.png\"),\n    (\"sim4\", 0.9, \"file4.png\")\n]\nexecute(db2, \"\"\"\nINSERT INTO simulation_parameters VALUES\n(?, ?, 0.01, ?)\n\"\"\", params)","category":"page"},{"location":"sqlite3/#Look-Up-Records","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Look Up Records","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"c = execute(db2, \"\"\"\nSELECT * from simulation_parameters\n\"\"\")\ncollect(c)","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Expected output:","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"(\"sim1\", 0.1, 0.01, \"file1.png\")\n(\"sim2\", 0.3, 0.01, \"file2.png\")\n(\"sim3\", 0.5, 0.01, \"file3.png\")\n(\"sim4\", 0.9, 0.01, \"file4.png\")","category":"page"},{"location":"sqlite3/#Delete-a-Record","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Delete a Record","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nDELETE from simulation_parameters WHERE name LIKE \"%3\"\n\"\"\")","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Now the records are","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"(\"sim1\", 0.1, 0.01, \"file1.png\")\n(\"sim2\", 0.3, 0.01, \"file2.png\")\n(\"sim4\", 0.9, 0.01, \"file4.png\")","category":"page"},{"location":"sqlite3/#Update-a-Record","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Update a Record","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nUPDATE simulation_parameters\nSET h = 0.2\nWHERE name = \"sim4\"\n\"\"\")","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Now the records are ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"(\"sim1\", 0.1, 0.01, \"file1.png\")\n(\"sim2\", 0.3, 0.01, \"file2.png\")\n(\"sim4\", 0.9, 0.2, \"file4.png\")","category":"page"},{"location":"sqlite3/#Insert-a-Conflict-Record","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Insert a Conflict Record","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Becase we set name as primary key, we cannot insert a record with the same name","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nINSERT INTO simulation_parameters VALUES\n(\"sim1\", 0.1, 0.1, \"file1_2.png\")\n\"\"\")","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"We have an error ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"IntegrityError('UNIQUE constraint failed: simulation_parameters.name')","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Alternatively, we can do ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nINSERT OR IGNORE INTO simulation_parameters VALUES\n(\"sim1\", 0.1, 0.1, \"file1_2.png\")\n\"\"\")","category":"page"},{"location":"sqlite3/#Querying-Meta-Data","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Querying Meta Data","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Get all tables in the database","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"keys(db2)","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Output:","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"\"simulation_parameters\"\n\"sqlite_autoindex_simulation_parameters_1\"","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"We can see a table that SQLites adds indexes to some fields: sqlite_autoindex_simulation_parameters_1. ","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Get column names in the database","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"keys(db2, \"simulation_parameters\")","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"Output:","category":"page"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"\"name\"\n\"dt\"\n\"h\"\n\"result\"","category":"page"},{"location":"sqlite3/#Drop-a-Table","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Drop a Table","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"execute(db2, \"\"\"\nDROP TABLE simulation_parameters\n\"\"\")","category":"page"},{"location":"sqlite3/#Next-Steps","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Next Steps","text":"","category":"section"},{"location":"sqlite3/","page":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","title":"Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management","text":"We introduced some basic usage of ADCME database and SQL integration for simulation data management. We used one common and lightweight database management system, SQLite, for managing data of moderate sizes. Due to SQL's wide adoption, it is possible to scale the data management system by adopting a full-fledged database, such as MySQL. In this case, developers can overload ADCME functions such as execute, commit, close, keys, etc., so that the top level codes requires little changes. ","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Core-Functions","page":"API Reference","title":"Core Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"ADCME.jl\", \"core.jl\", \"run.jl\"]","category":"page"},{"location":"api/#ADCME.control_dependencies-Tuple{Any,Union{Tuple, PyCall.PyObject, Array{PyCall.PyObject,N} where N}}","page":"API Reference","title":"ADCME.control_dependencies","text":"control_dependencies(f, ops::Union{Array{PyObject}, PyObject})\n\nExecutes all operations in ops before any operations created inside the block. \n\nop1 = tf.print(\"print op1\")\nop3 = tf.print(\"print op3\")\ncontrol_dependencies(op1) do\n    global op2 = tf.print(\"print op2\")\nend\nrun(sess, [op2,op3])\n\nIn this example, op1 must be executed before op2. But there is no guarantee when op3 will be executed.  There are several possible outputs of the program such as\n\nprint op3\nprint op1\nprint op2\n\nor \n\nprint op1\nprint op3\nprint op2\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_collection","page":"API Reference","title":"ADCME.get_collection","text":"get_collection(name::Union{String, Missing})\n\nReturns the collection with name name. If name is missing, returns all the trainable variables.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.get_mpi-Tuple{}","page":"API Reference","title":"ADCME.get_mpi","text":"get_mpi()\n\nReturns the MPI include directory and shared library.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_mpirun-Tuple{}","page":"API Reference","title":"ADCME.get_mpirun","text":"get_mpirun()\n\nReturns the default mpirun executable. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.has_gpu-Tuple{}","page":"API Reference","title":"ADCME.has_gpu","text":"has_gpu()\n\nChecks if GPU is available.\n\nnote: Note\nADCME will use GPU automatically if GPU is available. To disable GPU, set the environment variable ENV[\"CUDA_VISIBLE_DEVICES\"]=\"\" before importing ADCME \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.has_mpi","page":"API Reference","title":"ADCME.has_mpi","text":"has_mpi(verbose::Bool = true)\n\nDetermines whether MPI is installed. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.if_else-Tuple{Union{Bool, PyCall.PyObject, Array},Any,Any,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.if_else","text":"if_else(condition::Union{PyObject,Array,Bool}, fn1, fn2, args...;kwargs...)\n\nIf condition is a scalar boolean, it outputs fn1 or fn2 (a function with no input argument or a tensor) based on whether condition is true or false.\nIf condition is a boolean array, if returns condition .* fn1 + (1 - condition) .* fn2\n\ninfo: Info\nIf you encounter an error like this:tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have valueIt's probably that your code within if_else is not valid. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.independent-Tuple{PyCall.PyObject,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.independent","text":"independent(o::PyObject, args...; kwargs...)\n\nReturns o but when computing the gradients, the top gradients will not be back-propagated into dependent variables of o.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.reset_default_graph-Tuple{}","page":"API Reference","title":"ADCME.reset_default_graph","text":"reset_default_graph()\n\nResets the graph by removing all the operators. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.tensor-Tuple{String}","page":"API Reference","title":"ADCME.tensor","text":"tensor(s::String)\n\nReturns the tensor with name s. See tensorname.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.tensorname-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.tensorname","text":"tensorname(o::PyObject)\n\nReturns the name of the tensor. See tensor.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.while_loop-Tuple{Union{Function, PyCall.PyObject},Function,Union{PyCall.PyObject, Array{Any,N} where N, Array{PyCall.PyObject,N} where N}}","page":"API Reference","title":"ADCME.while_loop","text":"while_loop(condition::Union{PyObject,Function}, body::Function, loop_vars::Union{PyObject, Array{Any}, Array{PyObject}};\n    parallel_iterations::Int64=10, kwargs...)\n\nLoops over loop_vars while condition is true. This operator only creates one extra node to mark the loops in the computational graph.\n\nExample\n\nThe following script computes \n\nsum_i=1^10 i\n\nfunction condition(i, ta)\n    i <= 10\nend\nfunction body(i, ta)\n    u = read(ta, i-1)\n    ta = write(ta, i, u+1)\n    i+1, ta\nend\nta = TensorArray(10)\nta = write(ta, 1, constant(1.0))\ni = constant(2, dtype=Int32)\n_, out = while_loop(condition, body, [i, ta])\nsummation = stack(out)[10]\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.bind-Tuple{PyCall.PyObject,Vararg{Any,N} where N}","page":"API Reference","title":"Base.bind","text":"bind(op::PyObject, ops...)\n\nAdding operations ops to the dependencies of op. ops are guaranteed to be executed before op. The function is useful when we want to execute ops but ops is not  in the dependency of the final output. For example, if we want to print i each time i is evaluated\n\ni = constant(1.0)\nop = tf.print(i)\ni = bind(i, op)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.Session-Tuple","page":"API Reference","title":"ADCME.Session","text":"Session(args...; kwargs...)\n\nCreate an ADCME session. By default, ADCME will take up all the GPU resources at the start. If you want the GPU usage to grow on a need basis, before starting ADCME, you need to set the environment variable via\n\nENV[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n\nConfiguration\n\nSession accepts some runtime optimization configurations \n\nintra: Number of threads used within an individual op for parallelism\ninter: Number of threads used for parallelism between independent operations.\nCPU: Maximum number of CPUs to use. \nGPU: Maximum number of GPU devices to use\nsoft: Set to True/enabled to facilitate operations to be placed on CPU instead of GPU\n\nnote: Note\nCPU limits the number of CPUs being used, not the number of cores or threads.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.run_profile-Tuple","page":"API Reference","title":"ADCME.run_profile","text":"run_profile(args...;kwargs...)\n\nRuns the session with tracing information.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.save_profile","page":"API Reference","title":"ADCME.save_profile","text":"save_profile(filename::String=\"default_timeline.json\")\n\nSave the timeline information to file filename. \n\nOpen Chrome and navigate to chrome://tracing\nLoad the timeline file\n\n\n\n\n\n","category":"function"},{"location":"api/#Variables","page":"API Reference","title":"Variables","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"variable.jl\"]","category":"page"},{"location":"api/#ADCME.TensorArray","page":"API Reference","title":"ADCME.TensorArray","text":"TensorArray(size_::Int64=0, args...;kwargs...)\n\nConstructs a tensor array for while_loop.  \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.Variable-Tuple{Any}","page":"API Reference","title":"ADCME.Variable","text":"Variable(initial_value;kwargs...)\n\nConstructs a trainable tensor from value. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.cell-Tuple{Array,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.cell","text":"cell(arr::Array, args...;kwargs...)\n\nConstruct a cell tensor. \n\nExample\n\njulia> r = cell([[1.],[2.,3.]])\njulia> run(sess, r[1])\n1-element Array{Float32,1}:\n 1.0\njulia> run(sess, r[2])\n2-element Array{Float32,1}:\n 2.0\n 3.0\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.constant-Tuple{Any}","page":"API Reference","title":"ADCME.constant","text":"constant(value; kwargs...)\n\nConstructs a non-trainable tensor from value.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyCall.PyObject, Array{T,N} where N}}, Tuple{T}} where T<:Number","page":"API Reference","title":"ADCME.convert_to_tensor","text":"convert_to_tensor(o::Union{PyObject, Number, Array{T}, Missing, Nothing}; dtype::Union{Type, Missing}=missing) where T<:Number\nconvert_to_tensor(os::Array, dtypes::Array)\n\nConverts the input o to tensor. If o is already a tensor and dtype (if provided) is the same as that of o, the operator does nothing. Otherwise, convert_to_tensor converts the numerical array to a constant tensor or casts the data type. convert_to_tensor also accepts multiple tensors. \n\nExample\n\nconvert_to_tensor([1.0, constant(rand(2)), rand(10)], [Float32, Float64, Float32])\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_variable-Tuple{Union{Number, PyCall.PyObject, Array{#s326,N} where N where #s326<:Number}}","page":"API Reference","title":"ADCME.get_variable","text":"get_variable(o::Union{PyObject, Bool, Array{<:Number}}; \n    name::Union{String, Missing} = missing, \n    scope::String = \"\")\n\nCreates a new variable with initial value o. If name exists, get_variable returns the variable instead of create a new one.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_variable-Union{Tuple{Type}, Tuple{N}} where N","page":"API Reference","title":"ADCME.get_variable","text":"get_variable(dtype::Type;\nshape::Union{Array{<:Integer}, NTuple{N, <:Integer}}, \nname::Union{Missing,String} = missing\nscope::String = \"\")\n\nCreates a new variable with initial value o. If name exists, get_variable returns the variable instead of create a new one.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.gradient_checkpointing","page":"API Reference","title":"ADCME.gradient_checkpointing","text":"gradient_checkpointing(type::String=\"speed\")\n\nUses checkpointing scheme for gradients. \n\n'speed':  checkpoint all outputs of convolutions and matmuls. these ops are usually the most expensive,   so checkpointing them maximizes the running speed   (this is a good option if nonlinearities, concats, batchnorms, etc are taking up a lot of memory)\n'memory': try to minimize the memory usage   (currently using a very simple strategy that identifies a number of bottleneck tensors in the graph to checkpoint)\n'collection': look for a tensorflow collection named 'checkpoints', which holds the tensors to checkpoint\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.gradient_magnitude-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array}}","page":"API Reference","title":"ADCME.gradient_magnitude","text":"gradient_magnitude(l::PyObject, o::Union{Array, PyObject})\n\nReturns the gradient sum \n\nsqrtsum_i=1^n fracpartial lpartial o_i^2\n\nThis function is useful for debugging the training\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.gradients-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.gradients","text":"gradients(ys::PyObject, xs::PyObject; kwargs...)\n\nComputes the gradients of ys w.r.t xs. \n\nIf ys is a scalar, gradients returns the gradients with the same shape as xs.\nIf ys is a vector, gradients returns the Jacobian fracpartial ypartial x\n\nnote: Note\nThe second usage is not suggested since ADCME adopts reverse mode automatic differentiation.  Although in the case ys is a vector and xs is a scalar, gradients cleverly uses forward mode automatic differentiation, it requires that the second order gradients are implemented for relevant operators. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.gradients_colocate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N},Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.gradients_colocate","text":"gradients_colocate(loss::PyObject, xs::Union{PyObject, Array{PyObject}}, args...;use_locking::Bool = true, kwargs...)\n\nComputes the gradients of a scalar loss function loss with respect to xs. The gradients are colocated with respect to the forward pass.  This function is usually in distributed computing. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.hessian-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.hessian","text":"hessian(ys::PyObject, xs::PyObject; kwargs...)\n\nhessian computes the hessian of a scalar function f with respect to vector inputs xs. \n\nExample\n\nx = constant(rand(10))\ny = 0.5 * sum(x^2)\no = hessian(y, x)\n\nsess = Session(); init(sess)\nrun(sess, o) # should be an identity matrix\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.is_variable-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.is_variable","text":"is_variable(o::PyObject)\n\nDetermines whether o is a trainable variable.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.jacobian-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.jacobian","text":"jacobian(y::PyObject, x::PyObject)\n\nComputes the Jacobian matrix  J_ij = fracpartial y_ipartial x_j\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ones_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326<:Real},Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.ones_like","text":"ones_like(o::Union{PyObject,Real, Array{<:Real}}, args...; kwargs...)\n\nReturns a all-one tensor, which has the same size as o.\n\nExample\n\na = rand(100,10)\nb = ones_like(a)\n@assert run(sess, b)≈ones(100,10)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.placeholder-Tuple{Type}","page":"API Reference","title":"ADCME.placeholder","text":"placeholder(dtype::Type; kwargs...)\n\nCreates a placeholder of the type dtype.\n\nExample\n\na = placeholder(Float64, shape=[20,10])\nb = placeholder(Float64, shape=[]) # a scalar \nc = placeholder(Float64, shape=[nothing]) # a vector\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.placeholder-Tuple{Union{Number, PyCall.PyObject, Array}}","page":"API Reference","title":"ADCME.placeholder","text":"placeholder(o::Union{Number, Array, PyObject}; kwargs...)\n\nCreates a placeholder of the same type and size as o. o is the default value. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T","page":"API Reference","title":"ADCME.tensor","text":"tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T","page":"API Reference","title":"ADCME.tensor","text":"tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T\n\nConvert a generic array v to a tensor. For example, \n\nv = [0.0 constant(1.0) 2.0\n    constant(2.0) 0.0 1.0]\nu = tensor(v)\n\nu will be a 2times 3 tensor. \n\nnote: Note\nThis function is expensive. Use with caution.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.zeros_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326<:Real},Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.zeros_like","text":"zeros_like(o::Union{PyObject,Real, Array{<:Real}}, args...; kwargs...)\n\nReturns a all-zero tensor, which has the same size as o.\n\nExample\n\na = rand(100,10)\nb = zeros_like(a)\n@assert run(sess, b)≈zeros(100,10)\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.copy-Tuple{PyCall.PyObject}","page":"API Reference","title":"Base.copy","text":"copy(o::PyObject)\n\nCreates a tensor that has the same value that is currently stored in a variable.\n\nnote: Note\nThe output is a graph node that will have that value when evaluated. Any time you evaluate it, it will grab the current value of o. \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.read-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject}}","page":"API Reference","title":"Base.read","text":"read(ta::PyObject, i::Union{PyObject,Integer})\n\nReads data from TensorArray at index i.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.write-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject},PyCall.PyObject}","page":"API Reference","title":"Base.write","text":"write(ta::PyObject, i::Union{PyObject,Integer}, obj)\n\nWrites data obj to TensorArray at index i.\n\n\n\n\n\n","category":"method"},{"location":"api/#Random-Variables","page":"API Reference","title":"Random Variables","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"random.jl\"]","category":"page"},{"location":"api/#ADCME.categorical-Tuple{Union{Integer, PyCall.PyObject}}","page":"API Reference","title":"ADCME.categorical","text":"categorical(n::Union{PyObject, Integer}; kwargs...)\n\nkwargs has a keyword argument logits, a 2-D Tensor with shape [batch_size, num_classes].   Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.choice-Tuple{Union{PyCall.PyObject, Array},Union{Integer, PyCall.PyObject}}","page":"API Reference","title":"ADCME.choice","text":"choice(inputs::Union{PyObject, Array}, n_samples::Union{PyObject, Integer};replace::Bool=false)\n\nChoose n_samples samples from inputs with/without replacement. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.logpdf-Union{Tuple{T}, Tuple{T,Any}} where T<:ADCME.ADCMEDistribution","page":"API Reference","title":"ADCME.logpdf","text":"logpdf(dist::T, x) where T<:ADCMEDistribution\n\nReturns the log(prob) for a distribution dist.\n\n\n\n\n\n","category":"method"},{"location":"api/#Sparse-Matrix","page":"API Reference","title":"Sparse Matrix","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"sparse.jl\"]","category":"page"},{"location":"api/#ADCME.SparseTensor","page":"API Reference","title":"ADCME.SparseTensor","text":"SparseTensor\n\nA sparse matrix object. It has two fields \n\no: internal data structure \n_diag: true if the sparse matrix is marked as \"diagonal\".\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}","page":"API Reference","title":"ADCME.SparseTensor","text":"SparseTensor(A::SparseMatrixCSC)\nSparseTensor(A::Array{Float64, 2})\n\nCreates a SparseTensor from numerical arrays. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S},Union{Nothing, PyCall.PyObject, S}}} where S<:Integer where T<:Integer","page":"API Reference","title":"ADCME.SparseTensor","text":"SparseTensor(I::Union{PyObject,Array{T,1}}, J::Union{PyObject,Array{T,1}}, V::Union{Array{Float64,1}, PyObject}, m::Union{S, PyObject, Nothing}=nothing, n::Union{S, PyObject, Nothing}=nothing) where {T<:Integer, S<:Integer}\n\nConstructs a sparse tensor.  Examples:\n\nii = [1;2;3;4]\njj = [1;2;3;4]\nvv = [1.0;1.0;1.0;1.0]\ns = SparseTensor(ii, jj, vv, 4, 4)\ns = SparseTensor(sprand(10,10,0.3))\n\n\n\n\n\n","category":"method"},{"location":"api/#Core.Array-Tuple{SparseTensor}","page":"API Reference","title":"Core.Array","text":"Array(A::SparseTensor)\n\nConverts a sparse tensor A to dense matrix. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.RawSparseTensor-Union{Tuple{T}, Tuple{Union{Array{T,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Int64, PyCall.PyObject},Union{Int64, PyCall.PyObject}}} where T<:Integer","page":"API Reference","title":"ADCME.RawSparseTensor","text":"RawSparseTensor(indices::Union{PyObject,Array{T,2}}, value::Union{PyObject,Array{Float64,1}},\n    m::Union{PyObject,Int64}, n::Union{PyObject,Int64}; is_diag::Bool=false) where T<:Integer\n\nA convenient wrapper for making custom operators. Here indices is 0-based. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.SparseAssembler","page":"API Reference","title":"ADCME.SparseAssembler","text":"SparseAssembler(handle::Union{PyObject, <:Integer}, n::Union{PyObject, <:Integer}, tol::Union{PyObject, <:Real}=0.0)\n\nCreates a SparseAssembler for accumulating row, col, val for sparse matrices. \n\nhandle: an integer handle for creating a sparse matrix. If the handle already exists, SparseAssembler return the existing sparse matrix handle. If you are creating different sparse matrices, the handles should be different. \nn: Number of rows of the sparse matrix. \ntol (optional): Tolerance. SparseAssembler will treats any values less than tol as zero. \n\nExample 1\n\nhandle = SparseAssembler(100, 5, 1e-8)\nop1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])\nop2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])\nJ = assemble(5, 5, [op1;op2])\n\nJ will be a SparseTensor object. \n\nExample 2\n\nhandle = SparseAssembler(0, 5)\nop1 = accumulate(handle, 1, [1;2;3], ones(3))\nop2 = accumulate(handle, 1, [3], [1.])\nop3 = accumulate(handle, 2, [1;3], ones(2))\nJ = assemble(5, 5, [op1;op2;op3]) # op1, op2, op3 are parallel\nArray(run(sess, J))≈[1.0  1.0  2.0  0.0  0.0\n                1.0  0.0  1.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0\n                0.0  0.0  0.0  0.0  0.0]\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.assemble-Tuple{Union{PyCall.PyObject, #s327} where #s327<:Integer,Union{PyCall.PyObject, #s326} where #s326<:Integer,PyCall.PyObject}","page":"API Reference","title":"ADCME.assemble","text":"assemble(m::Union{PyObject, <:Integer}, n::Union{PyObject, <:Integer}, ops::PyObject)\n\nAssembles the sparse matrix from the ops created by accumulate. ops is either a single output from accumulate, or concated from several ops\n\nop1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])\nop2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])\nop = [op1;op2] # equivalent to `vcat([op1, op2]...)`\n\nm and n are rows and columns of the sparse matrix. \n\nSee SparseAssembler for an example.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.compress-Tuple{SparseTensor}","page":"API Reference","title":"ADCME.compress","text":"compress(A::SparseTensor)\n\nCompresses the duplicated index in A. \n\nExample\n\nusing ADCME\nindices = [\n    1 1 \n    1 1\n    2 2\n    3 3\n]\nv = [1.0;1.0;1.0;1.0]\nA = SparseTensor(indices[:,1], indices[:,2], v, 3, 3)\nAc = compress(A)\nsess = Session(); init(sess)\n\nrun(sess, A.o.indices) # expected: [0 0;0 0;1 1;2 2]\nrun(sess, A.o.values) # expected: [1.0;1.0;1.0;1.0]\n\n\nrun(sess, Ac.o.indices) # expected: [0 0;1 1;2 2]\nrun(sess, Ac.o.values) # expected: [2.0;1.0;1.0]\n\nnote: Note\nThe indices of A should be sorted. compress does not check the validity of the input arguments.  \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.find-Tuple{SparseTensor}","page":"API Reference","title":"ADCME.find","text":"find(s::SparseTensor)\n\nReturns the row, column and values for sparse tensor s.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_add-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T<:Real where S<:Real","page":"API Reference","title":"ADCME.scatter_add","text":"scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},\ni1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},\ni2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},\nB::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S<:Real,T<:Real}\n\nAdds B to a subblock of a sparse matrix A. Equivalently, \n\nA[i1, i2] += B\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{S}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T<:Real where S<:Real","page":"API Reference","title":"ADCME.scatter_update","text":"scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},\ni1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},\ni2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},\nB::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S<:Real,T<:Real}\n\nUpdates a subblock of a sparse matrix by B. Equivalently, \n\nA[i1, i2] = B\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.solve-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}","page":"API Reference","title":"ADCME.solve","text":"solve(A_factorized::Tuple{SparseTensor, PyObject}, rhs::Union{Array{Float64,1}, PyObject})\n\nSolves the equation A_factorized * x = rhs using the factorized sparse matrix. See factorize.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.spdiag-Tuple{Int64}","page":"API Reference","title":"ADCME.spdiag","text":"spdiag(n::Int64)\n\nConstructs a sparse identity matrix of size ntimes n, which is equivalent to spdiag(n, 0=>ones(n))\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.spdiag-Tuple{Integer,Vararg{Pair,N} where N}","page":"API Reference","title":"ADCME.spdiag","text":"spdiag(m::Integer, pair::Pair...)\n\nConstructs a square mtimes m SparseTensor from pairs of the form \n\noffset => array \n\nExample\n\nSuppose we want to construct a 10times 10 tridiagonal matrix, where the lower off-diagonals are all -2,  the diagonals are all 2, and the upper off-diagonals are all 3, the corresponding Julia code is \n\nspdiag(10, -1=>-2*ones(9), 0=>2*ones(10), 1=>3ones(9))\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.spdiag-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.spdiag","text":"spdiag(o::PyObject)\n\nConstructs a sparse diagonal matrix where the diagonal entries are o, which is equivalent to spdiag(length(o), 0=>o)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.spzero","page":"API Reference","title":"ADCME.spzero","text":"spzero(m::Int64, n::Union{Missing, Int64}=missing)\n\nConstructs a empty sparse matrix of size mtimes n. n=m if n is missing\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.trisolve-NTuple{4,Union{Array{Float64,1}, PyCall.PyObject}}","page":"API Reference","title":"ADCME.trisolve","text":"trisolve(a::Union{PyObject, Array{Float64,1}},b::Union{PyObject, Array{Float64,1}},\n    c::Union{PyObject, Array{Float64,1}},d::Union{PyObject, Array{Float64,1}})\n\nSolves a tridiagonal matrix linear system. The equation is as follows\n\na_i x_i-1 + b_i x_i + c_i x_i+1 = d_i\n\nIn the matrix format, \n\nbeginbmatrix\nb_1  c_1  0  \na_2  b_2  c_2   \n    a_3  b_3   \n               c_n-1 \n0   a_n  b_n  \nendbmatrixbeginbmatrix\nx_1\nx_2\nvdots \nx_n \nendbmatrix = beginbmatrix\nd_1\nd_2\nvdots\nd_nendbmatrix\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.:\\","page":"API Reference","title":"Base.:\\","text":"\\(A::SparseTensor, o::PyObject, method::String=\"SparseLU\")\n\nSolves the linear equation  A x = o\n\nMethod\n\nFor square matrices A, one of the following methods is available\n\nauto: using the solver specified by ADCME.options.sparse.solver\nSparseLU\nSparseQR\nSimplicialLDLT\nSimplicialLLT\n\nnote: Note\nIn the case o is 2 dimensional, \\ is understood as \"batched solve\". o must have size n_b times m, and  A has a size mtimes n. It returns the solution matrix of size n_b times ns_i = A^-1 o_i\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.:\\-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}","page":"API Reference","title":"Base.:\\","text":"Base.:\\(A_factorized::Tuple{SparseTensor, PyObject}, rhs::Union{Array{Float64,1}, PyObject})\n\nA convenient overload for solve. See factorize.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.accumulate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, #s327} where #s327<:Integer,Union{PyCall.PyObject, Array{#s326,N} where N where #s326<:Integer},Union{PyCall.PyObject, Array{#s263,N} where N where #s263<:Real}}","page":"API Reference","title":"Base.accumulate","text":"accumulate(handle::PyObject, row::Union{PyObject, <:Integer}, cols::Union{PyObject, Array{<:Integer}}, vals::Union{PyObject, Array{<:Real}})\n\nAccumulates row-th row. It adds the value to the sparse matrix\n\nfor k = 1:length(cols)\n    A[row, cols[k]] += vals[k]\nend\n\nhandle is the handle created by SparseAssembler. \n\nSee SparseAssembler for an example.\n\nnote: Note\nThe function accumulate returns a op::PyObject. Only when op is executed, the nonzero values are populated into the sparse matrix. \n\n\n\n\n\n","category":"method"},{"location":"api/#LinearAlgebra.factorize","page":"API Reference","title":"LinearAlgebra.factorize","text":"factorize(A::Union{SparseTensor, SparseMatrixCSC}, max_cache_size::Int64 = 999999)\n\nFactorizes A for sparse matrix solutions. max_cache_size specifies the maximum cache sizes in the C++ kernels,  which determines the maximum number of factorized matrices.  The function returns the factorized matrix, which is basically Tuple{SparseTensor, PyObject}. \n\nExample\n\nA = sprand(10,10,0.7)\nAfac = factorize(A) # factorizing the matrix\nrun(sess, Afac\\rand(10)) # no factorization, solving the equation\nrun(sess, Afac\\rand(10)) # no factorization, solving the equation\n\n\n\n\n\n","category":"function"},{"location":"api/#Operations","page":"API Reference","title":"Operations","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"ops.jl\"]","category":"page"},{"location":"api/#ADCME.argsort-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.argsort","text":"argsort(o::PyObject; \nstable::Bool = false, rev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)\n\nReturns the indices of a tensor that give its sorted order along an axis.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.batch_matmul-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.batch_matmul","text":"batch_matmul(o1::PyObject, o2::PyObject)\n\nComputes o1[i,:,:] * o2[i, :] or o1[i,:,:] * o2[i, :, :] for each index i.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.clip-Tuple{Union{Array{Any,N} where N, Array{PyCall.PyObject,N} where N},Any,Any,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.clip","text":"clip(o::Union{Array{Any}, Array{PyObject}}, vmin, vmax, args...;kwargs...)\n\nClips the values of o to the range [vmin, vmax]\n\nExample\n\na = constant(3.0)\na = clip(a, 1.0, 2.0)\nb = constant(rand(3))\nb = clip(b, 0.5, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.cvec-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.cvec","text":"rvec(o::PyObject; kwargs...)\n\nVectorizes the tensor o to a column vector, assuming column major.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.pad-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326<:Real},Array{Int64,2},Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.pad","text":"pad(o::PyObject, paddings::Array{Int64, 2}, args...; kwargs...)\n\nPads o with values on the boundary. \n\nExample\n\no = rand(3,3)\no = pad(o, [1 4      # first dimension\n             2 3])   # second dimension\nrun(sess, o)\n\nExpected:\n\n8×8 Array{Float64,2}:\n 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0\n 0.0  0.0  0.250457  0.666905  0.823611  0.0  0.0  0.0\n 0.0  0.0  0.23456   0.625145  0.646713  0.0  0.0  0.0\n 0.0  0.0  0.552415  0.226417  0.67802   0.0  0.0  0.0\n 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0\n 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0\n 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0\n 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.pmap-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}","page":"API Reference","title":"ADCME.pmap","text":"pmap(fn::Function, o::Union{Array{PyObject}, PyObject})\n\nParallel for loop. There should be no data dependency between different iterations.\n\nExample\n\nx = constant(ones(10))\ny1 = pmap(x->2.0*x, x)\ny2 = pmap(x->x[1]+x[2], [x,x])\ny3 = pmap(1:10, x) do z\n    i = z[1]\n    xi = z[2]\n    xi + cast(Float64, i)\nend\nrun(sess, y1)\nrun(sess, y2)\nrun(sess, y3)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rollmean-Tuple{Any,Int64}","page":"API Reference","title":"ADCME.rollmean","text":"rollmean(u, window::Int64)\n\nReturns the rolling mean given a window size m\n\no_k = fracsum_i=k^k+m-1 u_im\n\nRolling functions in ADCME:\n\nrollmean: rolling mean \nrollsum: rolling sum \nrollvar: rolling variance \nrollstd: rolling standard deviation\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rollstd-Tuple{Any,Int64}","page":"API Reference","title":"ADCME.rollstd","text":"rollstd(u, window::Int64)\n\nReturns the rolling standard deviation given a window size m\n\no_k = sqrtfracsum_i=k^k+m-1 (u_i - m_i)^2m-1\n\nHere m_i is the rolling mean computed using rollmean\n\nRolling functions in ADCME:\n\nrollmean: rolling mean \nrollsum: rolling sum \nrollvar: rolling variance \nrollstd: rolling standard deviation\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rollsum-Tuple{Any,Int64}","page":"API Reference","title":"ADCME.rollsum","text":"rollsum(u, window::Int64)\n\nReturns the rolling sum given a window size m\n\no_k = sum_i=k^k+m-1 u_i\n\nRolling functions in ADCME:\n\nrollmean: rolling mean \nrollsum: rolling sum \nrollvar: rolling variance \nrollstd: rolling standard deviation\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rollvar-Tuple{Any,Int64}","page":"API Reference","title":"ADCME.rollvar","text":"rollvar(u, window::Int64)\n\nReturns the rolling variance given a window size m\n\no_k = fracsum_i=k^k+m-1 (u_i - m_i)^2m-1\n\nHere m_i is the rolling mean computed using rollmean\n\nRolling functions in ADCME:\n\nrollmean: rolling mean \nrollsum: rolling sum \nrollvar: rolling variance \nrollstd: rolling standard deviation\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rvec-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.rvec","text":"rvec(o::PyObject; kwargs...)\n\nVectorizes the tensor o to a row vector, assuming column major.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_add","text":"scatter_add(A::PyObject, \n    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nA[xind, yind] += updates\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_add","text":"scatter_add(a::PyObject, \n    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nUpdates array add\n\na[indices] += updates\n\nExample\n\nJulia:\n\nA[[1;2;3]] += rand(3)\nA[2] += 1.0\n\nADCME:\n\nA = scatter_add(A, [1;2;3], rand(3))\nA = scatter_add(A, 2, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_sub","text":"scatter_add(A::PyObject, \n    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nA[xind, yind] -= updates\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_sub","text":"scatter_sub(a::PyObject, \n    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nUpdates array a\n\na[indices] -= updates\n\nExample\n\nJulia:\n\nA[[1;2;3]] -= rand(3)\nA[2] -= 1.0\n\nADCME:\n\nA = scatter_sub(A, [1;2;3], rand(3))\nA = scatter_sub(A, 2, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_update","text":"scatter_update(A::PyObject, \n    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nA[xind, yind] = updates\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329<:Real}}","page":"API Reference","title":"ADCME.scatter_update","text":"scatter_update(a::PyObject, \n    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},\n    updates::Union{Array{<:Real}, Real, PyObject})\n\nUpdates array a\n\na[indices] = updates\n\nExample\n\nJulia:\n\nA[[1;2;3]] = rand(3)\nA[2] = 1.0\n\nADCME:\n\nA = scatter_update(A, [1;2;3], rand(3))\nA = scatter_update(A, 2, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.set_shape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328<:Integer}}} where N","page":"API Reference","title":"ADCME.set_shape","text":"set_shape(o::PyObject, s::Union{Array{<:Integer}, Tuple{Vararg{<:Integer, N}}}) where N\nset_shape(o::PyObject, s::Integer...)\n\nSets the shape of o to s. s must be the actual shape of o. This function is used to convert a  tensor with unknown dimensions to a tensor with concrete dimensions. \n\nExample\n\na = placeholder(Float64, shape=[nothing, 10])\nb = set_shape(a, 3, 10)\nrun(sess, b, a=>rand(3,10)) # OK \nrun(sess, b, a=>rand(5,10)) # Error\nrun(sess, b, a=>rand(10,3)) # Error\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.softmax_cross_entropy_with_logits-Tuple{Union{PyCall.PyObject, Array},Union{PyCall.PyObject, Array}}","page":"API Reference","title":"ADCME.softmax_cross_entropy_with_logits","text":"softmax_cross_entropy_with_logits(logits::Union{Array, PyObject}, labels::Union{Array, PyObject})\n\nComputes softmax cross entropy between logits and labels\n\nlogits is typically the output of a linear layer. For example,\n\nlogits = [\n    0.124575  0.511463   0.945934\n    0.538054  0.0749339  0.187802\n    0.355604  0.052569   0.177009\n    0.896386  0.546113   0.456832\n]\nlabels = [2;1;2;3]\n\ninfo: Info\nThe values of labels are from  {1,2,...,num_classes}. Here num_classes is the number of columns in logits.\n\nThe predicted labels associated with logits is \n\nargmax(softmax(logits), dims = 2)\n\nLabels can also be one hot vectors \n\nlabels = [0 1\n          1 0\n          0 1\n          0 1]\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.solve_batch-Tuple{Union{PyCall.PyObject, Array{#s327,2} where #s327<:Real},Union{PyCall.PyObject, Array{#s326,2} where #s326<:Real}}","page":"API Reference","title":"ADCME.solve_batch","text":"solve_batch(A::Union{PyObject, Array{<:Real, 2}}, rhs::Union{PyObject, Array{<:Real,2}})\n\nSolves Ax = b for a batch of right hand sides. \n\nA: a mtimes n matrix, where mgeq n\nrhs: a n_btimes m matrix. Each row is a new right hand side to solve. \n\nThe returned value is a n_btimes n matrix. \n\nExample\n\na = rand(10,5)\nb = rand(100, 10)\nsol = solve_batch(a, b)\n@assert run(sess, sol) ≈ (a\\b')'\n\nnote: Note\nInternally, the matrix A is factorized first and then the factorization is used to solve multiple right hand side.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.stack-Tuple{PyCall.PyObject}","page":"API Reference","title":"ADCME.stack","text":"stack(o::PyObject)\n\nConvert a TensorArray o to a normal tensor. The leading dimension is the size of the tensor array. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.topk","page":"API Reference","title":"ADCME.topk","text":"topk(o::PyObject, k::Union{PyObject,Integer}=1;\n    sorted::Bool=true, name::Union{Nothing,String}=nothing)\n\nFinds values and indices of the k largest entries for the last dimension. If sorted=true the resulting k elements will be sorted by the values in descending order.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.vector-Union{Tuple{T}, Tuple{Union{PyCall.PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Int64, PyCall.PyObject}}} where T<:Integer","page":"API Reference","title":"ADCME.vector","text":"vector(i::Union{Array{T}, PyObject, UnitRange, StepRange}, v::Union{Array{Float64},PyObject},s::Union{Int64,PyObject})\n\nReturns a vector V with length s such that\n\nV[i] = v\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.adjoint-Tuple{PyCall.PyObject}","page":"API Reference","title":"Base.adjoint","text":"adjoint(o::PyObject; kwargs...)\n\nReturns the conjugate adjoint of o.  When the dimension of o is greater than 2, only the last two dimensions are permuted, i.e., permutedims(o, [1,2,...,n,n-1])\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.map-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}","page":"API Reference","title":"Base.map","text":"map(fn::Function, o::Union{Array{PyObject},PyObject};\nkwargs...)\n\nApplies fn to each element of o. \n\no∈Array{PyObject} : returns [fn(x) for x in o]\no∈PyObject : splits o according to the first dimension and then applies fn. \n\nExample\n\na = constant(rand(10,5))\nb = map(x->sum(x), a) # equivalent to `sum(a, dims=2)`\n\nnote: Note\nIf fn is a multivariate function, we need to specify the output type using dtype keyword. For example, a = constant(ones(10))\nb = constant(ones(10))\nfn = x->x[1]+x[2]\nc = map(fn, [a, b], dtype=Float64)\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.reshape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328<:Integer}}} where N","page":"API Reference","title":"Base.reshape","text":"reshape(o::PyObject, s::Union{Array{<:Integer}, Tuple{Vararg{<:Integer, N}}}) where N \nreshape(o::PyObject, s::Integer; kwargs...)\nreshape(o::PyObject, m::Integer, n::Integer; kwargs...)\nreshape(o::PyObject, ::Colon, n::Integer)\nreshape(o::PyObject, n::Integer, ::Colon)\n\nReshapes the tensor according to row major if the \"TensorFlow style\" syntax is used; otherwise  reshaping according to column major is assumed. \n\nExample\n\nreshape(a, [10,5]) # row major \nreshape(a, 10, 5) # column major \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.reverse-Tuple{PyCall.PyObject}","page":"API Reference","title":"Base.reverse","text":"reverse(o::PyObject, kwargs...)\n\nGiven a tensor o, and an index dims representing the set of dimensions of tensor to reverse.\n\nExample\n\na = rand(10,2)\nA = constant(a)\n@assert run(sess, reverse(A, dims=1)) == reverse(a, dims=1)\n@assert run(sess, reverse(A, dims=2)) == reverse(a, dims=2)\n@assert run(sess, reverse(A, dims=-1)) == reverse(a, dims=2)\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.sort-Tuple{PyCall.PyObject}","page":"API Reference","title":"Base.sort","text":"Base.:sort(o::PyObject; \nrev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)\n\nSort a multidimensional array o along the given dimension. \n\nrev: true for DESCENDING and false (default) for ASCENDING\ndims: -1 for last dimension. \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.split-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject, Array{#s326,N} where N where #s326<:Integer}}","page":"API Reference","title":"Base.split","text":"split(o::PyObject, \n    num_or_size_splits::Union{Integer, Array{<:Integer}, PyObject}; kwargs...)\n\nSplits o according to num_or_size_splits\n\nExample 1\n\na = constant(rand(10,8,6))\nsplit(a, 5)\n\nExpected output:\n\n5-element Array{PyCall.PyObject,1}:\n PyObject <tf.Tensor 'split_5:0' shape=(2, 8, 6) dtype=float64>\n PyObject <tf.Tensor 'split_5:1' shape=(2, 8, 6) dtype=float64>\n PyObject <tf.Tensor 'split_5:2' shape=(2, 8, 6) dtype=float64>\n PyObject <tf.Tensor 'split_5:3' shape=(2, 8, 6) dtype=float64>\n PyObject <tf.Tensor 'split_5:4' shape=(2, 8, 6) dtype=float64>\n\nExample 2\n\na = constant(rand(10,8,6))\nsplit(a, [4,3,1], dims=2)\n\nExpected output:\n\n3-element Array{PyCall.PyObject,1}:\n PyObject <tf.Tensor 'split_6:0' shape=(10, 4, 6) dtype=float64>\n PyObject <tf.Tensor 'split_6:1' shape=(10, 3, 6) dtype=float64>\n PyObject <tf.Tensor 'split_6:2' shape=(10, 1, 6) dtype=float64>\n\nExample 3\n\na = constant(rand(10,8,6))\nsplit(a, 3, dims=3)\n\nExpected output:\n\n3-element Array{PyCall.PyObject,1}:\n PyObject <tf.Tensor 'split_7:0' shape=(10, 8, 2) dtype=float64>\n PyObject <tf.Tensor 'split_7:1' shape=(10, 8, 2) dtype=float64>\n PyObject <tf.Tensor 'split_7:2' shape=(10, 8, 2) dtype=float64>\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.vec-Tuple{PyCall.PyObject}","page":"API Reference","title":"Base.vec","text":"vec(o::PyObject;kwargs...)\n\nVectorizes the tensor o assuming column major. \n\n\n\n\n\n","category":"method"},{"location":"api/#LinearAlgebra.svd-Tuple{PyCall.PyObject,Vararg{Any,N} where N}","page":"API Reference","title":"LinearAlgebra.svd","text":"svd(o::PyObject, args...; kwargs...)\n\nReturns a TFSVD structure which holds the following data structures\n\nS::PyObject\nU::PyObject\nV::PyObject\nVt::PyObject\n\nWe have the equality o = USV\n\nExample\n\nA = rand(10,20)\nr = svd(constant(A))\nA2 = r.U*diagm(r.S)*r.Vt # The value of `A2` should be equal to `A`\n\n\n\n\n\n","category":"method"},{"location":"api/#IO","page":"API Reference","title":"IO","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"io.jl\"]","category":"page"},{"location":"api/#ADCME.Diary","page":"API Reference","title":"ADCME.Diary","text":"Diary(suffix::Union{String, Nothing}=nothing)\n\nCreates a diary at a temporary directory path. It returns a writer and the corresponding directory path\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.activate","page":"API Reference","title":"ADCME.activate","text":"activate(sw::Diary, port::Int64=6006)\n\nRunning Diary at http://localhost:port.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.load","page":"API Reference","title":"ADCME.load","text":"load(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)\n\nLoads the values of variables to the session sess from the file file. If vars is nothing, it loads values to all the trainable variables. See also save, load\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.load-Tuple{Diary,String}","page":"API Reference","title":"ADCME.load","text":"load(sw::Diary, dirp::String)\n\nLoads Diary from dirp.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.logging-Tuple{Union{Nothing, String},Vararg{PyCall.PyObject,N} where N}","page":"API Reference","title":"ADCME.logging","text":"logging(file::Union{Nothing,String}, o::PyObject...; summarize::Int64 = 3, sep::String = \" \")\n\nLogging o to file. This operator must be used with bind. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.pload-Tuple{String}","page":"API Reference","title":"ADCME.pload","text":"pload(file::String)\n\nLoads a Python objection from file. See also psave\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.print_tensor","page":"API Reference","title":"ADCME.print_tensor","text":"print_tensor(in::Union{PyObject, Array{Float64,2}})\n\nPrints the tensor in\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.psave-Tuple{PyCall.PyObject,String}","page":"API Reference","title":"ADCME.psave","text":"psave(o::PyObject, file::String)\n\nSaves a Python objection o to file. See also pload\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.save","page":"API Reference","title":"ADCME.save","text":"save(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)\n\nSaves the values of vars in the session sess. The result is written into file as a dictionary. If vars is nothing, it saves all the trainable variables. See also save, load\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.save-Tuple{Diary,String}","page":"API Reference","title":"ADCME.save","text":"save(sw::Diary, dirp::String)\n\nSaves Diary to dirp.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.scalar","page":"API Reference","title":"ADCME.scalar","text":"scalar(o::PyObject, name::String)\n\nReturns a scalar summary object.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}","page":"API Reference","title":"Base.write","text":"write(sw::Diary, step::Int64, cnt::Union{String, Array{String}})\n\nWrites to Diary.\n\n\n\n\n\n","category":"method"},{"location":"api/#Optimization","page":"API Reference","title":"Optimization","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"optim.jl\"]","category":"page"},{"location":"api/#ADCME.AdadeltaOptimizer","page":"API Reference","title":"ADCME.AdadeltaOptimizer","text":"AdadeltaOptimizer(learning_rate=1e-3;kwargs...)\n\nSee AdamOptimizer for descriptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.AdagradDAOptimizer","page":"API Reference","title":"ADCME.AdagradDAOptimizer","text":"AdagradDAOptimizer(learning_rate=1e-3; global_step, kwargs...)\n\nSee AdamOptimizer for descriptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.AdagradOptimizer","page":"API Reference","title":"ADCME.AdagradOptimizer","text":"AdagradOptimizer(learning_rate=1e-3;kwargs...)\n\nSee AdamOptimizer for descriptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.AdamOptimizer","page":"API Reference","title":"ADCME.AdamOptimizer","text":"AdamOptimizer(learning_rate=1e-3;kwargs...)\n\nConstructs an ADAM optimizer. \n\nExample\n\nlearning_rate = 1e-3\nopt = AdamOptimizer(learning_rate).minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:1000\n    _, l = run(sess, [opt, loss])\n    @info \"Iteration $i, loss = $l\")\nend\n\nDynamical Learning Rate\n\nWe can also use dynamical learning rate. For example, if we want to use a learning rate l_t = frac11+t, we have \n\nlearning_rate = placeholder(1.0)\nopt = AdamOptimizer(learning_rate).minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:1000\n    _, l = run(sess, [opt, loss], lr = 1/(1+i))\n    @info \"Iteration $i, loss = $l\")\nend\n\nThe usage of other optimizers such as GradientDescentOptimizer, AdadeltaOptimizer, and so on  is similar: we can just replace AdamOptimizer with the corresponding ones. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.BFGS!","page":"API Reference","title":"ADCME.BFGS!","text":"BFGS!(value_and_gradients_function::Function, initial_position::Union{PyObject, Array{Float64}}, max_iter::Int64=50, args...;kwargs...)\n\nApplies the BFGS optimizer to value_and_gradients_function\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.BFGS!-2","page":"API Reference","title":"ADCME.BFGS!","text":"BFGS!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; \nvars::Array{PyObject}=PyObject[], callback::Union{Function, Nothing}=nothing, method::String = \"L-BFGS-B\", kwargs...)\n\nBFGS! is a simplified interface for L-BFGS-B optimizer. See also ScipyOptimizerInterface. callback is a callback function with signature \n\ncallback(vs::Array, iter::Int64, loss::Float64)\n\nvars is an array consisting of tensors and its values will be the input to vs.\n\nExample 1\n\na = Variable(1.0)\nloss = (a - 10.0)^2\nsess = Session(); init(sess)\nBFGS!(sess, loss)\n\nExample 2\n\nθ1 = Variable(1.0)\nθ2 = Variable(1.0)\nloss = (θ1-1)^2 + (θ2-2)^2\ncb = (vs, iter, loss)->begin \n    printstyled(\"[#iter $iter] θ1=$(vs[1]), θ2=$(vs[2]), loss=$loss\\n\", color=:green)\nend\nsess = Session(); init(sess)\ncb(run(sess, [θ1, θ2]), 0, run(sess, loss))\nBFGS!(sess, loss, 100; vars=[θ1, θ2], callback=cb)\n\nExample 3\n\nUse bounds to specify upper and lower bound of a variable. \n\nx = Variable(2.0)    \nloss = x^2\nsess = Session(); init(sess)\nBFGS!(sess, loss, bounds=Dict(x=>[1.0,3.0]))\n\nnote: Note\nUsers can also use other scipy optimization algorithm by providing method keyword arguments. For example, you can use the BFGS optimizer BFGS!(sess, loss, method = \"BFGS\")\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.BFGS!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject,Union{Nothing, PyCall.PyObject, Array{T,N} where N},Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}} where T<:Union{Nothing, PyCall.PyObject}","page":"API Reference","title":"ADCME.BFGS!","text":"BFGS!(sess::PyObject, loss::PyObject, grads::Union{Array{T},Nothing,PyObject}, \nvars::Union{Array{PyObject},PyObject}; kwargs...) where T<:Union{Nothing, PyObject}\n\nRunning BFGS algorithm min_textttvars textttloss(textttvars) The gradients grads must be provided. Typically, grads[i] = gradients(loss, vars[i]).  grads[i] can exist on different devices (GPU or CPU). \n\nExample 1\n\nimport Optim # required\na = Variable(0.0)\nloss = (a-1)^2\ng = gradients(loss, a)\nsess = Session(); init(sess)\nBFGS!(sess, loss, g, a)\n\nExample 2\n\nimport Optim # required\na = Variable(0.0)\nloss = (a^2+a-1)^2\ng = gradients(loss, a)\nsess = Session(); init(sess)\ncb = (vs, iter, loss)->begin \n    printstyled(\"[#iter $iter] a = $vs, loss=$loss\\n\", color=:green)\nend\nBFGS!(sess, loss, g, a; callback = cb)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.CustomOptimizer-Tuple{Function}","page":"API Reference","title":"ADCME.CustomOptimizer","text":"CustomOptimizer(opt::Function, name::String)\n\ncreates a custom optimizer with struct name name. For example, we can integrate Optim.jl with ADCME by  constructing a new optimizer\n\nCustomOptimizer(\"Con\") do f, df, c, dc, x0, x_L, x_U\n    opt = Opt(:LD_MMA, length(x0))\n    bd = zeros(length(x0)); bd[end-1:end] = [-Inf, 0.0]\n    opt.lower_bounds = bd\n    opt.xtol_rel = 1e-4\n    opt.min_objective = (x,g)->(g[:]= df(x); return f(x)[1])\n    inequality_constraint!(opt, (x,g)->( g[:]= dc(x);c(x)[1]), 1e-8)\n    (minf,minx,ret) = NLopt.optimize(opt, x0)\n    minx\nend\n\nHere\n\n∘ f: a function that returns f(x)\n\n∘ df: a function that returns nabla f(x)\n\n∘ c: a function that returns the constraints c(x)\n\n∘ dc: a function that returns nabla c(x)\n\n∘ x0: initial guess\n\n∘ nineq: number of inequality constraints\n\n∘ neq: number of equality constraints\n\n∘ x_L: lower bounds of optimizable variables\n\n∘ x_U: upper bounds of optimizable variables\n\nThen we can create an optimizer with \n\nopt = Con(loss, inequalities=[c1], equalities=[c2])\n\nTo trigger the optimization, use\n\nminimize(opt, sess)\n\nNote thanks to the global variable scope of Julia, step_callback, optimizer_kwargs can actually  be passed from Julia environment directly.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.GradientDescentOptimizer","page":"API Reference","title":"ADCME.GradientDescentOptimizer","text":"GradientDescentOptimizer(learning_rate=1e-3;kwargs...)\n\nSee AdamOptimizer for descriptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyCall.PyObject},Union{PyCall.PyObject, Array{Float64,N} where N}}} where T<:Real","page":"API Reference","title":"ADCME.NonlinearConstrainedProblem","text":"NonlinearConstrainedProblem(f::Function, L::Function, θ::PyObject, u0::Union{PyObject, Array{Float64}}; options::Union{Dict{String, T}, Missing}=missing) where T<:Integer\n\nComputes the gradients fracpartial Lpartial theta\n\nmin  L(u) quad mathrmst  F(theta u) = 0\n\nu0 is the initial guess for the numerical solution u, see newton_raphson.\n\nCaveats: Assume r, A = f(θ, u) and θ are the unknown parameters, gradients(r, θ) must be defined (backprop works properly)\n\nReturns: It returns a tuple (L: loss, C: constraints, and Graidents)\n\nleft(L(u) u fracpartial Lpartial θright)\n\nExample\n\nWe want to solve the following constrained optimization problem  beginalignedmin_theta  L(u) = (u-1)^3 textst  u^3 + u = thetaendaligned The solution is theta = 2. The Julia code is \n\nfunction f(θ, u)\n    u^3 + u - θ, spdiag(3u^2+1) \nend\nfunction L(u) \n    sum((u-1)^2)\nend\npl = Variable(ones(1))\nl, θ, dldθ = NonlinearConstrainedProblem(f, L, pl, ones(1))\n\nWe can coupled it with a mathematical optimizer \n\nusing Optim \nsess = Session(); init(sess)\nBFGS!(sess, l, dldθ, pl) \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.Optimize!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject}, Tuple{PyCall.PyObject,PyCall.PyObject,Int64}} where T<:Union{Nothing, PyCall.PyObject}","page":"API Reference","title":"ADCME.Optimize!","text":"Optimize!(sess::PyObject, loss::PyObject, max_iter::Int64 = 15000;\nvars::Union{Array{PyObject},PyObject, Missing} = missing, \ngrads::Union{Array{T},Nothing,PyObject, Missing} = missing, \noptimizer = missing,\ncallback::Union{Function, Missing}=missing,\nx_tol::Union{Missing, Float64} = missing,\nf_tol::Union{Missing, Float64} = missing,\ng_tol::Union{Missing, Float64} = missing, kwargs...) where T<:Union{Nothing, PyObject}\n\nAn interface for using optimizers in the Optim package or custom optimizers. \n\nsess: a session;\nloss: a loss function;\nmax_iter: maximum number of max_iterations;\nvars, grads: optimizable variables and gradients \noptimizer: Optim optimizers (default: LBFGS)\ncallback: callback after each linesearch completion (NOT one step in the linesearch)\n\nOther arguments are passed to Options in Optim optimizers. \n\nWe can also construct a custom optimizer. For example, to construct an optimizer out of Ipopt:\n\nimport Ipopt\nx = Variable(rand(2))\nloss = (1-x[1])^2 + 100(x[2]-x[1]^2)^2\n\nfunction opt(f, g, fg, x0, kwargs...)\n    prob = createProblem(2, -100ones(2), 100ones(2), 0, Float64[], Float64[], 0, 0,\n                     f, (x,g)->nothing, (x,G)->g(G, x), (x, mode, rows, cols, values)->nothing, nothing)\n    prob.x = x0 \n    Ipopt.addOption(prob, \"hessian_approximation\", \"limited-memory\")\n    status = Ipopt.solveProblem(prob)\n    println(Ipopt.ApplicationReturnStatus[status])\n    println(prob.x)\n    Ipopt.freeProblem(prob)\n    nothing\nend\n\nsess = Session(); init(sess)\nOptimize!(sess, loss, optimizer = opt)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.RMSPropOptimizer","page":"API Reference","title":"ADCME.RMSPropOptimizer","text":"RMSPropOptimizer(learning_rate=1e-3;kwargs...)\n\nSee AdamOptimizer for descriptions.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.ScipyOptimizerInterface-Tuple{Any}","page":"API Reference","title":"ADCME.ScipyOptimizerInterface","text":"ScipyOptimizerInterface(loss; method=\"L-BFGS-B\", options=Dict(\"maxiter\"=> 15000, \"ftol\"=>1e-12, \"gtol\"=>1e-12), kwargs...)\n\nA simple interface for Scipy Optimizer. See also ScipyOptimizerMinimize and BFGS!.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ScipyOptimizerMinimize-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.ScipyOptimizerMinimize","text":"ScipyOptimizerMinimize(sess::PyObject, opt::PyObject; kwargs...)\n\nMinimizes a scalar Tensor. Variables subject to optimization are updated in-place at the end of optimization.\n\nNote that this method does not just return a minimization Op, unlike minimize; instead it actually performs minimization by executing commands to control a Session https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface. See also ScipyOptimizerInterface and BFGS!.\n\nfeed_dict: A feed dict to be passed to calls to session.run.\nfetches: A list of Tensors to fetch and supply to loss_callback as positional arguments.\nstep_callback: A function to be called at each optimization step; arguments are the current values of all optimization variables packed into a single vector.\nloss_callback: A function to be called every time the loss and gradients are computed, with evaluated fetches supplied as positional arguments.\nrun_kwargs: kwargs to pass to session.run.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s237,N} where N where #s237<:Real},Vararg{PyCall.PyObject,N} where N}} where T<:Real","page":"API Reference","title":"ADCME.newton_raphson","text":"newton_raphson(func::Function, \n    u0::Union{Array,PyObject}, \n    θ::Union{Missing,PyObject, Array{<:Real}}=missing,\n    args::PyObject...) where T<:Real\n\nNewton Raphson solver for solving a nonlinear equation.  ∘ func has the signature \n\nfunc(θ::Union{Missing,PyObject}, u::PyObject)->(r::PyObject, A::Union{PyObject,SparseTensor}) (if linesearch is off)\nfunc(θ::Union{Missing,PyObject}, u::PyObject)->(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor}) (if linesearch is on)\n\nwhere r is the residual and A is the Jacobian matrix; in the case where linesearch is on, the function value fval must also be supplied. ∘ θ are external parameters. ∘ u0 is the initial guess for u ∘ args: additional inputs to the func function  ∘ kwargs: keyword arguments to func\n\nThe solution can be configured via ADCME.options.newton_raphson\n\nmax_iter: maximum number of iterations (default=100)\nrtol: relative tolerance for termination (default=1e-12)\ntol: absolute tolerance for termination (default=1e-12)\nLM: a float number, Levenberg-Marquardt modification x^k+1 = x^k - (J^k + mu^k)^-1g^k (default=0.0)\nlinesearch: whether linesearch is used (default=false)\n\nCurrently, the backtracing algorithm is implemented. The parameters for linesearch are supplied via options.newton_raphson.linesearch_options\n\nc1: stop criterion, f(x^k)  f(0) + alpha c_1  f(0)\nρ_hi: the new step size alpha_1leq rho_hialpha_0 \nρ_lo: the new step size alpha_1geq rho_loalpha_0 \niterations: maximum number of iterations for linesearch\nmaxstep: maximum allowable steps\nαinitial: initial guess for the step size alpha\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.newton_raphson_with_grad-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s157,N} where N where #s157<:Real},Vararg{PyCall.PyObject,N} where N}} where T<:Real","page":"API Reference","title":"ADCME.newton_raphson_with_grad","text":"newton_raphson_with_grad(f::Function, \nu0::Union{Array,PyObject}, \nθ::Union{Missing,PyObject, Array{<:Real}}=missing,\nargs::PyObject...) where T<:Real\n\nDifferentiable Newton-Raphson algorithm. See newton_raphson.\n\nUse ADCME.options.newton_raphson to supply options. \n\nExample\n\nfunction f(θ, x)\n    x^3 - θ, 3spdiag(x^2)\nend\n\nθ = constant([2. .^3;3. ^3; 4. ^3])\nx = newton_raphson_with_grad(f, constant(ones(3)), θ)\nrun(sess, x)≈[2.;3.;4.]\nrun(sess, gradients(sum(x), θ))\n\n\n\n\n\n","category":"method"},{"location":"api/#Neural-Networks","page":"API Reference","title":"Neural Networks","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"layers.jl\"]","category":"page"},{"location":"api/#ADCME.BatchNormalization","page":"API Reference","title":"ADCME.BatchNormalization","text":"BatchNormalization(dims::Int64=2; kwargs...)\n\nCreates a batch normalization layer. \n\nExample\n\nb = BatchNormalization(2)\nx = rand(10,2)\ntraining = placeholder(true)\ny = b(x, training)\nrun(sess, y)\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.Conv1D","page":"API Reference","title":"ADCME.Conv1D","text":"Conv1D(filters, kernel_size, strides, activation, args...;kwargs...)\n\nc = Conv1D(32, 3, 1, \"relu\")\nx = rand(100, 6, 128) # 128-length vectors with 6 timesteps (\"channels\")\ny = c(x) # shape=(100, 4, 32)\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.Conv2D","page":"API Reference","title":"ADCME.Conv2D","text":"Conv2D(filters, kernel_size, strides, activation, args...;kwargs...)\n\nThe arrangement is (samples, rows, cols, channels) (dataformat='channelslast')\n\nConv2D(32, 3, 1, \"relu\")\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.Conv3D","page":"API Reference","title":"ADCME.Conv3D","text":"Conv3D(filters, kernel_size, strides, activation, args...;kwargs...)\n\nThe arrangement is (samples, rows, cols, channels) (dataformat='channelslast')\n\nc = Conv3D(32, 3, 1, \"relu\")\nx = constant(rand(100, 10, 10, 10, 16))\ny = c(x)\n# shape=(100, 8, 8, 8, 32)\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.Dense","page":"API Reference","title":"ADCME.Dense","text":"Dense(units::Int64, activation::Union{String, Function, Nothing} = nothing,\n    args...;kwargs...)\n\nCreates a callable dense neural network.\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.Resnet1D","page":"API Reference","title":"ADCME.Resnet1D","text":"Resnet1D(out_features::Int64, hidden_features::Int64;\n    num_blocks::Int64=2, activation::Union{String, Function, Nothing} = \"relu\", \n    dropout_probability::Float64 = 0.0, use_batch_norm::Bool = false, name::Union{String, Missing} = missing)\n\nCreates a 1D residual network. If name is not missing, Resnet1D does not create a new entity. \n\nExample\n\nresnet = Resnet1D(20)\nx = rand(1000,10)\ny = resnet(x)\n\nExample: Digit recognition\n\nusing MLDatasets\nusing ADCME\n\n# load data \ntrain_x, train_y = MNIST.traindata()\ntrain_x = reshape(Float64.(train_x), :, size(train_x,3))'|>Array\ntest_x, test_y = MNIST.testdata()\ntest_x = reshape(Float64.(test_x), :, size(test_x,3))'|>Array\n\n# construct loss function \nADCME.options.training.training = placeholder(true)\nx = placeholder(rand(64, 784))\nl = placeholder(rand(Int64, 64))\nresnet = Resnet1D(10, num_blocks=10)\ny = resnet(x)\nloss = mean(sparse_softmax_cross_entropy_with_logits(labels=l, logits=y))\n\n# train the neural network \nopt = AdamOptimizer().minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    idx = rand(1:60000, 64)\n    _, loss_ = run(sess, [opt, loss], feed_dict=Dict(l=>train_y[idx], x=>train_x[idx,:]))\n    @info i, loss_\nend\n\n# test \nfor i = 1:10\n    idx = rand(1:10000,100)\n    y0 = resnet(test_x[idx,:])\n    y0 = run(sess, y0, ADCME.options.training.training=>false)\n    pred = [x[2]-1 for x in argmax(y0, dims=2)]\n    @info \"Accuracy = \", sum(pred .== test_y[idx])/100\nend\n\n(Image: )\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.ae","page":"API Reference","title":"ADCME.ae","text":"ae(x::PyObject, output_dims::Array{Int64}, scope::String = \"default\";\n    activation::Union{Function,String} = \"tanh\")\n\nAlias: fc, ae\n\nCreates a neural network with intermediate numbers of neurons output_dims.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{Array{Array{Float64,N} where N,N} where N, Array{PyCall.PyObject,N} where N}}","page":"API Reference","title":"ADCME.ae","text":"ae(x::Union{Array{Float64}, PyObject}, \n    output_dims::Array{Int64}, \n    θ::Union{Array{Array{Float64}}, Array{PyObject}};\n    activation::Union{Function,String} = \"tanh\")\n\nAlias: fc, ae\n\nConstructs a neural network with given weights and biases θ\n\nExample\n\nx = constant(rand(10,30))\nθ = ae_init([30, 20, 20, 5])\ny = ae(x, [20, 20, 5], θ) # 10×5\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyCall.PyObject, Array{Float64,N} where N}}","page":"API Reference","title":"ADCME.ae","text":"ae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject};\nactivation::Union{Function,String, Nothing} = \"tanh\")\n\nAlias: fc, ae\n\nCreates a neural network with intermediate numbers of neurons output_dims. The weights are given by θ\n\nExample 1: Explicitly construct weights and biases\n\nx = constant(rand(10,2))\nn = ae_num([2,20,20,20,2])\nθ = Variable(randn(n)*0.001)\ny = ae(x, [20,20,20,2], θ)\n\nExample 2: Implicitly construct weights and biases\n\nθ = ae_init([10,20,20,20,2]) \nx = constant(rand(10,10))\ny = ae(x, [20,20,20,2], θ)\n\nSee also ae_num, ae_init.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ae_init-Tuple{Array{Int64,N} where N}","page":"API Reference","title":"ADCME.ae_init","text":"ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=\"xavier\")\nfc_init(output_dims::Array{Int64})\n\nReturn the initial weights and bias values by TensorFlow as a vector. The neural network architecture is\n\no_1 (textInput layer) rightarrow o_2 rightarrow ldots rightarrow o_n (textOutput layer)\n\nThree types of  random initializers are provided\n\nxavier (default). It is useful for tanh fully connected neural network. \n\nW^l_i \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{1}{n_{l-1}}}\\right)\n\nxavier_avg. A variant of xavier\n\nW^l_i sim mathcalNleft(0 sqrtfrac2n_l + n_l-1right)\n\nhe. This is the activation aware initialization of weights and helps mitigate the problem\n\nof vanishing/exploding gradients. \n\nW^l_i sim mathcalNleft(0 sqrtfrac2n_l-1right)\n\nExample\n\nx = constant(rand(10,30))\nθ = fc_init([30, 20, 20, 5])\ny = fc(x, [20, 20, 5], θ) # 10×5\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ae_num-Tuple{Array{Int64,N} where N}","page":"API Reference","title":"ADCME.ae_num","text":"ae_num(output_dims::Array{Int64})\nfc_num(output_dims::Array{Int64})\n\nEstimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from ae since in ae the feature dimension can be inferred), and the last dimension should be the output dimension. \n\nExample\n\nx = constant(rand(10,30))\nθ = ae_init([30, 20, 20, 5])\n@assert ae_num([30, 20, 20, 5])==length(θ)\ny = ae(x, [20, 20, 5], θ)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ae_to_code","page":"API Reference","title":"ADCME.ae_to_code","text":"ae_to_code(file::String, scope::String; activation::String = \"tanh\")\n\nReturn the code string from the feed-forward neural network data in file. Usually we can immediately evaluate  the code string into Julia session by \n\neval(Meta.parse(s))\n\nIf activation is not specified, tanh is the default. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.bn-Tuple","page":"API Reference","title":"ADCME.bn","text":"bn(args...;center = true, scale=true, kwargs...)\n\nbn accepts a keyword parameter is_training. \n\nExample\n\nbn(inputs, name=\"batch_norm\", is_training=true)\n\nnote: Note\nbn should be used with control_dependencyupdate_ops = get_collection(UPDATE_OPS)\ncontrol_dependencies(update_ops) do \n    global train_step = AdamOptimizer().minimize(loss)\nend \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.dense-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326<:Real},Int64,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.dense","text":"dense(inputs::Union{PyObject, Array{<:Real}}, units::Int64, args...; \n    activation::Union{String, Function} = nothing, kwargs...)\n\nCreates a fully connected layer with the activation function specified by activation\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.dropout","page":"API Reference","title":"ADCME.dropout","text":"dropout(x::Union{PyObject, Real, Array{<:Real}}, \nrate::Union{Real, PyObject}, training::Union{PyObject,Bool} = true; kwargs...)\n\nRandomly drops out entries in x with a rate of rate. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.fc","page":"API Reference","title":"ADCME.fc","text":"ae(x::PyObject, output_dims::Array{Int64}, scope::String = \"default\";\n    activation::Union{Function,String} = \"tanh\")\n\nAlias: fc, ae\n\nCreates a neural network with intermediate numbers of neurons output_dims.\n\nae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject};\nactivation::Union{Function,String, Nothing} = \"tanh\")\n\nAlias: fc, ae\n\nCreates a neural network with intermediate numbers of neurons output_dims. The weights are given by θ\n\nExample 1: Explicitly construct weights and biases\n\nx = constant(rand(10,2))\nn = ae_num([2,20,20,20,2])\nθ = Variable(randn(n)*0.001)\ny = ae(x, [20,20,20,2], θ)\n\nExample 2: Implicitly construct weights and biases\n\nθ = ae_init([10,20,20,20,2]) \nx = constant(rand(10,10))\ny = ae(x, [20,20,20,2], θ)\n\nSee also ae_num, ae_init.\n\nae(x::Union{Array{Float64}, PyObject}, \n    output_dims::Array{Int64}, \n    θ::Union{Array{Array{Float64}}, Array{PyObject}};\n    activation::Union{Function,String} = \"tanh\")\n\nAlias: fc, ae\n\nConstructs a neural network with given weights and biases θ\n\nExample\n\nx = constant(rand(10,30))\nθ = ae_init([30, 20, 20, 5])\ny = ae(x, [20, 20, 5], θ) # 10×5\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.fc_init","page":"API Reference","title":"ADCME.fc_init","text":"ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=\"xavier\")\nfc_init(output_dims::Array{Int64})\n\nReturn the initial weights and bias values by TensorFlow as a vector. The neural network architecture is\n\n$\n\no1 (\\text{Input layer}) \\rightarrow o2 \\rightarrow \\ldots \\rightarrow o_n (\\text{Output layer}) $\n\nThree types of  random initializers are provided\n\nxavier (default). It is useful for tanh fully connected neural network.\n\nW^l_i \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{1}{n_{l-1}}}\\right)\n\nxavier_avg. A variant of xavier\n\n$\n\nW^li \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{2}{nl + n_{l-1}}}\\right) $\n\nhe. This is the activation aware initialization of weights and helps mitigate the problem\n\nof vanishing/exploding gradients. \n\n$\n\nW^li \\sim \\mathcal{N}\\left(0, \\sqrt{\\frac{2}{n{l-1}}}\\right) $\n\nExample\n\nx = constant(rand(10,30))\nθ = fc_init([30, 20, 20, 5])\ny = fc(x, [20, 20, 5], θ) # 10×5\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.fc_num","page":"API Reference","title":"ADCME.fc_num","text":"ae_num(output_dims::Array{Int64})\nfc_num(output_dims::Array{Int64})\n\nEstimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from ae since in ae the feature dimension can be inferred), and the last dimension should be the output dimension. \n\nExample\n\nx = constant(rand(10,30))\nθ = ae_init([30, 20, 20, 5])\n@assert ae_num([30, 20, 20, 5])==length(θ)\ny = ae(x, [20, 20, 5], θ)\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.fcx-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Array{Int64,1},Union{Array{Float64,1}, PyCall.PyObject}}","page":"API Reference","title":"ADCME.fcx","text":"fcx(x::Union{Array{Float64,2},PyObject}, output_dims::Array{Int64,1}, \nθ::Union{Array{Float64,1}, PyObject};\nactivation::String = \"tanh\")\n\nCreates a fully connected neural network with output dimension o and inputs xin mathbbR^mtimes n. \n\nx rightarrow o_1 rightarrow o_2 rightarrow ldots rightarrow o_k\n\nθ is the weights and biases of the neural network, e.g., θ = ae_init(output_dims).\n\nfcx outputs two tensors:\n\nthe output of the neural network: uin mathbbR^mtimes o_k.\nthe sensitivity of the neural network per sample: fracpartial upartial xin mathbbR^m times o_k times n\n\n\n\n\n\n","category":"method"},{"location":"api/#Generative-Neural-Nets","page":"API Reference","title":"Generative Neural Nets","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"gan.jl\"]","category":"page"},{"location":"api/#ADCME.GAN","page":"API Reference","title":"ADCME.GAN","text":"GAN(dat::Union{Array,PyObject}, generator::Function, discriminator::Function,\nloss::Union{Missing, Function}=missing; latent_dim::Union{Missing, Int64}=missing,\n    batch_size::Int64=32)\n\nCreates a GAN instance. \n\ndat in mathbbR^ntimes d is the training data for the GAN, where n is the number of training data, and d is the dimension per training data.\ngeneratormathbbR^d rightarrow mathbbR^d is the generator function, d is the hidden dimension.\ndiscriminatormathbbR^d rightarrow mathbbR is the discriminator function. \nloss is the loss function. See klgan, rklgan, wgan, lsgan for examples.\nlatent_dim (default=d, the same as output dimension) is the latent dimension.\nbatch_size (default=32) is the batch size in training.\n\nExample: Constructing a GAN\n\ndat = rand(10000,10)\ngenerator = (z, gan)->10*z\ndiscriminator = (x, gan)->sum(x)\ngan = GAN(dat, generator, discriminator, \"wgan_stable\")\n\nExample: Learning a Gaussian random variable\n\nusing ADCME \nusing PyPlot\nusing Distributions\ndat = randn(10000, 1) * 0.5 .+ 3.0\nfunction gen(z, gan)\n    ae(z, [20,20,20,1], \"generator_$(gan.ganid)\", activation = \"relu\")\nend\nfunction disc(x, gan)\n    squeeze(ae(x, [20,20,20,1], \"discriminator_$(gan.ganid)\", activation = \"relu\"))\nend\ngan = GAN(dat, gen, disc, g->wgan_stable(g, 0.001); latent_dim = 10)\n\ndopt = AdamOptimizer(0.0002, beta1=0.5, beta2=0.9).minimize(gan.d_loss, var_list=gan.d_vars)\ngopt = AdamOptimizer(0.0002, beta1=0.5, beta2=0.9).minimize(gan.g_loss, var_list=gan.g_vars)\nsess = Session(); init(sess)\nfor i = 1:5000\n    batch_x = rand(1:10000, 32)\n    batch_z = randn(32, 10)\n    for n_critic = 1:1\n        global _, dl = run(sess, [dopt, gan.d_loss], \n                feed_dict=Dict(gan.ids=>batch_x, gan.noise=>batch_z))\n    end\n    _, gl, gm, dm, gp = run(sess, [gopt, gan.g_loss, \n        gan.STORAGE[\"g_grad_magnitude\"], gan.STORAGE[\"d_grad_magnitude\"], \n        gan.STORAGE[\"gradient_penalty\"]],\n        feed_dict=Dict(gan.ids=>batch_x, gan.noise=>batch_z))\n    mod(i, 100)==0 && (@info i, dl, gl, gm, dm, gp)\nend\n\nhist(run(sess, squeeze(rand(gan,10000))), bins=50, density = true)\nnm = Normal(3.0,0.5)\nx0 = 1.0:0.01:5.0\ny0 = pdf.(nm, x0)\nplot(x0, y0, \"g\")\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.build!-Tuple{GAN}","page":"API Reference","title":"ADCME.build!","text":"build!(gan::GAN)\n\nBuilds the GAN instances. This function returns gan for convenience.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.jsgan-Tuple{GAN}","page":"API Reference","title":"ADCME.jsgan","text":"jsgan(gan::GAN)\n\nComputes the vanilla GAN loss function.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.klgan-Tuple{GAN}","page":"API Reference","title":"ADCME.klgan","text":"klgan(gan::GAN)\n\nComputes the KL-divergence GAN loss function.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.lsgan-Tuple{GAN}","page":"API Reference","title":"ADCME.lsgan","text":"lsgan(gan::GAN)\n\nComputes the least square GAN loss function.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.predict-Tuple{GAN,Union{PyCall.PyObject, Array}}","page":"API Reference","title":"ADCME.predict","text":"predict(gan::GAN, input::Union{PyObject, Array})\n\nPredicts the GAN gan output given input input. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rklgan-Tuple{GAN}","page":"API Reference","title":"ADCME.rklgan","text":"rklgan(gan::GAN)\n\nComputes the reverse KL-divergence GAN loss function.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.sample-Tuple{GAN,Int64}","page":"API Reference","title":"ADCME.sample","text":"sample(gan::GAN, n::Int64)\nrand(gan::GAN, n::Int64)\n\nSamples n instances from gan.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.wgan-Tuple{GAN}","page":"API Reference","title":"ADCME.wgan","text":"wgan(gan::GAN)\n\nComputes the Wasserstein GAN loss function.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.wgan_stable","page":"API Reference","title":"ADCME.wgan_stable","text":"wgan_stable(gan::GAN, λ::Float64)\n\nReturns the discriminator and generator loss for the Wasserstein GAN loss with penalty parameter lambda\n\nThe objective function is \n\nL = E_tilde xsim P_g D(tilde x) - E_xsim P_r D(x) + lambda E_hat xsim P_hat x(nabla_hat xD(hat x)^2-1)^2\n\n\n\n\n\n","category":"function"},{"location":"api/#Tools","page":"API Reference","title":"Tools","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"extra.jl\", \"kit.jl\", \"sqlite.jl\"]","category":"page"},{"location":"api/#ADCME.MCMCSimple","page":"API Reference","title":"ADCME.MCMCSimple","text":"MCMCSimple(obs::Array{Float64, 1}, h::Function, \nσ::Float64, θ0::Array{Float64,1}, lb::Float64, ub::Float64)\n\nA very simple yet useful interface for MCMC simulation in many scientific computing problems. \n\nobs: Observations\nh: Forward computation function\nσ: Noise standard deviation for the observed data \nub, lb: upper and lower bound\nθ0: Initial guess \n\nThe mathematical model is \n\ny_obs = h(theta)\n\nand we have a hard constraint lb\\leq \\theta \\leq ub. \n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.cmake","page":"API Reference","title":"ADCME.cmake","text":"cmake(DIR::String=\"..\"; CMAKE_ARGS::Union{Array{String}, String} = \"\")\n\nThe built-in Cmake command for building C/C++ libraries. If extra Cmake arguments are needed, please specify it through CMAKE_ARGS.\n\nExample\n\nADCME.cmake(CMAKE_ARGS=[\"SHARED=YES\", \"STAITC=NO\"])\n\nThe executed command might be:\n\n/home/darve/kailaix/.julia/adcme/bin/cmake -G Ninja -DCMAKE_MAKE_PROGRAM=/home/darve/kailaix/.julia/adcme/bin/ninja -DJULIA=/home/darve/kailaix/julia-1.3.1/bin/julia -DCMAKE_C_COMPILER=/home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc -DCMAKE_CXX_COMPILER=/home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ SHARED=YES STATIC=NO ..\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.compile-Tuple{String}","page":"API Reference","title":"ADCME.compile","text":"compile(s::String; force::Bool=false)\n\nCompiles the library given by path deps/s. If force is false, compile first check whether  the binary product exists. If the binary product exists, return 2. Otherwise, compile tries to  compile the binary product, and returns 0 if successful; it return 1 otherwise. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.compile-Tuple{}","page":"API Reference","title":"ADCME.compile","text":"compile()\n\nCompile a custom operator in the current directory. A CMakeLists.txt must be present. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.customop-Tuple{}","page":"API Reference","title":"ADCME.customop","text":"customop(;with_mpi::Bool = false)\n\nCreate a new custom operator. Typically users call customop twice: the first call generates a customop.txt,  users edit the content in the file; the second all generates C++ source code, CMakeLists.txt, and gradtest.jl from customop.txt.\n\nExample\n\njulia> customop() # create an editable `customop.txt` file\n[ Info: Edit custom_op.txt for custom operators\njulia> customop() # after editing `customop.txt`, call it again to generate interface files.\n\nOptions\n\nwith_mpi: Whether the custom operator uses MPI\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.debug","page":"API Reference","title":"ADCME.debug","text":"debug(libfile::String = \"\")\n\nLoading custom operator shared library. If the loading fails, detailed error message is printed.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.debug-Tuple{PyCall.PyObject,PyCall.PyObject}","page":"API Reference","title":"ADCME.debug","text":"debug(sess::PyObject, o::PyObject)\n\nIn the case a session run yields an error from the TensorFlow backend, this function can help print the exact error.  For example, you might encounter  InvalidArgumentError() with no detailed error information, and this function can be useful for debugging.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.doctor-Tuple{}","page":"API Reference","title":"ADCME.doctor","text":"doctor()\n\nReports health of the current installed ADCME package. If some components are broken, possible fix is proposed.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_library_symbols-Tuple{Union{String, PyCall.PyObject}}","page":"API Reference","title":"ADCME.get_library_symbols","text":"get_library_symbols(file::Union{String, PyObject})\n\nReturns the symbols in the custom op library file.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_placement-Tuple{}","page":"API Reference","title":"ADCME.get_placement","text":"get_placement()\n\nReturns the operation placements.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.install-Tuple{String}","page":"API Reference","title":"ADCME.install","text":"install(s::String; force::Bool = false, islocal::Bool = false)\n\nInstall a custom operator from a URL, a directory (when islocal is true), or a string. In any of the three case,  install copy the folder to /home/runner/work/ADCME.jl/ADCME.jl/deps/CustomOps/Plugin.  When s is a string, s is converted to \n\nhttps://github.com/ADCMEMarket/<s>\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.load_library-Tuple{String}","page":"API Reference","title":"ADCME.load_library","text":"load_library(filename::String)\n\nLoad custom operator libraries. If used with \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.load_op-Tuple{Union{String, PyCall.PyObject},String}","page":"API Reference","title":"ADCME.load_op","text":"load_op(oplibpath::Union{PyObject, String}, opname::String; verbose::Union{Missing, Bool} = missing)\n\nLoads the operator opname from library oplibpath.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.load_op_and_grad-Tuple{Union{String, PyCall.PyObject},String}","page":"API Reference","title":"ADCME.load_op_and_grad","text":"load_op_and_grad(oplibpath::Union{PyObject, String}, opname::String; multiple::Bool=false)\n\nLoads the operator opname from library oplibpath; gradients are also imported.  If multiple is true, the operator is assumed to have multiple outputs. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.load_system_op","page":"API Reference","title":"ADCME.load_system_op","text":"load_system_op(opname::String, grad::Bool=true; multiple::Bool=false)\n\nLoads custom operator from CustomOps directory (shipped with ADCME instead of TensorFlow) For example \n\ns = \"SparseOperator\"\noplib = \"libSO\"\ngrad = true\n\nthis will direct Julia to find library CustomOps/SparseOperator/libSO.dylib on MACOSX\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.make_library-Tuple{String}","page":"API Reference","title":"ADCME.make_library","text":"make_library(Libdir::String)\n\nMake shared library in Libdir. The structure of the source codes files are \n\n- Libdir \n  - *.cpp \n  - *.h \n  - CMakeLists\n  - build (Optional)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.nnuq-Tuple{Array{Float64,2},Union{Float64, Array{Float64,2}},Union{Float64, Array{Float64,2}}}","page":"API Reference","title":"ADCME.nnuq","text":"nnuq(H::Array{Float64,2}, invR::Union{Float64, Array{Float64,2}}, invQ::Union{Float64, Array{Float64,2}})\n\nReturns the variance matrix for the Baysian inversion. \n\nThe negative log likelihood function is\n\nl(s) =frac12 (y-h(s))^T R^-1 (y-h(s)) + frac12 s^T Q^-1 s\n\nThe covariance matrix is computed by first linearizing h(s)\n\nh(s)approx h(s_0) + nabla h(s_0) (s-s_0)\n\nand then computing the second order derivative\n\nV = left(fracpartial^2 lpartial s^Tpartial sright)^-1 = (H^T R^-1 H + Q^-1)^-1\n\nNote the result is independent of s_0, y_0, and only depends on nabla h(s_0)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.register-Tuple{Function,Function}","page":"API Reference","title":"ADCME.register","text":"register(forward::Function, backward::Function; multiple::Bool=false)\n\nRegister a function forward with back-propagated gradients rule backward to the backward.  ∘ forward: it takes n inputs and outputs m tensors. When m1, the keyword multiple must be true.  ∘ backward: it takes tilde m top gradients from float/double output tensors of forward, m outputs of the forward,     and n inputs of the forward. backward outputs n gradients for each input of forward. When input i of    forward is not float/double, backward should return nothing for the corresponding gradients. \n\nExample\n\nforward = x->log(1+exp(x))\nbackward = (dy, y, x)->dy*(1-1/(1+y))\nf = register(forward, backward)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.sleep_for-Tuple{Union{PyCall.PyObject, #s329} where #s329<:Real}","page":"API Reference","title":"ADCME.sleep_for","text":"sleep_for(t::Union{PyObject, <:Real})\n\nSleeps for t seconds. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.test_gpu-Tuple{}","page":"API Reference","title":"ADCME.test_gpu","text":"test_gpu()\n\nTests the GPU ultilities\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.timestamp","page":"API Reference","title":"ADCME.timestamp","text":"timestamp(deps::Union{PyObject, <:Real, Missing}=missing)\n\nThese functions are usually used with bind for profiling.  Note the timing is not very accurate in a multithreaded environment.\n\ndeps: deps is always executed before returning the timestamp.\n\nExample\n\na = constant(3.0)\nt0 = timestamp(a)\nsleep_time = sleep_for(a)\nt1 = timestamp(sleep_time)\nsess = Session(); init(sess)\nt0_, t1_ = run(sess, [t0, t1])\ntime = t1_ - t0_\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.xavier_init","page":"API Reference","title":"ADCME.xavier_init","text":"xavier_init(size, dtype=Float64)\n\nReturns a matrix of size size and its values are from Xavier initialization. \n\n\n\n\n\n","category":"function"},{"location":"api/#Base.precompile","page":"API Reference","title":"Base.precompile","text":"precompile(force::Bool=false)\n\nPrecompile the built-in custom operators. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.animate-Tuple{Function,Any}","page":"API Reference","title":"ADCME.animate","text":"animate(update::Function, frames; kwargs...)\n\nCreates an animation using update function update. \n\nExample\n\nθ = LinRange(0, 2π, 100)\nx = cos.(θ)\ny = sin.(θ)\npl, = plot([], [], \"o-\")\nt = title(\"0\")\nxlim(-1.2,1.2)\nylim(-1.2,1.2)\nfunction update(i)\n    t.set_text(\"$i\")\n    pl.set_data([x[1:i] y[1:i]]'|>Array)\nend\nanimate(update, 1:100)\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.gradview-Tuple{PyCall.PyObject,PyCall.PyObject,PyCall.PyObject,Any}","page":"API Reference","title":"ADCME.gradview","text":"gradview(sess::PyObject, pl::PyObject, loss::PyObject, u0; scale::Float64 = 1.0)\n\nVisualizes the automatic differentiation and finite difference convergence converge. For correctly implemented differentiable codes, the convergence rate for AD should be 2 and for FD should be 1 (if not evaluated at stationary point).\n\nscale: you can control the step size for perturbation. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.jacview-Tuple{PyCall.PyObject,Function,Union{Missing, PyCall.PyObject, Array{Float64,N} where N},Array{Float64,N} where N,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.jacview","text":"jacview(sess::PyObject, f::Function, θ::Union{Array{Float64}, PyObject, Missing}, \nu0::Array{Float64}, args...)\n\nPerforms gradient test for a vector function. f has the signature \n\nf(θ, u) -> r, J\n\nHere θ is a nuisance  parameter, u is the state variables (w.r.t. which the Jacobian is computed), r is the residual vector, and J is the Jacobian matrix (a dense matrix or a SparseTensor).\n\nExample 1\n\nu0 = rand(10)\nfunction verify_jacobian_f(θ, u)\n    r = u^3+u - u0\n    r, spdiag(3u^2+1.0)\nend\njacview(sess, verify_jacobian_f, missing, u0)\n\nExample 2\n\nu0 = rand(10)\nrs = rand(10)\nfunction verify_jacobian_f(θ, u)\n    r = [u^2;u] - [rs;rs]\n    r, [spdiag(2*u); spdiag(10)]\nend\njacview(sess, verify_jacobian_f, missing, u0); close(\"all\")\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.lineview","page":"API Reference","title":"ADCME.lineview","text":"lineview(sess::PyObject, pl::PyObject, loss::PyObject, θ1, θ2=nothing; n::Integer = 10)\n\nPlots the function \n\nh(α) = f((1-α)θ_1 + αθ_2)\n\nExample\n\npl = placeholder(Float64, shape=[2])\nl = sum(pl^2-pl*0.1)\nsess = Session(); init(sess)\nlineview(sess, pl, l, rand(2))\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.saveanim-Tuple{PyCall.PyObject,String}","page":"API Reference","title":"ADCME.saveanim","text":"saveanim(anim::PyObject, filename::String; kwargs...)\n\nSaves the animation produced by animate\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.test_gradients-Tuple{Function,Array{Float64,1}}","page":"API Reference","title":"ADCME.test_gradients","text":"test_gradients(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0, showfig::Bool = true)\n\nTesting the gradients of a vector function f: y, J = f(x) where y is a scalar output and J is the vector gradient.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.test_hessian-Tuple{Function,Array{Float64,1}}","page":"API Reference","title":"ADCME.test_hessian","text":"test_hessian(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0)\n\nTesting the Hessian of a scalar function f: g, H = f(x) where y is a scalar output, g is a vector gradient output, and H is the Hessian.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.test_jacobian-Tuple{Function,Array{Float64,1}}","page":"API Reference","title":"ADCME.test_jacobian","text":"test_jacobian(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0, showfig::Bool = true)\n\nTesting the gradients of a vector function f: y, J = f(x) where y is a vector output and J is the Jacobian.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.Database","page":"API Reference","title":"ADCME.Database","text":"Database(filename::Union{Missing, String} = missing; \n    commit_after_execute::Bool = true)\n\nCreates a database from filename. If filename is not provided, an in-memory database is created.  If commit_after_execute is false, no commit operation is performed after each execute.\n\ndo block syntax:\n\nDatabase() do db\n    execute(db, \"create table mytable (a real, b real)\")\nend\n\nThe database is automatically closed after execution. Therefore, if execute is a query operation,  users need to store the results in a global variable. \n\nQuery meta information \n\nkeys(db) # all tables \nkeys(db, \"mytable\") # all column names in `db.mytable` \n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.commit-Tuple{Database}","page":"API Reference","title":"ADCME.commit","text":"commit(db::Database)\n\nCommits changes to db.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.execute-Tuple{Database,String,Vararg{Any,N} where N}","page":"API Reference","title":"ADCME.execute","text":"execute(db::Database, sql::String, args...)\n\nExecutes the SQL statement sql in db. Users can also use the do block syntax. \n\nexecute(db) do \n    \"create table mytable (a real, b real)\"\nend\n\nexecute can also be used to insert a batch of records\n\nt1 = rand(10)\nt2 = rand(10)\nparam = collect(zip(t1, t2))\nexecute(db, \"INSERT TO mytable VALUES (?,?)\", param)\n\nor \n\nexecute(db, \"INSERT TO mytable VALUES (?,?)\", t1, t2)\n\n\n\n\n\n","category":"method"},{"location":"api/#ODE","page":"API Reference","title":"ODE","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"ode.jl\"]","category":"page"},{"location":"api/#ADCME.ExplicitNewmark","page":"API Reference","title":"ADCME.ExplicitNewmark","text":"ExplicitNewmark(M::Union{SparseTensor, SparseMatrixCSC}, Z1::Union{Missing, SparseTensor, SparseMatrixCSC}, Z2::Union{Missing, SparseTensor, SparseMatrixCSC}, Δt::Float64)\n\nAn explicit Newmark integrator for \n\nM ddotmathbfd + Z_1 dotmathbfd + Z_2 mathbfd + f = 0\n\nThe numerical scheme is \n\nleft(frac1Delta t^2 M + frac12Delta tZ_1right)d^n+1 = left(frac2Delta t^2 M - frac12Delta tZ_2right)d^n - left(frac1Delta t^2 M - frac12Delta tZ_1right) d^n-1 - f\n\nTo use this integrator, \n\nen = ExplicitNewmark(M, Z1, Z2, Δt)\nd2 = step(en, d0, d1, f)\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.TR_BDF2","page":"API Reference","title":"ADCME.TR_BDF2","text":"TR_BDF2(D0::Union{SparseTensor, SparseMatrixCSC}, \n    D1::Union{SparseTensor, SparseMatrixCSC}, \n    Δt::Float64)\n\nConstructs a TR-BDF2 (the Trapezoidal Rule with Second Order Backward Difference Formula) handler for  the DAE \n\nD_1 dot y + D_0 y = f\n\nThe struct is a functor, which performs one step simulation \n\n(tr::TR_BDF2)(y::Union{PyObject, Array{Float64, 1}}, \n    f1::Union{PyObject, Array{Float64, 1}}, \n    f2::Union{PyObject, Array{Float64, 1}}, \n    f3::Union{PyObject, Array{Float64, 1}})\n\nHere f1, f2, and f3 correspond to the right hand side at time step n, n+frac12, and n+1.\n\nOr we can pass a batched F defined as a (2NT+1) × DOF array\n\n(tr::TR_BDF2)(y0::Union{PyObject, Array{Float64, 1}}, \n    F::Union{PyObject, Array{Float64, 2}})\n\nThe output will be the entire solution of size (NT+1) × DOF.\n\ninfo: Info\nThe scheme takes the following form for n = 0, 1, ... beginaligned D_1(y^n+frac12-y^n) = frac12fracDelta t2left(f^n+frac12 + f^n - D_0 left(y^n+frac12 + y^nright)right) left(fracDelta t2right)^-1 D_1 left(frac32y^n+1 - 2y^n+frac12 + frac12 y^nright) + D_0 y^n+1 = f^n+1endaligned\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.constant-Tuple{TR_BDF2}","page":"API Reference","title":"ADCME.constant","text":"constant(tr::TR_BDF2)\n\nConverts tr to a symbolic solver. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ode45-Tuple","page":"API Reference","title":"ADCME.ode45","text":"ode45(y::Union{PyObject, Float64, Array{Float64}}, T::Union{PyObject, Float64}, \n            NT::Union{PyObject,Int64}, f::Function, θ::Union{PyObject, Missing}=missing)\n\nSolves \n\nfracdydt = f(y t theta)\n\nwith six-stage, fifth-order, Runge-Kutta method.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.rk4-Tuple","page":"API Reference","title":"ADCME.rk4","text":"rk4(y::Union{PyObject, Float64, Array{Float64}}, T::Union{PyObject, Float64}, \n            NT::Union{PyObject,Int64}, f::Function, θ::Union{PyObject, Missing}=missing)\n\nSolves \n\nfracdydt = f(y t theta)\n\nwith Runge-Kutta (order 4) method. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.runge_kutta","page":"API Reference","title":"ADCME.runge_kutta","text":"runge_kutta(f::Function, T::Union{PyObject, Float64}, \n            NT::Union{PyObject,Int64}, y::Union{PyObject, Float64, Array{Float64}}, θ::Union{PyObject, Missing}=missing; method::String=\"rk4\")\n\nSolves \n\nfracdydt = f(y t theta)\n\nwith Runge-Kutta method. \n\nFor example, the default solver, RK4, has the following numerical scheme per time step \n\nbeginaligned\nk_1 = Delta t f(t_n y_n theta)\nk_2 = Delta t f(t_n+Delta t2 y_n + k_12 theta)\nk_3 = Delta t f(t_n+Delta t2 y_n + k_22 theta)\nk_4 = Delta t f(t_n+Delta t y_n + k_3 theta)\ny_n+1 = y_n + frack_16 +frack_23 +frack_33 +frack_46\nendaligned\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.αscheme-Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{Array{Float64,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Array{Float64,1}}","page":"API Reference","title":"ADCME.αscheme","text":"αscheme(M::Union{SparseTensor, SparseMatrixCSC}, \n    C::Union{SparseTensor, SparseMatrixCSC}, \n    K::Union{SparseTensor, SparseMatrixCSC}, \n    Force::Union{Array{Float64}, PyObject}, \n    d0::Union{Array{Float64, 1}, PyObject}, \n    v0::Union{Array{Float64, 1}, PyObject}, \n    a0::Union{Array{Float64, 1}, PyObject}, \n    Δt::Array{Float64}; \n    solve::Union{Missing, Function} = missing,\n    extsolve::Union{Missing, Function} = missing, \n    ρ::Float64 = 1.0)\n\nGeneralized α-scheme.  M u_tt + C u_t + K u = F\n\nForce must be an array of size n×p, where d0, v0, and a0 have a size p Δt is an array (variable time step). \n\nThe generalized α scheme solves the equation by the time stepping\n\nbeginaligned\nbf d_n+1 = bf d_n + hbf v_n + h^2 left(left(frac12-beta_2 right)bf a_n + beta_2 bf a_n+1  right)\nbf v_n+1 = bf v_n + h((1-gamma_2)bf a_n + gamma_2 bf a_n+1)\nbf F(t_n+1-alpha_f_2) = M bf a _n+1-alpha_m_2 + C bf v_n+1-alpha_f_2 + K bfd_n+1-alpha_f_2\nendaligned\n\nwhere \n\nbeginaligned\nbf d_n+1-alpha_f_2 = (1-alpha_f_2)bf d_n+1 + alpha_f_2 bf d_n\nbf v_n+1-alpha_f_2 = (1-alpha_f_2) bf v_n+1 + alpha_f_2 bf v_n \nbf a_n+1-alpha_m_2  = (1-alpha_m_2) bf a_n+1 + alpha_m_2 bf a_n\nt_n+1-alpha_f_2  = (1-alpha_f_2) t_n+1 + alpha_f_2 + alpha_f_2t_n\nendaligned\n\nHere the parameters are computed using \n\nbeginaligned\ngamma_2 = frac12 - alpha_m_2 + alpha_f_2\nbeta_2 = frac14 (1-alpha_m_2+alpha_f_2)^2 \nalpha_m_2 = frac2rho_infty-1rho_infty+1\nalpha_f_2 = fracrho_inftyrho_infty+1\nendaligned\n\n∘ solve: users can provide a solver function, solve(A, rhs) for solving Ax = rhs ∘ extsolve: similar to solve, but the signature has the form \n\nextsolve(A, rhs, i)\n\nThis provides the users with more control, e.g., (time-dependent) Dirichlet boundary conditions.  See Generalized α Scheme for details.\n\nnote: Note\nIn the case u has a nonzero essential boundary condition u_b, we let tilde u=u-u_b, then  M tilde u_tt + C tilde u_t + K u = F - K u_b - C dot u_b\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.αscheme_time-Tuple{Array{Float64,N} where N}","page":"API Reference","title":"ADCME.αscheme_time","text":"αscheme_time(Δt::Array{Float64}; ρ::Float64 = 1.0)\n\nReturns the integration time t_i+1-alpha_f_2 between t_i t_i+1 using the alpha scheme.  If Delta t has length n, the output will also have length n. \n\n\n\n\n\n","category":"method"},{"location":"api/#Function-Approximators","page":"API Reference","title":"Function Approximators","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"RBF2D\ninterp1","category":"page"},{"location":"api/#ADCME.RBF2D","page":"API Reference","title":"ADCME.RBF2D","text":"function RBF2D(xc::Union{PyObject, Array{Float64, 1}}, yc::Union{PyObject, Array{Float64, 1}}; \n    c::Union{PyObject, Array{Float64, 1}, Missing} = missing, \n    eps::Union{PyObject, Array{Float64, 1}, Real, Missing} = missing,\n    d::Union{PyObject, Array{Float64, 1}} = zeros(0), \n    kind::Int64 = 0)\n\nConstructs a radial basis function representation on a 2D domain\n\nf(x y) = sum_i=1^N c_i phi(r epsilon_i) + d_0 + d_1 x + d_2 y\n\nHere d can be either 0, 1 (only d_0 is present), or 3 (d_0, d_1, and d_2 are all present).\n\nkind determines the type of radial basis functions \n\n0:Gaussian\n\nphi(r epsilon) = e^-(epsilon r)^2\n\n1:Multiquadric\n\nphi(r epsilon) = sqrt1+(epsilon r)^2\n\n2:Inverse quadratic\n\nphi(r epsilon) = frac11+(epsilon r)^2\n\n3:Inverse multiquadric\n\nphi(r epsilon) = frac1sqrt1+(epsilon r)^2\n\nReturns a callable struct, i.e. to evaluates the function at locations (x y) (x and y are both vectors), run \n\nrbf(x, y)\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.interp1","page":"API Reference","title":"ADCME.interp1","text":"interp1(x::Union{Array{Float64, 1}, PyObject},v::Union{Array{Float64, 1}, PyObject},xq::Union{Array{Float64, 1}, PyObject})\n\nreturns interpolated values of a 1-D function at specific query points using linear interpolation.  Vector x contains the sample points, and v contains the corresponding values, v(x).  Vector xq contains the coordinates of the query points.\n\ninfo: Info\nx should be sorted in ascending order. \n\nExample\n\nx = sort(rand(10))\ny = constant(@. x^2 + 1.0)\nz = [x[1]; x[2]; rand(5) * (x[end]-x[1]) .+ x[1]; x[end]]\nu = interp1(x,y,z)\n\n\n\n\n\n","category":"function"},{"location":"api/#Optimal-Transport","page":"API Reference","title":"Optimal Transport","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"ot.jl\"]","category":"page"},{"location":"api/#ADCME.dtw","page":"API Reference","title":"ADCME.dtw","text":"dtw(s::Union{PyObject, Array{Float64}}, t::Union{PyObject, Array{Float64}}, \n    use_fast::Bool = false)\n\nComputes the dynamic time wrapping (DTW) distance between two time series s and t.  Returns the distance and path. use_fast specifies whether fast algorithm is used. Note  fast algorithm may not be accurate.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}","page":"API Reference","title":"ADCME.emd","text":"emd(a::Union{PyObject, Array{Float64}}, b::Union{PyObject, Array{Float64}}, M::Union{PyObject, Array{Float64}};\niter::Int64 = 1000, tol::Float64 = 1e-9, returnall::Bool=false)\n\nComputes the Earth Mover's Distance, which is defined as \n\nD(M) = sum_i=1^m sum_j=1^n M_ij d_ij\n\nHere M in mathbbR^mtimes n is the ground distance matrix. The algorithm solves the following optimization problem \n\nbeginalignedmin_M  D(M)textst   sum_i=1^m M_ij = b_j  sum_j=1^n M_ij = a_i endaligned\n\nThe internal solver for the optimization problem is a netflow solver. The algorithm requires sum_i a_i = sum_j b_j = 1. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.empirical_emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}","page":"API Reference","title":"ADCME.empirical_emd","text":"empirical_emd(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}};\n    iter::Int64 = 1000, tol::Float64 = 1e-9, dist::Union{Integer,Function}=2, returnall::Bool=false)\n\nSame as empirical_sinkhorn, except that the Earth Mover Distance is computed. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.empirical_sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}","page":"API Reference","title":"ADCME.empirical_sinkhorn","text":"empirical_sinkhorn(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}};\n    reg::Union{PyObject,Float64} = 1.0, iter::Int64 = 1000, tol::Float64 = 1e-9, method::String=\"sinkhorn\", dist::Function=dist, returnall::Bool=false)\n\nComputes the empirical Sinkhorn distance with sinkhorn algorithm. Here x and y are samples from two distributions.  \n\nreg (default = 1.0): entropy regularization parameter \ntol (default = 1e-9), iter (default = 1000): tolerance and max iterations for the Sinkhorn algorithm \ndist (default = 2): Integer or Function, the distance function between two samples; if dist is integer, L-dist norm is used. \nreturnall: returns (TransportMatrix, Loss) if true; otherwise, only Loss is returned. \n\nThe implementation are adapted from https://github.com/rflamary/POT.  \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.ot_dist","page":"API Reference","title":"ADCME.ot_dist","text":"ot_dist(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}}, order::Union{Int64, PyObject}=2)\n\nComputes the distance function with norm order. dist returns a ntimes m matrix, where xin mathbbR^ntimes d and yin mathbbR^mtimes d, and the return Min mathbbR^ntimes m\n\nM_ij = x_i - y_j_o\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.ot_plot1D-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2}}","page":"API Reference","title":"ADCME.ot_plot1D","text":"ot_plot1D(a::Array{Float64, 1}, b::Array{Float64, 1}, M::Array{Float64, 2})\n\nPlots the optimal transport matrix for 1D distributions. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Array{Float64,2}, PyCall.PyObject}}","page":"API Reference","title":"ADCME.sinkhorn","text":"sinkhorn(a::Union{PyObject, Array{Float64}}, b::Union{PyObject, Array{Float64}}, M::Union{PyObject, Array{Float64}};\nreg::Float64 = 1.0, iter::Int64 = 1000, tol::Float64 = 1e-9, method::String=\"sinkhorn\")\n\nComputes the optimal transport with Sinkhorn algorithm. The mathematical formulation is \n\nbeginaligned\nargmin_P  left(P Mright) + lambda Omega(Gamma) \ntextst  Gamma 1 = a \n Gamma^T 1 = b \n Gamma geq 0 \nendaligned\n\nHere Omega is the entropic regularization. Note if lambda is very small, the algorithm may encounter numerical instabilities. \n\nThe implementation are adapted from https://github.com/rflamary/POT.  \n\n\n\n\n\n","category":"method"},{"location":"api/#MPI","page":"API Reference","title":"MPI","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"mpi.jl\"]","category":"page"},{"location":"api/#ADCME.mpi_SparseTensor","page":"API Reference","title":"ADCME.mpi_SparseTensor","text":"mutable struct mpi_SparseTensor\n    rows::PyObject \n    ncols::PyObject\n    cols::PyObject \n    values::PyObject \n    ilower::Int64 \n    iupper::Int64 \n    N::Int64\n    oplibpath::String\nend\n\nA structure to hold local data of a sparse matrix. The global matrix is assumed to be a Mtimes N square matrix.  The current processor owns rows from ilower to iupper (inclusive). The data is specified by \n\nrows: an array indicating the rows that contain nonzero values. Note rows ≥ ilower. \nncols: an array indicating the number of nonzero values for each row in rows. \ncols: the column indices for nonzero values. Its length is sum_i=1^mathrmncols mathrmncols_i\nvals: the nonzero values corresponding to each column index in cols\noplibpath: the backend library (returned by ADCME.load_plugin_MPITensor)\n\nAll data structure are 0-based. Note if we work with a linear solver, M=N.\n\nFor example, consider the sparse matrix \n\n[  1 0 0 1  ]\n[  0 1 2 1  ]\n\nWe have \n\nrows = Int32[0;1]\nncols = Int32[2;3]\ncols = Int32[0;3;1,2,3]\nvalues = [1.;1.;1.;2.;1.]\niupper = ilower + 2\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.mpi_SparseTensor-2","page":"API Reference","title":"ADCME.mpi_SparseTensor","text":"mpi_SparseTensor(sp::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}}, \n    ilower::Union{Int64, Missing} = missing,\n    iupper::Union{Int64, Missing} = missing)\n\nConstructing mpi_SparseTensor from a SparseTensor or a sparse Array.\n\n\n\n\n\n","category":"type"},{"location":"api/#ADCME.mpi_SparseTensor-Tuple{Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Int64,Int64,Int64}","page":"API Reference","title":"ADCME.mpi_SparseTensor","text":"mpi_SparseTensor(rows::Union{Array{Int32,1}, PyObject}, ncols::Union{Array{Int32,1}, PyObject}, cols::Union{Array{Int32,1}, PyObject},\n    vals::Union{Array{Float64,1}, PyObject}, ilower::Int64, iupper::Int64, N::Int64)\n\nCreate a Ntimes N distributed sparse tensor A for the current MPI processor. The current MPI processor owns rows with indices [ilower, iupper]. The submatrix is specified using the CSR format. \n\nrows: an array indicating the rows that contain nonzero values. Note rows ≥ ilower. \nncols: an array indicating the number of nonzero values for each row in rows. \ncols: the column indices for nonzero values. Its length is sum_i=1^mathrmncols mathrmncols_i\nvals: the nonzero values corresponding to each column index in cols\n\nNote that by default the indices are zero-based. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_bcast","page":"API Reference","title":"ADCME.mpi_bcast","text":"mpi_bcast(a::Union{Array{Float64}, Float64, PyObject}, root::Int64 = 0)\n\nBroadcast a from processor root to all other processors.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_finalize-Tuple{}","page":"API Reference","title":"ADCME.mpi_finalize","text":"mpi_finalize()\n\nFinalize the MPI call.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_finalized-Tuple{}","page":"API Reference","title":"ADCME.mpi_finalized","text":"mpi_finalized()\n\nReturns a boolean indicating whether the current MPI session is finalized.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_gather","page":"API Reference","title":"ADCME.mpi_gather","text":"mpi_gather(u::Union{Array{Float64, 1}, PyObject}, deps::Union{Missing, PyObject} = missing)\n\nGathers all the vectors from different processes to the root process. The function returns  a long vector which concatenates of local vectors in the order of process IDs. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_halo_exchange-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}","page":"API Reference","title":"ADCME.mpi_halo_exchange","text":"mpi_halo_exchange(u::Union{Array{Float64, 2}, PyObject},m::Int64,n::Int64; deps::Union{Missing, PyObject} = missing,\nfill_value::Float64 = 0.0, tag::Union{PyObject, Int64} = 0)\n\nPerform Halo exchnage on u (a k times k matrix). The output has a shape (k+2)times (k+2)\n\nfill_value: value used for the boundaries\ntag: message tag\ndeps: a scalar tensor; it can be used to serialize the MPI calls \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_halo_exchange2-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}","page":"API Reference","title":"ADCME.mpi_halo_exchange2","text":"mpi_halo_exchange2(u::Union{Array{Float64, 2}, PyObject},m::Int64,n::Int64; deps::Union{Missing, PyObject} = missing,\nfill_value::Float64 = 0.0, tag::Union{PyObject, Int64} = 0)\n\nSimilar to mpi_halo_exchange, but the reach is 2, i.e., for a Ntimes N matrix u, the output will be a  (N+4)times (N+4) matrix. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_init-Tuple{}","page":"API Reference","title":"ADCME.mpi_init","text":"mpi_init()\n\nInitialized the MPI session. mpi_init must be called before any run(sess, ...).\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_initialized-Tuple{}","page":"API Reference","title":"ADCME.mpi_initialized","text":"mpi_initialized()\n\nReturns a boolean indicating whether the current MPI session is initialized.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_rank-Tuple{}","page":"API Reference","title":"ADCME.mpi_rank","text":"mpi_rank()\n\nReturns the rank of current MPI process (rank 0 based).\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_recv","page":"API Reference","title":"ADCME.mpi_recv","text":"mpi_recv(a::Union{Array{Float64}, Float64, PyObject}, src::Int64, tag::Int64 = 0)\n\nReceives an array from processor src. mpi_recv requires an input for gradient backpropagation.  Typically we can write\n\nr = mpi_rank()\na = constant(Float64(r))\nif r==1\n    a = mpi_send(a, 0)\nend\nif r==0\n    a = mpi_recv(a, 1)\nend\n\nThen a=1 on both processor 0 and processor 1.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_send","page":"API Reference","title":"ADCME.mpi_send","text":"mpi_send(a::Union{Array{Float64}, Float64, PyObject}, dest::Int64,root::Int64 = 0)\n\nSends a to processor dest. a itself is returned so that the send action can be added to the computational graph.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_sendrecv","page":"API Reference","title":"ADCME.mpi_sendrecv","text":"mpi_sendrecv(a::Union{Array{Float64}, Float64, PyObject}, dest::Int64, src::Int64, tag::Int64=0)\n\nA convenient wrapper for mpi_send followed by mpi_recv.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_size-Tuple{}","page":"API Reference","title":"ADCME.mpi_size","text":"mpi_size()\n\nReturns the size of MPI world.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.mpi_sum","page":"API Reference","title":"ADCME.mpi_sum","text":"mpi_sum(a::Union{Array{Float64}, Float64, PyObject}, root::Int64 = 0)\n\nSum a on the MPI processor root.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.mpi_sync!","page":"API Reference","title":"ADCME.mpi_sync!","text":"mpi_sync!(message::Array{Int64,1}, root::Int64 = 0)\nmpi_sync!(message::Array{Float64,1}, root::Int64 = 0)\n\nSync message across all MPI processors.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.require_mpi-Tuple{}","page":"API Reference","title":"ADCME.require_mpi","text":"require_mpi()\n\nThrows an error if mpi_init() has not been called. \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.adjoint-Tuple{mpi_SparseTensor}","page":"API Reference","title":"Base.adjoint","text":"adjoint(A::mpi_SparseTensor)\n\nReturns the adjoint of A, i.e., A'. Each MPI rank owns the same number of rows.\n\n\n\n\n\n","category":"method"},{"location":"api/#Toolchain","page":"API Reference","title":"Toolchain","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"toolchain.jl\"]","category":"page"},{"location":"api/#ADCME.change_directory","page":"API Reference","title":"ADCME.change_directory","text":"change_directory(directory::Union{Missing, AbstractString})\n\nChange the current working directory to directory. If directory does not exist, it is made. \n\nIf directory is missing, the default is ADCME.PREFIXDIR.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.copy_file-Tuple{String,String}","page":"API Reference","title":"ADCME.copy_file","text":"copy_file(src::String, dest::String)\n\nCopy file src to dest\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_conda-Tuple{}","page":"API Reference","title":"ADCME.get_conda","text":"get_conda()\n\nReturns the conda executable location.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_gfortran-Tuple{}","page":"API Reference","title":"ADCME.get_gfortran","text":"get_gfortran()\n\nInstall a gfortran compiler if it does not exist.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_library-Tuple{AbstractString}","page":"API Reference","title":"ADCME.get_library","text":"get_library(filename::AbstractString)\n\nReturns a valid library file. For example, for filename = \"adcme\", we have \n\nOn MacOS, the function returns libadcme.dylib\nOn Linux, the function returns libadcme.so\nOn Windows, the function returns adcme.dll\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_library_name-Tuple{AbstractString}","page":"API Reference","title":"ADCME.get_library_name","text":"get_library_name(filename::AbstractString)\n\nReturns the OS-dependent library name \n\nExample\n\nget_library_name(\"mylibrary\")\n\nWindows: mylibrary.dll\nMacOS: libmylibrary.dylib\nLinux: libmylibrary.so\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.get_pip-Tuple{}","page":"API Reference","title":"ADCME.get_pip","text":"get_pip()\n\nReturns the location for pip\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.git_repository-Tuple{AbstractString,AbstractString}","page":"API Reference","title":"ADCME.git_repository","text":"git_repository(url::AbstractString, file::AbstractString)\n\nClone a repository url and rename it to file.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.http_file-Tuple{AbstractString,AbstractString}","page":"API Reference","title":"ADCME.http_file","text":"http_file(url::AbstractString, file::AbstractString)\n\nDownload a file from url and rename it to file.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.link_file-Tuple{AbstractString,AbstractString}","page":"API Reference","title":"ADCME.link_file","text":"link_file(target::AbstractString, link::AbstractString)\n\nMake a symbolic link link -> target\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.make_directory-Tuple{AbstractString}","page":"API Reference","title":"ADCME.make_directory","text":"make_directory(directory::AbstractString)\n\nMake a directory if it does not exist. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.read_with_env","page":"API Reference","title":"ADCME.read_with_env","text":"read_with_env(cmd::Cmd, env::Union{Missing, Dict} = missing)\n\nSimilar to run_with_env, but returns a string containing the output. \n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.require_cmakecache","page":"API Reference","title":"ADCME.require_cmakecache","text":"require_cmakecache(func::Function, DIR::String = \".\")\n\nCheck if cmake has output something. If not, func is executed.\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.require_file-Tuple{Function,Union{String, Array{String,N} where N}}","page":"API Reference","title":"ADCME.require_file","text":"require_file(f::Function, file::Union{String, Array{String}})\n\nIf any of the files/links/directories in file does not exist, execute f.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.require_import-Tuple{Symbol}","page":"API Reference","title":"ADCME.require_import","text":"require_import(s::Symbol)\n\nChecks whether the package s is imported in the Main namespace. Returns the package handle. \n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.require_library-Tuple{Function,AbstractString}","page":"API Reference","title":"ADCME.require_library","text":"require_library(func::Function, filename::AbstractString)\n\nIf the library file filename does not exist, func is executed.\n\n\n\n\n\n","category":"method"},{"location":"api/#ADCME.run_with_env","page":"API Reference","title":"ADCME.run_with_env","text":"run_with_env(cmd::Cmd, env::Union{Missing, Dict} = missing)\n\nRunning the command with the default environment and an extra environment variables env\n\n\n\n\n\n","category":"function"},{"location":"api/#ADCME.uncompress","page":"API Reference","title":"ADCME.uncompress","text":"uncompress(zipfile::AbstractString, file::AbstractString)\n\nUncompress a zip file zipfile to file (a directory). Note this function does not check that the  uncompressed content has the name file. It is used as a hint to skip uncompress action.\n\nUsers may use mv uncompress_file file to enforce the consistency.\n\n\n\n\n\n","category":"function"},{"location":"api/#Misc","page":"API Reference","title":"Misc","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [ADCME]\nPages   = [\"misc.jl\"]","category":"page"},{"location":"resource_manager/#Resource-Manager","page":"Resource Manager","title":"Resource Manager","text":"","category":"section"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"Sometimes we want to store data for different operations to share, or maintain a stateful kernel (data are shared across different invocations). One way to achieve this goal in the concurrency environment is to use  ResourceMgr in C++ custom operators. ","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"A typical usage of ResourceMgr is as follows","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"Define your own resource, which should inherent from ResourceBase and DebugString must be defined (it is an abstract method in ResourceBase).","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"#include \"tensorflow/core/framework/resource_mgr.h\"\nstruct MyVar: public ResourceBase{\n  string DebugString() const { return \"MyVar\"; };\n  mutex mu;\n  int32 val;\n};","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"Access the system ResourceMgr through ","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"auto rm = context->resource_manager();","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"Define your resource creation and manipulation method (make sure at any time there is only one single instance given the same container name and resource name).","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"MyVar* my_var;\nStatus s = rm->LookupOrCreate<MyVar>(\"my_container\", \"my_name\", &my_var, [&](MyVar** ret){\n    printf(\"Create a new container\\n\");\n    *ret = new MyVar;\n    (*ret)->val = *u_tensor;\n    return Status::OK();\n});\nDCHECK_EQ(s, Status::OK());\nmy_var->val += 1;\nmy_var->Unref();","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"When using the ResourceMgr, keep in mind that whenever you execute a new path in the computational graph, the system will create a new ResourceMgr. Therefore, to run operators that manipulate ResourceMgr in parallel, the trigger operator (which is fed to run(sess, ...)) must be attached those manipulation dependencies. ","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"See the following scripts for an example","category":"page"},{"location":"resource_manager/","page":"Resource Manager","title":"Resource Manager","text":"CMakeLists.txt, TestResourceManager.cpp, gradtest.jl","category":"page"},{"location":"videos_and_slides/#Video-Lectures-and-Slides","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"","category":"section"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"","category":"page"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"Do you know...","category":"page"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"ADCME has its own YouTube channel ADCME!","category":"page"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"","category":"page"},{"location":"videos_and_slides/#Slides","page":"Video Lectures and Slides","title":"Slides","text":"","category":"section"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"Physics Based Machine Learning for Inverse Problems (60 Pages)\nAutomatic Differentiation for Scientific Computing (51 Pages)\nDeep Neural Networks and Inverse Modeling (50 Pages)\nSubsurface Inverse Modeling with Physics Based Machine Learning (35 Pages)\nCalibrating Multivariate Lévy Processes with Neural Networks\nADCME.jl – Physics Based Machine Learning for Inverse Problems (JuliaCN 2020, 40 Pages)\nADCME – Machine Learning for Computational Engineering (Berkeley/Stanford CompFest)\nPresentation on 09/23/2020 (29 Pages)\nPresentation on 10/01/2020 (40 Pages)\nPresentation on 10/06/2020 (37 Pages)\nPresentation in SMS, Peking University 10/22/2020 (35 Pages)\nPresentation in Berkeley, 11/17/2020 (60 Pages); a relative comprehensive slide, see here (31 Pages) for a short version. \nWCCM 2020 (23 Pages)\nSIAM CSE21 (21 Pages)","category":"page"},{"location":"videos_and_slides/#Instruction-on-Installing-ADCME","page":"Video Lectures and Slides","title":"Instruction on Installing ADCME","text":"","category":"section"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"Installing ADCME (Windows)\nInstalling ADCME (MacOS)\nInstalling ADCME (Linux)\nGetting Started with ADCME","category":"page"},{"location":"videos_and_slides/#Posters","page":"Video Lectures and Slides","title":"Posters","text":"","category":"section"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"SPD-NN Poster","category":"page"},{"location":"videos_and_slides/#Videos","page":"Video Lectures and Slides","title":"Videos","text":"","category":"section"},{"location":"videos_and_slides/","page":"Video Lectures and Slides","title":"Video Lectures and Slides","text":"ADCME.jl – Physics Based Machine Learning for Inverse Problems (中文)\nData-Driven Inverse Modeling with Incomplete Observations\nAAAI Conference","category":"page"},{"location":"rbf/#Radial-Basis-Functions","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"","category":"section"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"The principle of radial basis functions (RBF) is to use linear combination of radial basis functions to approximate a function. The radial basis functions are usually global functions in the sense that its support spans over the entire domain. This property lends adaptivity and regularization to the RBF function form: unlike local basis functions such as piecewise linear functions, RBF usually does not suffer from local anomalies and produces a smoother approximation. ","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"The mathematical formulation of RBFs on a 2D domain is as follows","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"f(x y) = sum_i=1^N c_i phi(r epsilon_i) + d_0 + d_1 x + d_2 y","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Here r = sqrtx-x_i^2 + y-y_i^2. x_i y_i_i=1^N are called centers of the RBF, c_i is the coefficient, d_0+d_1x+d_2y is an additional affine term, and phi is a radial basis function parametrized by epsilon_i. Four common radial basis functions are as follows (all are supported by ADCME)","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Gaussian","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"phi(r epsilon) = e^-(epsilon r)^2","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Multiquadric","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"phi(r epsilon) = sqrt1+(epsilon r)^2","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Inverse quadratic","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"phi(r epsilon) = frac11+(epsilon r)^2","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Inverse multiquadric","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"phi(r epsilon) = frac1sqrt1+(epsilon r)^2","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"In ADCME, we allow (x_i y_i), epsilon_i, d_i and c_i to be trainable (of course, users can allow only a subset to be trainable). This is done via RBF2D function. As an example, we consider using radial basis function to approximate ","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"y = 1 + fracy^21+x^2","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"on the domain 01^2. We use the following function to visualize the result","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"using PyPlot\nn = 20\nh = 1/n\nx = Float64[]; y = Float64[]\nfor i = 1:n+1\n    for j = 1:n+1\n        push!(x, (i-1)*h)\n        push!(y, (j-1)*h)\n    end\nend\n\nclose(\"all\")\nf = run(sess, rbf(x, y))\ng = (@. 1+y^2/(1+x^2))\nfigure()\nscatter3D(x, y, f, color=\"r\")\nscatter3D(x, y, g, color=\"g\")\nxlabel(\"x\")\nylabel(\"y\")\nsavefig(\"compare.png\")\nfigure()\nscatter3D(x, y, abs.(f-g))\nxlabel(\"x\")\nylabel(\"y\")\nsavefig(\"diff.png\")","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"We consider several cases:","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Only c_i is trainable ","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"using ADCME\n\n# use centers on a uniform grid \nn = 5\nh = 1/n\nxc = Float64[]; yc = Float64[]\nfor i = 1:n+1\n    for j = 1:n+1\n        push!(xc, (i-1)*h)\n        push!(yc, (j-1)*h)\n    end\nend\n\n# by default, c is initialized to Variable(ones(...))\n# eps is initialized to ones(...) and no linear terms are used\nrbf = RBF2D(xc, yc) \n\nx = rand(100); y = rand(100)\nf = @. 1+y^2/(1+x^2)\n\nfv = rbf(x, y)\nloss = sum((f-fv)^2)\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Approximation Difference\n(Image: ) (Image: )","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Only c_i is trainable + Additional Linear Term ","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Here we need to specify d=Variable(zeros(3)) to tell ADCME we want both the constant and linear terms. If d=Variable(zeros(1)), only the constant term will be present.","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"using ADCME\n\n# use centers on a uniform grid \nn = 5\nh = 1/n\nxc = Float64[]; yc = Float64[]\nfor i = 1:n+1\n    for j = 1:n+1\n        push!(xc, (i-1)*h)\n        push!(yc, (j-1)*h)\n    end\nend\n\n# by default, c is initialized to Variable(ones(...))\n# eps is initialized to ones(...) and no linear terms are used\nrbf = RBF2D(xc, yc; d = Variable(zeros(3))) \n\nx = rand(100); y = rand(100)\nf = @. 1+y^2/(1+x^2)\n\nfv = rbf(x, y)\nloss = sum((f-fv)^2)\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Approximation Difference\n(Image: ) (Image: )","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Free every trainable variables","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"xc = Variable(rand(25))\nyc = Variable(rand(25))\nd = Variable(zeros(3))\ne = Variable(ones(25))\n\n# by default, c is initialized to Variable(ones(...))\n# eps is initialized to ones(...) and no linear terms are used\nrbf = RBF2D(xc, yc; eps = e, d = d) \n\nx = rand(100); y = rand(100)\nf = @. 1+y^2/(1+x^2)\n\nfv = rbf(x, y)\nloss = sum((f-fv)^2)\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"We see we get much better result by freeing up all variables. ","category":"page"},{"location":"rbf/","page":"Radial Basis Functions","title":"Radial Basis Functions","text":"Approximation Difference\n(Image: ) (Image: )","category":"page"},{"location":"options/#Global-Options","page":"Global Options","title":"Global Options","text":"","category":"section"},{"location":"options/","page":"Global Options","title":"Global Options","text":"ADCME manages certain algorithm hyperparameters using a global option ADCME.option. ","category":"page"},{"location":"options/","page":"Global Options","title":"Global Options","text":"Options\nOptionsSparse\nOptionsNewtonRaphson\nOptionsNewtonRaphson_LineSearch\nreset_default_options","category":"page"},{"location":"options/#ADCME.reset_default_options","page":"Global Options","title":"ADCME.reset_default_options","text":"reset_default_options()\n\nResults the ADCME options to default. \n\n\n\n\n\n","category":"function"},{"location":"options/","page":"Global Options","title":"Global Options","text":"The current options and their default values are","category":"page"},{"location":"options/","page":"Global Options","title":"Global Options","text":"using PrettyPrint\nusing ADCME\npprint(ADCME.options)","category":"page"},{"location":"options/","page":"Global Options","title":"Global Options","text":"ADCME.Options(\n  sparse=ADCME.OptionsSparse(\n    auto_reorder=true,\n    solver=\"SparseLU\",\n  ),\n  newton_raphson=ADCME.OptionsNewtonRaphson(\n    max_iter=100,\n    verbose=false,\n    rtol=1.0e-12,\n    tol=1.0e-12,\n    LM=0.0,\n    linesearch=false,\n    linesearch_options=ADCME.OptionsNewtonRaphson_LineSearch(\n      c1=0.0001,\n      ρ_hi=0.5,\n      ρ_lo=0.1,\n      iterations=1000,\n      maxstep=9999999,\n      αinitial=1.0,\n    ),\n  ),\n)","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ADCME is suitable for conducting inverse modeling in scientific computing; specifically, ADCME targets physics informed machine learning, which leverages machine learning techniques to solve challenging scientific computing problems. The purpose of the package is to: (1) provide differentiable programming framework for scientific computing based on TensorFlow automatic differentiation (AD) backend; (2) adapt syntax to facilitate implementing scientific computing, particularly for numerical PDE discretization schemes; (3) supply missing functionalities in the backend (TensorFlow) that are important for engineering, such as sparse linear algebra, constrained optimization, etc. Applications include","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"physics informed machine learning (a.k.a., scientific machine learning, physics informed learning, etc.)\ncoupled hydrological and full waveform inversion\nconstitutive modeling in solid mechanics\nlearning hidden geophysical dynamics\nparameter estimation in stochastic processes","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The package inherits the scalability and efficiency from the well-optimized backend TensorFlow. Meanwhile, it provides access to incorporate existing C/C++ codes via the custom operators. For example, some functionalities for sparse matrices are implemented in this way and serve as extendable \"plugins\" for ADCME. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"(Image: )","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"ADCME is open-sourced with an MIT license. You can find the source codes at ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"https://github.com/kailaix/ADCME.jl","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Read more about methodology, philosophy, and insights about ADCME: slides. Start with tutorial to solve your own inverse modeling problems!","category":"page"},{"location":"#Installation","page":"Overview","title":"Installation","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"It is recommended to install ADCME via","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using Pkg\nPkg.add(\"ADCME\")","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"❗ For windows users, please follow the instructions here. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"info: Info\nIn some cases, you may want to install the package and configure the environment manually. Step 1: Install ADCME on a computer with Internet access and zip all files from the following pathsjulia> using Pkg\njulia> Pkg.depots()The files will contain all the dependencies.Step 2:  Copy the deps.jl file from your built ADCME and modify it for your local repository. using ADCME; \nprint(joinpath(splitdir(pathof(ADCME))[1], \"deps/deps.jl\"))","category":"page"},{"location":"#Optimization","page":"Overview","title":"Optimization","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"ADCME is an all-in-one solver for gradient-based optimization problems. It leverages highly optimized and concurrent/parallel kernels that are implemented in C++ for both the forward computation and gradient computation. Additionally, it provides a friendly user interface to specify the mathematical optimization problem: constructing a computational graph. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Let's consider a simple problem: we want to solve the unconstrained optimization problem","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"f(mathbfx) = sum_i=1^n-1left 100(x_i+1-x_i^2) + (1-x_i)^2 right","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"where x_iin -1010 and n=100. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"We solve the problem using the L-BFGS-B method. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using ADCME\nn = 100\nx = Variable(rand(n)) # Use `Variable` to mark the quantity that gets updated in optimization\nf = sum(100((x[2:end]-x[1:end-1])^2 + (1-x[1:end-1])^2)) # Use typical Julia syntax \nsess = Session(); init(sess) # Create and initialize a session is mandatory for activating the computational graph\nBFGS!(sess, f, var_to_bounds = Dict(x=>[-10.,10.]))","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"To get the value of mathbfx, we use run to extract the values ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"run(sess, x)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The above code will return a value close to  the optimal values mathbfx = 1 1 ldots 1. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"info: Info\nYou can also use Optimize! to use other optimizers. For example, if you want to use an optimizer, such as ConjugateGraidient from the Optim package, simply replace BFGS! with Optimize! and specify the corresponding optimizerusing Optim\nOptimize!(sess, loss, optimizer = ConjugateGradient())","category":"page"},{"location":"#Machine-Learning","page":"Overview","title":"Machine Learning","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"You can also use ADCME to do typical machine learning tasks and leverage the Julia machine learning ecosystem! Here is an example of training a ResNet for digital number recognition.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using MLDatasets\nusing ADCME\n\n# load data \ntrain_x, train_y = MNIST.traindata()\ntrain_x = reshape(Float64.(train_x), :, size(train_x,3))'|>Array\ntest_x, test_y = MNIST.testdata()\ntest_x = reshape(Float64.(test_x), :, size(test_x,3))'|>Array\n\n# construct loss function \nADCME.options.training.training = placeholder(true)\nx = placeholder(rand(64, 784))\nl = placeholder(rand(Int64, 64))\nresnet = Resnet1D(10, num_blocks=10)\ny = resnet(x)\nloss = mean(sparse_softmax_cross_entropy_with_logits(labels=l, logits=y))\n\n# train the neural network \nopt = AdamOptimizer().minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    idx = rand(1:60000, 64)\n    _, loss_ = run(sess, [opt, loss], feed_dict=Dict(l=>train_y[idx], x=>train_x[idx,:]))\n    @info i, loss_\nend\n\n# test \nfor i = 1:10\n    idx = rand(1:10000,100)\n    y0 = resnet(test_x[idx,:])\n    y0 = run(sess, y0, ADCME.options.training.training=>false)\n    pred = [x[2]-1 for x in argmax(y0, dims=2)]\n    @info \"Accuracy = \", sum(pred .== test_y[idx])/100\nend","category":"page"},{"location":"#Contributing","page":"Overview","title":"Contributing","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Contribution and suggestions are always welcome. In addition, we are also looking for research collaborations. You can submit issues for suggestions, questions, bugs, and feature requests, or submit pull requests to contribute directly. You can also contact the authors for research collaboration. ","category":"page"},{"location":"installmpi/#Configure-MPI-for-Distributed-Computing","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"","category":"section"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"This section will cover how to configure ADCME for MPI functionalities.","category":"page"},{"location":"installmpi/#Configure-the-MPI-backend","page":"Configure MPI for Distributed Computing","title":"Configure the MPI backend","text":"","category":"section"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"The first step is to configure your MPI backend. There are many choices depending on your operation system. For example, Windows have Microsoft MPI. There are also OpenMPI and Intel MPI available on most Linux distributions. If you want to use your own MPI backend, you need to locate the MPI libraries, header files, and executable (e.g., mpirun). You need to build ADCME with the following environment variable:","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"MPI_C_LIBRARIES: the MPI shared library, for example, on Windows, it may be ","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\MPI\\\\Lib\\\\x64\\\\msmpi.lib","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"On Unix systems, it may be  /opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/lib/release/libmpi.so Note that you must include the shared library in the variable. ","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"MPI_INCLUDE_PATH: the directory where mpi.h is located, for example,","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"C:\\\\Program Files (x86)\\\\Microsoft SDKs\\\\MPI\\\\Include Or in a Unix system, we have  /opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/include/","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"The simplest way is to add these variables in the environment variables. For example, in Linux, we can add the following lines in the ~/.bashrc file. ","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"export MPI_C_LIBRARIES=/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/lib/libmpi.so\nexport MPI_INCLUDE_PATH=/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/include/\nalias mpirun=/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/bin/mpirun","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"In the case you do not have an MPI backend, ADCME provides you a convenient way to install MPI by compiling from source. Just run ","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"using ADCME\ninstall_openmpi()","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"This should install an OpenMPI library for you. Note this functionality does not work on Windows and is only tested on Linux. ","category":"page"},{"location":"installmpi/#Build-MPI-Libraries","page":"Configure MPI for Distributed Computing","title":"Build MPI Libraries","text":"","category":"section"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"The MPI functionality of ADCME is not fulfilled at this point. To enable the MPI support, you need to recompile the built-in custom operators.","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"using ADCME\nADCME.precompile(true)","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"At this point, you will be able to use MPI features. ","category":"page"},{"location":"installmpi/#Build-MPI-Custom-Operators","page":"Configure MPI for Distributed Computing","title":"Build MPI Custom Operators","text":"","category":"section"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"You can also build MPI-enabled custom operators by calling","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"using ADCME\ncustomop(with_mpi=true)","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"In this case, there will be extra lines in CMakeLists.txt to setup MPI dependencies.","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"IF(DEFINED ENV{MPI_C_LIBRARIES})\n  set(MPI_INCLUDE_PATH $ENV{MPI_INCLUDE_PATH})\n  set(MPI_C_LIBRARIES $ENV{MPI_C_LIBRARIES})\n  message(\"MPI_INCLUDE_PATH = ${MPI_INCLUDE_PATH}\")\n  message(\"MPI_C_LIBRARIES = ${MPI_C_LIBRARIES}\")\n  include_directories(${MPI_INCLUDE_PATH})\nELSE()\n  message(\"MPI_INCLUDE_PATH and/or MPI_C_LIBRARIES is not set. MPI operators are not compiled.\")\nENDIF()","category":"page"},{"location":"installmpi/#Running-MPI-Applications-with-Slurm","page":"Configure MPI for Distributed Computing","title":"Running MPI Applications with Slurm","text":"","category":"section"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"To run MPI applications with slurm, the following commands are useful","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"sbatch -n 4 -c 8 mpirun -n 4 julia app.jl ","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"This specifies 4 tasks and each task uses 8 cores. You can also replace sbatch with salloc.","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"To diagonose the application, you can also let mpirun print out the rank information, e.g., in OpenMPI we have","category":"page"},{"location":"installmpi/","page":"Configure MPI for Distributed Computing","title":"Configure MPI for Distributed Computing","text":"sbatch -n 4 -c 8 mpirun --report-bindings -n 4 julia app.jl","category":"page"},{"location":"tutorial/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"ADCME: Your Gateway to Inverse Modeling with Physics Based Machine Learning","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"ADCME is an open-source Julia package for inverse modeling in scientific computing using automatic differentiation. The backend of ADCME is the high performance deep learning framework, TensorFlow, which provides parallel computing and automatic differentiation features based on computational graph, but  ADCME augments TensorFlow by functionalities–-like sparse linear algebra–-essential for scientific computing. ADCME leverages the Julia environment for maximum efficiency of computing. Additionally, the syntax of ADCME is designed from the beginning to be compatible with the Julia syntax, which is friendly for scientific computing. ","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Prerequisites","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"The tutorial does not assume readers with experience in deep learning. However, basic knowledge of scientific computing in Julia is required. ","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Tutorial Series","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"PDE Constrained Optimization","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Sparse Linear Algebra in ADCME","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Numerical Scheme in ADCME: Finite Difference Example","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Numerical Scheme in ADCME: Finite Element Example","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Inverse Modeling in ADCME","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Inverse Modeling Recipe","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Combining NN with Numerical Schemes","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Advanced: Automatic Differentiation for Implicit Operations","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Advanced: Custom Operators","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Advanced: Debugging and Profiling","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"Exercise[exercise]","category":"page"},{"location":"tutorial/","page":"Overview","title":"Overview","text":"[exercise]: If you want to discuss or check your exercise solutions, you are welcome to send an email to kailaix@hotmail.com.","category":"page"},{"location":"multithreading/#Understand-the-Multi-threading-Model","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Multi-threading is a very important technique for accelerating simulations in ADCME. Through this section, we look into the multi-threading models of ADCME's backend, TensorFlow. Let us start with some basic concepts related to CPUs.","category":"page"},{"location":"multithreading/#Processes,-Threads,-and-Cores","page":"Understand the Multi-threading Model","title":"Processes, Threads, and Cores","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"We often hear about processes and threads when talking about multi-threading. In a word, a process is a program in execution. A process may invoke multiple threads. A thread can be viewed as a scheduler for executing each line of codes in order. It tells the CPU to perform an instruction. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"The biggest difference is that different processes do not share memory with each other. But different threads within the same process has the same memory space. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Up till now, processes and threads are logical concepts, which are not bound to the physical devices. Cores are physical concepts. Nowadays, each CPU contains multiple cores. Cores contain workers that actually perform computation, and these workers are called ALUs (arithmetic logic units). To use these ALUs, we need some schedulers that tell the CPU/cores to perform certain tasks. This is done by hardware threads. Typically when we want to do some computation, we need to load data first and then perform calculations on ALUs. The data loading process is also taken care by the hardware threads. Therefore, it is possible that the ALUs are waiting for input data. One clever idea in computer science is to use pipelining: overlapping data loading of the current instruction and computation of the last instruction. This means we need more schedulers, i.e., hardware threads, to take care of data loading and computing simultaneously. Therefore, modern CPUs usually have multiple hardware threads for one core. For example, Intel CPUs have the so-called hyperthreading technology, i.e., each core has two physical threads. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Now we understand four concepts: processes, (logical) threads, cores, hardware threads. So what is the relationship between threads and hardware threads? Actually this is straight-forward: logical threads are mapped to hardware threads. For example, if there are 4 logical threads and 4 hardware threads, the OS may map each logical thread to one distinct hardware thread. If there are more than 4 logical threads, some logical threads may be mapped to one. That says, these logical threads will not enjoy truly parallelism.","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Now let's consider how ADCME works: for one CPU, ADCME always runs only one process. But to gain maximum efficiency, ADCME will create multiple threads to leverage any parallelism we have in hardware resources and computational models. ","category":"page"},{"location":"multithreading/#Inter-and-Intra-Parallelism","page":"Understand the Multi-threading Model","title":"Inter and Intra Parallelism","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"There are two types of parallelism in ADCME execution: inter and intra. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Consider a computational graph, there may be multiple independent operators and therefore we can execute them in parallel. This type of parallelism is called inter-parallelism. For example, ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"using ADCME \n\na1 = constant(rand(10))\na2 = constant(rand(10))\na3 = a1 * a2 \na4 = a1 + a2 \na5 = a3 + a4","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"In the above code, a3 = a1 * a2 and a4 = a1 + a2 are independent and can be executed in parallel. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Another type of parallelism is intra-parallel, that is, the computation within each operator can be computed in parallel. For example, in the example above, we can compute the first 5 entries and last 5 entries in a4 = a1 + a2 in parallel. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"These types of parallelism can be achieved using multi-threading. In the next section, we explain how this is implemented in TensorFlow.","category":"page"},{"location":"multithreading/#ThreadPools","page":"Understand the Multi-threading Model","title":"ThreadPools","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"The backend of ADCME, TensorFlow, uses two threadpools for multithreading. One thread pool is for inter-parallelism, and the other is for intra-parallelism. They can be set by the users.","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"One common mistake is that users think in terms of hardware threads instead of logical threads. For example, if we have 8 hardware threads in total, one might want to allocate 4 threads for inter-parallelism and 4 threads for intra-parallelism. That's not true. When we talk about allocating threads for intra and inter thread pools, we are always talking about logical threads. So we can have a threadpool containing 100 threads for both inter and intra thread pools even if we only have 8 hardware threads in total. And in the runtime, inter and intra thread pools may use the same hardware threads for scheduling tasks. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"The following figure is an illustration of the two thread pools of ADCME. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"(Image: )","category":"page"},{"location":"multithreading/#How-to-Use-the-Intra-Thread-Pool","page":"Understand the Multi-threading Model","title":"How to Use the Intra Thread Pool","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"In practice, when we implement custom operators, we may want to use the intra thread pool. Here gives an example how to use thread pools. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"#include <thread>\n#include <chrono>\n#include <condition_variable>\n#include <atomic>\n\nvoid print_thread(std::atomic_int &cnt, std::condition_variable &cv){\n  std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n  printf(\"My thread ID is %d\\n\", std::this_thread::get_id());\n  cnt++;\n  if (cnt==7) cv.notify_one();\n}\n\nvoid threadpool_print(OpKernelContext* context){\n  thread::ThreadPool * const tp = context->device()->tensorflow_cpu_worker_threads()->workers;\n  std::atomic_int cnt = 0;\n  std::condition_variable cv;\n  std::mutex mu;\n\n  printf(\"Number of intra-parallel thread = %d\\n\", tp->NumThreads());\n  printf(\"Maximum Parallelism = %d\\n\", port::MaxParallelism());\n\n  for (int i = 0; i < 7; i++)\n    tp->Schedule([&cnt, &cv](){print_thread(cnt, cv);});\n  \n  {\n    std::unique_lock<std::mutex> lck(mu);\n    cv.wait(lck, [&cnt](){return cnt==7;});\n  }\n  printf(\"Op finished\\n\");\n}","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Basically, we can asynchronously launch jobs using the thread pools. Additionally, we are responsible for synchronization. Here we have used condition variables for synchronization. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Typically our CPU operators are synchronous and do not need the thread pools. But it does not hard to have an intra thread pool. ","category":"page"},{"location":"multithreading/#Runtime-Optimizations","page":"Understand the Multi-threading Model","title":"Runtime Optimizations","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"If you are using Intel CPUs, we may have some runtime optimization configurations. See this link for details. Here, we show the effects of some optimizations. ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"We already understand intra_op_parallelism_threads and inter_op_parallelism_threads; now let us consider some other options. We consider computing sin function using the following formula ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"sin x approx x - fracx^33 + fracx^55 - fracx^77","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"The implementation can be found here.","category":"page"},{"location":"multithreading/#Configure-OpenMP","page":"Understand the Multi-threading Model","title":"Configure OpenMP","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"To set the number of OMP threads, we can configure the OMP_NUM_THREADS environment variable. One caveat is that the variable must be set before loading ADCME. For example ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"ENV[\"OMP_NUM_THREADS\"] = 5\nusing ADCME","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Running the omp_thread.jl, we have the following output","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"There are 5 OpenMP threads\n4 is computing...\n0 is computing...\n4 is computing...\n1 is computing...\n1 is computing...\n0 is computing...\n3 is computing...\n3 is computing...\n2 is computing...\n2 is computing...","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"We see that there are 5 threads running. ","category":"page"},{"location":"multithreading/#Configure-Number-of-Devices","page":"Understand the Multi-threading Model","title":"Configure Number of Devices","text":"","category":"section"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"Session accepts keywords CPU, which limits the number of CPUs we can use. Note, CPU corresponds to the number of CPU devices, not cores or threads. For example, if we run num_device.jl with (default is using all CPUs)","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"sess = Session(CPU=1); init(sess)","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"We will see ","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"There are 144 OpenMP threads","category":"page"},{"location":"multithreading/","page":"Understand the Multi-threading Model","title":"Understand the Multi-threading Model","text":"This is because we have 144 cores in our machine. ","category":"page"},{"location":"tu_basic/#ADCME-Basics:-Tensor,-Type,-Operator,-Session-and-Kernel","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"","category":"section"},{"location":"tu_basic/#Tensors-and-Operators","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"Tensors and Operators","text":"","category":"section"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Tensor is a data structure for storing structured data, such as a scalar, a vector, a matrix or a high dimensional tensor. The name of the ADCME backend, TensorFlow, is also derived from its core framework, Tensor. Tensors can be viewed as symbolic versions of Julia's Array. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"A tensor is a collection of n-dimensional arrays. ADCME represents tensors using a PyObject handle to the TensorFlow Tensor data structure. A tensor has three important properties","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"name: Each Tensor admits a unique name. \nshape: For scalars, the shape is always an empty tuple (); for n-dimensional vectors, the shape is (n,); for matrices or higher order tensors, the shape has the form (n1, n2, ...)\ndtype: The type of the tensors. There is a one-to-one correspondence between most TensorFlow types and Julia types (e.g., Int64, Int32, Float64, Float32, String, and Bool). Therefore, we have overloaded the type name so users have a unified interface. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"(Image: )","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"An important difference is that tensor object stores data in the row-major while Julia's default for Array is column major. The difference may affect performance if not carefully dealt with, but more often than not, the difference is not relevant if you do not convert data between Julia and Python often. Here is a representation of ADCME tensor","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"(Image: )","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"There are 4 ways to create tensors. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"constant. As the name suggests, constant creates an immutable tensor from Julia Arrays. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"constant(1.0)\nconstant(rand(10))\nconstant(rand(10,10))","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Variable. In contrast to constant, Variable creates tensors that are mutable. The mutability allows us to update the tensor values, e.g., in an optimization procedure. It is very important to understand the difference between constant and Variable: simply put, in inverse modeling, tensors that are defined as Variable should be the quantity you want to invert, while constant is a way to provide known data.","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Variable(1.0)\nVariable(rand(10))\nVariable(rand(10,10))","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"placeholder. placeholder is a convenient way to specify a tensor whose values are to be provided in the runtime. One use case is that you want to try out different values for this tensor and scrutinize the simulation result. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"placeholder(Float64, shape=[10,10])\nplaceholder(rand(10)) # default value is `rand(10)`","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"SparseTensor. SparseTensor is a special data structure to store a sparse matrix. Although it is not very emphasized in machine learning, sparse linear algebra is one of the cores to scientific computing. Thus possessing a strong sparse linear algebra support is the key to success inverse modeling with physics based machine learning. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"using SparseArrays\nSparseTensor(sprand(10,10,0.3))\nSparseTensor([1,2,3],[2,2,2],[0.1,0.3,0.5],3,3) # specify row, col, value, number of rows, number of columns","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Now we know how to create tensors, the next step is to perform mathematical operations on those tensors.","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Operator can be viewed as a function that takes multiple tensors and outputs multiple tensors. In the computational graph, operators are represented by nodes while tensors are represented by edges. Most mathematical operators, such as +, -, * and /, and matrix operators, such as matrix-matrix multiplication, indexing and linear system solve, also work on tensors. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"a = constant(rand(10,10))\nb = constant(rand(10))\na + 1.0 # add 1 to every entry in `a`\na * b # matrix vector production\na * a # matrix matrix production\na .* a # element wise production\ninv(a) # matrix inversion","category":"page"},{"location":"tu_basic/#Session","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"Session","text":"","category":"section"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"With the aforementioned syntax to create and transform tensors, we have created a computational graph. However, at this point, all the operations are symbolic, i.e., the operators have not been executed yet. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"To trigger the actual computing, the TensorFlow mechanism is to create a session, which drives the graph based optimization (like detecting dependencies) and executes all the operations.  ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"(Image: )","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"a = constant(rand(10,10))\nb = constant(rand(10))\nc = a * b\nsess = Session()\nrun(sess, c) # syntax for triggering the execution of the graph","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"If your computational graph contains Variables, which can be listed via get_collection, then you must initialize your graph before any run command, in which the Variables are populated with initial values","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"init(sess)","category":"page"},{"location":"tu_basic/#Kernel","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"Kernel","text":"","category":"section"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"The kernels provide the low level C++ implementation for the operators. ADCME augments users with missing features in TensorFlow that are crucial for scientific computing and tailors the syntax for numerical schemes. Those kernels, depending on their implementation, can be used in CPU, GPU, TPU or heterogenious computing environments. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"All the intensive computations are  done either in Julia or C++, and therefore we can achieve very high performance if the logic is done appropriately. For performance critical part, users may resort to custom kernels using customop, which allows you to incooperate custom designed C++ codes. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"(Image: )","category":"page"},{"location":"tu_basic/#Summary","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"Summary","text":"","category":"section"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"ADCME performances operations on tensors. The actual computations are pushed back to low level C++ kernels via operators. A session is need to drive the executation of the computation. It will be easier for you to analyze computational cost and optimize your codes with this computation model in mind. ","category":"page"},{"location":"tu_basic/#Tensor-Operations","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"Tensor Operations","text":"","category":"section"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Here we show a list of commonly used operators in ADCME. ","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"Description API\nConstant creation constant(rand(10))\nVariable creation Variable(rand(10))\nGet size size(x)\nGet size of dimension size(x,i)\nGet length length(x)\nResize reshape(x,5,3)\nVector indexing v[1:3],v[[1;3;4]],v[3:end],v[:]\nMatrix indexing m[3,:], m[:,3], m[1,3],m[[1;2;5],[2;3]]\n3D Tensor indexing m[1,:,:], m[[1;2;3],:,3], m[1:3:end, 1, 4]\nIndex relative to end v[end], m[1,end]\nExtract row (most efficient) m[2], m[2,:]\nExtract column m[:,3]\nConvert to dense diagonal matrix diagm(v)\nConvert to sparse diagonal matrix spdiag(v)\nExtract diagonals as vector diag(m)\nElementwise multiplication a.*b\nMatrix (vector) multiplication a*b\nMatrix transpose m'\nDot product sum(a*b)\nSolve A\\b\nInversion inv(m)\nAverage all elements mean(x)\nAverage along dimension mean(x, dims=1)\nMaximum/Minimum of all elements maximum(x), minimum(x)\nSqueeze all single dimensions squeeze(x)\nSqueeze along dimension squeeze(x, dims=1), squeeze(x, dims=[1;2])\nReduction (along dimension) norm(a), sum(a, dims=1)\nElementwise Multiplication a.*b\nElementwise Power a^2\nSVD svd(a)\nA[indices] = updates A = scatter_update(A, indices, updates)\nA[indices] += updates A = scatter_add(A, indices, updates)\nA[indices] -= updates A = scatter_sub(A, indices, updates)\nA[idx, idy] = updates A = scatter_update(A, idx, idy, updates)\nA[idx, idy] += updates A = scatter_add(A, idx, idy, updates)\nA[idx, idy] -= updates A = scatter_sub(A, idx, idy, updates)","category":"page"},{"location":"tu_basic/","page":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","title":"ADCME Basics: Tensor, Type, Operator, Session & Kernel","text":"tip: Tip\nIn some cases you might find some features missing in ADCME but present in TensorFlow. You can always use tf.<function_name>. It's compatible.","category":"page"},{"location":"hessian/#The-Mathematical-Structure-of-DNN-Hessians","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"","category":"section"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"It has been observed empirically that the converged weights and biases of DNNs are close to a proper initial guess. This indicates that DNNs are well approximated with its first order Taylor expansion. ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Let us consider a scalar-valued DNN f(x theta), where x is a d-dimensional input and theta is the weights and biases. The initial guess is theta_0. Then we have ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"f(x theta) approx f(x theta_0) + nabla_theta f(x theta_0)^T (theta - theta_0)tag1","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Consider a quadratic loss function ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"L(theta) = sum_i=1^m (f(x_i theta) - y_i)^2","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Using the Taylor expansion Eq. 1, we have ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"L(theta) approx sum_i=1^m (f(x_i theta_0) + nabla_theta f(x_i theta_0)^T (theta - theta_0) - y_i)^2 tag2","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Eq. 2 is a quadratic function of theta, and the Hessian matrix is given by ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"H = sum_i=1^m nabla_theta f(x_i theta_0) nabla_theta f(x_i theta_0)^T","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Let us consider nabla_theta f(x_i theta_0) nabla_theta f(x_i theta_0)^T, which is a rank-one matrix. Therefore, one straight-forward corollary is ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"textrank(H) leq m","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"That is, for small data, the rank of H is small, and the rank of H is always no greater than the size of samples. The implication is significant for applications in computational engineering: unlike many machine learning problems, where plenty of training data are available, data are usually scarce in computational engineering (e.g., expensive to collect in experiments). Thus a low rank Hessian is predominate in engineering applications. ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"We can also write H as follows:","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"H = X^TX quad X = beginbmatrixnabla_theta f(x_1 theta_0)^T  nabla_theta f(x_2 theta_0)^T  ldots  nabla_theta f(x_m theta_0)^Tendbmatrix","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"We have textrank(H) = textrank(X^TX) leq textrank(X), that is, the rank of H is upper bounded by the rank of X. The rank of X determines on the information provided by x_i_i=1^m. For example, if most of x_i are the same or similar, we expect X to have a low rank. ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"We demonstrate the rank of Hessians using the following examples: let x_i = fraci-199, i = 1 2 ldots 100, and y_i = sin(pi x_i). We train a scalar-valued deep neural network f(x theta) with  3 hidden neurals, 20 neurons per layer, and tanh activation functions. The loss function is ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"L(theta) = sum_iinmathcalI (y_i - f(x_i theta))^2","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"Here mathcalI is a subset of 12ldots 100 and linearly spaced between 1 and 100. We train the deep neural network using L-BFGS-B optimizer, and calculate the Hessian matrix H = fracpartial^2 Lpartial theta partial theta^T. We report the number of positive eigenvalues, which is defined as  lambda  10^-6 lambda_max Here lambda_max is the maximum eigenvalue. ","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"(Image: )","category":"page"},{"location":"hessian/","page":"The Mathematical Structure of DNN Hessians","title":"The Mathematical Structure of DNN Hessians","text":"We can see when the dataset size is small, the Hessian rank is the same as the dataset size. The rank reaches plateau when the datasize increases to 6.  ","category":"page"},{"location":"tu_inv/#Inverse-Modeling-with-ADCME","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"","category":"section"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Roughly speaking, there are four types of inverse modeling in partial differential equations. We have developed numerical methods that takes advantage of deep neural networks and automatic differentiation. To be more concrete, let the forward model be a 1D Poisson equation","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"beginaligned-nabla (Xnabla u(x)) = varphi(x)  xin (01) u(0)=u(1) = 0endaligned","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Here X is the unknown  which may be one of the four forms: parameter, function, functional or random variable. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Inverse problem Problem type ADCME Approach Reference\nnablacdot(cnabla u) = varphi(x) Parameter Adjoint-State Method 1 2\nnablacdot(f(x)nabla u) = varphi(x) Function DNN as a Function Approximator 3\nnablacdot(f(u)nabla u) = varphi(x) Functional Residual Learning or Physics Constrained Learning 4\nnablacdot(varpinabla u) = varphi(x) Stochastic Inversion Generative Neural Networks 5","category":"page"},{"location":"tu_inv/#Parameter-Inverse-Problem","page":"Inverse Modeling with ADCME","title":"Parameter Inverse Problem","text":"","category":"section"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"When X is just a scalar/vector, we call this type of problem parameter inverse problem. We consider a manufactured solution: the exact X=1 and u(x)=x(1-x), so we have","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"varphi(x) = 2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Assume we can observe u(05)=025 and the initial guess for X_0=10. We use finite difference method to discretize the PDE and the interval 01 is divided uniformly to 0=x_0x_1ldotsx_n=1, with n=100, x_i+1-x_i = h=frac1n.","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"we can solve the problem with the following code snippet","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"using ADCME\nn = 100\nh = 1/n\nX0 = Variable(10.0)\nA = X0 * diagm(0=>2/h^2*ones(n-1), 1=>-1/h^2*ones(n-2), -1=>-1/h^2*ones(n-2)) # coefficient matrix for the finite difference\nφ = 2.0*ones(n-1) # right hand side\nu = A\\φ\nloss = (u[50] - 0.25)^2\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"After around 7 iterations, the estimated X_0 converges to 1.0000000016917243. ","category":"page"},{"location":"tu_inv/#Function-Inverse-Problem","page":"Inverse Modeling with ADCME","title":"Function Inverse Problem","text":"","category":"section"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"When X is a function that does not depend on u, i.e., a function of location x, we call this type of problem function inverse problem. A common approach to this type of problem is to approximate the unknown function X with a parametrized form, such as piecewise linear functions, radial basis functions or Chebyshev polynomials; sometimes we can also discretize X and substitute X by a vector of its values at the discrete grid nodes. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"This tutorial is not aimed at the comparison of different methods. Instead, we show how we can use neural networks to represent X and train the neural network by coupling it with numerical schemes. The gradient calculation can be laborious with the traditional adjoint state methods but is trivial with automatic differentiation. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Let's assume the true X has the following form","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"X(x) = frac11+x^2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The exact varphi is given by ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"varphi(x) = frac2 left(x^2 - x left(2 x - 1right) + 1right)left(x^2 + 1right)^2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The idea is to use a neural network mathcalN(xw) with weights and biases w that maps the location xin mathbbR to a scalar value such that","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"mathcalN(x w)approx X(x)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"To find the optional w, we solve the Poisson equation with X(x)=mathcalN(xw), where the numerical scheme is ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"left( -fracX_i+X_i+12 right) u_i+1 + fracX_i-1+2X_i+X_i+12 u_i + left( -fracX_i+X_i-12 right) = varphi(x_i) h^2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Here X_i = mathcalN(x_i w). ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Assume we can observe the full solution u(x), we can compare it with the solution u(xw), and minimize the loss function ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"L(w) = sum_i=2^n-1 (u(x_iw)-u(x_i))^2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"using ADCME\nn = 100\nh = 1/n\nx = collect(LinRange(0, 1.0, n+1))\nX = ae(x, [20,20,20,1])^2  # to ensure that X is positive, we use NN^2 instead of NN\nA = spdiag(\n  n-1,\n  1=>-(X[2:end-2] + X[3:end-1])/2,\n  -1=>-(X[3:end-1] + X[2:end-2])/2,\n  0=>(2*X[2:end-1]+X[3:end]+X[1:end-2])/2\n)/h^2\nφ = @. 2*x*(1 - 2*x)/(x^2 + 1)^2 + 2 /(x^2 + 1)\nu = A\\φ[2:end-1] # for efficiency, we can use A\\φ[2:end-1] (sparse solver)\nu_obs = (@. x * (1-x))[2:end-1]\nloss = sum((u - u_obs)^2)\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"We show the exact X(x) and the pointwise error in the following plots","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"leftmathcalN(x_iw)-X(x_i)right","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"(Image: errorX) (Image: exactX)\nPointwise Absolute Error Exact X(u)","category":"page"},{"location":"tu_inv/#Functional-Inverse-Problem","page":"Inverse Modeling with ADCME","title":"Functional Inverse Problem","text":"","category":"section"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"In the functional inverse problem, X is a function that depends on u (or both x and u); it must not be confused with the functional inverse problem and it is much harder to solve (since the equation is nonlinear). ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"As an example, assume ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"beginalignednabla (X(u)nabla u(x)) = varphi(x)  xin (01) u(0)=u(1) = 0endaligned","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"where the quantity of interest is ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"X(u) = frac11+100u^2","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The corresponding varphi can be analytically evaluated (e.g., using SymPy).","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"To solve the Poisson equation, we use the standard Newton-Raphson scheme, in which case, we need to compute the residual","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"R_i = X(u_i)left(fracu_i+1-u_i-12hright)^2 + X(u_i)fracu_i+1+u_i-1-2u_ih^2 - varphi(x_i)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"and the corresponing Jacobian","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"fracpartial R_ipartial u_j = left beginmatrix  -fracX(u_i)hfracu_i+1-u_i-12h + fracX(u_i)h^2  j=i-1 X(u_i)fracu_i+1-u_i-12h + X(u_i)fracu_i+1+u_i-1-2u_ih^2 - frac2h^2X(u_i)  j=i  fracX(u_i)2hfracu_i+1-u_i-12h + fracX(u_i)h^2  j=i+1 0  j-i1  endmatrix right","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Just like the function inverse problem, we also use a neural network to approximate X(u); the difference is that the input of the neural network is u instead of x. It is convenient to compute X(u) with automatic differentiation.","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Solving the forward problem (given X(u), solve for u) requires conducting Newton-Raphson iterations. One challenge here is that the Newton-Raphson operator is a nonlinear implicit operator that does not fall into the types of operators where automatic differentiation applies. The relevant technique is physics constrained learning. The basic idea is to extract the gradients by the implicit function theorem. The limitation is that we need to provide the Jacobian matrix for the residual term in the Newton-Raphson algorithm. In ADCME, the complex algorithm is wrapped in the API NonlinearConstrainedProblem and users only need to focus on constructing the residual and the gradient term","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"using ADCME \nusing PyPlot\n\nfunction residual_and_jacobian(θ, u)\n    X = ae(u, config, θ) + 1.0     # (1)\n    Xp = tf.gradients(X, u)[1]\n    Xpp = tf.gradients(Xp, u)[1]\n    up = [u[2:end];constant(zeros(1))]\n    un = [constant(zeros(1)); u[1:end-1]]\n    R = Xp .* ((up-un)/2h)^2 + X .* (up+un-2u)/h^2 - φ\n    dRdu = Xpp .* ((up-un)/2h)^2 + Xp.*(up+un-2u)/h^2 - 2/h^2*X \n    dRdun = -Xp[2:end]/h .* (up-un)[2:end]/2h + X[2:end]/h^2\n    dRdup = Xp[1:end-1]/h .* (up-un)[1:end-1]/2h + X[1:end-1]/h^2\n    J = spdiag(n-1, \n        -1=>dRdun,\n        0=>dRdu,\n        1=>dRdup)     # (2)\n    return R, J\nend\n\n\nconfig = [20,20,20,1]\nn = 100\nh = 1/n\nx = collect(LinRange(0, 1.0, n+1))\n\nφ = @. (1 - 2*x)*(-100*x^2*(2*x - 2) - 200*x*(1 - x)^2)/(100*x^2*(1 - x)^2 + 1)^2 - 2 - 2/(100*x^2*(1 - x)^2 + 1)\nφ = φ[2:end-1]\nθ = Variable(ae_init([1,config...]))\nu0 = constant(zeros(n-1)) \nfunction L(u)    # (3)\n  u_obs = (@. x * (1-x))[2:end-1]\n  loss = mean((u - u_obs)^2) \nend\nloss, solution, grad = NonlinearConstrainedProblem(residual_and_jacobian, L, θ, u0)\nX_pred = ae(collect(LinRange(0.0,0.25,100)), config, θ) + 1.0\n\nsess = Session(); init(sess)\nBFGS!(sess, loss, grad, θ)\nx_pred, sol = run(sess, [X_pred, solution])\n\nfigure(figsize=(10,4))\nsubplot(121)\ns = LinRange(0.0,0.25,100)\nx_exact = @. 1/(1+100*s^2) + 1\nplot(s, x_exact, \"-\", linewidth=3, label=\"Exact\")\nplot(s, x_pred, \"o\", markersize=2, label=\"Estimated\")\nlegend()\nxlabel(\"u\")\nylabel(\"X(u)\")\n\nsubplot(122)\ns = LinRange(0.0,1.0,101)[2:end-1]\nplot(s, (@. s * (1-s)), \"-\", linewidth=3, label=\"Exact\")\nplot(s, sol, \"o\", markersize=2, label=\"Estimated\")\nlegend()\nxlabel(\"x\")\nylabel(\"u\")\nsavefig(\"nn.png\")","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Detailed explaination: (1) This is the neural network we constructed. Note that with default initialization, the neural network output values are close to 0, and thus poses numerical stability issue for the solver. We can shift the neural network value by +1 (equivalently, we use 1 for the initial guess of the last bias term); (2) The jacobian matrix is sparse, and thus we use spdiag to create a sparse matrix; (3) A loss function is formulated and minimized in the physics constrained learning. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"(Image: nn)","category":"page"},{"location":"tu_inv/#Stochastic-Inverse-Problem","page":"Inverse Modeling with ADCME","title":"Stochastic Inverse Problem","text":"","category":"section"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The final type of inverse problem is called stochastic inverse problem. In this problem, X is a random variable with unknown distribution. Consequently, the solution u will also be a random variable. For example, we may have the following settings in practice","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The measurement of u(05) may not be accurate. We might assume that u(05) sim mathcalN(hat u(05) sigma^2) where hat u(05) is one observation and sigma is the prescribed standard deviation of the measurement. Thus, we want to estimate the distribution of X which will produce the same distribution for u(05). This type of problem falls under the umbrella of uncertainty quantification. \nThe quantity X itself is subject to randomness in nature, but its distribution may be positively/negatively skewed (e.g., the stock price returns). We can measure several samples of u(05) and want to estimate the distribution of X based on the samples. This problem is also called the probabilistic inverse problem. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"We cannot simply minimize the distance between u(05) and u   (which are random variables) as usual; instead, we need a metric to measure the discrepancy between two distributions–u and u(05). The observables u(05) may be given in multiple forms","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"The probability density function. \nThe unnormalized log-likelihood function. \nDiscrete samples. ","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"We consider the third type in this tutorial. The idea is to construct a sampler for X with a neural network and find the optimal weights and biases by minimizing the discrepancy between actually observed samples  and produced ones. Here is how we train the neural network:","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"We first propose a candidate neural network that transforms a sample from mathcalN(0 I_d) to a sample from X. Then we randomly generate K samples z_i_i=1^K from mathcalN(0 I_d) and transform them to X_i w_i=1^K. We solve the Poisson equation K times to obtain u(05z_i w)_i=1^K. Meanwhile, we sample K items from the observations (e.g., with the bootstrap method) u_i(05)_i=1^K. We can use a probability metric D to measure the discrepancy between u(05z_i w)_i=1^K and u_i(05)_i=1^K. There are many choices for D, such as (they are not necessarily non-overlapped)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Wasserstein distance (from optimal transport)\nKL-divergence, JS-divergence, etc. \nDiscriminator neural networks (from generative adversarial nets)","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"For example, we can consider the first approach, and invoke sinkhorn provided by ADCME","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"using ADCME\nusing Distributions\n\n# we add a mixture Gaussian noise to the observation\nm = MixtureModel(Normal[\n   Normal(0.3, 0.1),\n   Normal(0.0, 0.1)], [0.5, 0.5])\n\nfunction solver(a)\n  n = 100\n  h = 1/n\n  A = a[1] * diagm(0=>2/h^2*ones(n-1), 1=>-1/h^2*ones(n-2), -1=>-1/h^2*ones(n-2)) \n  φ = 2.0*ones(n-1) # right hand side\n  u = A\\φ\n  u[50]\nend\n\nbatch_size = 64\nx = placeholder(Float64, shape=[batch_size,10])\nz = placeholder(Float64, shape=[batch_size,1])\ndat = z + 0.25\nfdat  = reshape(map(solver, ae(x, [20,20,20,1])+1.0), batch_size, 1)\nloss = empirical_sinkhorn(fdat, dat, dist=(x,y)->dist(x,y,2), method=\"lp\")\nopt = AdamOptimizer(0.01, beta1=0.5).minimize(loss)\n\nsess = Session(); init(sess)\nfor i = 1:100000\n  run(sess, opt, feed_dict=Dict(\n        x=>randn(batch_size, 10),\n        z=>rand(m, batch_size,1)\n      ))\nend","category":"page"},{"location":"tu_inv/","page":"Inverse Modeling with ADCME","title":"Inverse Modeling with ADCME","text":"Loss Function Iteration 5000 Iteration 15000 Iteration 25000\n(Image: loss) (Image: test5000) (Image: test15000) (Image: test25000)","category":"page"},{"location":"alphascheme/#Generalized-α-Scheme","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"","category":"section"},{"location":"alphascheme/#Generalized-\\alpha-Scheme","page":"Generalized α Scheme","title":"Generalized alpha Scheme","text":"","category":"section"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The generalized alpha scheme is used to solve the second order linear differential equation of the form ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"mddot mathbfu + gammadotmathbfu + kmathbfu = mathbff","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"whose discretization form is ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Mmathbfa + Cmathbf v + K mathbf d = mathbf F","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Here M, C and K are the generalized mass, damping, and stiffness matrices, mathbf a, mathbf v, and mathbf d are the generalized acceleration, velocity, and displacement, and mathbf F is the generalized force vector. ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"There are two types of boundary conditions","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Dirichlet (essential) boundary condition. In this case, the displacement mathbfu is specified at a point mathbfx_0","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"mathbfu(mathbfx_0 t) = mathbfh(t)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"This boundary condition usually requires updating matrices M, C and K at each time step. ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Essential boundry condition. In this case the external force is specified","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"sigma(mathbfx)mathbfn(mathbfx) = mathbft(mathbfx)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"This term goes directly into mathbfF. ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The generalized alpha scheme solves for a discrete time step","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginaligned\nmathbf d_n+1 = mathbf d_n + hmathbf v_n + h^2 left(left(frac12-beta_2 right)mathbf a_n + beta_2 mathbf a_n+1  right)\nmathbf v_n+1 = mathbf v_n + h((1-gamma_2)mathbf a_n + gamma_2 mathbf a_n+1)\nmathbf F(t_n+1-alpha_f_2) = M mathbf a _n+1-alpha_m_2 + C mathbf v_n+1-alpha_f_2 + K mathbfd_n+1-alpha_f_2\nendaligned","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Here h is the time step and","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginaligned\nmathbf d_n+1-alpha_f_2 = (1-alpha_f_2)mathbf d_n+1 + alpha_f_2 mathbf d_n\nmathbf v_n+1-alpha_f_2 = (1-alpha_f_2) mathbf v_n+1 + alpha_f_2 mathbf v_n \nmathbf a_n+1-alpha_m_2  = (1-alpha_m_2) mathbf a_n+1 + alpha_m_2 mathbf a_n\nt_n+1-alpha_f_2  = (1-alpha_f_2) t_n+1 + alpha_f_2 + alpha_f_2t_n\nendaligned","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The parameters alpha_f_2, alpha_m_2, gamma_2, and beta_2 are used to control the amplification of high frequency numerical modes. High frequency modes normally describe motions with no physical sense (also contains very large phase error). Therefore, it is desirable to damp those high frequency modes. By properly choosing the parameters, we can recover HHT, Newmark, or WBZ methods. ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"We can design new algorithms by taking rho_inftyin 01 as a design variable to control the numerical dissipation above the normal frequency frachT, where T is the period associated with the highest frequency of interest. The following relationships are used to obtain a good algorithm that are accurate and preserve low-frequency modes","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginaligned\ngamma_2 = frac12 - alpha_m_2 + alpha_f_2\nbeta_2 = frac14 (1-alpha_m_2+alpha_f_2)^2 \nalpha_m_2 = frac2rho_infty-1rho_infty+1\nalpha_f_2 = fracrho_inftyrho_infty+1\nendaligned","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The following figure provides a plot of spectral radii versus frac hT[radii]","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"(Image: )","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"[radii]: http://www.dymoresolutions.com/AnalysisControls/CreateFEModel.html","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"In ADCME, we provide an API to the generalized alpha scheme, αscheme, and αscheme_time, which computes t_n+1-alpha_f_2.","category":"page"},{"location":"alphascheme/#Rayleigh-Damping","page":"Generalized α Scheme","title":"Rayleigh Damping","text":"","category":"section"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Rayleigh damping is widely used to model internal structural damping. It is  viscous damping that is proportional to a linear combination of mass and stiffness","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"C = alpha M + beta K","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The relation between the damping value xi and the naturual frequency omega is given by ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"xi =frac12left( fracalphaomega + betaomega right)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"In practice, we can measure two real frequencies xi_1 and xi_2, corresponding to omega_1 and omega_2 and find the coefficients via ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginbmatrix\nfrac12omega_1  fracomega_12\nfrac12omega_2  fracomega_22\nendbmatrixbeginbmatrixalphabetaendbmatrix = beginbmatrixxi_1xi_2endbmatrix","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"This approach will produce a curve that matches the two natural frequency points. In the case where the structure has one or two very dominant frequencies, Raleigh damping can closely approximate the behavior of a prescribed modal damping. ","category":"page"},{"location":"alphascheme/#Example:-Elasticity","page":"Generalized α Scheme","title":"Example: Elasticity","text":"","category":"section"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"In this example, we consider a plane stress elasticity deformation of a plate. The governing equation is given by","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginaligned\nsigma_ijj + f_i = ddot u_i \nsigma_ij = mathsfC epsilon_ij\nendaligned","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The elasticity tensor mathsfC is calculated using a Young's modulus E=1 and a Poisson's ratio nu=035. We consider a computational domain 02times01 and time horizon tin (01), the exact solution is given by ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"u_1(xyt) = e^-tx(2-x)y(1-y)qquad u_2(xyt) = e^-tx^2(2-x)^2y^2(1-y)^2","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The other terms can be computed analytically based on the exact solutions.","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"using ADCME\nusing AdFem \nusing PyPlot\n\nn = 20\nm = 2n\nNT = 200\nρ = 1.0\nΔt = 1/NT \nh = 1/n\nx = zeros((m+1)*(n+1))\ny = zeros((m+1)*(n+1))\nfor i = 1:m+1\n    for j = 1:n+1\n        idx = (j-1)*(m+1)+i \n        x[idx] = (i-1)*h \n        y[idx] = (j-1)*h \n    end\nend\nbd = bcnode(\"all\", m, n, h)\n\nu1 = (x,y,t)->exp(-t)*x*(2-x)*y*(1-y)\nu2 = (x,y,t)->exp(-t)*x^2*(2-x)^2*y^2*(1-y)^2\n\nts = Δt * ones(NT)\ndt = αscheme_time(ts, ρ = ρ )\nF = zeros(NT, 2(m+1)*(n+1))\nfor i = 1:NT \n    t = dt[i] \n    f1 = (x,y)->(-4.93827160493827*x^2*y^2*(x - 2)*(y - 1) - 4.93827160493827*x^2*y*(x - 2)*(y - 1)^2 - 4.93827160493827*x*y^2*(x - 2)^2*(y - 1) - 4.93827160493827*x*y*(x - 2)^2*(y - 1)^2 + x*y*(x - 2)*(y - 1) - 0.740740740740741*x*(x - 2) - 3.20987654320988*y*(y - 1))*exp(-t)\n  \tf2 = (x,y)->(x^2*y^2*(x - 2)^2*(y - 1)^2 - 3.20987654320988*x^2*y^2*(x - 2)^2 - 0.740740740740741*x^2*y^2*(y - 1)^2 - 12.8395061728395*x^2*y*(x - 2)^2*(y - 1) - 3.20987654320988*x^2*(x - 2)^2*(y - 1)^2 - 2.96296296296296*x*y^2*(x - 2)*(y - 1)^2 - 1.23456790123457*x*y - 1.23456790123457*x*(y - 1) - 0.740740740740741*y^2*(x - 2)^2*(y - 1)^2 - 1.23456790123457*y*(x - 2) - 1.23456790123457*(x - 2)*(y - 1))*exp(-t)\n    fval1 = eval_f_on_gauss_pts(f1, m, n, h)\n  \tfval2 = eval_f_on_gauss_pts(f2, m, n, h)\n    F[i,:] = compute_fem_source_term(fval1, fval2, m, n, h)\nend\n\nE = 1.0\nν = 0.35\nH = E/(1+ν)/(1-2ν)*[\n  1-ν ν 0\n  ν 1-ν 0\n  0 0 (1-2ν)/2\n]\nM = constant(compute_fem_mass_matrix(m, n, h))\nK = constant(compute_fem_stiffness_matrix(H, m, n, h))\n\na0 = [(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))]\nu0 = -[(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))]\nd0 = [(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))]\n\n\nfunction solver(A, rhs)\n    A, _ = fem_impose_Dirichlet_boundary_condition_experimental(A, bd, m, n, h)\n    rhs = scatter_update(rhs, [bd; bd .+ (m+1)*(n+1)], zeros(2*length(bd)))\n    return A\\rhs\nend\nd, u, a = αscheme(M, spzero(2(m+1)*(n+1)), K, F, d0, u0, a0, ts; solve=solver, ρ = ρ  )\n\nsess = Session()\nd_, u_, a_ = run(sess, [d, u, a])\n\n\nfunction plot_traj(idx)\n    figure(figsize=(12,3))\n    subplot(131)\n    plot((0:NT)*Δt, u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Acceleration\")\n    plot((0:NT)*Δt, a_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Acceleration\")\n    plot((0:NT)*Δt, a_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(133)\n    plot((0:NT)*Δt, u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Displacement\")\n    plot((0:NT)*Δt, d_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Displacement\")\n    plot((0:NT)*Δt, d_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(132)\n    plot((0:NT)*Δt, -u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Velocity\")\n    plot((0:NT)*Δt, u_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, -u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Velocity\")\n    plot((0:NT)*Δt, u_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    tight_layout()\nend\n\nidx2 = (n÷3)*(m+1) + m÷3\nplot_traj(idx2)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Using the above code, we plot the trajectories of mathbfa, mathbfv, and mathbfd at (064032), and obtain the following plot ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"(Image: alpha_elasticity)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"info: Info\nWhen we have (time-dependent) Dirichlet boundary conditions, we need to impose the boundary acceleration in each time step. This can be achieved using extsolve in αscheme. function solver(A, rhs, i)\n    A, Abd = fem_impose_Dirichlet_boundary_condition(A, bd, m, n, h)\n    rhs = rhs - Abd * abd[i]\n    rhs = scatter_update(rhs, [bd; bd .+ (m+1)*(n+1)], abd[i]) \n    return A\\rhs\nend\nd, u, a = αscheme(M, spzero(2(m+1)*(n+1)), K, F, d0, u0, a0, ts; extsolve=solver, ρ = ρ  )Basically, we haveA_II a_I + A_IB a_B = f Rightarrow A_II a_I = f-A_IBa_Band a_B(abd) is the acceleration from the Dirichlet boundary condition.  ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Here is a script for demonstrating how to impose the Dirichlet boundary condition","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"using Revise\nusing ADCME\nusing AdFem \nusing PyPlot\n\nn = 20\nm = 2n\nNT = 200\nρ = 0.5\nΔt = 1/NT \nh = 1/n\nx = zeros((m+1)*(n+1))\ny = zeros((m+1)*(n+1))\nfor i = 1:m+1\n    for j = 1:n+1\n        idx = (j-1)*(m+1)+i \n        x[idx] = (i-1)*h \n        y[idx] = (j-1)*h \n    end\nend\nbd = bcnode(\"all\", m, n, h)\n\nu1 = (x,y,t)->exp(-t)*(0.5-x)^2*(2-y)^2\nu2 = (x,y,t)->exp(-t)*(0.5-x)*(0.5-y)\n\nts = Δt * ones(NT)\ndt = αscheme_time(ts, ρ = ρ )\nF = zeros(NT, 2(m+1)*(n+1))\nfor i = 1:NT \n    t = dt[i] \n    f1 = (x,y)->((x - 0.5)^2*(y - 2)^2 - 0.740740740740741*(x - 0.5)^2 - 3.20987654320988*(y - 2)^2 - 1.23456790123457)*exp(-t)\n  \tf2 = (x,y)->(-3.93827160493827*x*y + 9.37654320987654*x + 1.96913580246914*y - 4.68827160493827)*exp(-t)\n    fval1 = eval_f_on_gauss_pts(f1, m, n, h)\n  \tfval2 = eval_f_on_gauss_pts(f2, m, n, h)\n    F[i,:] = compute_fem_source_term(fval1, fval2, m, n, h)\nend\n\nabd = zeros(NT, (m+1)*(n+1)*2)\ndt = αscheme_time(ts, ρ = ρ )\nfor i = 1:NT \n    t = dt[i]\n    abd[i,:] = [(@. u1(x, y, t)); (@. u2(x, y, t))] \nend\nabd = constant(abd[:, [bd; bd .+ (m+1)*(n+1)]])\n\nE = 1.0\nν = 0.35\nH = E/(1+ν)/(1-2ν)*[\n  1-ν ν 0\n  ν 1-ν 0\n  0 0 (1-2ν)/2\n]\nM = constant(compute_fem_mass_matrix(m, n, h))\nK = constant(compute_fem_stiffness_matrix(H, m, n, h))\n\n\n\n\na0 = [(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))] \nu0 = -[(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))] \nd0 = [(@. u1(x, y, 0.0)); (@. u2(x, y, 0.0))] \n\n\nfunction solver(A, rhs, i)\n    A, Abd = fem_impose_Dirichlet_boundary_condition(A, bd, m, n, h)\n    rhs = rhs - Abd * abd[i]\n    rhs = scatter_update(rhs, [bd; bd .+ (m+1)*(n+1)], abd[i]) \n    return A\\rhs\nend\nd, u, a = αscheme(M, spzero(2(m+1)*(n+1)), K, F, d0, u0, a0, ts; extsolve=solver, ρ = ρ  )\n\n\nsess = Session()\nd_, u_, a_ = run(sess, [d, u, a])\n\n\nfunction plot_traj(idx)\n    figure(figsize=(12,3))\n    subplot(131)\n    plot((0:NT)*Δt, u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Acceleration\")\n    plot((0:NT)*Δt, a_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Acceleration\")\n    plot((0:NT)*Δt, a_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(133)\n    plot((0:NT)*Δt, u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Displacement\")\n    plot((0:NT)*Δt, d_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Displacement\")\n    plot((0:NT)*Δt, d_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(132)\n    plot((0:NT)*Δt, -u1.(x[idx], y[idx],(0:NT)*Δt), \"b-\", label=\"x-Velocity\")\n    plot((0:NT)*Δt, u_[:,idx], \"y--\", markersize=2)\n  \tplot((0:NT)*Δt, -u2.(x[idx], y[idx],(0:NT)*Δt), \"r-\", label=\"y-Velocity\")\n    plot((0:NT)*Δt, u_[:,idx+(m+1)*(n+1)], \"c--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    tight_layout()\nend\n\nidx2 = (n÷3)*(m+1) + m÷2\nplot_traj(idx2)","category":"page"},{"location":"alphascheme/#Example:-Viscosity","page":"Generalized α Scheme","title":"Example: Viscosity","text":"","category":"section"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"In this section, we show how to use the generalized alpha scheme to solve the viscosity problem. The governing equation is given by ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"beginaligned\nsigma_3jj + f = ddot u \nsigma_3j = dot epsilon_3j\nendaligned","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"where u(xyt) is the displacement in the z-direction. We assume zero Dirichlet boundary condition,  the computational domain is 02times 01, and the exact solution is","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"u(x y t) = e^-t x(2-x)y(1-y)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"The weak form of the equation is ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"int_Omega ddot udelta u + int_Omega dot epsilondelta epsilon = int_Omega f delta u","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"In the discretization form we have","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Mmathbfa + K mathbfv = mathbfF","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"using ADCME\nusing AdFem \n\nn = 50\nm = 2n\nNT = 200\nρ = 0.1\nΔt = 1/NT \nh = 1/n\nx = zeros((m+1)*(n+1))\ny = zeros((m+1)*(n+1))\nfor i = 1:m+1\n    for j = 1:n+1\n        idx = (j-1)*(m+1)+i \n        x[idx] = (i-1)*h \n        y[idx] = (j-1)*h \n    end\nend\nbd = bcnode(\"all\", m, n, h)\n\nuexact = (x,y,t)->exp(-t)*x*(2-x)*y*(1-y)\n\nts = Δt * ones(NT)\ndt = αscheme_time(ts, ρ = ρ )\nF = zeros(NT, (m+1)*(n+1))\nfor i = 1:NT \n    t = dt[i] \n    f = (x,y)->uexact(x, y, t)  -2*(y-y^2+2x-x^2)*exp(-t)\n    fval = eval_f_on_gauss_pts(f, m, n, h)\n    F[i,:] = compute_fem_source_term1(fval, m, n, h)\nend\n\nM = constant(compute_fem_mass_matrix1(m, n, h))\nK = constant(compute_fem_stiffness_matrix1(diagm(0=>ones(2)), m, n, h))\n\na0 = @. x*(2-x)*y*(1-y)\nu0 = @. -x*(2-x)*y*(1-y)\nd0 = @. x*(2-x)*y*(1-y)\n\n\nfunction solver(A, rhs)\n    A, _ = fem_impose_Dirichlet_boundary_condition1(A, bd, m, n, h)\n    rhs = scatter_update(rhs, bd, zeros(length(bd)))\n    return A\\rhs\nend\nd, u, a = αscheme(M, K, spzero((m+1)*(n+1)), F, d0, u0, a0, ts; solve=solver, ρ = ρ  )\n\nsess = Session()\nd_, u_, a_ = run(sess, [d, u, a])\n\n\nfunction plot_traj(idx)\n    figure(figsize=(12,3))\n    subplot(131)\n    plot((0:NT)*Δt, uexact.(x[idx], y[idx],(0:NT)*Δt), \"-\", label=\"Acceleration\")\n    plot((0:NT)*Δt, a_[:,idx], \"--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(133)\n    plot((0:NT)*Δt, uexact.(x[idx], y[idx],(0:NT)*Δt), \"-\", label=\"Displacement\")\n    plot((0:NT)*Δt, d_[:,idx], \"--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    subplot(132)\n    plot((0:NT)*Δt, -uexact.(x[idx], y[idx],(0:NT)*Δt), \"-\", label=\"Velocity\")\n    plot((0:NT)*Δt, u_[:,idx], \"--\", markersize=2)\n    legend()\n    xlabel(\"Time\")\n    ylabel(\"Value\")\n\n    tight_layout()\nend\n\nidx = (n÷2)*(m+1) + m÷2\nidx2 = (n÷3)*(m+1) + m÷3\nplot_traj(idx2)","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"Using the above code, we plot the trajectories of mathbfa, mathbfv, and mathbfd at (064032), and obtain the following plot ","category":"page"},{"location":"alphascheme/","page":"Generalized α Scheme","title":"Generalized α Scheme","text":"(Image: )","category":"page"},{"location":"uq/#Uncertainty-Quantification","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"<!– qunatifying uncertainty of neural networks in inverse problems using linearized Gaussian modeels –>","category":"page"},{"location":"uq/#Theory","page":"Uncertainty Quantification","title":"Theory","text":"","category":"section"},{"location":"uq/#Basic-Model","page":"Uncertainty Quantification","title":"Basic Model","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We consider a physical model","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\ny = h(s) + delta  \ns = g(z) + epsilon\nendalignedtag1","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here delta and epsilon are independent Gaussian noises. sin mathbbR^m is the physical quantities we are interested in predicting, and yin mathbbR^n is the measurement. g is a function approximator, which we learn from observations in our inverse problem. z is considered fixed for quantifying the uncertainty for a specific observation under small perturbation, although z and s may have complex dependency.  delta can be interpreted as the measurement error","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"mathbbE(deltadelta^T) = R","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"epsilon","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"is interpreted as our prior for s","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"mathbbE(epsilonepsilon^T) = Q","category":"page"},{"location":"uq/#Linear-Gaussian-Model","page":"Uncertainty Quantification","title":"Linear Gaussian Model","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"When the standard deviation of epsilon is small, we can safely approximate h(s) using its linearized form ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"h(s)approx nabla h(s_0) (s-s_0) + h(s_0) = mu + H s","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here mu = h(s_0) - nabla h(s_0) s_0quad H = nabla h(x_0)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Therefore, we have an approximate governing equation for Equation 1:","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\ny = H s + mu + delta\ns = g(z) + epsilon\nendalignedtag2","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Using Equation 2, we have","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nmathbbE(y)  = H g(z) + mu  \ntextcov(y)  = mathbbEleft(H (x-g(z)) + delta )(H (x-g(z)) + delta )^T right = H QH^T + R\nendaligned","category":"page"},{"location":"uq/#Bayesian-Inversion","page":"Uncertainty Quantification","title":"Bayesian Inversion","text":"","category":"section"},{"location":"uq/#Derivation","page":"Uncertainty Quantification","title":"Derivation","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"From the model Equation 2 we can derive the joint distribution of s and y, which is a multivariate Gaussian distribution","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginbmatrix\nx_1 \nx_2\nendbmatrixsim mathcalNleft( \n    beginbmatrix\n        g(z) \n        Hg(z) + mu \n    endbmatrix Bigg beginbmatrix\n    Q  QH^T  \n    HQ  HQH^T + R\n    endbmatrix\n     right)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here the covariance matrix textcov(s y) is obtained via ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"textcov(s y) = mathbbE(s Hs + mu+delta) = mathbbE(s-g(z) H(s-g(z))) = mathbbE((s-g(z))(s-g(z))^T) H^T = QH^T","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Recall the formulas for conditional Gaussian distributions:","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Given ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginbmatrix\ns \ny\nendbmatrixsim mathcalNleft( \n    beginbmatrix\n        mu_1 \n        mu_2\n    endbmatrix Bigg beginbmatrix\n    Sigma_11  Sigma_12  \n    Sigma_21  Sigma_22\n    endbmatrix\n     right)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We have ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"x_1  x_2 sim mathcalN(mu_12 V_12)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"where ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nmu_12 = mu_1 + Sigma_12Sigma_22^-1 (x_2-mu_2) \nV_12 = Sigma_11 - Sigma_12 Sigma_22^-1Sigma_21\nendaligned","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Let x_1 = s, x_2 = y, we have the following formula for Baysian inversion:","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nmu_sy = g(z) + QH^T(HQH^T + R)^-1 (y - Hg(z) - mu) \nV_sy = Q - QH^T(HQH^T + R)^-1 HQ \nendalignedtag3","category":"page"},{"location":"uq/#Analysis","page":"Uncertainty Quantification","title":"Analysis","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Now we consider how to compute Equation 3. In practice, we should avoid direct inverting the matrix HQH^T + R since the cost is cubic in the size of dimensions of the matrix. Instead, the following theorem gives us a convenient way to solve the problem ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"info: Theorem\nLet beginbmatrixL  x^Tendbmatrix be the solution to beginbmatrix\nHQH^T + R  H g(z)  \ng(z)^T H^T  0 \nendbmatrixbeginbmatrix\nL  \nx^T\nendbmatrix = beginbmatrix\nHQ  \ng(z)^T\nendbmatrixtag4Then we have beginaligned\nmu_sy = g(z) + L^T (y-mu)  \nV_sy = Q - gx^T - QH^TL\nendalignedtag5","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The linear system in Equation 5 is symmetric but may not be SPD and therefore we may encounter numerical difficulty when solving the linear system Equation 4. In this case, we can add perturbation varepsilon g^T g to the zero entry. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"info: Theorem\nIf varepsilon frac14lambda_min, where lambda_min is the minimum eigenvalue of Q, then the linear system in Equation 4 is SPD. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The above theorem has a nice interpretation: typically we can choosee our prior for the physical quantity s to be a scalar matrix Q = sigma_s^2 I, where sigma_s is the standard deviation, then lambda_min = sigma_s^2. This indicates that if we use a very concentrated prior, the linear system can be far away from SPD and requires us to use a large perturbation for numerical stability. Therefore, in the numerical example below, we choose a moderate sigma_s. The alternative approach is to add the perturbation. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"In ADCME, we provide the implementation uq","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"s, Σ = uqlin(y-μ, H, R, gz, Q)","category":"page"},{"location":"uq/#Benchmark","page":"Uncertainty Quantification","title":"Benchmark","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"To show how the proposed method work compared to MCMC, we consider a model problem: estimating Young's modulus and Poisson's ratio from sparse observations. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nmathrmdiv sigma = f  text in  Omega  \nsigma n = 0  text on Gamma_N  \nu = 0  text on Gamma_D  \nsigma  = Hepsilon\nendaligned","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here the computational domain Omega=01times 015. We fixed the left side (Gamma_D) and impose an upward pressure on the right side. The other side is considered fixed. We consider the plane stress linear elasticity, where the constitutive relation determined by ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"H = fracE(1+nu)(1-2nu)beginbmatrix\n1-nu  nu  0  \nnu  1-nu  0  \n0  0  frac1-2nu2\nendbmatrix","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here the true parameters ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"E = 200textGPa quad nu = 035","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"They are the parameters to be calibrated in the inverse modeling. The observation is given by the displacement vectors of 20 random points on the plate. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We consider a uniform prior for the random walk MCMC simuation, so the log likelihood up to a constant is  given by ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"l(y) = -frac(y-y)^22sigma_0^2","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"where y is the current proposal, y is the measurement, and sigma_0 is the standard deviation. We simulate 100000 times, and the first 20% samples are used as \"burn-in\" and thus discarded.","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"For the linearized Gaussian model, we use Q=I and R=sigma_0^2I to account for a unit Gaussian prior and measurement error, respectively. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The following plots show the results","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"sigma_0=001 sigma_0=005 sigma_0=01\n(Image: ) (Image: ) (Image: )\nsigma_0=02 sigma_0=05 \n(Image: ) (Image: ) ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We see that when sigma_0 is small, the approximation is quite consistent with MCMC results. When sigma_0 is large, due to the assumption that the uncertainty is Gaussian, the linearized Gaussian model does not fit well with the uncertainty shape obtained with MCMC; however, the result is still consistent since the linearized Gaussian model yields a larger standard deviation. ","category":"page"},{"location":"uq/#Example-1:-UQ-for-Parameter-Inverse-Problems","page":"Uncertainty Quantification","title":"Example 1: UQ for Parameter Inverse Problems","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We consider a simple example for 2D Poisson problem.","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nnabla (K(x y) nabla u(x y)) = 1  text in  Omega \nu(xy) = 0   text on  partial Omega\nendaligned","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"where K(xy) = e^c_1 + c_2 x + c_3 y. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Here c_1, c_2, c_3 are parameter to be estimated. We first generate data using c_1=1c_2=2c_3=3 and add Gaussian noise mathcalN(0 10^-3) to 64 observation in the center of the domain 01^2. We run the inverse modeling and obtain an estimation of c_i's. Finally, we use uq to conduct the uncertainty quantification. We assume texterror_textmodel=0. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The following plot shows the estimated mean together with 2 standard deviations. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"(Image: )","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"using ADCME\nusing PyPlot\nusing AdFem\n\n\nRandom.seed!(233)\nidx = fem_randidx(100, m, n, h)\n\nfunction poisson1d(c)\n    m = 40\n    n = 40\n    h = 0.1\n    bdnode = bcnode(\"all\", m, n, h)\n    c = constant(c)\n    xy = gauss_nodes(m, n, h)\n    κ = exp(c[1] + c[2] * xy[:,1] + c[3]*xy[:,2])\n    κ = compute_space_varying_tangent_elasticity_matrix(κ, m, n, h)\n    K = compute_fem_stiffness_matrix1(κ, m, n, h)\n    K, _ = fem_impose_Dirichlet_boundary_condition1(K, bdnode, m, n, h)\n    rhs = compute_fem_source_term1(ones(4m*n), m, n, h)\n    rhs[bdnode] .= 0.0\n    sol = K\\rhs\n    sol[idx]\nend\n\nc = Variable(rand(3))\ny = poisson1d(c)\nΓ = gradients(y, c) \nΓ = reshape(Γ, (100, 3))\n\n# generate data \nsess = Session(); init(sess)\nrun(sess, assign(c, [1.0;2.0;3.0]))\nobs = run(sess, y) + 1e-3 * randn(100)\n\n# Inverse modeling \nloss = sum((y - obs)^2)\ninit(sess)\nBFGS!(sess, loss)\n\ny = obs \nH = run(sess, Γ)\nR = (2e-3)^2 * diagm(0=>ones(100))\nX = run(sess, c)\nQ = diagm(0=>ones(3))\nm, V = uqlin(y, H, R, X, Q)\nplot([1;2;3], [1.;2.;3.], \"o\", label=\"Reference\")\nerrorbar([1;2;3],m + run(sess, c), yerr=2diag(V), label=\"Estimated\")\nlegend()","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"info: The choice of $R$\nThe standard deviation 2times 10^-3 consists of the model error (10^-3) and the measurement error 10^-3. ","category":"page"},{"location":"uq/#Example-2:-UQ-for-Function-Inverse-Problems","page":"Uncertainty Quantification","title":"Example 2: UQ for Function Inverse Problems","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"In this example, let us consider uncertainty quantification for function inverse problems. We consider the same problem as Example 1, except that K(xy) is represented by a neural network (the weights and biases are represented by theta)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"mathcalNN_thetamathbbR^2 rightarrow mathbbR","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We consider a highly nonlinear K(xy)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"K(xy) = 01 + sin x+ x(y-1)^2  + log (1+y)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"(Image: )","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The left panel above shows the exact K(xy) and the learned K(xy). We see we have a good approximation but with some error. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"(Image: )","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The left panel above shows the exact solution while the right panel shows the reconstructed solution after learning. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We apply the UQ method and obtain the standard deviation plot on the left, together with absolute error on the right. We see that our UQ estimation predicts that the right side has larger uncertainty, which is true in consideration of the absolute error. ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"(Image: )","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"using Revise\nusing ADCME\nusing PyPlot\nusing AdFem\n\n\nm = 40\nn = 40\nh = 1/n\nbdnode = bcnode(\"all\", m, n, h)\nxy = gauss_nodes(m, n, h)\nxy_fem = fem_nodes(m, n, h)\n\nfunction poisson1d(κ)\n    κ = compute_space_varying_tangent_elasticity_matrix(κ, m, n, h)\n    K = compute_fem_stiffness_matrix1(κ, m, n, h)\n    K, _ = fem_impose_Dirichlet_boundary_condition1(K, bdnode, m, n, h)\n    rhs = compute_fem_source_term1(ones(4m*n), m, n, h)\n    rhs[bdnode] .= 0.0\n    sol = K\\rhs\nend\n\nκ = @. 0.1 + sin(xy[:,1]) + (xy[:,2]-1)^2 * xy[:,1] + log(1+xy[:,2])\ny = poisson1d(κ)\n\nsess = Session(); init(sess)\nSOL = run(sess, y)\n\n\n# inverse modeling \nκnn = squeeze(abs(ae(xy, [20,20,20,1])))\ny = poisson1d(κnn)\n\nusing Random; Random.seed!(233)\nidx = fem_randidx(100, m, n, h)\nobs = y[idx]\nOBS = SOL[idx]\nloss = sum((obs-OBS)^2)\n\ninit(sess)\nBFGS!(sess, loss, 200)\n\nfigure(figsize=(10,4))\nsubplot(121)\nvisualize_scalar_on_fem_points(SOL, m, n, h)\nsubplot(122)\nvisualize_scalar_on_fem_points(run(sess, y), m, n, h)\nplot(xy_fem[idx,1], xy_fem[idx,2], \"o\", c=\"red\", label=\"Observation\")\nlegend()\n\n\nfigure(figsize=(10,4))\nsubplot(121)\nvisualize_scalar_on_gauss_points(κ, m, n, h)\ntitle(\"Exact \\$K(x, y)\\$\")\nsubplot(122)\nvisualize_scalar_on_gauss_points(run(sess, κnn), m, n, h)\ntitle(\"Estimated \\$K(x, y)\\$\")\n\n\nH = gradients(obs, κnn) \nH = run(sess, H)\ny = OBS \nhs = run(sess, obs)\nR = (1e-1)^2*diagm(0=>ones(length(obs)))\ns = run(sess, κnn)\nQ = (1e-2)^2*diagm(0=>ones(length(κnn)))\nμ, Σ = uqnlin(y, hs, H, R, s, Q)\n\nσ = diag(Σ)\nfigure(figsize=(10,4))\nsubplot(121)\nvisualize_scalar_on_gauss_points(σ, m, n, h)\ntitle(\"Standard Deviation\")\nsubplot(122)\nvisualize_scalar_on_gauss_points(abs.(run(sess, κnn)-κ), m, n, h)\ntitle(\"Absolute Error\")","category":"page"},{"location":"uq/#Example-3:-UQ-for-Function-Inverse-Problem","page":"Uncertainty Quantification","title":"Example 3: UQ for Function Inverse Problem","text":"","category":"section"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"In this case, we consider a more challenging case, where K is a function of the state variable, i.e., K(u). K is approximated by a neural network, but we need an iterative solver that involves the neural network to solve the problem ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"beginaligned\nnablacdot (K(u) nabla u(x y)) = 1  text in  Omega \nu(xy) = 0   text on  partial Omega\nendaligned","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We tested two cases: in the first case, we use the synthetic observation u_textobsinmathbbR without adding any noise, while in the second case, we add 1% Gaussian noise to the observation data","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"u_textobs = u_textobs (1+001 z)quad zsim mathcalN(0 I_n)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The prior for K(u) is mathcalN(0 10^-2), where one standard deviation is around 10%~20% of the actual K(u) value.  The measurement prior is given by ","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"mathcalN(0 sigma_textmodel^2 + sigma_textnoise^2)","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"The total error is modeled by sigma_textmodel^2 + sigma_textnoise^2approx 10^-4.","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"Description Uncertainty Bound (two standard deviation) Standard Deviation at Grid Points\nsigma_textnoise=0 (Image: ) (Image: )\nsigma_textnoise=001 (Image: ) (Image: )","category":"page"},{"location":"uq/","page":"Uncertainty Quantification","title":"Uncertainty Quantification","text":"We see that in general when u is larger, the uncertainty bound is larger. For small u, we can estimate the map K(u) quite accurately using a neural network. ","category":"page"},{"location":"mcmc/#Uncertainty-Quantification-of-Neural-Networks-in-Physics-Informed-Learning-using-MCMC","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"","category":"section"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"In this section, we consider uncertainty quantification of a neural network prediction using Markov Chain Monte Carlo. The idea is that we use MCMC to sample from the posterior distribution of the neural network weights and biases. We consider an inverse problem, where the governing equation is a heat equation in an 1D interval 01.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"The simulation is conducted over a time horizon 01. We record the temperature u(0t) on the left of the interval. The diffusivity coefficient kappa(x) is assumed unknown and will be estimated from the temperature record. kappa(x) is approximated by a neural network","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"kappa(x) = mathcalNN_w(x)","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"Here w is the neural network weights and biases.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"First of all, we define a function simulate that takes in the diffusivity coefficient, and returns the solution of the PDE.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"File heateq.jl:","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"using ADCME\nusing PyPlot\nusing ADCME\nusing PyCall\nusing ProgressMeter\nusing Statistics\nusing MAT\nusing DelimitedFiles\nmpl = pyimport(\"tikzplotlib\")\n\nfunction simulate(κ)\n    κ = constant(κ)\n    m = 50\n    n = 50\n    dt = 1 / m\n    dx = 1 / n\n    F = zeros(m + 1, n)\n    xi = LinRange(0, 1, n + 1)[1:end - 1]\n    f = (x, t)->exp(-50(x - 0.5)^2)\n    for k = 1:m + 1\n        t = (k - 1) * dt\n        F[k,:] = dt * f.(xi, t)\n    end\n\n    λ = κ*dt/dx^2\n    mask = ones(n-1)\n    mask[1] =  2.0\n    A = spdiag(n, -1=>-λ[2:end], 0=>1+2λ, 1=>-λ[1:end-1].*mask)\n\n\n    function condition(i, u_arr)\n        i <= m + 1\n    end\n\n    function body(i, u_arr)\n        u = read(u_arr, i - 1)\n        rhs = u + F[i]\n        u_next = A \\ rhs\n        u_arr = write(u_arr, i, u_next)\n        i + 1, u_arr\n    end\n\n    F = constant(F)\n    u_arr = TensorArray(m + 1)\n    u_arr = write(u_arr, 1, zeros(n))\n    i = constant(2, dtype = Int32)\n    _, u = while_loop(condition, body, [i, u_arr])\n    u = set_shape(stack(u), (m + 1, n))\nend","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"We set up the geometry as follows","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"n = 50\nxi = LinRange(0, 1, n + 1)[1:end - 1]\nx = Array(LinRange(0, 1, n+1)[1:end-1])","category":"page"},{"location":"mcmc/#Forward-Computation","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Forward Computation","text":"","category":"section"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"The forward computation is run with an analytical kappa(x), given by kappa(x) = 5x^2 + exp(x) + 10 We can generate the code using the following code:","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"include(\"heateq.jl\")\n\nκ = @. 5x^2 + exp(x) + 1.0\nout = simulate(κ)\nobs = out[:,1]\n\nsess = Session(); init(sess)\nobs_ = run(sess, obs)\n\nwritedlm(\"obs.txt\", run(sess, out))\no = run(sess, out)\npcolormesh( (0:49)*1/50, (0:50)*1/50, o, rasterized=true)\nxlabel(\"\\$x\\$\")\nylabel(\"\\$t\\$\")\nsavefig(\"solution.png\")\n\nfigure()\nplot((0:50)*1/50, obs_)\nxlabel(\"\\$t\\$\")\nylabel(\"\\$u(0,t)\\$\")\nsavefig(\"obs.png\")\n\nfigure()\nplot(x, κ)\nxlabel(\"\\$x\\$\")\nylabel(\"\\$\\\\kappa\\$\")\nsavefig(\"kappa.png\")","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"Solution Observation kappa(x)\n(Image: ) (Image: ) (Image: )","category":"page"},{"location":"mcmc/#Inverse-Modeling","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Inverse Modeling","text":"","category":"section"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"Although it is possible to use MCMC to solve the inverse problem, the convergence can be very slow if our initial guess is far away from the solution.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"Therefore, we first solve the inverse problem by solving a PDE-constrained optimization problem. We use the BFGS! optimizer. Note we do not need to solve the inverse problem very accurately because in Bayesian approaches, the solution is interpreted as a probability, instead of a point estimation.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"include(\"heateq.jl\")\nusing PyCall\nusing Distributions\nusing Optim\nusing LineSearches\nreset_default_graph()\nusing Random; Random.seed!(2333)\nw = Variable(ae_init([1,20,20,20,1]), name=\"nn\")\nκ = fc(x, [20,20,20,1], w, activation=\"tanh\") + 1.0\nu = simulate(κ)\nobs = readdlm(\"obs.txt\")\nloss = sum((u[:,1]-obs[:,1])^2)\nloss = loss*1e10\n\nsess = Session(); init(sess)\n\n\nBFGS!(sess, loss)\n\nκ1 = @. 5x^2 + exp(x) + 1.0\nplot(x, run(sess, κ), \"+--\", label=\"Estimation\")\nplot(x, κ1, label=\"Reference\")\nlegend()\nsavefig(\"inversekappa.png\")","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"(Image: )","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"We also save the solution for MCMC","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"matwrite(\"nn.mat\", Dict(\"w\"=>run(sess, w)))","category":"page"},{"location":"mcmc/#Uncertainty-Quantification","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"Finally, we are ready to conduct uncertainty quantification using MCMC. We will use the Mamba package, which provides MCMC utilities. We will use the random walk MCMC because of its simplicity.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"include(\"heateq.jl\")\nusing PyCall\nusing Mamba\nusing ProgressMeter\nusing PyPlot","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"The neural network weights and biases are conveniently expressed as a placeholder. This allows us to sample from a distribution of weights and biases easily.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"w = placeholder(ae_init([1,20,20,20,1]))\nκ = fc(x, [20,20,20,1], w, activation=\"tanh\") + 1.0\nu = simulate(κ)\nobs = readdlm(\"obs.txt\")\n\nsess = Session(); init(sess)\nw0 = matread(\"nn.mat\")[\"w\"]","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"The log likelihood function (up to an additive constant) is given by -left u_rmest(w) - u_rmobs right^2 over 2sigma ^2 - left w right^2 over 2sigma _w^2","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"The absolute value of sigma and sigma_w does not really matter. Only their ratios matter. Let's fix sigma = 1. What is the interpretation of sigma_w?","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"A large sigma_w means very wide prior, and a small sigma_w means a very narrow prior. The relative value sigmasigma_w implies the strength of prior influence. Typically, we can choose a very large sigma_w so that the prior does not influence the posterior too much. ","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"σ = 1.0\nσx = 1000000.0\nfunction logf(x)\n    y = run(sess, u, w=>x)\n    -sum((y[:,1] - obs[:,1]).^2)/2σ^2 - sum(x.^2)/2σx^2\nend\n\nn = 5000\nburnin = 1000\nsim = Chains(n, length(w0))","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"A second important parameter is the scale (0.002 in the following code). It controls the uncertainty bound width via the way we generate the random numbers.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"θ = RWMVariate(copy(w0), 0.001ones(length(w0)), logf, proposal = SymUniform)","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"An immediate consequence is that the smaller the scale factor we use, the narrower the uncertainty band will be. In sum, we have two important parameters–relative standard deviation and the scaling factor–to control our uncertainty bound.","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"\n@showprogress for i = 1:n \n    sample!(θ)\n    sim[i,:,1] = θ\nend\n\n\nv = sim.value\nK = zeros(length(κ), n-burnin)\n@showprogress for i = 1:n-burnin\n    ws = v[i+burnin,:,1]\n    K[:,i] = run(sess, κ, w=>ws)\nend \n\nkappa = mean(K, dims=2)[:]\nk_std = std(K, dims=2)[:]\nfigure()\nκ1 = @. 5x^2 + exp(x) + 1.0\nPyPlot.plot(x, kappa, \"--\", label=\"Posterior Mean\")\nPyPlot.plot(x, κ1, \"r\", label=\"True\")\nPyPlot.plot(x, run(sess, κ, w=>w0), label=\"Point Estimation\")\nfill_between(x, kappa-3k_std, kappa+3k_std, alpha=0.5)\nlegend()\nxlabel(\"x\")\nylabel(\"\\$\\\\kappa(x)\\$\")\nsavefig(\"kappa_mcmc.png\")","category":"page"},{"location":"mcmc/","page":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","title":"Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC","text":"(Image: )","category":"page"},{"location":"ode/#PDE/ODE-Solvers","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"","category":"section"},{"location":"ode/#Runge-Kutta-Method","page":"PDE/ODE Solvers","title":"Runge Kutta Method","text":"","category":"section"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The Runge Kutta method is one of the workhorses for solving ODEs. The method is a higher order interpolation to the derivatives. The system of ODE has the form","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"fracdydt = f(y t theta)","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"where t denotes time, y denotes states and theta denotes parameters. ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The Runge-Kutta method is defined as","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"beginaligned\nk_1 = Delta t f(t_n y_n theta)\nk_2 = Delta t f(t_n+Delta t2 y_n + k_12 theta)\nk_3 = Delta t f(t_n+Delta t2 y_n + k_22 theta)\nk_4 = Delta t f(t_n+Delta t y_n + k_3 theta)\ny_n+1 = y_n + frack_16 +frack_23 +frack_33 +frack_46\nendaligned","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"ADCME provides a built-in Runge Kutta solver rk4 and ode45. Consider an example: the Lorentz equation","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"beginaligned\nfracdxdt = 10(y-x) \nfracdydt = x(27-z)-y \nfracdzdt = xy -frac83z\nendaligned","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"Let the initial condition be x_0 = 100, the following code snippets solves the Lorentz equation with ADCME","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"function f(t, y, θ)\n    [10*(y[2]-y[1]);y[1]*(27-y[3])-y[2];y[1]*y[2]-8/3*y[3]]\nend\nx0 = [1.;0.;0.]\nrk4(f, 30.0, 10000, x0)","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"(Image: )","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"We can also solve three body problem with the Runge-Kutta method. The full script is ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"# \n# adapted from \n# https://github.com/pjpmarques/Julia-Modeling-the-World/\n# \nusing Revise\nusing ADCME\nusing PyPlot\nusing Printf\n\nfunction f(t, y, θ)\n    # Extract the position and velocity vectors from the g array\n    r0, v0 = y[1:2], y[3:4]\n    r1, v1 = y[5:6], y[7:8]\n    r2, v2 = y[9:10], y[11:12]\n    \n    # The derivatives of the position are simply the velocities\n    dr0 = v0\n    dr1 = v1\n    dr2 = v2\n    \n    # Now calculate the the derivatives of the velocities, which are the accelarations\n    # Start by calculating the distance vectors between the bodies (assumes m0, m1 and m2 are global variables)\n    # Slightly rewriten the expressions dv0, dv1 and dv2 comprared to the normal equations so we can reuse d0, d1 and d2\n    d0  = (r2 - r1) / ( norm(r2 - r1)^3.0 )\n    d1  = (r0 - r2) / ( norm(r0 - r2)^3.0 )\n    d2  = (r1 - r0) / ( norm(r1 - r0)^3.0 )    \n    \n    dv0 = m1*d2 - m2*d1\n    dv1 = m2*d0 - m0*d2\n    dv2 = m0*d1 - m1*d0\n    \n    # Reconstruct the derivative vector\n    [dr0; dv0; dr1; dv1; dr2; dv2]\nend\n\nfunction plot_trajectory(t1, t2)\n\n    t1i = round(Int,NT * t1/T) + 1\n    t2i = round(Int,NT * t2/T) + 1\n    \n    # Plot the initial and final positions\n    # In these vectors, the first coordinate will be X and the second Y\n    X = 1\n    Y = 2\n    \n    # figure(figsize=(6,6))\n    plot(r0[t1i,X], r0[t1i,Y], \"ro\")\n    plot(r0[t2i,X], r0[t2i,Y], \"rs\")\n    plot(r1[t1i,X], r1[t1i,Y], \"go\")\n    plot(r1[t2i,X], r1[t2i,Y], \"gs\")\n    plot(r2[t1i,X], r2[t1i,Y], \"bo\")\n    plot(r2[t2i,X], r2[t2i,Y], \"bs\")\n    \n    # Plot the trajectories\n    plot(r0[t1i:t2i,X], r0[t1i:t2i,Y], \"r-\")\n    plot(r1[t1i:t2i,X], r1[t1i:t2i,Y], \"g-\")\n    plot(r2[t1i:t2i,X], r2[t1i:t2i,Y], \"b-\")\n    \n    # Plot cente of mass\n    # plot(cx[t1i:t2i], cy[t1i:t2i], \"kx\")\n    \n    # Setup the axis and titles\n    xmin = minimum([r0[t1i:t2i,X]; r1[t1i:t2i,X]; r2[t1i:t2i,X]]) * 1.10\n    xmax = maximum([r0[t1i:t2i,X]; r1[t1i:t2i,X]; r2[t1i:t2i,X]]) * 1.10\n    ymin = minimum([r0[t1i:t2i,Y]; r1[t1i:t2i,Y]; r2[t1i:t2i,Y]]) * 1.10\n    ymax = maximum([r0[t1i:t2i,Y]; r1[t1i:t2i,Y]; r2[t1i:t2i,Y]]) * 1.10\n    \n    axis([xmin, xmax, ymin, ymax])\n    title(@sprintf \"3-body simulation for t=[%.1f .. %.1f]\" t1 t2)\nend;\n\nm0 = 5.0\nm1 = 4.0\nm2 = 3.0\n\n# Initial positions and velocities of each body (x0, y0, vx0, vy0) \ngi0 = [ 1.0; -1.0; 0.0; 0.0]\ngi1 = [ 1.0;  3.0; 0.0; 0.0]\ngi2 = [-2.0; -1.0; 0.0; 0.0]\n\n\nT  = 30.0\nNT  = 500*300\ng0  = [gi0; gi1; gi2]\n\nres_ = ode45(f, T, NT, g0)\n\nsess = Session(); init(sess)\nres = run(sess, res_)\n\nr0, v0, r1, v1, r2, v2 = res[:,1:2], res[:,3:4], res[:,5:6], res[:,7:8], res[:,9:10], res[:,11:12]\n\nfigure(figsize=[4,1])\nsubplot(131); plot_trajectory(0.0,10.0)\nsubplot(132); plot_trajectory(10.0,20.0)\nsubplot(133); plot_trajectory(20.0,30.0)","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"(Image: )","category":"page"},{"location":"ode/#Explicit-Newmark-Scheme","page":"PDE/ODE Solvers","title":"Explicit Newmark Scheme","text":"","category":"section"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"ExplicitNewmark provides an explicit Newmark integrator for ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"M ddotmathbfd + Z_1 dotmathbfd + Z_2 mathbfd + f = 0","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The numerical scheme is given by ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"left(frac1Delta t^2 M + frac12Delta tZ_1right)d^n+1 = left(frac2Delta t^2 M - frac12Delta tZ_2right)d^n - left(frac1Delta t^2 M - frac12Delta tZ_1right) d^n-1 - f^n","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"We consider an example:","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"mathbfd = beginbmatrixe^-t e^-2tendbmatrix","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"and ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"M = beginbmatrix1  23 4 endbmatrixqquad Z_1 = beginbmatrix5  67 8 endbmatrixqquad Z_2 =beginbmatrix9  1011 12 endbmatrix \n\nThe function f is given by \n\nf(t) = -beginbmatrix5e^-t + 6e^-2t 7 e^-t + 12 e^-2tendbmatrix","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"We can carry out the simulation using the following codes:","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"using ADCME \nusing PyPlot \n\nM = Float64[1 2;3 4]\nZ1 = Float64[5 6;7 8]\nZ2 = Float64[9 10;11 12]\n\nNT = 200\nΔt = 1/NT \n\nF = zeros(NT+1, 2)\nfor i = 1:NT+1\n    t = (i-1)*Δt \n    F[i,1] = -(5exp(-t) + 6exp(-2t))\n    F[i,2] = -(7exp(-t) + 12exp(-2t))\nend \nF = constant(F)\n\nen = ExplicitNewmark(M, Z1, Z2, Δt)\n\nfunction condition(i, d)\n    i<=NT\nend\n\nfunction body(i, d)\n    d0 = read(d, i-1)\n    d1 = read(d, i)\n    d2 = step(en, d0, d1, F[i-1])\n    i+1, write(d, i+1, d2)\nend\n\nd = TensorArray(NT+1)\nd = write(d, 1, [1.0;1.0])\nd = write(d, 2, [exp(-Δt);exp(-2Δt)])\ni = constant(2, dtype = Int32)\n_, d = while_loop(condition, body, [i, d])\nd = stack(d)\n\nsess = Session(); init(sess)\nD = run(sess, d)\nts = (0:NT)*Δt\nclose(\"all\")\nplot(ts, D[:, 1], \"b.\")\nplot(ts, D[:,2], \"g.\")\nplot(ts, exp.(-ts), \"r--\")\nplot(ts, exp.(-2ts), \"r--\")\nxlabel(\"t\"); ylabel(\"y\")\nsavefig(\"ode_solution.png\")","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"(Image: )","category":"page"},{"location":"ode/#Build-Your-Own-Solvers","page":"PDE/ODE Solvers","title":"Build Your Own Solvers","text":"","category":"section"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"Sometimes it is helpful to build your own ODE/PDE solvers. The basic routine is ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"Implement the one step state transition function;\nUse while_loop to build the time integrator. ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"As an example, we build a second-order Runge-Kutta scheme for ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"dotmathbfd + beta mathbfd = mathbft","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The numerical scheme is","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"beginalignedh_1 = -beta mathbfd^n + mathbft^n h_2 = -beta(mathbfd^n + Delta t h_1) + mathbft^n mathbfd^n+1 = mathbfd^n + fracDelta t2(h_1 + h_2)endaligned","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The state transition function has the following form ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"function rk_one_step(d2, t)\n    h1 = -β*d2 + t \n    h2 = -β*(d2+Δt*h1)+t \n    d2 + Δt/2*(h1+h2)\nend","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"Now consider an analytical solution ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"mathbfd = beginbmatrixe^-te^-2tendbmatrix quad beta = 2","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"Then we have ","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"mathbft = beginbmatrixe^-t0endbmatrix","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"The main code is as follows","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"using ADCME\nusing PyPlot\n\nNT = 100\nΔt = 1/NT \nts = Array((0:NT)*Δt)\nt = constant([exp.(-ts) zeros(NT+1)])\nβ = 2.0\n\n\n\nfunction condition(i, d)\n    i<=NT\nend\n\nfunction body(i, d)\n    d0 = read(d, i)\n    d1 = rk_one_step(d0, t[i])\n    i+1, write(d, i+1, d1) \nend\n\nd = TensorArray(NT+1)\nd = write(d, 1, ones(2))\ni = constant(1, dtype = Int32)\n_, d = while_loop(condition, body, [i, d])\nd = stack(d)\n\nsess = Session(); init(sess)\nD = run(sess, d)\n\nclose(\"all\")\nplot(ts, D[:,1], \"y.\")\nplot(ts, D[:,2], \"g.\")\nplot(ts, exp.(-ts), \"r--\")\nplot(ts, exp.(-2ts), \"r--\")\nxlabel(\"t\"); ylabel(\"y\")\nsavefig(\"ode_solution2.png\")","category":"page"},{"location":"ode/","page":"PDE/ODE Solvers","title":"PDE/ODE Solvers","text":"(Image: )","category":"page"},{"location":"fdtd/#Finite-difference-Time-domain-for-Electromagnetics-and-Seismic-Inversion","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"","category":"section"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"The finite-difference time-domain (FDTD) is a very conceptually and technically simple technique for full-wave simulation. It has been widely adopted in electromagnetics and geophysics. For example, the full-waveform inversion (FWI), which is arguably the most famous seismic inversion technique, is typically implemented with FDTD. It is also known as Yee scheme. Given its significance, in this section, we show how to implement FDTD in one-dimension using ADCME, and use the forward computation code to do inverse problems. ","category":"page"},{"location":"fdtd/#FDTD","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"FDTD","text":"","category":"section"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"To make the discussion clear and consistent throughout the session, we use notations from electromagnetics, E, the electric field, and H, the magnetic flux. In 1D, the Faraday's law and Ampere's law are simplified to ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"beginaligned\r\nmu fracpartial Hpartial t = fracpartial Epartial x \r\nepsilon fracpartial Epartial t = fracpartial Hpartial x\r\nendaligned","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"We use the staggered grid shown in the following figure ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"(Image: )","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"The superscript denotes time step, while the subscript denotes location index. The electric field E_i^q is defined on the grid point, while the magnetic flux is defined in the cell center. The Yee algorithm alternatively updates H and E with ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"beginaligned\r\nH_i^q+frac12  = H_i^q-frac12 + fracDelta tmuDelta x (E^q_i+1 - E^q_i) \r\nE_i^q+1 = E_i^q + fracDelta tepsilon Delta x(H^q+frac12_i - H^q+frac12_i-1)\r\nendaligned","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"When we simulate within a finite computational domain, we usually need to design a boundary condition that \"absorbs\" reflecting waves. This can be done with the so-called perfectly matched layer (PML) boundaries. In practice, we can pad the computational domain with extra grids (the magenta region in the figure above). See the next section for a detailed discussion. ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"In the case we want to add some source functions, there are typically two ways:","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Hardwiring source functions by setting E_k^q=s_k^q for all q and certain index k. \nAdditive source functions. This is achieved by replacing the second equation with ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"E_i^q+1 = E_i^q + fracDelta tepsilon Delta x(H^q+frac12_i - H^q+frac12_i-1) + fracDelta tepsilon J_i^q+frac12","category":"page"},{"location":"fdtd/#Perfectly-Matched-Layer-(PML)","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Perfectly Matched Layer (PML)","text":"","category":"section"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Let us consider the plane wave e^i kx. In the infinite space, the plane wave will pass through the domain of interest and never get reflected back. However, in practice, computational domains are finite. If we impose a reflection boundary condition, the plane wave will get reflected. Even if we impose Dirichlet boundary conditions, some portions of reflection is still present. These reflections are not desirable for relevant applications. Therefore, we want to find a way for damping reflected waves away. ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Let us consider the plane waves e^ikx. It's complex but we can always think of it as an analytical continuous of sin(kx) in the complex space. Instead of looking at real x, we consider a complex x, and we have","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"e^ik(Re x + iIm x) = e^ikRe x - kIm x","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Here is an important observation: if Im x = f(Re x) 0 for some increasing function f(x), the magnitude of the wave e^ikx along the line Re x + i f(Re x) will decay exponentially. Thus, within a finite computational domain 01, we can extend the governing equation beyond 01 in the complex domain, with the path given by ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":" x + i f(x) xin mathbbR","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Here f(x) = 0, xin (01), and ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"f(x) = fracsigma(x)k x1","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"The case for f(x)0 is similar. ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"The fundamental idea is that instead of looking at the governing equation in 01, we extend it analytically into the complex space. For example, the transport equation ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"fracpartial u(x t)partial t = fracpartial u(x t)partial x","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"becomes ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"fracpartial tilde u(z t)partial t = fracpartial tilde u(z t)partial z zin mathbbC","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Then the question is: what is the governing equation for bar u(x t) = tilde u(x+i f(x) t)?","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"To simplify our notation, we omit t here because it is unrelated to the complex domain. We denote z = x + i f(x) and ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Re tilde u = u_1 Im tilde u = u_2","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Then we have ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"beginaligned\r\nfracpartial bar u(x)partial x = fracpartial tilde u(x+i f(x))partial x \r\n= fracpartial (u_1(x+i f(x)) + i u_2(x+i f(x)))partial x \r\n= fracpartial (u_1(x+i f(x))partial x + i fracpartial u_2(x+i f(x)))partial x  \r\n= fracpartial u_1partial x + i fracpartial u_2partial x + i fracpartial u_1partial x fracpartial fpartial x - fracpartial u_2partial xfracpartial fpartial x\r\nendaligned","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Note from complex analysis, ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"fracpartial tilde u(z)partial z = fracpartial u_1partial x + i fracpartial u_2partial x","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"We have","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"fracpartial bar u(x)partial x =left(1 + ifracpartial fpartial x right) fracpartial tilde upartial ztag1","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Now let us consider the Faraday's law","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"mu fracpartial Hpartial t = fracpartial Epartial xtag2","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"We consider the plane wave H = e^-ikx, which we want to damp outside the computational domain. First we extend Equation 2 to the complex domain and plug H to the equation (note fracpartial Hpartial t = fracpartial bar Hpartial t)","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"-imu k bar H = fracpartial tilde Epartial z","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Using Equation 1, we have","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"-i mu k bar H+ mu sigma_x(x) bar H= fracpartial bar  Epartial x","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Converting back to the time domain, we have ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"mufracpartial bar Hpartial t = fracpartial bar  Epartial x - mu sigma_x(x) bar H","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Likewise, we have","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"epsilonfracpartial bar Hpartial t = fracpartial bar  Epartial x - epsilon sigma_x(x) bar H","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Note that the two above equations are exactly the original equations within the domain 01. ","category":"page"},{"location":"fdtd/#Numerical-Experiment:-Forward-Computation","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Numerical Experiment: Forward Computation","text":"","category":"section"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Let us consider a 1D wave equation ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"fracpartial^2 upartial t^2 = c^2 fracpartial^2 upartial x^2","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"which is equivalent to ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"beginaligned\r\nfracpartial upartial t = c fracpartial vpartial x\r\nfracpartial vpartial t = c fracpartial upartial x \r\nendaligned","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"This set of equations is related to Faraday's law and Ampere's law via","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"E = v H = u epsilon = frac1c mu = frac1c","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"We use a hardwiring source at the center of the computational domain 01. The source function is shown in the left panel. The evolution of u is shown in the right panel. ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"|Source Function|Evolution of u| |–|–| |(Image: )|(Image: )|","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"using ADCME\r\nusing PyPlot \r\nusing ADCMEKit \r\n\r\nn = 200\r\npml = 30\r\nC = 100.0\r\nNT = 1000\r\nΔt = 1.5/NT \r\nx0 = LinRange(0, 1, n+1)\r\nh = 1/n \r\nxE = Array((0:n+2pml)*h .- pml*h)\r\nxH = (xE[2:end]+xE[1:end-1])/2 \r\nN = n + 2pml + 1\r\n\r\nσE = zeros(N)\r\nfor i = 1:pml\r\n    d = i*h\r\n    σE[pml + n + 1 + i] = C* (d/(pml*h))^3\r\n    σE[pml+1-i] = C* (d/(pml*h))^3\r\nend\r\n\r\nσH = zeros(N-1)\r\nfor i = 1:pml \r\n    d = (i-1/2)*h \r\n    σH[pml + n + i] = C* (d/(pml*h))^3\r\n    σH[pml+1-i] = C* (d/(pml*h))^3\r\nend\r\n\r\nfunction ricker(dt = 0.002, f0 = 3.0)\r\n    nw = 2/(f0*dt)\r\n    nc = floor(Int, nw/2)\r\n    t = dt*collect(-nc:1:nc)\r\n    b = (π*f0*t).^2\r\n    w = @. (1 - 2b)*exp(-b)\r\nend\r\nR = ricker()\r\nif length(R)<NT+1\r\n    R = [R;zeros(NT+1-length(R))]\r\nend\r\n\r\nR_ = constant(R)\r\n\r\n# cH = constant(ones(N-1))\r\ncH = ones(length(xH)) * 1.5\r\ncE = (cH[1:end-1]+cH[2:end])/2\r\nZ = zeros(N)\r\nZ[N÷2] = 1.0\r\nZ = Z[2:end-1]\r\n\r\nfunction condition(i, E_arr, H_arr)\r\n    i<=NT+1\r\nend\r\n\r\nfunction body(i, E_arr, H_arr)\r\n    E = read(E_arr, i-1)\r\n    H = read(H_arr, i-1)\r\n    ΔH = cH * (E[2:end]-E[1:end-1])/h - σH*H\r\n    H += ΔH * Δt\r\n    ΔE = cE * (H[2:end]-H[1:end-1])/h - σE[2:end-1]*E[2:end-1] #+ R_[i] * Z\r\n    E = scatter_add(E, 2:N-1, ΔE * Δt)\r\n    E = scatter_update(E, N÷2, R_[i])\r\n    i+1, write(E_arr, i, E), write(H_arr, i, H)\r\nend\r\n\r\nE_arr = TensorArray(NT+1)\r\nH_arr = TensorArray(NT+1)\r\n\r\nE0 = zeros(N)\r\nE0[N÷2] = R[1]\r\nE_arr = write(E_arr, 1, E0)\r\nH_arr = write(H_arr, 1, zeros(N-1))\r\n\r\ni = constant(2, dtype = Int32)\r\n\r\n_, E, H = while_loop(condition, body, [i, E_arr, H_arr])\r\n\r\nE = stack(E)\r\nH = stack(H)\r\n\r\nsess = Session(); init(sess)\r\nE_, H_ = run(sess, [E, H])\r\n\r\n\r\npl, = plot([], [], \".-\")\r\nxlim(-0.5,1.5)\r\nylim(minimum(E_), maximum(E_))\r\nxlabel(\"x\")\r\nylabel(\"y\")\r\nt = title(\"time = 0.0000\")\r\nfunction update(i)\r\n    t.set_text(\"time = $(round(i*Δt, digits=4))\")\r\n    pl.set_data([xE E_[i,:]]'|>Array)\r\nend \r\np = animate(update, 1:10:NT+1)\r\n# saveanim(p, \"fdtd.gif\")","category":"page"},{"location":"fdtd/#Numerical-Experiment","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Numerical Experiment","text":"","category":"section"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"Let us consider inverting for a constant c_H. The following code is mainly a copy and paste from the above code. The optimization converges within a few iterations. ","category":"page"},{"location":"fdtd/","page":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","title":"Finite-difference Time-domain for Electromagnetics and Seismic Inversion","text":"using ADCME\r\nusing PyPlot \r\nusing ADCMEKit \r\n\r\nn = 200\r\npml = 30\r\nC = 100.0\r\nNT = 1000\r\nΔt = 1.5/NT \r\nx0 = LinRange(0, 1, n+1)\r\nh = 1/n \r\nxE = Array((0:n+2pml)*h .- pml*h)\r\nxH = (xE[2:end]+xE[1:end-1])/2 \r\nN = n + 2pml + 1\r\n\r\nσE = zeros(N)\r\nfor i = 1:pml\r\n    d = i*h\r\n    σE[pml + n + 1 + i] = C* (d/(pml*h))^3\r\n    σE[pml+1-i] = C* (d/(pml*h))^3\r\nend\r\n\r\nσH = zeros(N-1)\r\nfor i = 1:pml \r\n    d = (i-1/2)*h \r\n    σH[pml + n + i] = C* (d/(pml*h))^3\r\n    σH[pml+1-i] = C* (d/(pml*h))^3\r\nend\r\n\r\nfunction ricker(dt = 0.002, f0 = 3.0)\r\n    nw = 2/(f0*dt)\r\n    nc = floor(Int, nw/2)\r\n    t = dt*collect(-nc:1:nc)\r\n    b = (π*f0*t).^2\r\n    w = @. (1 - 2b)*exp(-b)\r\nend\r\nR = ricker()\r\nif length(R)<NT+1\r\n    R = [R;zeros(NT+1-length(R))]\r\nend\r\n\r\nR_ = constant(R)\r\n\r\n# cH = constant(ones(N-1))\r\n# cH = Variable(ones(length(cH)))\r\nb = softplus(Variable(1.0))\r\ncH = ones(length(xH)) * b\r\ncE = (cH[1:end-1]+cH[2:end])/2\r\nZ = zeros(N)\r\nZ[N÷2] = 1.0\r\nZ = Z[2:end-1]\r\n\r\nfunction condition(i, E_arr, H_arr)\r\n    i<=NT+1\r\nend\r\n\r\nfunction body(i, E_arr, H_arr)\r\n    E = read(E_arr, i-1)\r\n    H = read(H_arr, i-1)\r\n    ΔH = cH * (E[2:end]-E[1:end-1])/h - σH*H\r\n    H += ΔH * Δt\r\n    ΔE = cE * (H[2:end]-H[1:end-1])/h - σE[2:end-1]*E[2:end-1] #+ R_[i] * Z\r\n    E = scatter_add(E, 2:N-1, ΔE * Δt)\r\n    E = scatter_update(E, N÷2, R_[i])\r\n    i+1, write(E_arr, i, E), write(H_arr, i, H)\r\nend\r\n\r\nE_arr = TensorArray(NT+1)\r\nH_arr = TensorArray(NT+1)\r\n\r\nE0 = zeros(N)\r\nE0[N÷2] = R[1]\r\n# v0[N÷2] = 1.0\r\nE_arr = write(E_arr, 1, E0)\r\nH_arr = write(H_arr, 1, zeros(N-1))\r\n\r\ni = constant(2, dtype = Int32)\r\n\r\n_, E, H = while_loop(condition, body, [i, E_arr, H_arr])\r\n\r\nE = stack(E); E = set_shape(E, (NT+1, N))\r\nH = stack(H)\r\n\r\nreceivers = [pml+1:pml+10; N-pml-9:N-pml]\r\nloss = sum((E[:,receivers] - E_[:,receivers])^2)\r\nsess = Session(); init(sess)\r\nBFGS!(sess, loss)","category":"page"},{"location":"quadrature/#Numerical-Integration","page":"Numerical Integration","title":"Numerical Integration","text":"","category":"section"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"This section describes how to do numerical integration in ADCME. In fact, the numerical integration functionality is independent of automatic differentiation. We can use a third-party library, such as FastGaussQuadrature for extracts the quadrature weights and points. Then the quadrature weights and points can be used to calculate the integral. ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"The general rule for numerical integral is ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"int_a^b w(x) f(x) dx = sum_i=1^n w_i f(x_i)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"The method works best when f(x) can be approximated by a polynomial on the interval (a b). ","category":"page"},{"location":"quadrature/#Examples","page":"Numerical Integration","title":"Examples","text":"","category":"section"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"Let us consider some examples. ","category":"page"},{"location":"quadrature/#Example-1","page":"Numerical Integration","title":"Example 1","text":"","category":"section"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"int_0^1fracsin(a*x)sqrt1-x^2dx","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"Here a is a tensor (e.g., a = Variable(1.0)). We can use the Gauss-Chebyshev quadrature rule of the 1st kind. The corresponding weight function is frac1sqrt1-x^2","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"using FastGaussQuadrature, ADCME\nx, w = gausschebyshev(100) # 100 is the number of quadrature nodes\na = Variable(1.0)\nintegral = sum(cos(a * x) * w)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"We can verify the result with the exact value ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"sess = Session(); init(sess)\n@show sum(cos.(x) .* w), run(sess, integral)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"The output is ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"(sum(cos.(x) .* w), run(sess, integral)) = (2.4039394306344133, 2.4039394306344137)","category":"page"},{"location":"quadrature/#Example-2","page":"Numerical Integration","title":"Example 2","text":"","category":"section"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"int_0^infty (x-1)^β x^alpha exp(-x) dx","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"Here we consider the Gauss-Laguerre quadrature rule. The weight function is w(x) = x^alpha exp(-x) and f(x) = (x-1)^2.","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"using FastGaussQuadrature, ADCME\nα = 2.0\nx, w = gausslaguerre(100, α)\nβ = Variable(2.0)\nintegrand = constant(x .- 1)^β\nintegral = sum(integrand .* w)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"We can verify the result with the exact value ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"sess = Session(); init(sess)\n@show sum((x .- 1).^2 .* w), run(sess, integral)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"The output is ","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"(sum((x .- 1) .^ 2 .* w), run(sess, integral)) = (14.000000000000039, 14.000000000000037)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"The integral rule is also differentiable, for example, we can calculate the gradient of the integral with respect to beta","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"run(sess, gradients(integral, β))","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"For convenience, here is a list of supported quadrature rules (run using FastGaussQuadrature first)","category":"page"},{"location":"quadrature/","page":"Numerical Integration","title":"Numerical Integration","text":"Interval ω(x) Orthogonal polynomials Function\n1 1 1 Legendre polynomials gausslegendre(n)\n(1 1) (1-x)^alpha (1+x)^beta Jacobi polynomials gaussjacobi(n, a, b)\n(1 1) frac1sqrt1-x^2 Chebyshev polynomials (first kind) gausschebyshev(n, 1)\n1 1 sqrt1-x^2 Chebyshev polynomials (second kind) gausschebyshev(n, 2)\n1 1 sqrt(1+x)(1-x) Chebyshev polynomials (third kind) gausschebyshev(n, 3)\n1 1 sqrt(1-x)(1+x) Chebyshev polynomials (fourth kind) gausschebyshev(n, 4)\n0 infty) e^-x Laguerre polynomials gausslaguerre(n)\n0 infty) x^alpha e^-x alpha1 Generalized Laguerre polynomials gausslaguerre(n, α)\n(-infty infty) e^-x^2 Hermite polynomials gausshermite(n)","category":"page"},{"location":"designpattern/#Design-Pattern","page":"Design Pattern","title":"Design Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Design patterns aim at providing reusable solutions for solving the challenges in the process of software development. The ultimate goal of design patterns is to avoid reinventing the wheels and making software flexible and resilient to change. Design patterns are neither concrete algorithms, nor programming templates, but ways of thinking. They are not always necessary if you can come up with very simple designs, which are actually more preferable in practice. Rather, they are \"rules of thumb\" that facilitates you when you have a hard time how to design the structure of your codes. ","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"We strive to make ADCME easily maintainable and extendable by using well-established design patterns for some design decisions. In this section, we describe some design patterns that are useful for programming ADCME. ","category":"page"},{"location":"designpattern/#Strategy-Pattern","page":"Design Pattern","title":"Strategy Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The strategy pattern defines a family of algorithms, encapsulates each one, and makes them interchangeable. The strategy pattern makes programmers wrap algorithms that are subject to frequent changes (e.g., extending) as interfaces instead of concrete implementations. For example, in ADCME, FlowOp is implemented using the strategy pattern. ","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"When you want to create a flow-based model, the structure NormalizingFlow has a method that performs a sequence of forward operations. The forward operations might have different combinations, which results in a large number of different normalizing flows. If we define a different normalizing flow structure for a different combination, there will be exponentially many such structures. Instead of defining a separate forward method for each different normalizing flow, we define an interface FlowOp, which has a forward method. ","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The interface is implemented with many concrete structures, which are called algorithms in the strategy pattern. These concrete FlowOps, such as SlowMAF and MAF, have their specific forward implementations. Therefore, the system become easily extendable. When we have a new algorithm, we only need to add a new FlowOp instead of modifying NormalizingFlow. ","category":"page"},{"location":"designpattern/#Adaptor-Pattern","page":"Design Pattern","title":"Adaptor Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The adapter pattern converts the interface of a structure into another interface users expect. It is very useful to unify the APIs and reuses the existing functions, and thus reliefs users from memorizing many new functions. The typical structure of an adaptor has the form","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"struct Adaptor <: AbstractNewComponent\n    o::LegacyComponent\n    function new_do_this(adaptor, x)\n        old_do_this(adaptor.o, x)\n    end\n    ...\nend ","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Here users work with AbstractNewComponent, whose concrete types implement a function new_do_this. However, we have a structure of type LegacyComponent, which has a function old_do_this. An adaptor pattern is used to match an old function call old_do_this to new_do_this in the new system.","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"An example of adaptor pattern is SparseTensor, which wraps a PyObject. The operations on the SparseTensor is propagated to the PyObject, and therefore users can think in terms of the new SparseTensor data type. ","category":"page"},{"location":"designpattern/#Observer-Pattern","page":"Design Pattern","title":"Observer Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The observer pattern define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. The basic pattern is ","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Subject","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"struct Subject\n    o # Observer \n    state\n    function update(s)\n        # some operations on `s.state`\n    end\n    function notify(s)\n        # some operations on `s.o`\n    end\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Observer","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"struct Observer\n    subjects::Array{Subject}\n    function update(o)\n        for s in o.subjects\n            update(s)\n        end\n    end\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"For example, the commitHistory function in NNFEM.jl uses the observer pattern to update states from Domain, to Element, and finally to Material. ","category":"page"},{"location":"designpattern/#Decorator-Pattern","page":"Design Pattern","title":"Decorator Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The decorator pattern attaches additional responsibilities to an object dynamically. Decorator patterns are very similar to adaptor patterns. The difference is that the input and output types of the decorator pattern are the same. For example, if the input is a SparseTensor, the output should also be a SparseTensor. The adaptor pattern converts PyObject to SparseTensor. Another difference is that the decorator pattern usually does not change the methods and fields of the structure. For example,","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"struct Juice\n    cost::Float64 \nend\n\nfunction add_one_dollar(j::Juice)\n    Juice(j.cost+1)\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Then add_one_dollar(j) is still a Juice structure but the cost is increased by 1. You can also compose multiple add_one_dollar:","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"add_one_dollar(add_one_dollar(j))","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"In Julia, this can be done elegantly using macros. We do not discuss macros in this section but leave it to another section on macros. ","category":"page"},{"location":"designpattern/#Iterator-Pattern","page":"Design Pattern","title":"Iterator Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Iterator patterns provide a way to access the elements of an aggregate object sequentially without exposing its underlying representation. Julia has built-in iterator support. The in keyword loops through iterations and collect collects all the entries in the iterator. In Julia, to understand iteration, remember that the following code","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"for i in x\n    # stuff\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"is a shorthand for writing","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"it = iterate(x)\nwhile it !== nothing\n    i, state = it\n    # stuff\n    it = iterate(x, state)\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Therefore, we only need to implement iterate","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"iterate(iter [, state]) -> Union{Nothing, Tuple{Any, Any}}","category":"page"},{"location":"designpattern/#Factory-Pattern","page":"Design Pattern","title":"Factory Pattern","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"The factory pattern defines an interface for creating an object, but lets subclasses decide which class to instantiate. Simply put, we define a function that returns a specific structure","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"function factory(s::String)\n    if s==\"StructA\"\n        return StructA()\n    elseif s==\"StructB\"\n        return StructB()\n    elseif s==\"StructC\"\n        return StructC()\n    else\n        error(ArgumentError(\"$s is not understood\"))\n    end\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"For example, FiniteStrainContinuum in NNFEM.jl has a constructor","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"function FiniteStrainContinuum(coords::Array{Float64}, elnodes::Array{Int64}, props::Dict{String, Any}, ngp::Int64=2)\n    eledim = 2\n    dhdx, weights, hs = get2DElemShapeData( coords, ngp )\n    nGauss = length(weights)\n    name = props[\"name\"]\n    if name==\"PlaneStrain\"\n        mat = [PlaneStrain(props) for i = 1:nGauss]\n    elseif name==\"Scalar1D\"\n        mat = [Scalar1D(props) for i = 1:nGauss]\n    elseif name==\"PlaneStress\"\n        mat = [PlaneStress(props) for i = 1:nGauss]\n    elseif name==\"PlaneStressPlasticity\"\n        mat = [PlaneStressPlasticity(props) for i = 1:nGauss]\n    elseif name==\"PlaneStrainViscoelasticityProny\"\n        mat = [PlaneStrainViscoelasticityProny(props) for i = 1:nGauss]\n    elseif name==\"PlaneStressViscoelasticityProny\"\n        mat = [PlaneStressViscoelasticityProny(props) for i = 1:nGauss]\n    elseif name==\"PlaneStressIncompressibleRivlinSaunders\"\n        mat = [PlaneStressIncompressibleRivlinSaunders(props) for i = 1:nGauss]\n    elseif name==\"NeuralNetwork2D\"\n        mat = [NeuralNetwork2D(props) for i = 1:nGauss]\n    else\n        error(\"Not implemented yet: $name\")\n    end\n    strain = Array{Array{Float64}}(undef, length(weights))\n    FiniteStrainContinuum(eledim, mat, elnodes, props, coords, dhdx, weights, hs, strain)\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"Every time we add a new material, we need to modify this structure. This is not very desirable. Instead, we can have a function","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"function get_element(s)\n    if name==\"PlaneStrain\"\n        PlaneStrain\n    elseif name==\"Scalar1D\"\n        Scalar1D\n    ...\nend","category":"page"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"This can also be achieved via Julia macros, thanks to the powerful meta-programming feature in ADCME. ","category":"page"},{"location":"designpattern/#Summary","page":"Design Pattern","title":"Summary","text":"","category":"section"},{"location":"designpattern/","page":"Design Pattern","title":"Design Pattern","text":"We have introduced some important design patterns that facilitate design maintainable and extendable software. Design patterns should not be viewed as rules to abide by, but they are useful principles in face of design difficulties. As mentioned, Julia provides powerful meta-programming features. These features can be used in the design patterns to simplify implementations. Meta-programming will be discussed in a future section.","category":"page"},{"location":"apps_nnfem/#Symmetric-Positive-Definite-Neural-Networks-(SPD-NN)","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"","category":"section"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"Kailai Xu (co-first author), Huang, Daniel Z. (co-first author), and Eric Darve. \"Learning Constitutive Relations using Symmetric Positive Definite Neural Networks\"","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"Project Website","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"Material modeling aims to construct constitutive models to describe the relationship between strain and stress, in which the relationship may be hysteresis. The constitutive relations can be derived from microscopic interactions between multiscale structures or between atoms. However, the first-principles simulations, which resolve all these interactions, remain prohibitively expensive. This motivates to learn a data-driven constitutive relation that expresses the mapping from strain tensors (possibly with historic information) to stress tensors. ","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"In a previous application, we showed how to learn a constitutive relation, which is a (nonlinear) map from strain tensors to stress tensors, from state variables in a static equation. However, many constitutive relations also depend on the historic information, such as (elasto-)plasticity and viscosity. The constitutive relation is much more complex since they have the form ","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"sigma(t) = mathcalM(epsilon(t) mathcalI(t))","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"where t is the time, sigma, epsilon are strain and stress tensors,  mathcalI contains the historic information in 0t), and mathcalM is an unknown function. This is a high dimensional mapping and traditional methods, such as piecewise linear functions, suffer from the curse of dimensionality problem. This issue motivates us to use neural network as surrogate models. ","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"However, typically we cannot measure the stress directly and therefore a strain-stress pair training data set is not available. The idea is to plug the neural network based constitutive relation into physical laws, i.e., the kinematic and kinetic equations of motion, and obtain a hypothetical displacement u. u is a quantity which we can measure. We can find the optimal weights and biases of the neural network by minimizing the discrepancy between u and observed displacement. This procedure is done using automatic differentiation, where the gradients are back-propagated through both the numerical solver and the neural network. ","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"The challenge here is that the numerical solver is unstable if we plug in a random neural network based constitutive relation. Indeed, numerical solvers are developed based on certain physical assumptions, and a  neural network from random choices may go wild and can be quite ill-behaved. The idea is to add physical constraints to the neural network. The solution we proposed is the symmetric positive definite neural network (SPD-NN): instead of modeling the constitutive relation directly, we model the tangent stiffness matrix. To be more specific,","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"Delta sigma =mathsfL_thetamathsfL_theta^T Delta epsilon","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"where mathsf L_theta is a Cholesky factor and therefore mathsfL_thetamathsfL_theta^T is SPD. The formulation preserves both time consistency and weak convexity of the strain energy. In specific applications, the formulation is further customized. For example, ","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"sigma^n+1 = mathsfM_theta(epsilon^n+1 epsilon^n sigma^n) = leftbeginmatrix\n mathsfC_thetaepsilon^n+1   textLinear Elasticity\nmathsfL_theta(epsilon^n+1 )mathsfL_theta(epsilon^n+1)^T(epsilon^n+1 -  epsilon^n)  + sigma^n  textNonlinear Elasticity\n (1 - D(sigma^n tildesigma_Y)) sigma_mathrmelasticity^n+1 + D(sigma^n tildesigma_Y) sigma_mathrmplasticity^n+1  textElasto-Plasticity\nendmatrixright","category":"page"},{"location":"apps_nnfem/","page":"Symmetric Positive Definite Neural Networks (SPD-NN)","title":"Symmetric Positive Definite Neural Networks (SPD-NN)","text":"As a final remark, the challenge in learning plasticity behavior is that we have to capture the loading and unloading transitions. In this case, the tangent stiffness matrix exhibits a discontinuity. To alleviate the problem, we adjust the neural network by using a transition function D in the elasto-plasticity case. ","category":"page"},{"location":"tu_whatis/#What-is-ADCME?-Computational-Graph,-Automatic-Differentiation-and-TensorFlow","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"","category":"section"},{"location":"tu_whatis/#Computational-Graph","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Computational Graph","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"A computational graph is a functional description of the required computation. In the computationall graph, an edge represents a value, such as a scalar, a vector, a matrix or a tensor. A node represents a function whose input arguments are the the incoming edges and output values are are the outcoming edges. Based on the number of input arguments, a function can be nullary, unary, binary, ..., and n-ary; based on the number of output arguments, a function can be single-valued or multiple-valued. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Computational graphs are directed and acyclic. The acyclicity implies the forward propagation computation is well-defined: we loop over edges in topological order and evaluates the outcoming edges for each node. To make the discussion more concrete, we illustrate the computational graph for ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"z = sin(x_1+x_2) + x_2^2 x_3","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"(Image: )","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"There are in general two programmatic ways to construct computational graphs: static and dynamic declaration. In the static declaration, the computational graph is first constructed symbolically, i.e., no actual numerical arithmetic are executed. Then a bunch of data is fed to the graph for the actual computation. An advantage of static declarations is that they allow for graph optimization such as removing unused branches. Additionally, the dependencies can be analyzed for parallel execution of independent components. Another approach is the dynamic declaration, where the computational graph is constructed on-the-fly as the forward computation is executed. The dynamic declaration interleaves construction and evaluation of the graph, making software development more intuitive. ","category":"page"},{"location":"tu_whatis/#Automatic-Differentiation","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Automatic Differentiation","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"An important application of computational graphs is automatic differentiation (AD). In general, there are three modes of AD: reverse-mode, forward-mode, and mixed mode. In this tutorial, we focus on the forward-mode and reverse-mode.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Basically, the forward mode and the reverse mode automatic differenation both use the. chain rule for computing the gradients. They evaluate the gradients of \"small\" functions analytically (symbolically) and chain all the computed numerical gradients via the chain rule","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"fracpartial fcirc g (x)partial x = fracpartial fcirc g(x)partial g fracpartial g(x)partial x","category":"page"},{"location":"tu_whatis/#Forward-Mode","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Forward Mode","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"In the forward mode, the gradients are computed in the same order as function evaluation, i.e., fracpartial g(x)partial x is computed first, and then fracpartial fcirc g(x)partial g fracpartial g(x)partial x as a whole. The idea is the same for a computational graph, except that we need to aggregate all the gradients from up-streams first, and then forward the gradients to down-stream nodes. Here we show how the gradient ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"f(x) = beginbmatrix\n\t\t\tx^4\n\t\t\tx^2 + sin(x) \n\t\t\t-sin(x)endbmatrix","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"is computed.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Forward-mode AD in the Computational Graph Example\n(Image: ) (Image: )","category":"page"},{"location":"tu_whatis/#Reverse-Mode","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Reverse Mode","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"In contrast, the reverse-mode AD computes the gradient  in the reverse order of forward computation, i.e., fracpartial fcirc g(x)partial g is first evaluated and then fracpartial fcirc g(x)partial g fracpartial g(x)partial x as a whole. In the computational graph, each node first aggregate all the gradients from down-streams  and then back-propagates the gradient to upstream nodes.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"We show how the gradients of z = sin(x_1+x_2) + x_2^2 x_3 is evaluated. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Reverse-mode AD in the Computational Graph Step 1 Step 2 Step 3 Step 4\n(Image: ) (Image: ) (Image: ) (Image: ) (Image: )","category":"page"},{"location":"tu_whatis/#Comparison","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Comparison","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Reverse-mode AD reuses gradients from down-streams. Therefore, this mode is useful for many-to-few mappings. In contrast, forward-mode AD reuses gradients from upstreams. This mechanism makes forward-mode AD suitable for few-to-many mappings. Therefore, for inverse modeling problems where the objective function is usually a scalar, reverse-mode AD is most relevant. For uncertainty quantification or sensitivity analysis, the forward-mode AD is most useful. We summarize the two modes in the following table:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"For a function fmathbfR^n rightarrow mathbfR^m","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Mode Suitable for... Complexity[OPS] Application\nForward mgg n leq 25mathrmOPS(f(x)) UQ\nReverse mll n leq 4mathrmOPS(f(x)) Inverse Modeling","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"[OPS]: See \"Margossian CC. A review of automatic differentiation and its efficient implementation. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery. 2019 Jul;9(4):e1305.\".","category":"page"},{"location":"tu_whatis/#A-Mathematical-Description-of-Reverse-mode-Automatic-Differentiation","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"A Mathematical Description of Reverse-mode Automatic Differentiation","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Because the reverse-mode automatic differentiation is very important for inverse modeling, we devote this section to a rigorious mathematical description of the reverse-mode automatic differentiation. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"To explain how reverse-mode AD works, let's consider constructing a computational graph with independent variables ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"x_1 x_2 ldots x_n","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"and the forward propagation produces a single output x_N, Nn. The gradients fracpartial x_N(x_1 x_2 ldots x_n)partial x_i i=1, 2, ldots, n are queried. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"The idea is that this algorithm can be decomposed into a sequence of functions f_i (i=n+1 n+2 ldots N) that can be easily differentiated analytically, such as addition, multiplication, or basic functions like exponential, logarithm and trigonometric functions. Mathematically, we can formulate it as","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"beginaligned\n    x_n+1 = f_n+1(mathbfx_pi(n+1))\n    x_n+2 = f_n+2(mathbfx_pi(n+2))\n    ldots\n    x_N = f_N(mathbfx_pi(N))\nendaligned","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"where mathbfx = x_i_i=1^N and pi(i) are the parents of x_i, s.t., pi(i) in 12ldotsi-1.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"(Image: )","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"The idea to compute partial x_N  partial x_i is to start from i = N, and establish recurrences to calculate derivatives with respect to x_i in terms of derivatives with respect to x_j, j i. To define these recurrences rigorously, we need to define different functions that differ by the choice of independent variables.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"The starting point is to define x_i considering all previous x_j, j  i, as independent variables. Then:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"x_i(x_1 x_2 ldots x_i-1) = f_i(mathbfx_pi(i))","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Next, we observe that x_i-1 is a function of previous x_j, j  i-1, and so on; so that we can recursively define x_i in terms of fewer independent variables, say in terms of x_1, ..., x_k, with k  i-1. This is done recursively using the following definition:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"x_i(x_1 x_2 ldots x_j) = x_i(x_1 x_2 ldots x_j f_j+1(mathbfx_pi(j+1))) quad n  j+1  i","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Observe that the function of the left-hand side has j arguments, while the function on the right has j+1 arguments. This equation is used to \"reduce\" the number of arguments in x_i.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"With these definitions, we can define recurrences for our partial derivatives which form the basis of the back-propagation algorithm. The partial derivatives for","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"x_N(x_1 x_2 ldots x_N-1)","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"are readily available since we can differentiate","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"f_N(mathbfx_pi(N))","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"directly. The problem is therefore to calculate partial derivatives for functions of the type x_N(x_1 x_2 ldots x_i) with iN-1. This is done using the following recurrence:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"fracpartial x_N(x_1 x_2 ldots x_i)partial x_i = sum_jiin pi(j)\n    fracpartial x_N(x_1 x_2 ldots x_j)partial x_j\n    fracpartial x_j(x_1 x_2 ldots x_j-1)partial x_i","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"with n  i N-1. Since i in pi(j), we have i  j. So we are defining derivatives with respect to x_i in terms of derivatives with respect to x_j with j  i. The last term","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"fracpartial x_j(x_1 x_2 ldots x_j-1)partial x_k","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"is readily available since:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"x_j(x_1 x_2 ldots x_j-1) = f_j(mathbfx_pi(j))","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"(Image: )","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"The computational cost of this recurrence is proportional to the number of edges in the computational graph (excluding the nodes 1 through n), assuming that the cost of differentiating f_k is O(1). The last step is defining","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"fracpartial x_N(x_1 x_2 ldots x_n)partial x_i = sum_jiin pi(j)\n    fracpartial x_N(x_1 x_2 ldots x_j)partial x_j\n    fracpartial x_j(x_1 x_2 ldots x_j-1)partial x_i","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"with 1 le i le n. Since n  j, the first term","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"fracpartial x_N(x_1 x_2 ldots x_j)partial x_j","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"has already been computed in earlier steps of the algorithm. The computational cost is equal to the number of edges connected to one of the nodes in 1 dots n.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"We can see that the complexity of the back-propagation is bounded by that of the forward step, up to a constant factor. Reverse mode differentiation is very useful in the penalty method, where the loss function is a scalar, and no other constraints are present. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"As a concrete example, we consider the example of evaluating fracdz(x_1x_2x_3)dx_i, where z = sin(x_1+x_2) + x_2^2x_3. The gradients are  backward propagated exactly in the reverse order of the forward propagation. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Step 1 Step 2 Step 3 Step 4\n(Image: ) (Image: ) (Image: ) (Image: )","category":"page"},{"location":"tu_whatis/#TensorFlow","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"TensorFlow","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Google's TensorFlow provides a convenient way to specify the computational graph statically. TensorFlow  has automatic differentiation features and its performance is optimized for large-scale computing. ADCME is built on TensorFlow by overloading numerical operators and augmenting TensorFlow with essential scientific computing functionalities. We contrast the TensorFlow implementation with the ADCME implementation of computing the objective function and its gradient in the following example.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"y(x) = (AA^T+xI)^-1b-c^2  z = y(x)","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"where Ain mathbbR^ntimes n is a random matrix, xbc are scalars, and n=10.","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"TensorFlow Implementation","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"import tensorflow as tf\nimport numpy as np \nA = tf.constant(np.random.rand(10,10), dtype=tf.float64)\nx = tf.constant(1.0, dtype=tf.float64)\nb = tf.constant(np.random.rand(10), dtype=tf.float64)\nc = tf.constant(np.random.rand(10), dtype=tf.float64)\nB = tf.matmul(A, tf.transpose(A)) + x * tf.constant(np.identity(10))\ny = tf.reduce_sum((tf.squeeze(tf.matrix_solve(B, tf.reshape(b, (-1,1))))-c)**2)\nz = tf.gradients(y, x)[0]\nsess = tf.Session()\nsess.run([y, z])","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Julia Implementation","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"using ADCME, LinearAlgebra\nA = constant(rand(10,10))\nx = constant(1.0)\nb = rand(10)\nc = rand(10)\ny = sum(((A*A'+x*diagm(0=>ones(10)))\\b - c)^2)\nz = gradients(y, x)\nsess = Session()\nrun(sess, [y,z])","category":"page"},{"location":"tu_whatis/#Summary","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"Summary","text":"","category":"section"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"The computational graph and automatic differentiation are the core concepts underlying ADCME. TensorFlow works as the workhorse for optimion and execution of the computational graph in a high performance environment. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"To construct a computational graph for a Julia program, ADCME overloads most numerical operators like +, -, *, / and matrix multiplication in Julia by the corresponding TensorFlow operators. Therefore, you will find many similar workflows and concepts as TensorFlow, such as constant, Variable, session, etc. However, not all operators relevant to scientific computing in Julia have its counterparts in TensorFlow. To that end, custom kernels are implemented to supplement TensorFlow, such as sparse linear algebra related functions. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"ADCME aims at providing a easy-to-use, flexible,  and high performance interface to do data processing, implement numerical schemes, and conduct mathematical optimization. It is built not only for academic interest but also for real-life large-scale simulations. ","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Like TensorFlow, ADCME works in sessions, in which each session consumes a computational graph. Usually the workflow is split into three steps:","category":"page"},{"location":"tu_whatis/","page":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","title":"What is ADCME? Computational Graph, Automatic Differentiation & TensorFlow","text":"Define independent variables. constant for tensors that do not require gradients and Variable for those requiring gradients. \na = constant(0.0)\nConstruct the computational graph by defining the computation\nL = (a-1)^2\nCreate a session and run the computational graph\nsess = Session()\nrun(sess, L)","category":"page"},{"location":"julia_customop/#Julia-Custom-Operators","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"","category":"section"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"warning: Warning\nCurrently, embedding Julia suffers from multithreading issues: calling Julia from a non-Julia thread is not supported in ADCME. When TensorFlow kernel codes are executed concurrently, it is difficult to invoke the Julia functions. See issue.","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"In scientific and engineering applications, the operators provided by TensorFlow are not sufficient for high performance computing. In addition, constraining oneself to TensorFlow environment sacrifices the powerful scientific computing ecosystems provided by other languages such as Julia and Python. For example, one might want to code a finite volume method for a sophisticated fluid dynamics problem; it is hard to have the flexible syntax to achieve this goal, obtain performance boost from existing fast solvers such as AMG, and benefit from many other third-party packages within TensorFlow. This motivates us to find a way to \"plugin\" custom operators to TensorFlow.","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"We have already introduced how to incooperate C++ custom operators.  For many researchers, they usually prototype the solvers in a high level language such as MATLAB, Julia or Python. To enjoy the parallelism and automatic differentiation feature of TensorFlow, they need to port them into C/C++. However, this is also cumbersome sometimes, espeically the original solvers depend on many packages in the high-level language. ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"We solve this problem by incorporating Julia functions directly into TensorFlow. That is, for any Julia functions, we can immediately convert it to a TensorFlow operator. At runtime, when this operator is executed, the corresponding Julia function is executed. That implies we have the Julia speed. Most importantly, the function is perfectly compitable with the native Julia environment; third-party packages, global variables, nested functions, etc. all work smoothly. Since Julia has the ability to call other languages in a quite elegant and simple manner, such as C/C++, Python, R, Java, this means it is possible to incoporate packages/codes from any supported languages into TensorFlow ecosystem. We need to point out that in TensorFlow, tf.numpy_function can be used to convert a Python function to a TensorFlow operator. However, in the runtime, the speed for this operator falls back to Python (or numpy operation for related parts). This is a drawback. ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"The key for implementing the mechanism is embedding Julia in C++. Still we need to create a C++ dynamic library for TensorFlow. However, the library is only an interface for invoking Julia code. At runtime, jl_get_function is called to search for the related function in the main module. C++ arrays, which include all the relavant data, are passed to this function through jl_call. It requires routine convertion from C++ arrays to Julia array interfaces jl_array_t*. However, those bookkeeping tasks are programatic and possibly will be automated in the future. Afterwards,Julia returns the result to C++ and thereafter the data are passed to the next operator. ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"There are two caveats in the implementation. The first is that due to GIL of Python, we must take care of the thread lock while interfacing with Julia. This was done by putting a guard around th eJulia interface","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"PyGILState_STATE py_threadstate;\npy_threadstate = PyGILState_Ensure();\n// code here \nPyGILState_Release(py_threadstate);","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"The second is the memory mangement of Julia arrays. This was done by defining gabage collection markers explicitly","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"jl_value_t **args;\nJL_GC_PUSHARGS(args, 6); // args can now hold 2 `jl_value_t*` objects\nargs[0] = ...\nargs[1] = ...\n# do something\nJL_GC_POP();","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"This technique is remarkable and puts together one of the best langages in scientific computing and that in machine learning. The work that can be built on ADCME is enormous and significantly reduce the development time. ","category":"page"},{"location":"julia_customop/#Example","page":"Julia Custom Operators","title":"Example","text":"","category":"section"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Here we present a simple example. Suppose we want to compute the Jacobian of a two layer neural network fracpartial ypartial x","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"y = W_2tanh(W_1x+b_1)+b_2","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"where x b_1 b_2 yin mathbbR^10, W_1 W_2in mathbbR^100. In TensorFlow, this can be done by computing the gradients fracpartial y_ipartial x for each i. In Julia, we can use ForwardDiff to do it automatically. ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"function twolayer(J, x, w1, w2, b1, b2)\n    f = x -> begin\n        w1 = reshape(w1, 10, 10)\n        w2 = reshape(w2, 10, 10)\n        z = w2*tanh.(w1*x+b1)+b2\n    end\n    J[:] = ForwardDiff.jacobian(f, x)[:]\nend","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"To make a custom operator, we first generate a wrapper","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"using ADCME\nmkdir(\"TwoLayer\")\ncd(\"TwoLayer\")\ncustomop()","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"We modify custom_op.txt","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"TwoLayer\ndouble x(?)\ndouble w1(?)\ndouble b1(?)\ndouble w2(?)\ndouble b2(?)\ndouble y(?) -> output","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"and run ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"customop()","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Three files are generatedCMakeLists.txt, TwoLayer.cpp and gradtest.jl. Now create a new file TwoLayer.h","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"#include \"julia.h\"\n#include \"Python.h\"\n\nvoid forward(double *y, const double *x, const double *w1, const double *w2, const double *b1, const double *b2, int n){\n    PyGILState_STATE py_threadstate;\n    py_threadstate = PyGILState_Ensure();\n    jl_value_t* array_type = jl_apply_array_type((jl_value_t*)jl_float64_type, 1);\n    jl_value_t **args;\n    JL_GC_PUSHARGS(args, 6); // args can now hold 2 `jl_value_t*` objects\n    args[0] = (jl_value_t*)jl_ptr_to_array_1d(array_type, y, n*n, 0);\n    args[1] = (jl_value_t*)jl_ptr_to_array_1d(array_type, const_cast<double*>(x), n, 0);\n    args[2] = (jl_value_t*)jl_ptr_to_array_1d(array_type, const_cast<double*>(w1), n*n, 0);\n    args[3] = (jl_value_t*)jl_ptr_to_array_1d(array_type, const_cast<double*>(w2), n*n, 0);\n    args[4] = (jl_value_t*)jl_ptr_to_array_1d(array_type, const_cast<double*>(b1), n, 0);\n    args[5] = (jl_value_t*)jl_ptr_to_array_1d(array_type, const_cast<double*>(b2), n, 0);\n    auto fun = jl_get_function(jl_main_module, \"twolayer\");\n  \tif (fun==NULL) jl_errorf(\"Function not found in Main module.\");\n    else jl_call(fun, args, 6);\n    JL_GC_POP();\n    if (jl_exception_occurred())\n        printf(\"%s \\n\", jl_typeof_str(jl_exception_occurred()));\n    PyGILState_Release(py_threadstate);\n}","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Most of the codes have been explanined except jl_ptr_to_array_1d. This function generates a Julia array wrapper from C++ arrays. The last argument 0 indicates that Julia is not responsible for gabage collection. TwoLayer.cpp should also be modified according to https://github.com/kailaix/ADCME.jl/blob/master/examples/twolayer_jacobian/TwoLayer.cpp.","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Finally, we can test in gradtest.jl ","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"two_layer = load_op(\"build/libTwoLayer\", \"two_layer\")\n\n\nw1 = rand(100)\nw2 = rand(100)\nb1 = rand(10)\nb2 = rand(10)\nx = rand(10)\nJ = rand(100)\ntwolayer(J, x, w1, w2, b1, b2)\n\ny = two_layer(constant(x), constant(w1), constant(b1), constant(w2), constant(b2))\nsess = Session(); init(sess)\nJ0 = run(sess, y)\n@show norm(J-J0)","category":"page"},{"location":"julia_customop/#Embedded-in-Modules","page":"Julia Custom Operators","title":"Embedded in Modules","text":"","category":"section"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"If the custom operator is intended to be used in a precompiled module, we can load the dynamic library at initialization","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"global my_op \nfunction __init__()\n\tglobal my_op = load_op(\"$(@__DIR__)/path/to/libMyOp\", \"my_op\")\nend","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"The corresponding Julia function called by my_op must be exported in the module (such that it is in the Main module when invoked). One such example is given in MyModule","category":"page"},{"location":"julia_customop/#Quick-Reference-for-Implementing-C-Custom-Operators-in-ADCME","page":"Julia Custom Operators","title":"Quick Reference for Implementing C++ Custom Operators in ADCME","text":"","category":"section"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Set output shape","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"c->set_output(0, c->Vector(n));\nc->set_output(0, c->Matrix(m, n));\nc->set_output(0, c->Scalar());","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Names","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":".Input and .Ouput : names must be in lower case, no _, only letters.","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"TensorFlow Input/Output to TensorFlow Tensors","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"grad.vec<double>();\ngrad.scalar<double>();\ngrad.matrix<double>();\ngrad.flat<double>();","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Obtain flat arrays","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"grad.flat<double>().data()","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Scalars","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Allocate scalars using TensorShape()","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Allocate Shapes","category":"page"},{"location":"julia_customop/","page":"Julia Custom Operators","title":"Julia Custom Operators","text":"Although you can use -1 for shape reference, you must allocate exact shapes in Compute","category":"page"},{"location":"mpi/#Distributed-Scientific-Machine-Learning-using-MPI","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Many large-scale scientific computing involves parallel computing. Among many parallel computing models, the MPI  is one of the most popular models. In this section, we describe how ADCME can work with MPI for solving inverse modeling. Specifically, we describe how gradients can be back-propagated via MPI function calls.  ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"info: Info\nMessage Passing Interface (MPI) is an interface for parallel computing based on message passing models. In the message passing model, a master process assigns work to workers by passing them a message that describes the work. The message may be data or meta information (e.g., operations to perform). A consensus was reached around 1992 and the MPI standard was born. MPI is a definition of interface, and the implementations are left to hardware venders. ","category":"page"},{"location":"mpi/#MPI-Support-in-ADCME","page":"Distributed Scientific Machine Learning using MPI","title":"MPI Support in ADCME","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"The ADCME solution to distributed computing for scientific machine learning is to provide a set of \"data communication\" nodes in the computational graph. Each machine (MPI processor) runs an identical computational graph. The computational nodes are executed independently on each processor, and the data communication nodes need to synchronize among different processors. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"These data communication nodes are implemented using MPI APIs. They are not necessarily blocking operations, but because ADCME respects the data dependency of computation, they act like blocking operations and the child operators are executed only when data communication is finished. For example, in the following example,","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"b = mpi_op(a)\nc = custom_op(b)","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"even though mpi_op and custom_op can overlap, ADCME still sequentially execute these two operations. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"This blocking behavior simplifies the synchronization logic as well as the implementation of gradient back-propagation while harming little performance. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"ADCME provides a set of commonly used MPI operators. See MPI Operators. Basically, they are","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"mpi_init, mpi_finalize: Initialize and finalize MPI session. \nmpi_rank, mpi_size: Get the MPI rank and size.\nmpi_sum, mpi_bcast: Sum and broadcast tensors in different processors. \nmpi_send, mpi_recv: Send and receive operators. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"The above two set of operators support automatic differentiation. They were implemented with MPI adjoint methods, which have existed in academia for decades. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"This section shows how to configure MPI for distributed computing in ADCME. ","category":"page"},{"location":"mpi/#Limitations","page":"Distributed Scientific Machine Learning using MPI","title":"Limitations","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Despite that the provided mpi_* operations meet most needs,  some sophisticated data communication operations may not be easily expressed using these APIs. For example, when solving the Poisson's equation on a uniform grid, we may decompose the domain into many squares, and two adjacent squares exchange data in each iteration. A sequence of mpi_send, mpi_recv will likely cause deadlock. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Just like when it is difficult to use automatic differentiation to implement a forward computation and its gradient back-propagation, we resort to custom operators, it is the same case for MPI. We can design a specialized custom operator for data communication. To resolve the deadlock problem, we found the asynchronous sending, followed by asynchronous receiving, and then followed by waiting, a very general and convenient way to implement custom operators. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/#Implementing-Custom-Operators-using-MPI","page":"Distributed Scientific Machine Learning using MPI","title":"Implementing Custom Operators using MPI","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"We can also make custom operators with MPI. Let us consider computing","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"f(theta) = sum_i=1^n f_i(theta)","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Each f_i is a very expensive function so it makes sense to use MPI to split the jobs on different processors. To simplify the problem, we consider ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"f(theta) = f_1(theta) + f_2(theta) + f_3(theta) + f_4(theta)","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"where f_i(theta) = theta^i-1. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Using the ADCME MPI API, we have the following code (test_simple.jl)","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"using ADCME\n\nmpi_init()\nθ = placeholder(ones(1))\nfθ = mpi_bcast(θ)\nl = fθ^mpi_rank()\nL = sum(mpi_sum(l))\ng = gradients(L, θ)\nsess = Session(); init(sess)\nL_ = run(sess, L, θ=>ones(1)*2.0)\ng_ = run(sess, g, θ=>ones(1)*2.0)\n\nif mpi_rank()==0\n    @info  L_, g_ \nend\nmpi_finalize()","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"We run the program with 4 processors","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"mpirun -n 4 julia test_simple.jl","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"We have the results:","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"[ Info: (15.0, [17.0])","category":"page"},{"location":"mpi/#Hybrid-Programming","page":"Distributed Scientific Machine Learning using MPI","title":"Hybrid Programming","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Each MPI processor can communicate data between processes, which do not share memory. Within each process, ADCME also allows for multi-threaded parallelism with a shared-memory model. For example, we can use OpenMP to accelerate matrix vector production. We can also use a threadpool per process to manage more complex and dynamic parallel tasks. However, the hybrid model brings challenges to communicate data using MPI. When we post MPI calls from different threads within the same process, we need to prevent data races and match the corresponding broadcast and collective operators. For example, without any guarantee on the ordering of concurrent MPI calls, we might incorrectly matched a send operator with a gather operator. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"In ADCME, we adopt the dependency injection technique: we explicitly serialize the MPI calls by adding ghost dependencies. For example, in the following computational graph, originally, Operator 2 and Operator 3 are independent. In a concurrent computing environment, Rank 0 may execute Operator 2 first and then Operator 3, while Rank 1 executes Operator 3 first and then Operator 2. Then there is a mismatch of the MPI call (race condition): Operator 2 in Rank 0 coacts with Operator 3 in Rank 1, and Operator 3 in Rank 0 coacts with Operator 2 in Rank 1. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"To resolve the data race issue, we can explicitly make Operator 3 depend on Operator 2. In this way, we can ensure that the MPI calls Operator 1, 2, and 3 are executed in order. Note this technique sacrifices some concurrency (Operator 2 and Operator 3 cannot be executed concurrently), but the concurrency of most non-MPI operators is still preserved. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/#Optimization","page":"Distributed Scientific Machine Learning using MPI","title":"Optimization","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"For solving inverse problems using distributed computing, an MPI-capable optimizer is required. The ADCME solution to distributed optimization is that the master machine holds, distributes and updates the optimizable variables. The gradients are calculated in the same device where the corresponding forward computation is done. Therefore, for a given serial optimizer, we can refactor it to a distributed one by letting worker nodes wait for instructions from the master node to compute either the objective function or the gradient.","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"This idea is implemented in the ADOPT.jl package, a customized version of Optim.jl. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"In the following, we try to solve ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"1+theta +theta^2+theta^3 = 2","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"using MPI-enabled LBFGS optimizer. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"using ADCME\nusing ADOPT\nmpi_init()\nθ = placeholder(ones(1))\nfθ = mpi_bcast(θ)\nl = fθ^mpi_rank()\nL = (sum(mpi_sum(l)) - 2.0)^2\nsess = Session(); init(sess)\n\nf = x->run(sess, L, θ=>x)\ng! = (G, x)->(G[:] = run(sess, g, θ=>x))\n\noptions = Options()\nif mpi_rank()==0\n    options.show_trace = true \nend\nmpi_optimize(f, g!, ones(1), ADOPT.LBFGS(), options)\nif mpi_rank()==0\n    @info  result.minimizer, result.minimum\nend\n\nmpi_finalize()","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"The expected output is ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Iter     Function value   Gradient norm\n     0     4.000000e+00     2.400000e+01\n * time: 0.00012421607971191406\n     1     6.660012e-01     7.040518e+00\n * time: 1.128843069076538\n     2     7.050686e-02     1.322515e+00\n * time: 1.210536003112793\n     3     2.254820e-03     2.744374e-01\n * time: 1.2910940647125244\n     4     4.319834e-07     3.908046e-03\n * time: 1.3442070484161377\n     5     2.894433e-16     1.011994e-07\n * time: 1.3975300788879395\n     6     0.000000e+00     0.000000e+00\n * time: 1.4507441520690918\n[ Info: ([0.5436890126920764], 0.0)","category":"page"},{"location":"mpi/#Reduce-Sum","page":"Distributed Scientific Machine Learning using MPI","title":"Reduce Sum","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"using ADCME\n\nmpi_init()\nr = mpi_rank()\na = constant(Float64.(Array(1:10) * r))\nb = mpi_sum(a)\n\nL = sum(b)\ng = gradients(L, a)\nsess = Session(); init(sess)\nv, G = run(sess, [b,g])\nmpi_finalize()","category":"page"},{"location":"mpi/#Broadcast","page":"Distributed Scientific Machine Learning using MPI","title":"Broadcast","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"using ADCME\n\nmpi_init()\nr = mpi_rank()\na = constant(ones(10) * r)\nb = mpi_bcast(a, 3)\nL = sum(b^2)\nL = mpi_sum(L)\ng = gradients(L, a)\n\nsess = Session(); init(sess)\nv, G = run(sess, [b, G])\nmpi_finalize()","category":"page"},{"location":"mpi/#Send-and-Receive","page":"Distributed Scientific Machine Learning using MPI","title":"Send and Receive","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"# mpiexec.exe -n 4 julia .\\mpisum.jl\nusing ADCME\n\nmpi_init()\nr = mpi_rank()\na = constant(ones(10) * r)\na = mpi_sendrecv(a, 0, 2)\n\nL = sum(a^2)\ng = gradients(L, a)\n\nsess = Session(); init(sess)\nv, G = run(sess, [a,g])\nmpi_finalize()","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"mpi_sendrecv is a lightweight wrapper for mpi_send followed by mpi_recv. Equivalently, we have","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"if r==2\n    global a\n    a = mpi_send(a, 0)\nend\nif r==0\n    global a\n    a = mpi_recv(a,2)\nend","category":"page"},{"location":"mpi/#Solving-the-Heat-Equation","page":"Distributed Scientific Machine Learning using MPI","title":"Solving the Heat Equation","text":"","category":"section"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"In this section, we consider solving the Poisson equation ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"fracpartial u(xy)partial t =kappa(xy) Delta u(xy) quad (xy) in 01^2","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"We discretize the above PDE with an explicit finite difference scheme","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"fracu_ij^n+1 - u^n_ijDelta t = kappa_ij fracu_i+1j^n + u_ij+1^n + u_ij-1^n + u_i-1j^n - 4u_ij^nh^2 tag1","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"To mitigate the computational and memory requirement, we use MPI APIs to implement a domain decomposition solver for the heat equation. The mesh is divided into Ntimes M rectangle patches. We implemented two operation:","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"heat_op, which updates u_ij^n+1 using Equation 1 for a specific patch, with state variables u_ij^n in the current rectangle patch and on the boundary (from adjacent patches). \ndata_exchange, which is a data communication operator that sends the boundary data to adjacent patches and receives boundary data from other patches. ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"(Image: )","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"Then the time marching scheme can be implemented with the following code:","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"function heat_update_u(u, kv, f)\n    r = mpi_rank()\n    I = div(r, M)\n    J = r%M\n\n    up_ = constant(zeros(m))\n    down_ = constant(zeros(m))\n    left_ = constant(zeros(n))\n    right_ = constant(zeros(n))\n\n\n    up = constant(zeros(m))\n    down = constant(zeros(m))\n    left = constant(zeros(n))\n    right = constant(zeros(n))\n\n    (I>0) && (up = u[1,:])\n    (I<N-1) && (down = u[end,:])\n    (J>0) && (left = u[:,1])\n    (J<M-1) && (right = u[:,end])\n\n    left_, right_, up_, down_ = data_exchange(left, right, up, down)\n\n    u = heat(u, kv, up_, down_, left_, right_, f, h, Δt)\nend","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"An MPI-capable heat equation time integrator can be implemented with ","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"function heat_solver(u0, kv, f, NT=10)\n    f = constant(f)\n    function condition(i, u_arr)\n        i<=NT\n    end\n    function body(i, u_arr)\n        u = read(u_arr, i)\n        u_new = heat_update_u(u, kv, f[i])\n        # op = tf.print(r, i)\n        # u_new = bind(u_new, op)\n        i+1, write(u_arr, i+1, u_new)\n    end\n    i = constant(1, dtype =Int32)\n    u_arr = TensorArray(NT+1)\n    u_arr = write(u_arr, 1, u0)\n    _, u = while_loop(condition, body, [i, u_arr])\n    reshape(stack(u), (NT+1, n, m))\nend","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"For example, we can implement the heat solver with diffusivity coefficient K_0 and initial condition u_0 with the following code:","category":"page"},{"location":"mpi/","page":"Distributed Scientific Machine Learning using MPI","title":"Distributed Scientific Machine Learning using MPI","text":"K = placeholder(K0)\na_ = mpi_bcast(K)\nsol = heat_solver(u0, K_, F, NT)","category":"page"},{"location":"global/#Shared-Memory-Across-Kernels","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"","category":"section"},{"location":"global/#Introuction","page":"Shared Memory Across Kernels","title":"Introuction","text":"","category":"section"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"In many use cases, we want to share data across multiple kernels. For example, if we want to design several custom operators for finite element analysis (e.g., one for assembling, one for solving the linear system and one for performing Newton's iteration), we might want to share the geometric data such as nodes and element connectivity matrices. This can be done by the share memory mechanism of dynamical shared libraries. ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"The technique introduced here is very useful. For example, in the ADCME standard library, factorize is implemented using this technique. factorize factorizes a nonsingular matrix and store the factorized form in the shared library so you can amortize the computational cost for factorization by efficiently solving many linear systems. ","category":"page"},{"location":"global/#Solutions-for-*nix","page":"Shared Memory Across Kernels","title":"Solutions for *nix","text":"","category":"section"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Dynamical shared libraries have the following property: in Unix-like environments, shared libries export all extern global variables. That is, multiple shared libraries can change the same variable as long as the variable is marked as extern. However, extern variable itself is not a definition but only a declaration. The variable should be defined in one and only one shared library. ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Therefore, when we design custom operators and want to have global variables that will be reused by multiple custom kernels (each constitutes a separate dynamical shared library), we can link each of them to a \"data storage\" shared library. The \"data storage\" shared library should contain the definition of the global variable to be shared among those kernels. ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"(Image: )","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"As an example, consider we want to share Float64 vectors (with String keys). The data structure of the storage is given in Saver.h","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"#include <map>\n#include <string>\n#include <vector>\n\nstruct DataStore\n{        \n    std::map<std::string, std::vector<double>> vdata;\n};\nextern DataStore ds;","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Note we include extern DataStore ds; for convenience: we can include Saver.h for our custom operator kernels so that we have access to ds. ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Additionally, in Saver.cpp, we define ds","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"#include \"Saver.h\"\nDataStore ds;","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Now we can compile a dynamical shared library Saver.so (or Saver.dylib) with Saver.h and Saver.cpp. For all the other kernel implementation, we can include the header file Saver.h and link to Saver.so (or Saver.dylib) during compilation. ","category":"page"},{"location":"global/#Code-Examples","page":"Shared Memory Across Kernels","title":"Code Examples","text":"","category":"section"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"We show an example for storing, querying and deleting 10times 1 Float64 vectors with this technique. The main files are (the codes can be accessed here)","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"SaverTensor.cpp","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"#include \"Saver.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/default/logging.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include<cmath>\n#include<string> \n#include<eigen3/Eigen/Core>\nusing std::string;\nusing namespace tensorflow;\n\nREGISTER_OP(\"SaveTensor\")\n\n.Input(\"handle : string\")\n  .Input(\"val : double\")\n  .Output(\"out : string\")\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    \n        shape_inference::ShapeHandle handle_shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 0, &handle_shape));\n        shape_inference::ShapeHandle val_shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &val_shape));\n\n        c->set_output(0, c->Scalar());\n    return Status::OK();\n  });\n\nclass SaveTensorOp : public OpKernel {\nprivate:\n  \npublic:\n  explicit SaveTensorOp(OpKernelConstruction* context) : OpKernel(context) {\n\n  }\n\n  void Compute(OpKernelContext* context) override {    \n    DCHECK_EQ(2, context->num_inputs());\n    \n    \n    const Tensor& handle = context->input(0);\n    const Tensor& val = context->input(1);\n    \n    \n    const TensorShape& val_shape = val.shape();\n    \n    \n    DCHECK_EQ(val_shape.dims(), 1);\n\n    // extra check\n        \n    // create output shape\n    \n    TensorShape out_shape({});\n            \n    // create output tensor\n    \n    Tensor* out = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &out));\n    \n    // get the corresponding Eigen tensors for data access\n    auto handle_tensor = handle.flat<string>().data();\n    auto val_tensor = val.flat<double>().data();\n    auto out_tensor = out->flat<string>().data();   \n\n    // implement your forward function here \n    // context->tensors_[string(*handle_tensor)] = val;\n    ds.vdata[string(*handle_tensor)] = std::vector<double>(val_tensor, val_tensor+10);\n    *out_tensor = *handle_tensor;    \n    printf(\"[Add] %s to collections.\\n\", string(*handle_tensor).c_str());\n    printf(\"========Existing Keys========\\n\");\n    for(auto & kv: ds.vdata){\n      printf(\"Key %s\\n\", kv.first.c_str());\n    }\n    printf(\"\\n\");\n  }\n};\nREGISTER_KERNEL_BUILDER(Name(\"SaveTensor\").Device(DEVICE_CPU), SaveTensorOp);","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"GetTensor.cpp","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"#include \"Saver.h\"\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/default/logging.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include<cmath>\n#include<string> \n#include<map>\n#include<eigen3/Eigen/Core>\nusing std::string;\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"GetTensor\")\n.Input(\"handle : string\")\n  .Output(\"val : double\")\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    \n        shape_inference::ShapeHandle handle_shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 0, &handle_shape));\n\n        c->set_output(0, c->Vector(-1));\n    return Status::OK();\n  });\n\nclass GetTensorOp : public OpKernel {\nprivate:\n  \npublic:\n  explicit GetTensorOp(OpKernelConstruction* context) : OpKernel(context) {\n\n  }\n\n  void Compute(OpKernelContext* context) override {    \n    DCHECK_EQ(1, context->num_inputs());\n    \n    const Tensor& handle = context->input(0);    \n    auto handle_tensor = handle.flat<string>().data();\n\n    auto val_shape = TensorShape({10});   \n    Tensor *val = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, val_shape, &val));\n\n    if (!ds.vdata.count(string(*handle_tensor))){\n        printf(\"[Get] Key %s does not exist.\\n\", string(*handle_tensor).c_str());\n    }\n    else{\n      printf(\"[Get] Key %s exists.\\n\", string(*handle_tensor).c_str());\n      auto v = ds.vdata[string(*handle_tensor)];\n      for(int i=0;i<10;i++){\n        val->flat<double>().data()[i] = v[i];\n      }\n    }\n    printf(\"========Existing Keys========\\n\");\n    for(auto & kv: ds.vdata){\n      printf(\"Key %s\\n\", kv.first.c_str());\n    }\n    printf(\"\\n\");\n    \n\n  }\n};\nREGISTER_KERNEL_BUILDER(Name(\"GetTensor\").Device(DEVICE_CPU), GetTensorOp);","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"DeleteTensor.cpp","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"#include \"Saver.h\"\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/platform/default/logging.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include<cmath>\n#include<string> \n#include<map>\n#include<eigen3/Eigen/Core>\nusing std::string;\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"DeleteTensor\")\n.Input(\"handle : string\")\n  .Output(\"val : bool\")\n.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\n    \n        shape_inference::ShapeHandle handle_shape;\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 0, &handle_shape));\n\n        c->set_output(0, c->Scalar());\n    return Status::OK();\n  });\n\nclass DeleteTensorOp : public OpKernel {\nprivate:\n  \npublic:\n  explicit DeleteTensorOp(OpKernelConstruction* context) : OpKernel(context) {\n\n  }\n\n  void Compute(OpKernelContext* context) override {    \n    DCHECK_EQ(1, context->num_inputs());\n    \n    const Tensor& handle = context->input(0);    \n    auto handle_tensor = handle.flat<string>().data();\n\n    auto val_shape = TensorShape({});   \n    Tensor *val = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, val_shape, &val));\n\n    if (ds.vdata.count(string(*handle_tensor))){\n      ds.vdata.erase(string(*handle_tensor));\n      printf(\"[Delete] Erase key %s.\\n\", string(*handle_tensor).c_str());\n      *(val->flat<bool>().data()) = true;\n    }\n    else{\n      printf(\"[Delete] Key %s does not exist.\\n\", string(*handle_tensor).c_str());\n      *(val->flat<bool>().data()) = false;\n    }\n    printf(\"========Existing Keys========\\n\");\n    for(auto & kv: ds.vdata){\n      printf(\"Key %s\\n\", kv.first.c_str());\n    }\n    printf(\"\\n\");\n  }\n};\nREGISTER_KERNEL_BUILDER(Name(\"DeleteTensor\").Device(DEVICE_CPU), DeleteTensorOp);","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Here is part of the CMakeLists.txt used for compilation, where we link XXTensor.cpp with Saver","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"cmake_minimum_required(VERSION 3.5)\nproject(TF_CUSTOM_OP)\nset (CMAKE_CXX_STANDARD 11)\n\nmessage(\"JULIA=${JULIA}\")\nexecute_process(COMMAND ${JULIA} -e \"import ADCME; print(ADCME.__STR__)\" OUTPUT_VARIABLE JL_OUT)\nlist(GET JL_OUT 0 BINDIR)\nlist(GET JL_OUT 1 LIBDIR)\nlist(GET JL_OUT 2 TF_INC)\nlist(GET JL_OUT 3 TF_ABI)\nlist(GET JL_OUT 4 PREFIXDIR)\nlist(GET JL_OUT 5 CC)\nlist(GET JL_OUT 6 CXX)\nlist(GET JL_OUT 7 CMAKE)\nlist(GET JL_OUT 8 MAKE)\nlist(GET JL_OUT 9 GIT)\nlist(GET JL_OUT 10 PYTHON)\nlist(GET JL_OUT 11 TF_LIB_FILE)\n\n\nmessage(\"BINDIR=${BINDIR}\")\nmessage(\"LIBDIR=${LIBDIR}\")\nmessage(\"TF_INC=${TF_INC}\")\nmessage(\"TF_ABI=${TF_ABI}\")\nmessage(\"PREFIXDIR=${PREFIXDIR}\")\nmessage(\"Python path=${PYTHON}\")\nmessage(\"TF_LIB_FILE=${TF_LIB_FILE}\")\n\n\nif (CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 5.0 OR CMAKE_CXX_COMPILER_VERSION VERSION_EQUAL 5.0)\n  set(CMAKE_CXX_FLAGS \"-D_GLIBCXX_USE_CXX11_ABI=${TF_ABI} ${CMAKE_CXX_FLAGS}\")\nendif()\n\nset(CMAKE_BUILD_TYPE Release)\nif(MSVC)\nset(CMAKE_CXX_FLAGS_RELEASE \"-DNDEBUG\")\nelse()\nset(CMAKE_CXX_FLAGS_RELEASE \"-O3 -DNDEBUG\")\nendif()\ninclude_directories(${TF_INC} ${PREFIXDIR})\nlink_directories(${TF_LIB})\n\n\nif(MSVC)\n  if(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n    string(REGEX REPLACE \"/W[0-4]\" \"/W0\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n  else()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /W0\")\n  endif()\n  add_library(Saver SHARED Saver.cpp SaveTensor.cpp GetTensor.cpp DeleteTensor.cpp)\n  set_property(TARGET Saver PROPERTY POSITION_INDEPENDENT_CODE ON)\n  target_link_libraries(Saver ${TF_LIB_FILE})\n  add_definitions(-DNOMINMAX)\nelse()\n  add_library(Saver SHARED Saver.cpp)\n  set_property(TARGET Saver PROPERTY POSITION_INDEPENDENT_CODE ON)\n\n  add_library(SaveTensor SHARED SaveTensor.cpp)\n  set_property(TARGET SaveTensor PROPERTY POSITION_INDEPENDENT_CODE ON)\n  target_link_libraries(SaveTensor ${TF_LIB_FILE} Saver)\n\n  add_library(GetTensor SHARED GetTensor.cpp)\n  set_property(TARGET GetTensor PROPERTY POSITION_INDEPENDENT_CODE ON)\n  target_link_libraries(GetTensor ${TF_LIB_FILE} Saver)\n\n  add_library(DeleteTensor SHARED DeleteTensor.cpp)\n  set_property(TARGET DeleteTensor PROPERTY POSITION_INDEPENDENT_CODE ON)\n  target_link_libraries(DeleteTensor ${TF_LIB_FILE} Saver)\nendif()","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Here we have separate procedure for Windows and *nix systems. ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"We can test our implementation with ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"using ADCME\n\nif Sys.iswindows()\n    global save_tensor = load_op_and_grad(\"./build/Release/libSaver\",\"save_tensor\")\n    global get_tensor = load_op_and_grad(\"./build/Release/libSaver\",\"get_tensor\")\n    global delete_tensor = load_op_and_grad(\"./build/Release/libSaver\",\"delete_tensor\")\nelse \n    global save_tensor = load_op_and_grad(\"./build/libSaveTensor\",\"save_tensor\")\n    global get_tensor = load_op_and_grad(\"./build/libGetTensor\",\"get_tensor\")\n    global delete_tensor = load_op_and_grad(\"./build/libDeleteTensor\",\"delete_tensor\")\nend \n\nval = constant(rand(10))\nt1 = constant(\"tensor1\")\nt2 = constant(\"tensor2\")\nt3 = constant(\"tensor3\")\nu1 = save_tensor(t1,val)\nu2 = save_tensor(t2,2*val)\nu3 = save_tensor(t3,3*val)\n\nz1 = get_tensor(t1);\nz2 = get_tensor(t2);\nz3 = get_tensor(t3);\n\nd1 = delete_tensor(t1);\nd2 = delete_tensor(t2);\nd3 = delete_tensor(t3);\nsess = Session(); \nrun(sess, [u1,u2,u3]) # add all the keys\n\n# get the keys one by one\nrun(sess, z1)\nrun(sess, z2)\nrun(sess, z3)\n\n# delete 2nd key\nrun(sess, d2)","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"The expected output is ","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"[Add] tensor3 to collections.\n========Existing Keys========\nKey tensor3\n\n[Add] tensor2 to collections.\n========Existing Keys========\nKey tensor2\nKey tensor3\n\n[Add] tensor1 to collections.\n========Existing Keys========\nKey tensor1\nKey tensor2\nKey tensor3\n\n[Get] Key tensor1 exists.\n========Existing Keys========\nKey tensor1\nKey tensor2\nKey tensor3\n\n[Get] Key tensor2 exists.\n========Existing Keys========\nKey tensor1\nKey tensor2\nKey tensor3\n\n[Get] Key tensor3 exists.\n========Existing Keys========\nKey tensor1\nKey tensor2\nKey tensor3\n\n[Delete] Erase key tensor2.\n========Existing Keys========\nKey tensor1\nKey tensor3","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"For example, in this article we use the technique introduced here to design a custom operator for direct methods for sparse matrix solutions. ","category":"page"},{"location":"global/#Solutions-for-Windows","page":"Shared Memory Across Kernels","title":"Solutions for Windows","text":"","category":"section"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"Windows systems have special rules for creating and linking dynamic libraries. Basically you need to export symbols in the dynamic libraries so that they are visiable to application programs. To avoid many troubles that you may encounter getting the macros and configurations correct, you can instead compile all the source into a single dynamic library. The model is as follows","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"(Image: )","category":"page"},{"location":"global/","page":"Shared Memory Across Kernels","title":"Shared Memory Across Kernels","text":"The source codes and CMakeLists.txt in the above section can be reused without any modification.","category":"page"},{"location":"tu_fem/#Numerical-Scheme-in-ADCME:-Finite-Element-Example","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"","category":"section"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The purpose of this tutorial is to show how to work with the finite element method (FEM) in ADCME. The tutorial is divided into two part:","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"In the first part, we implement a finite element code for a time independent Poisson's equation in 1D and 2D. We present two styles of implementing a finite element code: using vectorized expression and low level C++ implementation using custom operators. The first approach is elegant and only uses ADCME syntax. The second approach is more flexible and allows for efficient optimization. However, the limitation is that you are responsible to calculate the sensititity of your finite element sensitivity matrix. ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The second part is about solving a time dependent problem. Here we use finite element methods for the spatial discretization and a backward Euler for time integration. The custom operator approach is used. In this example, you will understand how while_loop can help avoid creating a computational graph for each time step. This is important because for many applications the number of time steps can be enormous.","category":"page"},{"location":"tu_fem/#Poisson's-Problem:-Vectorized-Implementation","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Poisson's Problem: Vectorized Implementation","text":"","category":"section"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"Let us consider the following Poisson's equation in (01):","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"(kappa(x) u(x)) = f(x)qquad u(0) = u(1) = 0tag1","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"To make the problem more interesting, we make kappa parameterized by a, which is constructed using constant so we can keep track of the dependencies of intermediate values on a. ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"kappa(x) = frac11+x^2  u(x) = x(1-x)","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"and f(x) can be calculated according to Equation 1. We use the finite element method with a linear basis to solve Equation 1: find uin H_0^1((01)), such that ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"int_0^1 kappa(x) u(x) v(x) dx = int_0^1 f(x) v(x) dx quad forall vin H_0^1((01))","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"We consider a uniform grid with n intervals of equal lengths. The common approach for assembling the finite element matrix A is to iterate over elements and compute the contribution  int_E kappa(x) phi_i(x)phi_j(x) dx and add it to the entry A_ij; here phi_i(x) is the basis function associated with node i. ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The integration is usually done with numerical integration. Here we consider the Gauss quadrature. Consider the i-th element, the local stiffness matrix is ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"L_i = sum_k=1^G hbeginbmatrix fracw_kkappa(x_k)h^2  -fracw_kkappa(x_k)h^2  -fracw_kkappa(x_k)h^2  fracw_kkappa(x_k)h^2 endbmatrix = beginbmatrix 1  -1 -1  1 endbmatrixfracsum_k=1^G w_kkappa(x_k)h \n\nHere (xi_k w_k) are Gauss quadrature points and weights on 01 and \n\nx_k = (1-xi_k) (i-1)h + xi_k ih","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The corresponding DOF (degrees of freedom) matrix, i.e., the mapping of local index to global index, is ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"D_i = beginbmatrix(ii)  (ii+1)  (i+1 i)  (i+1 i+1)endbmatrix","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"xk = zeros(n, length(ξ))\nfor i = 1:length(ξ)\n    xk[:,i] = x[1:end-1] * (1-ξ[i]) + x[2:end] * ξ[i]\nend\nxk = constant(xk) # convert xk from Julia array to tensor\ns = kappa(xk) * w / h\ni0 = Array(1:n)\ni1 = Array(2:n+1)\nII = [i0;i0;i1;i1]\nJJ = [i0;i1;i0;i1]\nVV = [s;-s;-s;s]\nA = SparseTensor(II, JJ, VV, n+1, n+1)","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The right hand side int_Omega f(x) v(x) dx can be computed in a similar fashion: the local contribution l_i and DOF d_i are ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"l_i = sum_k=1^G hbeginbmatrix\n    w_k f(x_k) (1-xi_k) \n    w_k f(x_k) xi_k \nendbmatrixqquad d_i = beginbmatrix\n    i \n    i+1\nendbmatrix","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"This is done with ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"rhs = zeros(n+1)\ns = [f(xk) * (w .* (1 .-ξ)); f(xk) * (w .* ξ)] * h\nrhs = -vector([i0;i1], s, n+1)","category":"page"},{"location":"tu_fem/#Full-Code-Listing","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Full Code Listing","text":"","category":"section"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"using ADCME\n\nfunction kappa(x)\n    return 1/(1+a*x^2)\nend\n\nfunction f(x)\n    return -2*a*x .* (1 - 2*x) ./(a*x^2 + 1)^2 - 2/(a*x^2 + 1)\nend\n\nfunction uexact(x)\n    return x*(1-x)\nend\n\nn = 100\nh = 1/n \nx = Array(LinRange(0, 1, n+1))\na = constant(1.0)\nξ = [0.1127016653792583; 0.5;0.8872983346207417]\nw = [5/18; 4/9; 5/18]\n\nxk = zeros(n, length(ξ))\nfor i = 1:length(ξ)\n    xk[:,i] = x[1:end-1] * (1-ξ[i]) + x[2:end] * ξ[i]\nend\n\nxk = constant(xk) # convert xk from Julia array to tensor\n\n# Assemble left hand side \ns = kappa(xk) * w / h\ni0 = Array(1:n)\ni1 = Array(2:n+1)\nII = [i0;i0;i1;i1]\nJJ = [i0;i1;i0;i1]\nVV = [s;-s;-s;s]\nA = SparseTensor(II, JJ, VV, n+1, n+1)\n\n\n# Assemble right hand side \nrhs = zeros(n+1)\ns = [f(xk) * (w .* (1 .-ξ)); f(xk) * (w .* ξ)] * h\nrhs = -vector([i0;i1], s, n+1)\n\n# Impose boundary condition using static condensation \nA = A[2:end-1, 2:end-1]\nrhs = rhs[2:end-1]\n\n# Solve \nsol = A\\rhs\nsess = Session(); init(sess)\n\nsolution = run(sess, sol)","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The result for a=1 is shown below","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"<center><img src=\"https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/poisson.png?raw=true\" width=\"50%\"></center>","category":"page"},{"location":"tu_fem/#Poisson's-Problem:-Custom-Operators","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Poisson's Problem: Custom Operators","text":"","category":"section"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"Vectorized implementation is great and elegant when we can easily figure out the mathematical formula. However, for more complicated problems and modular development, it is awkward to reason about vectorization each time. A preferred approach is to loop over elements and focus on calculating local contribution. However, a direct for loop will create a large computational graph and will not be able to take advantage of efficient implementation (e.g., parallel computing). ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"In what follows, we consider another approach: custom operator. To motivate our method, we consider a 2D Poisson's equation in a domain Omega","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"nabla cdot (kappa(x) nabla u) = f(x)qquad u(x) = 0 xin partialOmega","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The weak formulation is given by ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"int_Omega kappa(x) nabla u cdot nabla v dx = - int_Omega f(x) v(x) dxquad forall v in H_0^1(Omega)","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"The strategy is to implement two custom operators, one for computing the stiffness matrix, and the other for computing the right hand side. We suggest readers to use our AdFem library instead of their own. the AdFem library is built on ADCME and contains a rich set of custom operators that allow users to implement FEM fairly easily. ","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"using AdFem \nusing PyPlot \n\nmmesh = Mesh(50, 50, 1/50)\n\nfunction kappa(x, y)\n    return 1/(1+a*(x^2+y^2))\nend\n\nfunction ffun(x, y)\n    return -2*x*(1 - x)/(x^2 + y^2 + 1) - 2*x*(-x*y*(1 - y) + y*(1 - x)*(1 - y))/(x^2 + y^2 + 1)^2 - 2*y*(1 - y)/   (x^2 + y^2 + 1) - 2*y*(-x*y*(1 - x) + x*(1 - x)*(1 - y))/(x^2 + y^2 + 1)^2\nend\n\na = constant(1.0)\nκ = eval_f_on_gauss_pts(kappa, mmesh, tensor_input = true)\nfv = eval_f_on_gauss_pts(ffun, mmesh, tensor_input = true)\nA = compute_fem_laplace_matrix1(κ, mmesh)\nrhs = -compute_fem_source_term1(fv, mmesh)\n\nbd = bcnode(mmesh)\nA, rhs = impose_Dirichlet_boundary_conditions(A, rhs, bd, zeros(length(bd)))\nsol = A\\rhs \n\nsess = Session(); init(sess)\nU = run(sess, sol)\n\nclose(\"all\")\nfigure(figsize = (15, 5))\nsubplot(131)\nvisualize_scalar_on_fem_points(U, mmesh)\nsubplot(132)\nxy = fem_nodes(mmesh)\nx, y = xy[:,1], xy[:,2]\nvisualize_scalar_on_fem_points((@. x*(1-x)*y*(1-y)), mmesh)\nsubplot(133)\nvisualize_scalar_on_fem_points(abs.(U - (@. x*(1-x)*y*(1-y))), mmesh)\nsavefig(\"poisson2d.png\")","category":"page"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"<center><img src=\"https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/poisson2d.png?raw=true\" width=\"50%\"></center>","category":"page"},{"location":"tu_fem/#Summary","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Summary","text":"","category":"section"},{"location":"tu_fem/","page":"Numerical Scheme in ADCME: Finite Element Example","title":"Numerical Scheme in ADCME: Finite Element Example","text":"Finite element analysis is a powerful tool in numerical PDEs. However, it is more conceptually sophisticated than the finite difference method and requires more implementation efforts. The important lesson we learned from this tutorial is how to separate the computation into pure Julia and ADCME C++ kernels, and how complex numerical schemes can be implemented in ADCME. ","category":"page"},{"location":"apps_adseismic/#General-Seismic-Inversion-using-Automatic-Differentiation","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"","category":"section"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"","category":"page"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"Weiqiang Zhu (co-first author), Kailai Xu (co-first author), Eric Darve, and Gregory C. Beroza","category":"page"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"Project Website","category":"page"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"","category":"page"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"Imaging Earth structure or seismic sources from seismic data involves minimizing a target misfit function, and is commonly solved through gradient-based optimization. The adjoint-state method has been developed to compute the gradient efficiently; however, its implementation can be time-consuming and difficult. We develop a general seismic inversion framework to calculate gradients using reverse-mode automatic differentiation. The central idea is that adjoint-state methods and reverse-mode automatic differentiation are mathematically equivalent. The mapping between numerical PDE simulation and deep learning allows us to build a seismic inverse modeling library, ADSeismic, based on deep learning frameworks, which supports high performance reverse-mode automatic differentiation on CPUs and GPUs. We demonstrate the performance of ADSeismic on inverse problems related to velocity model estimation, rupture imaging, earthquake location, and source time function retrieval. ADSeismic has the potential to solve a wide variety of inverse modeling applications within a unified framework.","category":"page"},{"location":"apps_adseismic/","page":"General Seismic Inversion using Automatic Differentiation","title":"General Seismic Inversion using Automatic Differentiation","text":"Connection Between the Adjoint-State Method and Automatic Differentiation Remarkable Multi-GPU Acceleration Earthquake Location and Source-Time Function Inversion\n(Image: compare-NN-PDE) (Image: image-20200313110921108) (Image: image-20200313111045121)","category":"page"},{"location":"apps_ad/#Intelligent-Automatic-Differentiation","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"","category":"section"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"Kailai Xu, Dongzhuo Li, Eric Darve, and Jerry M. Harris. \"Learning Hidden Dynamics using Intelligent Automatic Differentiation\"","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"Dongzhuo Li, Kailai Xu, Jerry M. Harris, and Eric Darve. \"Time-lapse Full Waveform Inversion for Subsurface Flow Problems with Intelligent Automatic Differentiation\"","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"Project Website","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"We treat physical simulations as a chain of multiple differentiable operators, such as discrete Laplacian evaluation, a Poisson solver and a single implicit time stepping for nonlinear PDEs. They are like building blocks that can be assembled to make simulation tools for new physical models.","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"Those operators are differentiable and integrated in a computational graph so that the gradients can be computed automatically and efficiently via analyzing the dependency in the graph. Independent operators are parallelized executed. With the gradients we can perform gradient-based PDE-constrained optimization for inverse problems.","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"(Image: )","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"This view of numerical simulation enables us to develope very sophisticated tools for inverse modeling: we decouple the individual operators and implement a forward/backward for each of them; they are consolidated using ADCME to create a computational graph. The computational dependency is then parsed and gradients are automatically computed based on the dependency. For example, in this work, we coupled multiphysics and obtain the gradients of the objective function with respect to the hidden dynamics parameters (i.e., permeability). This can be quite time-consuming and error-prone if we are going to derive the gradients by hand, implement and debug. With ADCME, we \"chain\" all the operators and the gradients are obtained automatically. ","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"(Image: )","category":"page"},{"location":"apps_ad/","page":"Intelligent Automatic Differentiation","title":"Intelligent Automatic Differentiation","text":"We call this technique intelligent automatic differentiation, since we can design our own operators for performance and those operators are submodules that can be flexibly replaced and reused. For more details, see FwiFlow.jl, a package focused on elastic full waveform inversion for subsurface flow problems.","category":"page"},{"location":"ot/#Optimal-Transport","page":"Optimal Transport","title":"Optimal Transport","text":"","category":"section"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"Optimal transport (OT) can be used to measure the \"distance\" between two probability distribution. ","category":"page"},{"location":"ot/#Discrete-Wasserstein-Distance","page":"Optimal Transport","title":"Discrete Wasserstein Distance","text":"","category":"section"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"In this section, we introduce a novel approach for training a general model: SinkHorn Generative Networks (SGN). In this approach, a neural network is used to transform a sample from uniform distributions to a sample of targeted distribution. We train the neural network by minimizing the discrepancy between the targeted distribution and the desired distribution, which is described by optimal transport distance. Different from generative adversarial nets (GAN), we do not use a discriminator neural network to construct the discrepancy; instead, it is computed directly with efficient SinkHorn algorithm or net-flow solver. The minimization is conducted via a gradient-based optimizer, where the gradients are computed with reverse mode automatic differentiation. ","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"To begin with, we first construct the sample x of the targeted distribution and the sample s from the desired distribution and compute the loss function with sinkhorn","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"using Revise\nusing ADCME\nusing PyPlot\n\nreset_default_graph()\nK = 64\nz = placeholder(Float64, shape=[K, 10])\nx = squeeze(ae(z, [20,20,20,1]))\ns = placeholder(Float64, shape=[K])\nM = abs(reshape(x, -1, 1) - reshape(s, 1, -1))\nloss = sinkhorn(ones(K)/K, ones(K)/K, M, reg=0.1)","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"Example 1 In the first example, we assume the desired distribution is the standard Gaussian. We minimize the loss function with the Adam optimizer","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"opt = AdamOptimizer().minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    _, l = run(sess, [opt, loss], z=>rand(K, 10), s=>randn(K))\n    @show i, l\nend","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"The result is shown below","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"V = []\nfor k = 1:100\n    push!(V,run(sess, x, z=>rand(K,10)))\nend\nV = vcat(V...)\nhist(V, bins=50, density=true)\nx0 = LinRange(-3.,3.,100)\nplot(x0, (@. 1/sqrt(2π)*exp(-x0^2/2)), label=\"Reference\")\nxlabel(\"x\")\nylabel(\"f(x)\")\nlegend()","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"(Image: )","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"Example 2 In the first example, we assume the desired distribution is the positive part of the the standard Gaussian. ","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"opt = AdamOptimizer().minimize(loss)\nsess = Session(); init(sess)\nfor i = 1:10000\n    _, l = run(sess, [opt, loss], z=>rand(K, 10), s=>abs.(randn(K)))\n    @show i, l\nend","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"(Image: )","category":"page"},{"location":"ot/#Dynamic-Time-Wrapping","page":"Optimal Transport","title":"Dynamic Time Wrapping","text":"","category":"section"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"Dynamic time wrapping is suitable for computing the distance of two time series. The idea is that we can shift the time series to obtain the \"best\" match while retaining the causality in time. This is best illustrated in the following figure  (Image: )","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"In ADCME, the distance is computed using dtw. As an example, given two time series","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"Sample = Float64[1,2,3,5,5,5,6]\nTest = Float64[1,1,2,2,3,5]","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"The distance can be computed by ","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"c, p = dtw(Sample, Test, true)","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"c is the distance and p is the path.","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"If we have 2000 time series A and 2000 time series B and we want to compute the total distance of the corresponding time series, we can use map function ","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"A = constant(rand(2000,1000))\nB = constant(rand(2000,1000))\ndistance = map(x->dtw(x[1],x[2],false)[1],[A,B], dtype=Float64)","category":"page"},{"location":"ot/","page":"Optimal Transport","title":"Optimal Transport","text":"distances is a 2000 length vector and gives us the pairwise distance for all time series. ","category":"page"},{"location":"apps_constitutive_law/#Learning-Constitutive-Relations-from-Indirect-Observations-Using-Deep-Neural-Networks","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"","category":"section"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"Huang, Daniel Z. (co-first author), Kailai Xu (co-first author), Charbel Farhat, and Eric Darve. \"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks\"","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"Project Website","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"We present a new approach for predictive modeling and its uncertainty quantification for mechanical systems, where coarse-grained models such as constitutive relations are derived directly from observation data. We explore the use of neural networks to represent the unknowns functions (e.g., constitutive relations). Its counterparts, like piecewise linear functions and radial basis functions, are compared, and the strength of neural networks is explored. The training and predictive processes in this framework seamlessly combine the finite element method, automatic differentiation, and neural networks (or its counterparts). Under mild assumptions, we establish convergence guarantees. This framework also allows uncertainty quantification analysis in the form of intervals of confidence. Numerical examples on a multiscale fiber-reinforced plate problem and a nonlinear rubbery membrane problem from solid mechanics demonstrate the effectiveness of the framework.","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"The solid mechanics equation can be formulated as","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"mathcalP(u(mathbfx) mathcalM(u(mathbfx)dot u(mathbfx) mathbfx)) = mathcalF(u(mathbfx) mathbfx p)","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"where u is the displacement, mathbfx is the location, p is the external pressure, mathcalF is the external force, mathcalM(u(mathbfx)dot u(mathbfx) mathbfx) is the stress (mathcalM is also called the constitutive law), mathcalP(u(mathbfx) mathcalM(u(mathbfx)dot u(mathbfx) mathbfx)) is the internal force. For a new material or nonhomogeneous material, the constitutive relation mathcalM is not known and we want to estimate it. In laboratory, usually only u(mathbfx) can be measured but the stress cannot. The idea is to substitute the constitutive law relation–in this work, we assume mathcalM only depends on u(mathbfx) and the neural network is mathcalM_theta(u(mathbfx)), where theta is the unknown parameter. ","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"We train the neural network by solving the optimization problem","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"min_thetamathcalP(mathbfu mathcalM_theta(mathbfu)) - mathcalF(mathbfu mathbfx p) ^2_2","category":"page"},{"location":"apps_constitutive_law/","page":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","title":"Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks","text":"(Image: image-20191031200808697)","category":"page"},{"location":"second_order_pcl/#Second-Order-Physics-Constrained-Learning","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"","category":"section"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"In this note, we describe the second order physics constrained learning (PCL) for efficient calculating Hessians using computational graphs. To begin with, let xinmathbbR^d be the coordinates and consider a chain of operations ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"l(x) = F_ncirc F_n-1circ cdots circ F_1(x) tag1","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Here l is a scalar function, which means F_n is a scalar function. It is not hard to see that we can express any computational graph with a scalar output using Eq. 1. For convenience, given a fixed kin12ldots n, we define Phi, F as follows","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"l(x) = underbraceF_ncirc F_n-1circ cdots circ F_k_Phi circ underbraceF_k-1cdots circ F_1_F(x)","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We omit k in Phi, F for clarity. ","category":"page"},{"location":"second_order_pcl/#Calculating-the-Hessian-in-TensorFlow","page":"Second Order Physics Constrained Learning","title":"Calculating the Hessian in TensorFlow","text":"","category":"section"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"TensorFlow provides tf.hessians to calculate hessian functions. ADCME exposes this function via hessians. The idea is to first construct a computational graph for the gradients nabla_x l(x), then for each component of nabla_x l(x), nabla_x_i l(x), we construct a gradient back-propagation computational graph ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"nabla_x nabla_x_i l(x)","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"This gives us a row/column in the Hessian matrix. The following shows the main code from TensorFlow:","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"_, hessian = control_flow_ops.while_loop(\n        lambda j, _: j < n,\n        lambda j, result: (j + 1,\n                           result.write(j, gradients(gradient[j], x)[0])),\n        loop_vars\n    )","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We see it's essentially a loop over each component in gradient","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Albeit straight-forward, this approach suffers from three drawbacks:","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"The algorithm does not leverage the symmetry of the Hessian matrix. The Hessian structure can be exploited for efficient computations. \nThe algorithm can be quite expensive. Firstly, it requires a gradient back-propagation over each component of nabla_x l(x). Although TensorFlow can concurrently evaluates these Hessian rows/columns concurrently, the dimension of x can be very large and therefore the computations cannot be fully parallelized. Secondly, each back-propagation of nabla_x_i l(x) requires both forward computation l(x) and gradient back-propagation for nabla_x l(x), we need to carefully arrange the computations and storages so that these intermediate results can be reused. Otherwise, redundant computations lead to extra costs. \nThe most demanding requirements of the algorithm is that we need to implement–-for every operator–-the \"gradients of gradients\". Although simple for some operators (there are already existing implementations for some operators in TensorFlow!), this can be very hard for sophisticated operators, e.g., implicit operators. ","category":"page"},{"location":"second_order_pcl/#Second-Order-Physics-Constrained-Learning-2","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"","category":"section"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Here we consider the second order physics constrained learning. The main idea is to apply the implicit function theorem to ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"l = Phi(F(x)) tag2","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"twice. First, we introduce some notation:","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Phi_k(y) = fracpartial Phi(y)partial y_k quad Phi_kl(y) = fracpartial^2 Phi(y)partial y_k partial y_l","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"F_kl(x) = fracpartial F_k(x)partial x_l quad F_klr(x) = fracpartial^2 F_k(x)partial x_lpartial x_r","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We take the derivative with respect to x_i on both sides of Eq. 2, and get","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"fracpartial lpartial x_i = Phi_k F_ki tag3","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We take the derivative with respect to x_j on both sides of Eq. 3, and get ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"fracpartial^2 lpartial x_ipartial x_j = Phi_kr F_kiF_rj + Phi_k F_k ij tag4","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Here we have used the Einstein notation. Let barPhi = nabla Phi but we treat x as a independent variable of barPhi, then we can rewrite Eq. 4 to ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"nabla_x^2 l = (nabla_x F) nabla^2_xPhi (nabla_x F)^T + nabla_x^2 (barPhi^T F)tag5","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Note the values of barPhi is already available in the gradient back-propagation. ","category":"page"},{"location":"second_order_pcl/#Algorithm","page":"Second Order Physics Constrained Learning","title":"Algorithm","text":"","category":"section"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Based on Eq. 5, we have the following algorithm for calculating the Hessian","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Initialize H = 0\nfor k = n-1 n-2ldots 1\nCalculate J = nabla F_k and extract bar Phi_k+1 from the gradient back-propagation tape.\nCalculate Z = nabla^2 (barPhi_k+1^T F_k)\nH gets JHJ^T + Z","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"This algorithm only requires one backward pass and constructs the Hessian iteratively. Additionally, we can leverage the symmetry of the Hessian when we do the calculations in the second step. This algorithm also doesn't require looping over each components of the gradient. ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"However, the challenge here is that we need to calculate nabla F_k and Z = nabla^2 (barPhi_k+1^T F_k). Developing a complete support of such calculations for all operators  can be a time-consuming task. But due to the benefit brought by the trust region method, we deem it to be a rewarding investment. ","category":"page"},{"location":"second_order_pcl/#Example:-Developing-Second-Order-PCL-for-a-Sparse-Linear-Solver","page":"Second Order Physics Constrained Learning","title":"Example: Developing Second Order PCL for a Sparse Linear Solver","text":"","category":"section"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Here we consider an application of second order PCL for a sparse solver. We focus on the operator that takes the sparse entries of a matrix AinmathbbR^ntimes n as input, and outputs u","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Au = f","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Let A = a_ij, and some of a_ij are zero. According to 2nd order PCL, we need to calculate fracpartial u_kpartial a_ij and fracpartial^2 (y^T u)partial a_ij partial a_rs. ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We consider a multi-index l and r. We take the gradient with respect to a_l on both sides of ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"a_i1u_1 + a_i2u_2 + ldots + a_inu_n = f_i","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"which leads to ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"a_i1^lu_1 + a_i2^lu_2 + ldots + a_in^lu_n + a_i1u^l_1 + a_i2u^l_2 + ldots + a_inu^l_n = 0tag6","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Here the superscript indicates the derivative. ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Eq. 6 leads to ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"u^l = -A^-1A^l u tag7","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Note at most one entry in A^l is nonzero, and therefore at most one entry in A^l u is nonzero. Thus to calculate Eq. 7, we can calculate the inverse A^-1 first, and then u^l can be obtained cheaply by taking a column from A^-1. The complexity will be mathcalO(n^3)–-the cost of inverting A^-1.","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Now take the derivative with respect to a_r on both sides of Eq. 6, we have","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"beginaligned\na_i1^lu_1^r + a_i2^lu_2^r + ldots + a_in^lu_n^r +  a_i1^ru^l_1 + a_i2^ru^l_2 + ldots + a_in^ru^l_n + a_i1u^rl_1 + a_i2u^rl_2 + ldots + a_inu^rl_n = 0\nendaligned","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"which leads to ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Au^rl = -A^l u^r - A^r u^l","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Therefore, ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"(y^Tu)^rl = - y^TA^-1(A^l u^r + A^r u^l)","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"We can calculate z^T = y^TA^-1 first with a cost mathcalO(n^2). Because u^r, u^l has already been calculated and A^l, A^r has at most one nonzero entry, A^l u^r + A^r u^l has at most two nonzero entries. The calculation z^T(A^l u^r + A^r u^l) can be done in mathcalO(1) and therefore the total cost is mathcalO(d^2), where d is the number of nonzero entries. ","category":"page"},{"location":"second_order_pcl/","page":"Second Order Physics Constrained Learning","title":"Second Order Physics Constrained Learning","text":"Upon obtaining fracpartial u_kpartial a_ij and fracpartial^2 (y^T u)partial a_ij partial a_rs, we can apply the recursive the formula to \"back-propagate\" the Hessian matrix. ","category":"page"},{"location":"optim/#Study-on-Optimizers","page":"Study on Optimizers","title":"Study on Optimizers","text":"","category":"section"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"When working with BFGS/LBFGS, there are some important aspects of the algorithm, which affect the convergence of the optimizer. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"BFGS approximates the Hessian or the inverse Hessian matrix. LBFGS, instead, stores a limited set of vectors and does not explicitly formulate the Hessian matrices. The Hessian matrix solve is approximated using recursions on vector vector production. \nBoth BFGS and LBFGS deploy a certain kind of line search strategies. For example, the Hager-Zhang and More-Thuente are two commonly used strategies. These linesearch algorithms require evaluating gradients in each line search step. This means we need to frequently do gradient back-propagation, which may be quite expensive.  We instead employ a backtracking strategy, which requires evaluating forward computation only. \nInitial guess of the line search algorithm. We found that the following initial guess is quite effective for our problems:\nalpha=min100alpha_0 10\nHere alpha_0 is the line search step size for the last step (for the first step, alpha=1 is used). Using this choice, we found that in a typical line search step, only 1~3 evaluations of the loss function is needed. \nStopping criterion in line search algorithms. The algorithm backtracks until a certain set of condition is met. Typically the Wolfe condition, the Armijo curvature rule, or the strong Wolfe conditions are used. Note that these criterion require gradient information, and we want to avoid calculating extra gradients during linesearch. Therefore, we use the following sufficient decrease condition ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"phi(alpha) leq phi(0) + c_1 alpha phi(0)","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Here c_1=10^-4. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"One interesting observation is that if we apply BFGS/LBFGS directly, we usually cannot make any progress. There are many reasons for this phenomenon:","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"The initial guess for the neural network is far away from optimal, and quasi-Newton methods usually do not work well in this regime. \nThe approximate Hessian is quite different from the true one. The estimated search direction may deviate from the optimal one too much. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"First-order methods, such as Adam optimizer, usually does not suffer from these difficulties. Therefore, one solution to this problem is via \"warm start\" by running a first order optimizer (Adam) for a few iterations. Additionally, for BFGS, we can build Hessian approximations while we are running the Adam optimizer. In this way, we can use the historic information as much as possible. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Our algorithm is as follows (BFGS+Adam+Hessian):","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Run the Adam optimizer for the first few iterations, and build the approximate Hessian matrix at the same time. That is, in each iteration, we update an approximate Hessian B using \nB_k+1 = left(I - fracs_k y_k^Ty_k^Ts_kright)B_kleft(I - frac y_ks_k^Ty_k^Ts_kright) + fracs_ks_k^Ty_k^Ts_k\nHere y_k = nabla f(x_k+1) - nabla f(x_k) s_k = x_k+1-x_k B_0 = I. Note B_k is not used in the Adam optimizer. \nRun the BFGS optimizer and use the last Hessian matrix B_k built in Step 1 as the initial guess. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We compare our algorithm with those without approximated Hessian (BFGS+Adam) or warm start (BFGS). Additionally, we also compare our algorithm with LBFGS counterparts. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"In the test case II and III, a physical field, f, is approximated using deep neural networks, f_theta, where theta is the weights and biases. The neural network maps coordinates to a scalar value. f_theta is coupled with a DAE:","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"F(u u Du D^2u ldots f_theta) = 0 tag1","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Here u represents the time derivative of u, and Du, D^2u, ldots are first-, second-, ldots order spatial gradients. Typically we can observe u on some discrete points mathbfx_k_kin mathcalI. To train the neural network, we consider the following optimization problem ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"min_theta sum_kin mathcalI (u(mathbfx_i) - u_theta(mathbfx_i))","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Here u_theta is the solution from Eq. 1. ","category":"page"},{"location":"optim/#Test-Case-I","page":"Study on Optimizers","title":"Test Case I","text":"","category":"section"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"In the first case, we train a 4 layer network with 20 neurons per layer, and tanh activation functions. The data set is x_i sin(x_i)_i=1^100, where x_i are randomly generated from mathcalU(01). The neural network f_theta is trained by solving the following optimization problem:","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"min_theta sum_i=1^100 (sin(x_i) - f_theta(x_i))^2","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"The neural network is small, and thus we can use BFGS/LBFGS to train. In fact, the following plot shows that BFGS/LBFGS is much more accurate and effective than the commonly used Adam optimizer. Considering the wide range of computational engineering applications, where a small neural network is sufficient, this result implies that BFGS/LBFGS for training neural networks should receive far more attention than what it does nowadays. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Also, in many applications, the major runtime is doing physical simulations instead of updating neural network parameters or approximate Hessian matrices, these \"expensive\" BFGS/LBFGS optimization algorithms should be considered a good way to leverage as much history information as possible, so as to reduce the total number of iterations (simulations). ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/#Test-Case-II","page":"Study on Optimizers","title":"Test Case II","text":"","category":"section"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"In this test case, we consider solving a Poisson's equation in this post. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"The exact kappa and the corresponding solution u is shown below","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We run different optimization algorithms and obtain the following loss function profiles. We see that BFGS/LBFGS without Adam warm start terminates early. BFGS in general has much better accuracy than LBFGS. An extra benefit of BFGS+Adam+Hessian compared to BFGS+Adam is that we can achieve much better accuracy. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Loss Function Zoom-in View\n(Image: ) (Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We also show the mean squared error for kappa, which confirms that BFGS+Adam+Hessian achieves the best test error. The error is calculated using the formula ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"frac1n (kappa_texttrue(textbfx_i) - kappa_theta(textbfx_i))^2","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Here textbfx_i is defined on Gauss points. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Algorithm Adam BFGS+Adam+Hessian BFGS+Adam BFGS LBFGS+Adam LBFGS\nMSE 0.013 1.00E-11 1.70E-10 1.10E+04 0.00023 97000","category":"page"},{"location":"optim/#Test-Case-III","page":"Study on Optimizers","title":"Test Case III","text":"","category":"section"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"In the last example, we consider the linear elasticity. The problem description can be found here.","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We fix the random seed for neural network initialization and run different optimization algorithms. The initial guess for the Young's modulus and the reference one are shown in the following plot ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"The corresponding velocity and stress fields are ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We perform the optimization using different algorithms. In the case where Adam is used as warm start, we run Adam optimization for 50 iterations. We run the optimization for at most 500 iterations (so there is at most 500 evaluations of gradients) The loss function is shown below","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We see that BFGS+Adam+Hessian achieves the smallest loss functions among all algorithms. We also show the MSE for E, i.e., frac1n (E_texttrue(textbfx_i) - E_theta(textbfx_i))^2, where textbfx_i is defined on Gauss points. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"Algorithm Adam BFGS+Adam+Hessian BFGS+Adam BFGS LBFGS+Adam LBFGS\nMSE 0.0033 1.90E-07 4.00E-06 6.20E-06 0.0031 0.0013","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"This confirms that BFGS+Adam+Hessian indeed generates a much more accurate result. ","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We also compare the results for the BFGS+Adam+Hessian and Adam algorithms:","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"(Image: )","category":"page"},{"location":"optim/","page":"Study on Optimizers","title":"Study on Optimizers","text":"We see the Adam optimizer achieves reasonable result but is challenging to deliver high accurate estimation within 500 iterations.","category":"page"},{"location":"customopt/#Custom-Optimizer","page":"Custom Optimizer","title":"Custom Optimizer","text":"","category":"section"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"In this article, we describe how to make your custom optimizer","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"CustomOptimizer","category":"page"},{"location":"customopt/#ADCME.CustomOptimizer","page":"Custom Optimizer","title":"ADCME.CustomOptimizer","text":"CustomOptimizer(opt::Function, name::String)\n\ncreates a custom optimizer with struct name name. For example, we can integrate Optim.jl with ADCME by  constructing a new optimizer\n\nCustomOptimizer(\"Con\") do f, df, c, dc, x0, x_L, x_U\n    opt = Opt(:LD_MMA, length(x0))\n    bd = zeros(length(x0)); bd[end-1:end] = [-Inf, 0.0]\n    opt.lower_bounds = bd\n    opt.xtol_rel = 1e-4\n    opt.min_objective = (x,g)->(g[:]= df(x); return f(x)[1])\n    inequality_constraint!(opt, (x,g)->( g[:]= dc(x);c(x)[1]), 1e-8)\n    (minf,minx,ret) = NLopt.optimize(opt, x0)\n    minx\nend\n\nHere\n\n∘ f: a function that returns f(x)\n\n∘ df: a function that returns nabla f(x)\n\n∘ c: a function that returns the constraints c(x)\n\n∘ dc: a function that returns nabla c(x)\n\n∘ x0: initial guess\n\n∘ nineq: number of inequality constraints\n\n∘ neq: number of equality constraints\n\n∘ x_L: lower bounds of optimizable variables\n\n∘ x_U: upper bounds of optimizable variables\n\nThen we can create an optimizer with \n\nopt = Con(loss, inequalities=[c1], equalities=[c2])\n\nTo trigger the optimization, use\n\nminimize(opt, sess)\n\nNote thanks to the global variable scope of Julia, step_callback, optimizer_kwargs can actually  be passed from Julia environment directly.\n\n\n\n\n\n","category":"function"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"We will show here a few examples of custom optimizer. These examples can be cast to your specific applications. ","category":"page"},{"location":"customopt/#Ipopt-Custom-Optimizer","page":"Custom Optimizer","title":"Ipopt Custom Optimizer","text":"","category":"section"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"For a concrete example, let us consider using Ipopt as a constrained optimization optimizer. ","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"using Ipopt\nusing ADCME\n\nIPOPT = CustomOptimizer() do f, df, c, dc, x0, x_L, x_U\n    n_variables = length(x0)\n    nz = length(dc(x0)) \n  \tm = div(nz, n_variables) # Number of constraints\n    g_L, g_U = [-Inf;-Inf], [0.0;0.0]\n    function eval_jac_g(x, mode, rows, cols, values)\n        if mode == :Structure\n            rows[1] = 1; cols[1] = 1\n            rows[2] = 1; cols[2] = 1\n            rows[3] = 2; cols[3] = 1\n            rows[4] = 2; cols[4] = 1\n        else\n            values[:]=dc(x)\n        end\n    end\n  \n    nele_jac = 0 # Number of non-zeros in Jacobian\n    prob = Ipopt.createProblem(n_variables, x_L, x_U, m, g_L, g_U, nz, nele_jac,\n            f, (x,g)->(g[:]=c(x)), (x,g)->(g[:]=df(x)), eval_jac_g, nothing)\n    addOption(prob, \"hessian_approximation\", \"limited-memory\")\n    addOption(prob, \"max_iter\", 100)\n  \taddOption(prob, \"print_level\", 2) # 0 -- 15, the larger the number, the more detailed the information\n\n    prob.x = x0\n    status = Ipopt.solveProblem(prob)\n    println(Ipopt.ApplicationReturnStatus[status])\n    println(prob.x)\n    prob.x\nend\n\nreset_default_graph() # be sure to reset graph before any optimization\nx = Variable([1.0;1.0])\nx1 = x[1]; x2 = x[2]; \nloss = x2\ng = x1\nh = x1*x1 + x2*x2 - 1\nopt = IPOPT(loss, inequalities=[g], equalities=[h], var_to_bounds=Dict(x=>(-1.0,1.0)))\nsess = Session(); init(sess)\nminimize(opt, sess)","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Here is a detailed description of the code","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Ipopt.createProblem has signature","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"function createProblem(\n  n::Int,                     # Number of variables\n  x_L::Vector{Float64},       # Variable lower bounds\n  x_U::Vector{Float64},       # Variable upper bounds\n  m::Int,                     # Number of constraints\n  g_L::Vector{Float64},       # Constraint lower bounds\n  g_U::Vector{Float64},       # Constraint upper bounds\n  nele_jac::Int,              # Number of non-zeros in Jacobian\n  nele_hess::Int,             # Number of non-zeros in Hessian\n  eval_f,                     # Callback: objective function\n  eval_g,                     # Callback: constraint evaluation\n  eval_grad_f,                # Callback: objective function gradient\n  eval_jac_g,                 # Callback: Jacobian evaluation\n  eval_h = nothing)           # Callback: Hessian evaluation","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Typically nabla c(x) is a mtimes n sparse matrix, where m is the number of constraints, n is the number of variables. nz = length(dc(x0)) computes the number of nonzeros in the Jacobian matrix. \ng_L, g_U specify the constraint lower and upper bounds: g_L leq c(x) leq g_U. If g_L=g_U=0, the constraint is reduced to equality constraint. Each of the parameters should have the same length as the number of variables, i.e., n\neval_jac_g has two modes. In the Structure mode, as we mentioned, the constraint nabla c(x) is a sparse matrix, and therefore we should specify the nonzero pattern of the sparse matrix in row and col. However, in our application, we usually assume a dense Jacobian matrix, and therefore, we can always use the following code for Structure\nk = 1\nfor i = 1:div(nz, n_variables)\n  for j = 1:n_variables\n    rows[k] = i \n    cols[k] = j\n    k += 1\n  end\nend\nFor the other mode, eval_jac_g simply assign values to the array. \nWe can add optimions to the Ipopt optimizer via addOptions. See here for a full list of available options. \nTo add callbacks, you can simply refactor your functions f, df, c, or dc. ","category":"page"},{"location":"customopt/#NLopt-Custom-Optimizer","page":"Custom Optimizer","title":"NLopt Custom Optimizer","text":"","category":"section"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Here is an example of using NLopt for optimization. ","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"using ADCME\nusing NLopt\n\np = ones(10)\nCon = CustomOptimizer() do f, df, c, dc, x0, x_L, x_U \n    opt = Opt(:LD_MMA, length(x0))\n    opt.upper_bounds = 10ones(length(x0))\n    opt.lower_bounds = zeros(length(x0))\n  \topt.lower_bounds[end-1:end] = [-Inf, 0.0]\n    opt.xtol_rel = 1e-4\n    opt.min_objective = (x,g)->(g[:]= df(x); return f(x)[1])\n    inequality_constraint!(opt, (x,g)->( g[:]= dc(x);c(x)[1]), 1e-8)\n    (minf,minx,ret) = NLopt.optimize(opt, x0)\n    minx\nend\n\nreset_default_graph() # be sure to reset the graph before any operation\nx = Variable([1.234; 5.678])\ny = Variable([1.0;2.0])\nloss = x[2]^2 + sum(y^2)\nc1 = (x[1]-1)^2 - x[2] \nopt = Con(loss, inequalities=[c1])\nsess = Session(); init(sess)\nopt.minimize(sess)\nxmin = run(sess, x) # expected: (1., 0.)","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Here is the detailed explanation","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"NLopt solver takes the following parameters \nalgorithm\nstopval # stop minimizing when an objective value ≤ stopval is found\nftol_rel\nftol_abs\nxtol_rel\nxtol_abs\nconstrtol_abs\nmaxeval\nmaxtime\ninitial_step # a vector, initial step size \npopulation\nseed\nvector_storage # number of \"remembered gradients\" in algorithms such as \"quasi-Newton\"\nlower_bounds\nupper_bounds\nFor a full list of optimization algorithms, see NLopt algorithms.\nYou can provide upper and lower bounds either via var_to_bounds or inside CustomOptimizer. ","category":"page"},{"location":"customopt/#Drop-in-Substitutes-of-BFGS!","page":"Custom Optimizer","title":"Drop-in Substitutes of BFGS!","text":"","category":"section"},{"location":"customopt/#IPOPT","page":"Custom Optimizer","title":"IPOPT","text":"","category":"section"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"The following codes are for unconstrained optimizattion of BFGS! optimizer. Copy and execute the following code to have access to IPOPT! function. ","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"using PyCall\nusing Ipopt\nusing ADCME\n\n\nfunction IPOPT!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; \n            verbose::Int64=0, vars::Array{PyObject}=PyObject[], \n                    callback::Union{Function, Nothing}=nothing, kwargs...)\n    losses = Float64[]\n    loss_ = 0\n    cnt_ = -1\n    iter_ = 0\n    IPOPT = CustomOptimizer() do f, df, c, dc, x0, x_L, x_U\n        n_variables = length(x0)\n        nz = length(dc(x0)) \n        m = div(nz, n_variables) # Number of constraints\n        # g_L, g_U = [-Inf;-Inf], [0.0;0.0]\n        g_L = Float64[]\n        g_U = Float64[]\n        function eval_jac_g(x, mode, rows, cols, values); end\n        function eval_f(x)\n          loss_ = f(x)\n          iter_ += 1\n          if iter_==1\n            push!(losses, loss_)\n            if !isnothing(callback)\n                callback(run(sess, vars), cnt_, loss_)\n            end\n          end\n          println(\"iter $iter_, current loss= $loss_\")\n          return loss_\n        end\n\n        function eval_g(x, g)\n          if cnt_>=1\n            push!(losses, loss_)\n            if !isnothing(callback)\n                callback(run(sess, vars), cnt_, loss_)\n            end\n          end\n          cnt_ += 1\n          if cnt_>=1\n            println(\"================ ITER $cnt_ ===============\")\n          end\n          g[:]=df(x)\n        end\n      \n        nele_jac = 0 # Number of non-zeros in Jacobian\n        prob = Ipopt.createProblem(n_variables, x_L, x_U, m, g_L, g_U, nz, nele_jac,\n                eval_f, (x,g)->(), eval_g, eval_jac_g, nothing)\n        addOption(prob, \"hessian_approximation\", \"limited-memory\")\n        addOption(prob, \"max_iter\", max_iter)\n        addOption(prob, \"print_level\", verbose) # 0 -- 15, the larger the number, the more detailed the information\n\n        prob.x = x0\n        status = Ipopt.solveProblem(prob)\n        if status == 0\n          printstyled(Ipopt.ApplicationReturnStatus[status],\"\\n\", color=:green)\n        else \n          printstyled(Ipopt.ApplicationReturnStatus[status],\"\\n\", color=:red)\n        end\n        prob.x\n    end\n    opt = IPOPT(loss; kwargs...)\n    minimize(opt, sess)\n    return losses\nend","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"The usage is exactly the same as BFGS!. Therefore, you can simply replace BFGS! to Ipopt. For example","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"x = Variable(rand(10))\nloss = sum((x-0.6)^2 + (x^2-2x+0.8)^4)\ncb = (vs, i, l)->println(\"$i, $l\")\nsess = Session(); init(sess)\nIPOPT!(sess, loss, vars=[x], callback = cb)","category":"page"},{"location":"customopt/#NLOPT","page":"Custom Optimizer","title":"NLOPT","text":"","category":"section"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"Likewise, NLOPT! also has the dropin substitute of BFGS!","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"using ADCME\nusing NLopt\nusing PyCall\n\nfunction NLOPT!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; \n            algorithm::Union{Symbol, Enum} = :LD_LBFGS, vars::Array{PyObject}=PyObject[], \n                    callback::Union{Function, Nothing}=nothing, kwargs...)\n    losses = Float64[]\n    iter_ = 0 \n    NLOPT = CustomOptimizer() do f, df, c, dc, x0, x_L, x_U \n        opt = Opt(algorithm, length(x0))\n        opt.upper_bounds = x_U\n        opt.lower_bounds = x_L\n        opt.maxeval = max_iter\n        opt.min_objective = (x,g)->begin\n            g[:]= df(x); \n            iter_ += 1\n            l = f(x)[1]\n            println(\"================ ITER $iter_ ===============\")\n            println(\"current loss= $l\")\n            push!(losses, l)\n            if !isnothing(callback)\n                callback(run(sess, vars), iter_, l)\n            end\n            return f(x)[1]\n        end\n        (minf,minx,ret) = NLopt.optimize(opt, x0)\n        minx\n    end\n    opt = NLOPT(loss; kwargs...)\n    minimize(opt, sess)\n    return losses\nend","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"For example","category":"page"},{"location":"customopt/","page":"Custom Optimizer","title":"Custom Optimizer","text":"x = Variable(rand(10))\nloss = sum((x-0.6)^2 + (x^2-2x+0.8)^4)\ncb = (vs, i, l)->println(\"$i, $l\")\nsess = Session(); init(sess)\nNLOPT!(sess, loss, vars=[x], callback = cb, algorithm = :LD_TNEWTON)","category":"page"},{"location":"factorization/#Direct-Methods-for-Sparse-Matrices","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"","category":"section"},{"location":"factorization/#Usage","page":"Direct Methods for Sparse Matrices","title":"Usage","text":"","category":"section"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"The direct methods for sparse matrix solutions feature a matrix factorization for solving a set of equations. This procedure is call factorization or decomposition. We can also support factorization or decomposition via shared memory across kernels. The design is to store the factorized matrix in the C++ memory and pass an identifying code (an integer) to the solution operators. Here is how you solve Ax_i = b_i for a list of (x_i b_i)","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"Step 1: Factorization","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"A_factorized = factorize(A)","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"Step2: Solve","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"x1 = A_factorized\\b1\nx2 = A_factorized\\b2\n......","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"Compared to A\\b, the factorize-then-solve approach is more efficient, especially when you have to solve a lot of equations. ","category":"page"},{"location":"factorization/#Control-Flow-Safety","page":"Direct Methods for Sparse Matrices","title":"Control Flow Safety","text":"","category":"section"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"The factorize-then-solve method is also control flow safe. That is, we can safely use it in the control flow and gradient backpropagation is correct. For example, if the matrix A keeps unchanged throught the loop, we might want to factorize A first and then use the factorized A to solve equations repeatly. To verify the control flow safety, consider the following code, where in the loop we have ","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"u_i+1 = A^-1(u_i + r) i=12ldots","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"using ADCME\nusing SparseArrays\nusing ADCMEKit\n\n\nfunction while_loop_simulation(vv, rhs, ns = 10)\n    A = SparseTensor(ii, jj, vv, 10, 10) + spdiag(10)*100.\n\n    Afac = factorize(A)\n\n    ta = TensorArray(ns)\n    i = constant(2, dtype=Int32)\n    ta = write(ta, 1, ones(10))\n    function condition(i, ta)\n        i<= ns\n    end\n    function body(i, ta)\n        u = read(ta, i-1)\n        res = Afac\\(u + rhs)\n        # res = u \n        ta = write(ta, i, res)\n        i+1, ta \n    end\n    _, out = while_loop(condition, body, [i, ta])\n    sum(stack(out)^2)\nend\n\n\nsess = Session(); init(sess)\n\nA = sprand(10, 10, 0.8)\nii, jj, vv = find(constant(A))\nk = length(vv)\n\n# Test 1: autodiff through A\npl = placeholder(rand(k))\nres = while_loop_simulation(pl, rhs , 100)\ngradview(sess, pl, res, rand(k))\n\n# Test 2: autodiff through rhs\npl = placeholder(rand(10))\nres = while_loop_simulation(vv, pl , 100)\ngradview(sess, pl, res, rand(10))","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"We have the following convergence plot","category":"page"},{"location":"factorization/","page":"Direct Methods for Sparse Matrices","title":"Direct Methods for Sparse Matrices","text":"(Image: Screen Shot 2020-04-04 at 11.15.19 PM)","category":"page"},{"location":"windows_installation/#Install-ADCME-on-Windows","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"","category":"section"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"The following sections provide instructions on installing ADCME on Windows computers. ","category":"page"},{"location":"windows_installation/#Install-Julia","page":"Install ADCME on Windows","title":"Install Julia","text":"","category":"section"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Windows users can install ADCME following these instructions. Choose your version of Windows (32-bit or 64-bit).","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Detailed instructions to install Julia on Windows","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"For Windows users, you can press the Windows button or click the Windows icon (usually located in the lower left of your screen) and type julia. Open the Desktop App Julia and you will see a Julia prompt. ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/#Install-C/C-Compilers","page":"Install ADCME on Windows","title":"Install C/C++ Compilers","text":"","category":"section"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"To use and build custom operators, you need a C/C++ compiler that is compatible with the TensorFlow backend. The prebuilt TensorFlow shipped with ADCME was built using Microsoft Visual Studio 2017 15. Therefore, you need to install this specific version. ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Download and install from here","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Note that this is an older version of Visual Studio. It's not the one from 2019 but the previous version from 2017.","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Double click the installer that you just downloaded. You will see the following image:","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"A free community version is available (Visual Studio Community 2017). Click install and a window will pop up. ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Make sure the following two checkboxes are checked:","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"In the Workloads tab, Desktop development with C++ is checked.","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"In the Indivisual components tab, MSBuild is checked.","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Click install on the lower right corner. You will see the following window. ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"The installation may take some time. Once the installation is finished, you can safely close the installer. ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/#Configure-Paths","page":"Install ADCME on Windows","title":"Configure Paths","text":"","category":"section"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"In order to locate shared libraries and executable files provided by ADCME, you also need to set an extra set of PATH environment variables. Please add the following environment variables to your system path (my user name is kaila; please replace it with yours!)","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"C:\\Users\\kaila\\.julia\\adcme\\Scripts\nC:\\Users\\kaila\\.julia\\adcme\\Library\\bin\nC:\\Users\\kaila\\.julia\\adcme\\","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Here is how you can add these environment paths:","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"(Image: )","category":"page"},{"location":"windows_installation/#Install-ADCME","page":"Install ADCME on Windows","title":"Install ADCME","text":"","category":"section"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"Now you can install ADCME via ","category":"page"},{"location":"windows_installation/","page":"Install ADCME on Windows","title":"Install ADCME on Windows","text":"using Pkg\nPkg.add(\"ADCME\")","category":"page"},{"location":"tu_debug/#Advanced:-Debugging-and-Profiling","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"There are many handy tools implemented in ADCME for analysis, benchmarking, input/output, etc. ","category":"page"},{"location":"tu_debug/#Debugging-and-Printing","page":"Advanced: Debugging and Profiling","title":"Debugging and Printing","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Add the following line before Session and change tf.Session to see verbose printing (such as GPU/CPU information)","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"tf.debugging.set_log_device_placement(true)","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"tf.print can be used for printing tensor values. It must be binded with an executive operator.","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"# a, b are tensors, and b is executive\nop = tf.print(a)\nb = bind(b, op)","category":"page"},{"location":"tu_debug/#Debugging-Python-Codes","page":"Advanced: Debugging and Profiling","title":"Debugging Python Codes","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"If the error comes from Python (through PyCall), we can print out the Python trace with the following commands","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"debug(sess, o)","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"where o is a tensor. ","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"The debug function traces back the Python function call. The above code is equivalent to ","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"import traceback\ntry:\n    # Your codes here \nexcept Exception:\n    print(traceback.format_exc())","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"This Python script can be inserted to Julia and use interpolation to invoke Julia functions (in the comment line).","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"This technique can also be applied to other TensorFlow codes. For example, we can use this trick to debug \"NotFoundError\" for custom operators","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"using ADCME, PyCall\npy\"\"\"\nimport tensorflow as tf\nimport traceback\ntry:\n    tf.load_op_library(\"../libMyOp.so\")\nexcept Exception:\n    print(traceback.format_exc())\n\"\"\"","category":"page"},{"location":"tu_debug/#Profiling","page":"Advanced: Debugging and Profiling","title":"Profiling","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Profiling can be done with the help of run_profile and save_profile","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"a = normal(2000, 5000)\nb = normal(5000, 1000)\nres = a*b \nrun_profile(sess, res)\nsave_profile(\"test.json\")","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Open Chrome and navigate to chrome://tracing\nLoad the timeline file","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Below shows an example of profiling results.","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"(Image: )","category":"page"},{"location":"tu_debug/#Suppress-Debugging-Messages","page":"Advanced: Debugging and Profiling","title":"Suppress Debugging Messages","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"If you want to suppress annoying debugging messages, you can suppress them using the following command","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Messages originated from Python ","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"By default, ADCME sets the warning level to ERROR only. To set other evels of messages, choose one from the following:","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.DEBUG)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.WARNING)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.FATAL)","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"Messages originated from C++","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"In this case, we can set TF_CPP_MIN_LOG_LEVEL in the environment variable. Set TF_CPP_MIN_LOG_LEVEL to 1 to filter out INFO logs, 2 to additionally filter out WARNING, 3 to additionally filter out ERROR (all messages).","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"For example,","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"ENV[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nusing ADCME # must be called after the above line","category":"page"},{"location":"tu_debug/#Save-and-Load-Diary","page":"Advanced: Debugging and Profiling","title":"Save and Load Diary","text":"","category":"section"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"We can use TensorBoard to track a scalar value easily","category":"page"},{"location":"tu_debug/","page":"Advanced: Debugging and Profiling","title":"Advanced: Debugging and Profiling","text":"d = Diary(\"test\")\np = placeholder(1.0, dtype=Float64)\nb = constant(1.0)+p\ns = scalar(b, \"variable\")\nfor i = 1:100\n    write(d, i, run(sess, s, Dict(p=>Float64(i))))\nend\nactivate(d)","category":"page"},{"location":"second_order_optimizer/#Training-Deep-Neural-Networks-with-Trust-Region-Methods","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Trust-region methods are a class of global optimization methods. The basic idea is to successively solve an approximated optimization problem in a small neighborhood of the current state. For example, we can approximate the local landscape of the objective function using a quadratic function, and thus can solve efficiently and accurately. The biggest advantage of trust-region methods in the context of deep neural network is that they can escape saddle points, which are demonstrated to be the dominant causes for slow convergence, with proper algorithm design. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"However, the most challenging problem with trust-region methods is that we need to calculate the Hessian (curvature information) to leverage the local curvature information. Computing the Hessian can be quite expensive and challenging, especially if the forward computation involves complex procedures and has a large number of optimizable variables. Fortunately, for many deep neural network based inverse problems, the DNNs do not need to be huge for good accuracy. Therefore, calculating the Hessian is plausible. This does not mean that efficient computation is easy, and we introduce the technique is another post. In this post, we compare the trust-region method with other competing methods (L-BFGS-B, BFGS, and ADAM optimizer) for training deep neural networks that are coupled with a numerical solver. We also shed lights on why the other optimizers slow down. ","category":"page"},{"location":"second_order_optimizer/#Trust-region-Methods","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Trust-region Methods","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We consider an unconstrained optimization problem ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"min_x f(x) tag1","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The trust-region method solves the optimization problem Eq. 1 by iteratively solving many simpler subproblems, which are good approximation to f(x_k) at the neighborhood of x_k. We model f(x_k+s) using a quadratic model ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"m(s) = f_k + s^T g_k + frac12s^T H_k s tag2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here f_k = f(x_k), g_k = nabla f(x_k), H_k = nabla^2 f(x_k). ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Eq. 2 is essentially the Taylor expansion of f(x) at x_k. This approximation is only accurate within the neighborhood of x_k. Therefore, we constrain our subproblem to a trust region ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"sleq Delta_k","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The subproblem has the following form ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"beginalignedmin_s   m(s)  textst   sleq Delta_kendaligned tag3","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"In this work, we use the method proposed in [^trust-region] to solve Eq. 3 nearly exactly. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"[^trust-region]: A.R. Conn, N.I. Gould, and P.L. Toint, \"Trust region methods\", Siam, pp. 169-200, 2000.","category":"page"},{"location":"second_order_optimizer/#Example:-Static-Poisson's-Equation","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Example: Static Poisson's Equation","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"In this example, we consider the Poisson's equation ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"nabla cdot (kappa_theta(u) nabla u)) = f(x) xin Omega  xin partialOmega","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here kappa_theta(u) is a deep neural network and theta is the weights and biases. We discretize Omega using a uniform grid. Assume we can observe the full field data u_obs on the grid points. We can then train the deep neural network using the residual minimization method [^residual-minimization]","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"min_theta sum_ij (F_ij(theta) - f_ij)^2 tag4","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here F_ij(theta) is the finite difference discretization of nabla cdot (kappa_theta(u_obs) nabla u_obs)) at the grid points. In our benchmark, we add 10% uniform random noise to f and u_obs to make the problem more challenging.  ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"[^residual-minimization]: Huang, Daniel Z., et al. \"Learning constitutive relations from indirect observations using deep neural networks.\" Journal of Computational Physics (2020): 109491.","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We apply 4 optimizers to solve Eq. 4. Because the optimization results depend on the initialization of the deep neural network, we use 5 different initial guess for DNNs. The result is shown below","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Case Convergence Plots\n1 (Image: )\n2 (Image: )\n3 (Image: )\n4 (Image: )\n5 (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We can see for all cases, the trust-region method provides a much more accurate result, and in general converges faster. The ADAM optimizer is the least competent, partially because it's a first-order optimizer and is not able to fully leverage the curvature information. The BFGS optimizers constructs an approximate Hessian that is SPD. The L-BFGS-B optimizer is an approximation to BFGS, where it uses only a limited number of previous iterates to construct the Hessian matrix. As mentioned, in the optimization problem involving deep neural networks, the slow down is mainly due to the saddle point, where the descent direction corresponds to the negative eigenvalues of the Hessian matrix. Because BFGS and L-BFGS-B ensure that the Hessian matrix is SPD, they cannot provide approximate guidance to escape the saddle point. This hypothesis is demonstrated in the following plot, where we show the distribution of Hessian eigenvalues at the last step for Case 2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Optimizer L-BFGS-B BFGS Trust Region\nEigenvalue Distribution (Image: ) (Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"In the following, we show the eigenvalue distribution of the Hessian matrix for ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"l(theta) = sum_i=1^n (kappa_theta(u_i) - kappa_i)^2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We can see that the Hessian possesses some negative eigenvalues. This implies that the DNN and DNN-FEM loss functions indeed have different curvature structures at the local minimum. The structure is altered by the PDE constraint. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Optimizer L-BFGS-B BFGS Trust Region\nEigenvalue Distribution (Image: ) (Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We also show the number of negative eigenvalues for the BFGS and trust region optimizer. Here we use a threshold epsilon=10^-6: for a given eigenvalue lambda, it is treated as \"positive\" if lambdaepsilon lambda_max, and \"negative\" if lambda  - epsilon lambda_max, otherwise zero. Here lambda_max is the maximum eigenvalue. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"BFGS Trust Region\n(Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We can see that the number of positive eigenvalues stays at around 18 and 30 for BFGS and trust region methods after a sufficient number of iterations. The number of negative eigenvalues is nearly zero. This means that both optimizers converge to points with positive semidefinite Hessian matrices. Stationary points are true local minima, instead of saddle points. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We also analyze the direction of the search direction p_k in the BFGS optimizer. We consider two values","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"beginalignedcos(theta_1) = frac-p_k^T g_kp_kg_k  cos(theta_2) = fracp_k^T q_kp_kq_kendaligned","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here q_k is the direction for the Newton's point","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"q_k = -H_k^-1g_k","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The two quantities are shown in the following plots (since the trust-region method converges in around 270 iterations, cos(theta2) only has limited data points)","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"cos(theta_1) cos(theta_2)\n(Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"There are two conclusions to draw from the plots","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The search direction of the BFGS optimizer deviates from the gradient descent method. \nThe search direction of the BFGS optimizer is not very correlated with the Newton's point direction; this indicates the search direction poorly recognizes the negative curvature directions. ","category":"page"},{"location":"second_order_optimizer/#Example:-Heat-Equation","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Example: Heat Equation","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We consider a time-dependent PDE problem: the heat equation","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"fracpartial upartial t = nabla cdot (kappa_theta(x) nabla u)) + f(x) xin Omega  xin partialOmega","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We assume that we can observe the full field data of u as snapshots. We again apply the residual minimization method to train the deep neural network. The following shows the convergence plots for different initial guesses of the DNNs. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Case Convergence Plots\n1 (Image: )\n2 (Image: )\n3 (Image: )\n4 (Image: )\n5 (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We see that the trust-region is more competitive than the other methods. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We also show the eigenvalue distribution of the Hessian matrices for Case 3. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"ADAM BFGS LBFGS Trust Region\n(Image: ) (Image: ) (Image: ) (Image: )\n50 31 22 35","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The eigenvalues of Hessian matrices are nonnegative except for the ADAM case, where the optimizer does not converge to a satisfactory local minimum after 5000 iterations. Hence, in what follows, we omit the discussion of ADAM optimizers. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The third row show the number of positive eigenvalues using the criterion mentioned before. We again see that among all three methods–-BFGS, LBFGS, and trust region–-the smaller loss function at the last step is associated with a larger number of positive eigenvalues. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We can interpret the eigenvalues associated with zero eigenvalues as \"inactive directions\", in the sense that given the gradient norm is small, perturbation in the direction of zero eigenvalues almost does not change the loss function values. In other words, the local minimum found by trust region methods has more active directions than BFGS and LBFGS. The active directions can also be viewed as \"effective degrees of freedoms (DOFs)\", and thus we conclude trust region methods find a local minimum with smaller loss function due to more effective DOFs. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The readers may wonder why different local minimums have different effective DOFs. To answer this question, we show the cumulative distribution of the maginitude of weights and biases in the following plot","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"(Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The plot shows that BFGS and LBFGS outweight trust region methods in terms of large weights and biases (in terms of maginitudes). Because we use tanh as activation values, for fixed intermediate activation values, large weights and biases are more likely to cause saturation of activation values, i.e., the inputs to tanh is large or small and thus the outputs are close to 1. To illustrate the idea, consider a simple function ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"y = w_1 tanh(w_2 x + b_2) + b_1","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Given a reasonable x (e.g., xapprox 01), if w_2 or b_2 is large, y approx b_1 pm w_1, and thus the effective DOF is 2; if w_2 and b_2 is close to 0, yapprox w_1 w_2 x + w_1 b_2 + b_1, perturbation of all four parameters w_1, w_2, b_1, b_2 may contribute to the change of y, and thus the effective DOF is 4. In sum, trust region methods yield weights and biases with smaller magnitudes compared to BFGS/LBFGS in general, and thus achieve more effective DOFs. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"This conjecture is confirmed by the following plot, which shows the histogram of the intermediate activation values. We fixed the input x = (0505) (the midpoint of the computational domain), and collected all the outputs of the tanh function within the DNN. The figure shows that compared to the trust region method, the activation values of ADAM, BFGS and LBFGS are more concentrated near the extreme values -1 and 1. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"(Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"How can trust region methods manage the magnitudes of the weights and biases? The benefit is intrinsic to how the trust region method works: it only searches for \"optimal solution\" with a small neighborhood of the current state. However, BFGS and LBFGS searches for \"optimal solution\" along a direction aggressively. Given so many local minima, it is very likely that BFGS and LBFGS get trapped in a local minimum with smaller effective DOFs. In this perspective, trust region methods are useful methods for avoiding (instead of \"escaping\") bad local minima. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"ADAM BFGS LBFGS Trust Region\n(Image: ) (Image: ) (Image: ) (Image: )\n132 34 41 38","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"In the above plot, we show the eigenvalue distribution of the Hessian matrix for ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"l(theta) = sum_i=1^n (kappa_theta(x_i) - kappa_i)^2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here kappa_i is the true kappa value at location x_i (x_i is the Gauss quadrature point), and kappa_theta(x_i) is the DNN estimate. We get rid of the PDE out of the loss function. The pattern of the eigenvalue distribution–-a few positive eigenvalues accompanied by zero eigenvalues–-still persists. The difference is that the number of positive eigenvalues are slightly larger than the loss function that couples DNNs and PDEs.This implies that PDEs restricts effective DOFs. We attribute the diminished effective DOFs to the physical constraints imposed by PDEs. ","category":"page"},{"location":"second_order_optimizer/#Example:-FEM-for-Static-Poisson's-Equation","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Example: FEM for Static Poisson's Equation","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Consider the Poisson's equation again. This time, the loss function is formulated as ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"L(theta) = sum_i (u_obs(x_i) - u_theta(x_i))^2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Here u_theta is the numerical solution to the Poisson's equation. The evaluation of nabla^2_theta L(theta) requires back-propagating the Hessian matrix through various operators including the sparse solver (see this post for how the back-propagation rule is implemented). ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The following shows an example of the implementation, which is annotated for convenience. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"using AdFem \nusing PyPlot \nusing LinearAlgebra\nusing JLD2\n\n# disable auth reordering so that the Hessian back-propagation works properly \nADCME.options.sparse.auto_reorder = false\n\nusing Random; Random.seed!(233)\nsess = Session()\n\nfunction simulate(θ)\n\n    # The first part is a standard piece of codes for doing numerical simulation in ADCME \n    global mmesh = Mesh(10,10,0.1)\n    x = gauss_nodes(mmesh)\n    Fsrc = eval_f_on_gauss_pts((x,y)->1.0, mmesh)\n    \n    global kappa = squeeze(fc(x, [20,20,20,1], θ)) + 0.5\n    A_orig = compute_fem_laplace_matrix1(kappa, mmesh)\n    F = compute_fem_source_term1(Fsrc, mmesh)\n    global bdnode = bcnode(mmesh)\n    global A, F = impose_Dirichlet_boundary_conditions(A_orig, F, bdnode, zeros(length(bdnode)))\n\n    @load \"Data/fwd_data.jld2\" sol \n    SOL = sol \n    \n    global sol = A\\F\n\n    global loss = sum((sol-SOL)^2)\n\n    # We now calculate some extra tensors for use in Hessian back-propagation \n\n    # We use the TensorFlow tf.hessians (hessian in ADCME) to calculate the Hessian of DNNs. Note this algorithm is different from second order PCL \n    global H_dnn_pl, W_dnn_pl = pcl_hessian(kappa, θ, loss)\n    global dsol = gradients(loss, sol)\n    global dθ = gradients(loss, θ)\n\n    # We need the indices for sparse matrices in the Hessian back-propagation \n    init(sess)\n    global indices_orig = run(sess, A_orig.o.indices) .+ 1\n    global indices = run(sess, A.o.indices) .+ 1\n\nend\n\n\nfunction calculate_hessian(θ0)\n    # Retrieve intermediate values. Note in an optimized implementation, these values should already be available in the \"tape\". However, because second order PCL is currently in development, we recalculate these values for simplicity \n    A_vals, sol_vals, dsol_vals  = run(sess, [A.o.values, sol, dsol], θ=>θ0)\n\n    # SoPCL for `loss = sum((sol-SOL)^2)`\n    W = pcl_square_sum(length(sol))\n\n    # SoPCL for `sol = A\\F` \n    W = pcl_sparse_solve(indices, \n        A_vals, \n        sol_vals, \n        W, \n        dsol_vals)\n        \n    # SoPCL for `A, F = impose_Dirichlet_boundary_conditions(...)`\n    J = pcl_impose_Dirichlet_boundary_conditions(indices_orig, bdnode, size(indices,1))\n    W = pcl_linear_op(J, W)\n\n    # SoPCL for `A_orig = compute_fem_laplace_matrix1(kappa, mmesh)`\n    J = pcl_compute_fem_laplace_matrix1(mmesh)\n    W = pcl_linear_op(J, W)\n\n    # SoPCL for DNN\n    run(sess, H_dnn_pl, feed_dict=Dict(W_dnn_pl=>W, θ=>θ0))\nend\n\nfunction calculate_gradient(θ0)\n    run(sess, dθ, θ=>θ0)\nend\n\nfunction calculate_loss(θ0)\n    L = run(sess, loss, θ=>θ0)\n    @info \"Loss = $L\"\n    L\nend\n\n# The optimization step\nθ = placeholder(fc_init([2,20,20,20,1]))\nsimulate(θ)\nres = opt.minimize(\n    calculate_loss,\n    θ0,\n    method = \"trust-exact\",\n    jac = calculate_gradient,\n    hess = calculate_hessian,\n    tol = 1e-12,\n    options = Dict(\n        \"maxiter\"=> 5000,\n        \"gtol\"=>0.0 # force the optimizer not to stop\n    )\n)","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"It is very important that before we perform the optimization, we carry out the Hessian test using the test_hessian function.","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"function test_f(θ0)\n    calculate_gradient(θ0), calculate_hessian(θ0)\nend\nθ0 = run(sess, θ)\ntest_jacobian(test_f, θ0, scale=1e-3)","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"This should give us a plot as follows:","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"(Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Now let us consider the inverse problem. First we generate the observation using ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"kappa(x) = frac11+x_2^2+1","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The observation is shown as below","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"(Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"We use the full field data for simplicity, although our method also applies to sparse observations. The following plots shows results where the trust region method performs significantly better than the BFGS and LBFGS method. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Case 1","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Description Result\nLoss (Image: )\nLBFGS (Image: )\nBFGS (Image: )\nTrust Region (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Case 2","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Description Result\nLoss (Image: )\nLBFGS (Image: )\nBFGS (Image: )\nTrust Region (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Case 3","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Description Result\nLoss (Image: )\nLBFGS (Image: )\nBFGS (Image: )\nTrust Region (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"In the following plots, we show the absolute eigenvalue distributions of Hessians at the terminal point for Case 2. The red dashed line represents the level 10^-6lambda_max, where lambda_max is the maximum eigenvalue. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"LBFGS BFGS Trust Region\n(Image: ) (Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Eigenvalues that lie below the red dashed line can be treated as zero. This means that for BFGS and the trust region method, the optimizers find local minima. In fact, we show ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"F(alpha) = L(x^* + alpha v)","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"in the following plots, where x^* is the converged point for LBFGS, v is the eigenvector corresponding to either the minimum or maximum eigenvalues of the Hessian. The profile for the former case is quite flat, indicating that small perturbation along the eigenvector direction makes little change to the loss function. Thus, for LBFGS, we can also assume that a local minimum is found. ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Interestingly, even though all optimizers find local minima. The final loss functions and errors are quite different. Trust methods perform much better in these cases compared to BFGS and LBFGS (in some other cases, BFGS may perform better). ","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"lambda_min lambda_max\n(Image: ) (Image: )","category":"page"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"The problem itself is nonconvex and has many local minima–-different from the common belief that in deep learning, stationary points are usually saddle points if they are not the global minimum. Trust region methods do not guarantee that we can find a global  minimum, or even a \"good\" local minimum. However, because trust region methods shows faster convergence and superior accuracy in many cases, it never harms to add trust region methods into the optimization tool box. Additionally, the Hessian calculated using the second order PCL is a powerful weapon for diagnosing the convergence and provides curvature information for more sophisticated optimizers. ","category":"page"},{"location":"second_order_optimizer/#Limitations","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Limitations","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Despite many promising features of the trust region method, it is not without limitations, which we want to discuss here. The current trust-region method requires calculating the Hessian matrix. Firstly, computing the Hessian matrix can be technically difficult, especially when DNNs are coupled with a sophisticated numerical PDE solver. There are many existing techniques for computing the Hessian. The TensorFlow backend supports Hessian computation concurrently, but it requires users to implement rules for calculating \"gradients of gradients\". Additionally, TensorFlow uses reverse-mode automatic differentiation to evaluate the Hessian. This means that TensorFlow loops over each gradient component and calculating a row of Hessian at a time. This does not leverage the symmetry of Hessians and can be quite inefficient if the number of unknowns is large. Another approach, the edge pushing algorithm, uses one backward pass to evaluate the Hessian. This approach takes advantage of the symmetry of Hessians. However, the implementation can be quite convolved and computations can be expensive in some scenarios. We will cover this topic in more details in another post. ","category":"page"},{"location":"second_order_optimizer/#Conclusion","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Conclusion","text":"","category":"section"},{"location":"second_order_optimizer/","page":"Training Deep Neural Networks with Trust-Region Methods","title":"Training Deep Neural Networks with Trust-Region Methods","text":"Trust-region methods are a class of global optimization techniques. They are less popular in the deep learning approach because the DNNs tend to be huge and the computation of Hessians is expensive. However, they are very suitable for many computational engineering problems, where DNNs are typically small, and convergence as well as accuracy is a critical concern. Our point of view is that although the Hessian computations are expensive, they are quite rewarding. Future researches will focus on efficient computation and automation of Hessian computations. ","category":"page"},{"location":"bnn/#Bayesian-Neural-Networks","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"","category":"section"},{"location":"bnn/#Uncertainty-Quantification","page":"Bayesian Neural Networks","title":"Uncertainty Quantification","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"We want to quantify uncertainty. But what is uncertainty? In the literature, there are usually two types of uncertainty: aleatoric, the irreducible part of the uncertainty, and epidemic, the reducible part of the uncertainty. For example, when we flip a coin, the outcome of one experiment is intrinsically stochastic, and we cannot reduce the uncertainty by conducting more experiments. However, if we want to estimate the probability of heads, we can reduce the uncertainty of estimation by observing more experiments.  In finance, the words for these two types of uncertainty is systematic and non-systematic uncertainty. The total uncertainty is composed of these two types of uncertainty.  ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Statistics Finance Reducibility\naleatoric systematic irreducible\nepidemic non-systematic reducible","category":"page"},{"location":"bnn/#Bayesian-Thinking","page":"Bayesian Neural Networks","title":"Bayesian Thinking","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"One popular approach for uncertainty quantification is the Bayesian method. One distinct characteristic of the Bayesian method is that we have a prior. The prior can be subjective: it is up to the researcher to pick and justify one. Even for the so-called non-informative prior, it introduces some bias if the posterior is quite different from the prior. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"However, this should be the most exciting part of the Bayesian philosophy: as human beings, we do have prior knowledge on stochastic events. The prior knowledge can be domain specific knowledge, experience, or even opinions. As long as we can justify the prior well, it is fine. ","category":"page"},{"location":"bnn/#Bayesian-Neural-Network","page":"Bayesian Neural Networks","title":"Bayesian Neural Network","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"The so-called Bayesian neural network is the application of the Bayesian thinking on neural networks. Instead of treating the weights and biases as deterministic numbers, we consider them as probability distributions with certain priors. As we collect more and more data, we can calculate the posteriors. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"But why do we bother with the Bayesian approach? For example, if we just want to quantify the uncertainty in the prediction, suppose we have a point estimation w for the neural network, we can perturb w a little and run the forward inference. This process will give us many candidate values of the prediction, which serve as our uncertainty estimation. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"If we think about it, it is actually an extreme case in the Bayesian approach: we actually use the prior to do uncertainty quantification. The perturbation is our prior, and we have not taken into account of the observed data for constructing the distribution except for that we get our point estimation w. The Bayesian approach goes a bit further: instead of just using a prior, we use data to calibrate our distribution, and this leads to the posterior. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"The following figure shows training of a Bayesian network. The figure with the title \"Prior\" is obtained by using a prior distribution. From 1 to 3, the weight for the data (compared to the prior) is larger and larger. We can see the key idea of Bayesian methods is a trade-off game between how strongly we believe in our point estimation, and how eagerly we want to take the uncertainty exposed in the data into consideration. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Point Estimation Prior 1 2 3\n(Image: ) (Image: ) (Image: ) (Image: ) (Image: )","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"using ADCME\nusing PyPlot\n\n\nx0 = rand(100)\nx0 = @. x0*0.4 + 0.3\nx1 = collect(LinRange(0, 1, 100))\ny0 = sin.(2π*x0)\nw = Variable(fc_init([1, 20, 20, 20, 1]))\ny = squeeze(fc(x0, [20, 20, 20, 1], w))\nloss = sum((y - y0)^2)\n\nsess = Session(); init(sess)\nBFGS!(sess, loss)\ny1 = run(sess, y)\nplot(x0, y0, \".\", label=\"Data\")\nx_dnn = run(sess,  squeeze(fc(x1, [20, 20, 20, 1], w)))\nplot(x1, x_dnn,  \"--\", label=\"DNN Estimation\")\nlegend()\nw1 = run(sess, w)\n\n\n\n##############################\n\nμ = Variable(w1)\nρ = Variable(zeros(length(μ)))\nσ = log(1+exp(ρ))\n\nfunction likelihood(z)\n    w = μ + σ * z\n    y = squeeze(fc(x0, [20, 20, 20, 1], w))\n    sum((y - y0)^2) - sum((w-μ)^2/(2σ^2)) + sum((w-w1)^2)\nend\n\nfunction inference(x)\n    z = tf.random_normal((length(σ),), dtype=tf.float64)\n    w = μ + σ * z\n    y = squeeze(fc(x, [20, 20, 20, 1], w))|>squeeze\nend\n\nW = tf.random_normal((10, length(w)), dtype=tf.float64)\nL = constant(0.0)\nfor i = 1:10\n    global L += likelihood(W[i])\nend\n\ny2 = inference(x1)\n\n\nopt = AdamOptimizer(0.01).minimize(L)\ninit(sess)\n# run(sess, L)\nlosses = []\nfor i = 1:2000\n    _, l = run(sess, [opt, L])\n    push!(losses, l)\n    @info i, l\nend\n\nY = zeros(100, 1000)\nfor i = 1:1000\n    Y[:,i] = run(sess, y2)\nend\n\nfor i = 1:1000\n    plot(x1, Y[:,i], \"--\", color=\"gray\", alpha=0.5)\nend\nplot(x1, x_dnn, label=\"DNN Estimation\")\nplot(x0, y1, \".\", label=\"Data\")\nlegend()\n\n\n##############################\n# Naive Uncertainty Quantification \nfunction inference_naive(x)\n    z = tf.random_normal((length(w1),), dtype=tf.float64)\n    w = w1 + log(2)*z\n    y = squeeze(fc(x, [20, 20, 20, 1], w))|>squeeze\nend\ny3 = inference(x1)\n\nY = zeros(100, 1000)\nfor i = 1:1000\n    Y[:,i] = run(sess, y3)\nend\n\nfor i = 1:1000\n    plot(x1, Y[:,i], \"--\", color=\"gray\", alpha=0.5)\nend\nplot(x1, x_dnn, label=\"DNN Estimation\")\nplot(x0, y1, \".\", label=\"Data\")\nlegend()","category":"page"},{"location":"bnn/#Training-the-Neural-Network","page":"Bayesian Neural Networks","title":"Training the Neural Network","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"One caveat here is that deep neural networks may be hard to train, and we may get stuck at a local minimum. But even in this case, we can get an uncertainty quantification. But is it valid? No. The Bayesian approach assumes that your prior is reasonable. If we get stuck at a bad local minimum w, and use a prior mathcalN(w sigma I), then the results are not reliable at all. Therefore, to obtain a reasonable uncertainty quantification estimation, we need to make sure that our point estimation is valid. ","category":"page"},{"location":"bnn/#Mathematical-Formulation","page":"Bayesian Neural Networks","title":"Mathematical Formulation","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Now let us do the math. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Bayesian neural networks are different from plain neural networks in that weights and biases in Bayesian neural networks are interpreted in a probabilistic manner. Instead of finding a point estimation of weights and biases, in Bayesian neural networks, a prior distribution is assigned to the weights and biases, and a posterior distribution is obtained from the data. It relies on the Bayes formula ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"p(wmathcalD) = fracp(mathcalDw)p(w)p(mathcalD)","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Here mathcalD is the data, e.g., the input-output pairs of the neural network (x_i y_i), w is the weights and biases of the neural network, and p(w) is the prior distribution. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"If we have a full posterior distribution p(wmathcalD), we can conduct predictive modeling using ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"p(yx mathcalD) = int p(yx w) p(wmathcalD)d w","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"However, computing p(wmathcalD) is usually intractable since we need to compute the normalized factor p(mathcalD) = int p(mathcalDw)p(w) dw, which requires us to integrate over all possible w. Traditionally, Markov chain Monte Carlo (MCMC) has been used to sample from p(wmathcalD) without evaluating p(mathcalD). However, MCMC can converge very slowly and requires a voluminous number of sampling, which can be quite expensive. ","category":"page"},{"location":"bnn/#Variational-Inference","page":"Bayesian Neural Networks","title":"Variational Inference","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"In Bayesian neural networks, the idea is to approximate p(wmathcalD) using a parametrized family p(wtheta), where theta is the parameters. This method is called variational inference. We minimize the KL divergeence between the true posterior and the approximate posterial to find the optimal theta","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"textKL(p(wtheta)p(wmathcalD)) = textKL(p(wtheta)p(W)) - mathbbE_p(wtheta)log p(mathcalDw) + log p(mathcalD)","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Evaluating p(mathcalD)geq 0 is intractable, so we seek to minimize a lower bound of the KL divergence, which is known as variational free energy","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"F(mathcalD theta) =  textKL(p(wtheta)p(w)) - mathbbE_p(wtheta)log p(mathcalDw)","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"In practice, thee variational free energy is approximated by the discrete samples ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"F(mathcalD theta) approx  frac1Nsum_i=1^N leftlog p(w_itheta)) - log p(w_i)  - log p(mathcalDw_i)right","category":"page"},{"location":"bnn/#Parametric-Family","page":"Bayesian Neural Networks","title":"Parametric Family","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"In Baysian neural networks, the parametric family is usually chosen to be the Gaussian distribution. For the sake of automatic differentiation, we usually parametrize w using ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"w = mu + sigma otimes zqquad z sim mathcalN(0 I) tag1","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Here theta = (mu sigma). The prior distributions for mu and sigma are given as hyperparameters. For example, we can use a mixture of Gaussians as prior ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"pi_1 mathcalN(0 sigma_1) + pi_2 mathcalN(0 sigma_2)","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"The advantage of Equation 1 is that we can easily obtain the log probability log p(wtheta). ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Because sigma should always be positive, we can instead parametrize another parameter rho and transform rho to sigma using a softplus function ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"sigma = log (1+exp(rho))","category":"page"},{"location":"bnn/#Example","page":"Bayesian Neural Networks","title":"Example","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Now let us consider a concrete example. The following example is adapted from this post. ","category":"page"},{"location":"bnn/#Generating-Training-Data","page":"Bayesian Neural Networks","title":"Generating Training Data","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"We first generate some 1D training data ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"using ADCME\nusing PyPlot \nusing ProgressMeter\nusing Statistics\n\nfunction f(x, σ)\n    ε = randn(size(x)...) * σ\n    return 10 * sin.(2π*x) + ε\nend\n\nbatch_size = 32\nnoise = 1.0\n\nX = reshape(LinRange(-0.5, 0.5, batch_size)|>Array, :, 1)\ny = f(X, noise)\ny_true = f(X, 0.0)\n\nclose(\"all\")\nscatter(X, y, marker=\"+\", label=\"Training Data\")\nplot(X, y_true, label=\"Truth\")\nlegend()","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"(Image: )","category":"page"},{"location":"bnn/#Construct-Bayesian-Neural-Network","page":"Bayesian Neural Networks","title":"Construct Bayesian Neural Network","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"\nmutable struct VariationalLayer\n    units\n    activation\n    prior_σ1\n    prior_σ2\n    prior_π1\n    prior_π2\n    Wμ\n    bμ\n    Wρ\n    bρ\n    init_σ\nend\n\nfunction VariationalLayer(units; activation=relu, prior_σ1=1.5, prior_σ2=0.1,\n        prior_π1=0.5)\n    init_σ = sqrt(\n        prior_π1 * prior_σ1^2 + (1-prior_π1)*prior_σ2^2\n    )\n    VariationalLayer(units, activation, prior_σ1, prior_σ2, prior_π1, 1-prior_π1,\n                        missing, missing, missing, missing, init_σ)\nend\n\nfunction kl_loss(vl, w, μ, σ)\n    dist = ADCME.Normal(μ,σ)\n    return sum(logpdf(dist, w)-logprior(vl, w))\nend\n\nfunction logprior(vl, w)\n    dist1 = ADCME.Normal(constant(0.0), vl.prior_σ1)\n    dist2 = ADCME.Normal(constant(0.0), vl.prior_σ2)\n    log(vl.prior_π1*exp(logpdf(dist1, w)) + vl.prior_π2*exp(logpdf(dist2, w)))\nend\n\nfunction (vl::VariationalLayer)(x)\n    x = constant(x)\n    if ismissing(vl.bμ)\n        vl.Wμ = get_variable(vl.init_σ*randn(size(x,2), vl.units))\n        vl.Wρ = get_variable(zeros(size(x,2), vl.units))\n        vl.bμ = get_variable(vl.init_σ*randn(1, vl.units))\n        vl.bρ = get_variable(zeros(1, vl.units))\n    end\n    Wσ = softplus(vl.Wρ)\n    W = vl.Wμ + Wσ.*normal(size(vl.Wμ)...) \n    bσ = softplus(vl.bρ)\n    b = vl.bμ + bσ.*normal(size(vl.bμ)...)\n    loss = kl_loss(vl, W, vl.Wμ, Wσ) + kl_loss(vl, b, vl.bμ, bσ)\n    out = vl.activation(x * W + b)\n    return out, loss \nend\n\nfunction neg_log_likelihood(y_obs, y_pred, σ)\n    y_obs = constant(y_obs)\n    dist = ADCME.Normal(y_pred, σ)\n    sum(-logpdf(dist, y_obs))\nend\n\nipt = placeholder(X)\nx, loss1 = VariationalLayer(20, activation=relu)(ipt)\nx, loss2 = VariationalLayer(20, activation=relu)(x)\nx, loss3 = VariationalLayer(1, activation=x->x)(x)\n\nloss_lf = neg_log_likelihood(y, x, noise)\nloss = loss1 + loss2 + loss3 + loss_lf","category":"page"},{"location":"bnn/#Optimization","page":"Bayesian Neural Networks","title":"Optimization","text":"","category":"section"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"We use an ADAM optimizer to optimize the loss function. In this case, quasi-Newton methods that are typically used for deterministic function optimization are not appropriate because the loss function essentially involves stochasticity. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"Another caveat is that because the neural network may have many local minimum, we need to run the optimizer multiple times in order to obtain a good local minimum. ","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"\nopt = AdamOptimizer(0.08).minimize(loss)\nsess = Session(); init(sess)\n@showprogress for i = 1:5000\n    run(sess, opt)\nend\n\n\nX_test = reshape(LinRange(-1.5,1.5,32)|>Array, :, 1)\ny_pred_list = []\n@showprogress for i = 1:10000\n    y_pred = run(sess, x, ipt=>X_test)\n    push!(y_pred_list, y_pred)\nend\n\ny_preds = hcat(y_pred_list...)\n\ny_mean = mean(y_preds, dims=2)[:]\ny_std = std(y_preds, dims=2)[:]\n\nclose(\"all\")\nplot(X_test, y_mean)\nscatter(X[:], y[:], marker=\"+\")\nfill_between(X_test[:], y_mean-2y_std, y_mean+2y_std, alpha=0.5)","category":"page"},{"location":"bnn/","page":"Bayesian Neural Networks","title":"Bayesian Neural Networks","text":"(Image: )","category":"page"},{"location":"tu_implicit/#Advanced:-Automatic-Differentiation-for-Implicit-Operators","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"","category":"section"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"An explicit operator is an operator directly supplied by the AD library while an implicit operator is an operator whose outputs must be computed using compositions of functions that may not be differentiable, or involving iterative algorithms. For example, y = textttsigmoid(x) is an implicit operator while x = textttsigmoid(y) is an implicit operator if the library does not provide textttsigmoid^-1, where x is the input and y is the output. ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Implicit operators are everywhere in scientific computing, from implicit numerical schemes to iterative algorithms. How to incooperate implicit operators into a differentiable programming framework is the true challenge in AD. AD is not the panacea to all inverse modeling problems; it must be augmented with abilities to tackle implicit operators to be real useful for a large variety of real-world applications. ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"(Image: Operators) ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Roughly speaking, there are four types of operators in the computational graph, depending on whether it is linear or nonlinear and whether it is explicit or implicit. Let A be a matrix, f be a nonlinear function, F be a bivariate nonlinear function, and it is hard to express y analytically as a function of x in F(xy)=0. ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Operator Linear Nonlinear\nExplicit y = Ax y = f(x)\nImplicit Ay = x F(x y)=0","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"It is straightforward to apply AD to explicit operators, provided that the AD library supports the corresponding operators A and f (which usually do). In this tutorial, we focus on the implicit operators. ","category":"page"},{"location":"tu_implicit/#Implicit-Function-Theorem","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Implicit Function Theorem","text":"","category":"section"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"We change our notation for clarity in this section. Let L_h be a error functional, F_h be the corresponding nonlinear implicit operator, theta is all the input to this operator and u_h is all the output of this node.","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"beginaligned\n    min_theta L_h(u_h) \n    mathrmst F_h(theta u_h) = 0\nendaligned","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Assume in the forward computation, we solve for u_h=G_h(theta) in F_h(theta u_h)=0, and then ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"tilde L_h(theta)  = L_h(G_h(theta))","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Applying the implicit function theorem ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"beginaligned\n\t fracpartial F_h(theta u_h)partial theta  + fracpartial F_h(theta u_h)partial u_h  fracpartial G_h(theta)partial theta = 0 qquad Rightarrow 4pt\n     fracpartial G_h(theta)partial theta =  -Big( fracpartial F_h(theta u_h)partial u_h Big)^ - 1 fracpartial F_h(theta u_h)partial theta \nendaligned","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"therefore we have","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"beginaligned\n    fracpartial tilde L_h(theta )partial theta  \n    = fracpartial  L_h(u_h )partial u_hfracpartial G_h(theta)partial theta \n    = - fracpartial L_h(u_h)partial u_h \n    Big( fracpartial F_h(theta u_h)partial u_hBig_u_h = G_h(theta ) Big)^ - 1 \n    fracpartial F_h(theta u_h)partial theta Big_u_h = G_h(theta )\nendaligned","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"This is the desired gradient. For efficiency, the computation strategy is crucial. We can either evaluate from left to right or from right to left. The correct approach is to compute from left to right. A detailed justification of this computational order is beyond the scope of this tutorial. Instead, we simply list the steps for calculating the gradients ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Step 1: Calculate w by solving a linear system (never invert the matrix!)","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"w^T = underbracefracpartial L_h(u_h)partial u_hrule-9pt1pt0pt_1times N \n        \n        underbraceBig( fracpartial F_hpartial u_hBig_u_h = G_h(theta ) Big)^ - 1_Ntimes N","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Step 2: Calculate the gradient by automatic differentiation ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"w^Tunderbracefracpartial F_hpartial theta Big_u_h = G_h(theta )_Ntimes p = fracpartial (w^T  F_h(theta u_h))partial theta Bigg_u_h = G_h(theta )","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"This step can be done using independent, which stops back-propagating the gradients for its argument.  ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"l  = L(u)\nr  = F(theta, u)\ng  = gradients(l, u)\nx  = dF'\\g\nx  = independent(x)\ndL = -gradients(sum(r*x), theta)","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Despite the complex nature of this approach, it is quite powerful and efficient in treating implicit operators. To make it more clear, we consider a simpler special case below: the linear implicit operator. ","category":"page"},{"location":"tu_implicit/#Special-Case:-Linear-Implicit-Operator","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Special Case: Linear Implicit Operator","text":"","category":"section"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"The linear implicit operator can be viewed as a special case of the nonlinear explicit operator. In this case","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"F(xy) = x - Ay","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"and therefore ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"fracpartial Jpartial x = fracpartial Jpartial yA^-1","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"This requires us to solve a linear system with the adjoint of A, i.e., ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"A^T g = left(fracpartial Jpartial yright)^T","category":"page"},{"location":"tu_implicit/#Implementation-in-ADCME","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Implementation in ADCME","text":"","category":"section"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"Let's see in action how to implement an implicit operator in ADCME. First of all, we can use the NonlinearConstrainedProblem used in Functional Inverse Problem. The API is suitable when the residual and the Jacobian matrix can be expressed using ADCME operators (or through custom operators) and a general Newton-Raphson algorithm is satisfactory. However, if the forward solver is performance critical and requires special accleration (such as preconditioning), then building custom operator is a preferable approach. ","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"This approach is named physics constrained learning and has been used to develop FwiFlow.jl, a package for elastic full waveform inversion for subsurface flow problems. The physical equation is nonlinear, the discretization is implicit, and thus it must be solved using the Newton-Raphson method.","category":"page"},{"location":"tu_implicit/","page":"Advanced: Automatic Differentiation for Implicit Operators","title":"Advanced: Automatic Differentiation for Implicit Operators","text":"(Image: diagram)","category":"page"},{"location":"topopt/#Topological-Optimization","page":"Topological Optimization","title":"Topological Optimization","text":"","category":"section"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"In this section, we present the ADCME implementation of a structural topology optimization problem. The optimization problem can be mathematically described as ","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"beginalignedmin_x  l(x u)  textst  V(x) = fV_0(x)   F(x u) = 0   0x_min  x leq  1 endaligned","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"Here x is a design variable, such as density in each element. u is the state variable, such as the displacement vector. F(x u) = 0 is the governing equation. V(x) is the total volumn and f is the prescribed volumn fraction. x_min is the lower bound for the design variable. ","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"Specifically, we consider a static linear elasticity load problem, where the governing equation is discretized to a linear system ","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"K(x) U - F = 0","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"Here U is the discretized solution for u, F is the load vector, K(x) is the stiffness matrix. The discretized loss function L is the strain energy, which has the form ","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"L(x U) = U^T K(x) U = F^T K(x)^-1 F","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"The original optimization problem becomes a constrained optimization problem. The following code is used for forward computation","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"using AdFem \n\nm = 32\nn = 20 \nh = 1.0\nfracvol = 0.4\np = 3.0\nx = Variable(fracvol*ones(m*n))\nρ = reshape(repeat(x^p, 1, 4), (-1,1))\nke = compute_plane_stress_matrix(1.0,0.3)\nρ = reshape(ρ * reshape(ke, 1, 9), (-1,3,3))\nK = compute_fem_stiffness_matrix(ρ, m, n, h)\n\nbdedge = bcedge(\"right\", m, n, h)\nt1 = zeros(size(bdedge,1))\nt2 = zeros(size(bdedge, 1))\nt2[end] = 0.0001\nF = compute_fem_traction_term([t1 t2],bdedge, m, n, h)\n\nbdnode = bcnode(\"left\", m, n, h)\n\nK_, F_ = impose_Dirichlet_boundary_conditions(K, F, [bdnode; bdnode .+ (m+1)*(n+1)], zeros(2length(bdnode)))\nsol = K_\\F_","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"Here shows the initial guess for x:","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"using PyPlot \nsess = Session(); init(sess)\nSOL = run(sess, sol)\nvisualize_displacement(reshape(SOL, 1, :), m, n, h)\nsavefig(\"init_opt.png\")","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"We will use the Ipopt optimizer to solve the constraint optimization problem. The following code ","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"import Ipopt\n\nloss = sum(sol'*K*sol)\n\nfunction eval_g(x, g)\n    g[1] = sum(x) - fracvol*m*n\nend\nfunction eval_jac_g(x, mode, rows, cols, values)\n  if mode == :Structure\n    for i = 1:length(x)\n        rows[i] = 1; cols[i] = i\n    end\n  else\n    for i = 1:length(x)\n        values[i] = 1.0\n    end\n  end\nend\n\nfunction opt(f, g, fg, x0, kwargs...)\n    prob = Ipopt.createProblem(m*n, 1e-6*ones(m*n), ones(m*n), 1, zeros(1), zeros(1), m*n, 0,\n                     f, eval_g, (x,G)->g(G, x), eval_jac_g, nothing)\n    prob.x = x0 \n    Ipopt.addOption(prob, \"hessian_approximation\", \"limited-memory\")\n    \n    status = Ipopt.solveProblem(prob)\n    println(Ipopt.ApplicationReturnStatus[status])\n    Ipopt.freeProblem(prob)\n    nothing\nend\n\nsess = Session(); init(sess)\nlosses = Optimize!(sess, loss, optimizer = opt)\n\nvisualize_scalar_on_fvm_points(run(sess, x).^p, m, n, h, vmin = 0, vmax = 1)","category":"page"},{"location":"topopt/","page":"Topological Optimization","title":"Topological Optimization","text":"(Image: )","category":"page"},{"location":"newton_raphson/#Newton-Raphson","page":"Newton Raphson","title":"Newton Raphson","text":"","category":"section"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"Newton-Raphson algorithm is widely used in scientific computing. In ADCME, the function for the algorithm is newton_raphson. And the signature is","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"newton_raphson","category":"page"},{"location":"newton_raphson/#ADCME.newton_raphson","page":"Newton Raphson","title":"ADCME.newton_raphson","text":"newton_raphson(func::Function, \n    u0::Union{Array,PyObject}, \n    θ::Union{Missing,PyObject, Array{<:Real}}=missing,\n    args::PyObject...) where T<:Real\n\nNewton Raphson solver for solving a nonlinear equation.  ∘ func has the signature \n\nfunc(θ::Union{Missing,PyObject}, u::PyObject)->(r::PyObject, A::Union{PyObject,SparseTensor}) (if linesearch is off)\nfunc(θ::Union{Missing,PyObject}, u::PyObject)->(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor}) (if linesearch is on)\n\nwhere r is the residual and A is the Jacobian matrix; in the case where linesearch is on, the function value fval must also be supplied. ∘ θ are external parameters. ∘ u0 is the initial guess for u ∘ args: additional inputs to the func function  ∘ kwargs: keyword arguments to func\n\nThe solution can be configured via ADCME.options.newton_raphson\n\nmax_iter: maximum number of iterations (default=100)\nrtol: relative tolerance for termination (default=1e-12)\ntol: absolute tolerance for termination (default=1e-12)\nLM: a float number, Levenberg-Marquardt modification x^k+1 = x^k - (J^k + mu^k)^-1g^k (default=0.0)\nlinesearch: whether linesearch is used (default=false)\n\nCurrently, the backtracing algorithm is implemented. The parameters for linesearch are supplied via options.newton_raphson.linesearch_options\n\nc1: stop criterion, f(x^k)  f(0) + alpha c_1  f(0)\nρ_hi: the new step size alpha_1leq rho_hialpha_0 \nρ_lo: the new step size alpha_1geq rho_loalpha_0 \niterations: maximum number of iterations for linesearch\nmaxstep: maximum allowable steps\nαinitial: initial guess for the step size alpha\n\n\n\n\n\n","category":"function"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"As an example, assume we want to solve ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"u_i^2 - 1 = 0 i=12ldots 10","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"We first need to construct a function ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"function f(θ, u)\n    return u^2 - 1, 2*spdiag(u)\nend","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"Here 2textttspdiag(u) is the Jacobian matrix for the equation. Then we construct a Newton Raphson solver via","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"nr = newton_raphson(f, constant(rand(10)))","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"nr is a NRResult struct which is runnable and can be materialized by ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"nr = run(sess, nr)","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"The signature for NRResult is ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"struct NRResult\n    x::Union{PyObject, Array{Float64}} # final solution\n    res::Union{PyObject, Array{Float64, 1}} # residual\n    u::Union{PyObject, Array{Float64, 2}} # solution history\n    converged::Union{PyObject, Bool} # whether it converges\n    iter::Union{PyObject, Int64} # number of iterations\nend","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"uin mathbbR^ptimes n where p is the solution dimension and n is the number of iterations. ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"note: Note\nSometimes we want to construct f via some external variables theta, e.g., when theta is a trainable variable and embeded in the Newton-Raphson solver, we can pass this parameter to newton_raphson via the third parameternr = newton_raphson(f, constant(rand(10)),θ)","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"note: Note\nWe can provide options to newton_raphson using ADCME.options.newton_raphson. For exampleADCME.options.newton_raphson.verbose = true \nADCME.options.newton_raphson.tol = 1e-6\nnr = newton_raphson(f, constant(rand(10)), missing)This might be useful for debugging.","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"In the case we want to apply a linesearch step in our Newton-Raphson solver, we can turn on the linesearch option in options. However, in this case, we must provide the function value for f (assuming we are solving a minimization problem).  ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"function f(θ, u)\n    return sum(1/3*u^3-u), u^2 - 1, 2*spdiag(u)\nend","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"The corresponding driver code is","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"ADCME.options.newton_raphson.verbose = false\nADCME.options.newton_raphson.linesearch = true\nADCME.options.newton_raphson.tol = 1e-12\nADCME.options.newton_raphson.linesearch_options.αinitial = 1.0\nnr = newton_raphson(f, constant(rand(10)), missing","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"Finally we consider the differentiable Newton-Raphson algorithm. Consider we want to construct a map fxmapsto y, which satisfies","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"y^3-x=0","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"In a later stage, we also want to evaluate fracdydx. To this end, we can use newton_raphson_with_grad, which provides a differentiable implementation of the Newton-Raphson's algorithm. ","category":"page"},{"location":"newton_raphson/","page":"Newton Raphson","title":"Newton Raphson","text":"function f(θ, x)\n    x^3 - θ, 3spdiag(x^2)\nend\n\nθ = constant([2. .^3;3. ^3; 4. ^3])\nx = newton_raphson_with_grad(f, constant(ones(3)), θ)\nrun(sess, x)≈[2.;3.;4.]\nrun(sess, gradients(sum(x), θ))≈1/3*[2. .^3;3. ^3; 4. ^3] .^(-2/3)","category":"page"},{"location":"customopt2/#Custom-Optimizers","page":"Custom Optimizers","title":"Custom Optimizers","text":"","category":"section"},{"location":"customopt2/","page":"Custom Optimizers","title":"Custom Optimizers","text":"ADCME provides a function UnconstrainedOptimizer that allows users to craft their own optimizers for unconstrained optimization problems. ","category":"page"},{"location":"customopt2/","page":"Custom Optimizers","title":"Custom Optimizers","text":"using Optim \n\nx = Variable(rand(2))\nloss = (1-x[1])^2 + 100(x[2]-x[1]^2)^2\n\nsess = Session(); init(sess)\nuo = UnconstrainedOptimizer(sess, loss)\n\nfunction f(x)\n    return getLoss(uo, x)\nend\n\nfunction g!(G, x)\n    _, g = getLossAndGrad(uo, x)\n    G[:] = g  \nend\n\nx0 = getInit(uo)\noptimize(f, g!, x0, LBFGS())","category":"page"},{"location":"exercise/#Exercise:-Inverse-Modeling-with-ADCME","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"","category":"section"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The starter code can be downloaded here.","category":"page"},{"location":"exercise/#Background","page":"Exercise: Inverse Modeling with ADCME","title":"Background","text":"","category":"section"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The thermal diffusivity is the measure of the ease with which heat can diffuse through a material. Let u be the temperature, and kappa be the thermal diffusivity. The heat transfer process is described by the Fourier law ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"fracpartial u(mathbfx t)partial t = kappaDelta u(mathbfx t) + f(mathbfx t) quad tin (0T) xin Omega tag1","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Here f is the heat source and Omega is the domain.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"To make use of the heat equation, we need additional information. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Initial Condition: the initial temperature distribution is given by u(mathbfx 0) = u_0(mathbfx). \nBoundary Conditions: the temperature of the material is affected by what happens on the boundary. There are several possible boundary conditions. In this exercise we consider two of them:\n(1) Temperature fixed at a boundary,\nu(mathbfx t) = 0 quad mathbfxin Gamma_D tag2\n(2) Insulated boundary. The heat flow can be prescribed (known as the no flow boundary condition)\n-kappafracpartial u(mathbfxt)partial n = 0 quad mathbfxin Gamma_N tag3\nHere n is the outward normal vector. \nThe boundaries Gamma_D and Gamma_N satisfy partial Omega = Gamma_D cup Gamma_N Gamma_Dcap Gamma_N = emptyset.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Assume that we want to experiment with a piece of new material. The thermal diffusivity coefficient of the material is an unknown function of the space. Our goal of the experiment is to find out the thermal diffusivity coefficient. To this end, we place some sensors in the domain or on the boundary. The measurements are sparse in the sense that only the temperature from those sensors–-but nowhere else–-are collected. Namely, let the sensors be located at mathbfx_i_i=1^M, then we can observe hat u(mathbfx_i t)_i=1^M, i.e., the measurements of  u(mathbfx_i t) _i=1^M. We also assume that the boundary conditions, initial conditions and the source terms are known. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"(Image: ) ","category":"page"},{"location":"exercise/#Problem-1:-Parameter-Inverse-Problem-in-1D","page":"Exercise: Inverse Modeling with ADCME","title":"Problem 1: Parameter Inverse Problem in 1D","text":"","category":"section"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"We first consider the 1D case. In this problem, the material is a rod Omega=01. We consider a homogeneous (zero) fixed boundary condition on the right side, and an insulated boundary on the left side. The initial temperature is zero everywhere, i.e., u(x 0)=0, xin 01. The source term is f(x t) = exp(-10(x-05)^2), and kappa(x) is a function of space","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"kappa(x) = a + bx","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Our task is to estimate the coefficient a and b in kappa(x). To this end, we place a sensor at x=0 and the sensor records the temperature as a time series u_0(t), tin (01). ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Recall that in lecture slide 35/47 of AD.pdf, we formulate the inverse modeling problem as a PDE-constrained optimization problem","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"beginaligned\nmin_a b  int_0^t ( u(0 t)- u_0(t))^2 dt \nmathrmst  fracpartial u(x t)partial t = kappa(x)Delta u(x t) + f(x t) quad tin (0T) xin (01) \n -kappa(0)fracpartial u(0t)partial x = 0 t0\n u(1 t) = 0 t0\n u(x 0) = 0 xin 01\n kappa(x) = a x + b\nendaligned","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"We consider the discretization of the above forward problem. We divide the domain 01 into n equispaced intervals. We consider the time horizon T = 1, and divide the time horizon 0T into m equispaced intervals. We use a finite difference scheme to solve the 1D heat equation Equations (1)–(3). Specifically, we use an implicit scheme for stability:","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"fracu^k+1_i-u^k_iDelta t = kappa_i fracu^k+1_i+1+u^k+1_i-1-2u^k+1_iDelta x^2 + f_i^k+1","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"k=12ldotsm i=12ldots n tag4","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"where Delta t is the time interval, Delta x is the space interval, u_i^k is the numerical approximation to u((i-1)Delta x (k-1)Delta t), kappa_i is the numerical approximation to kappa((i-1)Delta x) = a + b(i-1)Delta x, and f_i^k = f((i-1)Delta x (k-1)Delta t).","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"For the insulated boundary, we introduce the ghost node u_0^k at location x=-Delta x, and the insulated boundary condition can be numerically discretized by ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"-kappa_1 fracu_2^k-u_0^k2Delta x = 0tag5","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Let","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"U^k = beginbmatrixu_1^k u_2^k vdots u_n^kendbmatrix","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The index starts from 1 and ends with n. Using the finite difference scheme, together with eliminating the boundary values u_0^k, u_n+1^k, we have the following formula","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"AU^k+1 = U^k + F^k+1","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Express the matrix Ain mathbbR^ntimes n in terms of Delta t, Delta x and kappa_i_i=1^n. What is F^k+1in mathbbR^n ?","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Hint: Can you eliminate u_0^k and u_n+1^k in Eq. (4) using Eq. (5) and u_n+1^k=0 ?","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The starter code Case1D/starter1.jl precomputes the force vector F^k and packs it into a matrix Fin mathbbR^(m+1)times n. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Use spdiag[spdiag]  to construct A as a SparseTensor (see the starter code for details). spdiag is an ADCME function. See the documentation[spdiag] for the syntax. Here kappa is given by","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"kappa(x) = 2+15x","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"[spdiag]: API Reference","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"For debugging, check that your A_ij is tridiagonal. You can use run(sess, A) to evaluate the SparseTensor A. You should get the following values:","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Entry Value\nA_11 201\nA_12 -200\nA_21 -1015\nA_33 207\nA_1010 228","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The computational graph of the dynamical system can be efficiently constructed using while_loop. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Implement the forward computation using while_loop. Turn in your code.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"For debugging, you can plot the temperature on the left side, i.e., u(0t). You should have something similar to the following plot ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"(Image: )","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Now we are ready to perform inverse modeling. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Read the starter code Case1D/starter2.jl carefully and complete the missing implementations. Turn in your code. What is your estimate a and b?","category":"page"},{"location":"exercise/#Problem-2:-Function-Inverse-Problem","page":"Exercise: Inverse Modeling with ADCME","title":"Problem 2: Function Inverse Problem","text":"","category":"section"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Let us consider the function inverse problem, where we do not know the form of kappa(x). To this end, we substitute kappa(x) using a neural network. We will use physics constrained learning (PCL) to train kappa(x) from the temperature data u_0(x t), where x is the location of a sensor.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Since we do not know the form of kappa(x), we need more data to solve the inverse problem. Therefore, we assume that we place sensors at the first 25 locations in the discretized grid. The observation data data_pcl.txt is a (m+1)times 25 matrix; each column corresponds to the observation at one sensor. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"In this problem, let us parametrize kappa(x) with a fully connected neural network with 3 hidden layers, 20 neurons per layer, and tanh activation functions. In ADCME, such a neural network can be constructed using ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"y = fc(x, [20,20,20,1])","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Here x is a n times 1 input, y is a n times 1 output, 2020201 is the number of neurons per layer (last output layer only has 1 neuron), and fc stands for \"fully-connected\". ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Assume that the neural network is written as kappa_theta(x), where theta is the weights and biases.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Write down the mathematical optimization problem for the inverse modeling. What variables are we optimizing for this problem?\nComplete the starter code Case1D/starter3.jl for conducting physics constrained learning. The observation data is provided as data_pcl.txt. Run the program several times to ensure you do not terminate early at a bad local minimum. Turn in your code.\nPlot your estimated kappa_theta curve. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Hint: Your curve should look like the following","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"(Image: )","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Add 1% and 10% Gaussian noise to the dataset and redo (7). Plot the estimated kappa_theta curve. Comment on your observations.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Hint: You can add noise using","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"uc = @. uc * (1 + 0.01*randn(length(uc)))\nuc = @. uc * (1 + 0.1*randn(length(uc)))","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Here @. is for elementwise operations. ","category":"page"},{"location":"exercise/#Problem-3:-Parameter-Inverse-Problem-in-2D","page":"Exercise: Inverse Modeling with ADCME","title":"Problem 3: Parameter Inverse Problem in 2D","text":"","category":"section"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"In this problem, we will explore more deeply how ADCME works with numerical solvers. We will use an important technique, custom operators, for incorporating C++ codes. This will be useful when you want to accelerate a performance-critical part, or you want to reuse existing codes. To make the problem simple, the C++ kernel has been prepared for you. For this exercise, you will be working with Case2D/starter.jl. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"We consider the 2D case and T=1  We assume that Omega=01^2. We impose zero boundary conditions on the entire boundary Gamma_D=partialOmega. Additionally, we assume that the initial condition is zero everywhere. Two sensors are located at (0202) and (0808) and these sensors record time series of the temperature u_1(t) and u_2(t). The thermal diffusivity coefficient is a linear function of the space coordinates","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"kappa(x y) = a + bx + cy","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"where a b and c are three coefficients we want to find out from the data u_1(t) and u_2(t). ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Write down the mathematical optimization problem for the inverse modeling. As before, explain what variables we are optimizing for this problem.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"We use the finite difference method to discretize the PDE. Consider Omega=01times 01, we use a uniform grid and divide the domain into mtimes n squares, with length Delta  x. We also divide 0T into N_T intervals of equal length. The implicit scheme for the equation is ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"fracu_ij^k+1-u_ij^kDelta t = kappa_ijfracu_i+1j^k+1+u_ij+1^k+1+u_i-1j^k+1+u_ij-1^k+1-4u_ij^k+1Delta x^2 + f_ij^k+1","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"where i=23ldots m j=23ldots n k=12ldots N_T.","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Here u_ij^k is an approximation to u((i-1)h (j-1)h (k-1)Delta t), and f_ij^k = f((i-1)h (j-1)h (k-1)Delta t).","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"We flatten u_ij^k to a 1D vector U^k, using i as the leading dimension, i.e., the ordering of the vector is u_11^k u_12^k ldots; We also flatten f_ij^k+1 and kappa_ij as well. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"In this problem, we extend the AD framework using custom operators (also known as external function support in the AD community). In the starter code Case2D/starter.jl, we provide a function, heat_equation, a differentiable heat equation solver, which is already implemented for you using C++. By using custom operators, we replace the PDE solver node in the computational graph with our own, more efficient, implementation. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Read the instructions on how to compile the custom operator, and answer the following two questions. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Similar to Problem 1, implement the forward computation using while_loop with the starter code Case2D/starter.jl. Plot the curve of the temperature at (0505). ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Hint: you should obtain something similar to","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"(Image: )","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The parameters used in this problem are: m=50, n=50, T=1, N_T=50, f(mathbfxt) = e^-texp(-50((x-05)^2+(y-05)^2)), a = 15, b=10, c=20. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"The data file data.txt is a (N_T+1)times 2 matrix, where the first and the second columns are u_1(t) and u_2(t) respectively. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Use these data to do inverse modeling and report the values a b and c. We do not provide a starter code intentionally, but the forward computation codes in Case2D/starter.jl and neural-network-based inverse modeling codes in Case1D/starter3.jl will be helpful. ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"Hint: ","category":"page"},{"location":"exercise/","page":"Exercise: Inverse Modeling with ADCME","title":"Exercise: Inverse Modeling with ADCME","text":"For checking your program, you can save your own data.txt from Question 10, try to estimate a, b, and c, and check if you can recover the true values. \nIf the optimization stops too early, you can multiply your loss function by a large number (e.g., 10^10) and run your BFGS! optimizer again. An alternative approach is to use a smaller tolerance. See the BFGS! function documentation for details. ","category":"page"}]
}
