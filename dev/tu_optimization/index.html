<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>PDE Constrained Optimization · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../videos_and_slides/">Video Lectures and Slides</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li class="is-active"><a class="tocitem" href>PDE Constrained Optimization</a><ul class="internal"><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#Method-1:-Penalty-Method"><span>Method 1: Penalty Method</span></a></li><li><a class="tocitem" href="#Method-2:-Primal-and-Primal-Dual-Method"><span>Method 2: Primal and Primal-Dual Method</span></a></li><li><a class="tocitem" href="#Method-3:-Primal-Method"><span>Method 3: Primal Method</span></a></li><li><a class="tocitem" href="#Other-Optimization-Techniques"><span>Other Optimization Techniques</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../optimizers/">Optimizers</a></li><li><a class="tocitem" href="../optim/">Study on Optimizers</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li><li><a class="tocitem" href="../mcmc/">Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC</a></li><li><a class="tocitem" href="../mpi/">Distributed Scientific Machine Learning using MPI</a></li><li><a class="tocitem" href="../mpi_benchmark/">MPI Benchmarks</a></li><li><a class="tocitem" href="../multithreading/">Understand the Multi-threading Model</a></li><li><a class="tocitem" href="../rbf/">Radial Basis Functions</a></li><li><a class="tocitem" href="../topopt/">Topological Optimization</a></li><li><a class="tocitem" href="../quadrature/">Numerical Integration</a></li><li><a class="tocitem" href="../sqlite3/">Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management</a></li><li><a class="tocitem" href="../hessian/">The Mathematical Structure of DNN Hessians</a></li><li><a class="tocitem" href="../plotly/">Visualization with Plotly</a></li></ul></li><li><span class="tocitem">Physics Informed Machine Learning</span><ul><li><a class="tocitem" href="../fdtd/">Finite-difference Time-domain for Electromagnetics and Seismic Inversion</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="../flow/">Normalizing Flows</a></li><li><a class="tocitem" href="../convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="../bnn/">Bayesian Neural Networks</a></li><li><a class="tocitem" href="../reinforcement_learning/">Reinforcement Learning Basics: Q-learning and SARSA</a></li></ul></li><li><span class="tocitem">Developer Guide</span><ul><li><a class="tocitem" href="../designpattern/">Design Pattern</a></li><li><a class="tocitem" href="../toolchain/">Built-in Toolchain for Third-party Libraries</a></li><li><a class="tocitem" href="../installmpi/">Configure MPI for Distributed Computing</a></li><li><a class="tocitem" href="../windows_installation/">Install ADCME on Windows</a></li><li><a class="tocitem" href="../docker/">Install ADCME Docker Image</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href>PDE Constrained Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>PDE Constrained Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/tu_optimization.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="PDE-Constrained-Optimization"><a class="docs-heading-anchor" href="#PDE-Constrained-Optimization">PDE Constrained Optimization</a><a id="PDE-Constrained-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#PDE-Constrained-Optimization" title="Permalink"></a></h1><p>In the broad context, the physics based machine learning can be formulated as a PDE-constrained optimization problem. The PDE-constrained optimization problem aims at finding the optimal design variables such that the objective function is minimized and the constraints–-usually described by PDEs–-are satisfied. PDE-contrained optimization has a large variety of applications, such as optimal control and inverse problem. The topic is at the intersection of numerical PDE discretization, mathematical optimization, software design, and physics modeling. </p><p>Mathematically, a PDE-constrained optimization can be formulated as </p><p class="math-container">\[\begin{aligned}
\min_{y\in \mathcal{Y}, u\in \mathcal{U}}&amp;\; J(y, u)\\
\text{s.t.}&amp;\; F(y, u)=0 &amp; \text{the governing PDEs}\\
&amp;\; c(y,u)=0&amp;\text{additional equality constraints}\\
&amp;\; h(y, u)\geq 0&amp;\text{additional inequality constraints}
\end{aligned}\]</p><p>Here <span>$J$</span> is the objective function, <span>$y$</span> is the <strong>design variable</strong>, <span>$u$</span> is the <strong>state variable</strong>. </p><p>In this section, we will focus on the PDE-constrained optimization with only the governing PDE constraints, and we consider a discretize-then-optimize and gradient-based optimization approach. Specifically, the objective function and the PDEs are first discretized numerically, leading to a constrained optimization problem with  a finite dimensional optimization variable. We use gradient-based optimization because it provides fast convergence and an efficient way to integrate optimization and simulation. However, this approach requires insight into the simulator and can be quite all-consuming to obtain the gradients. </p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>We consider an exemplary PDE-constrained optimization problem: assume we want to have a specific temperature distribution on a metal bar <span>$\bar u(x)$</span> by imposing a heat source <span>$y(x)$</span> on the bar</p><p class="math-container">\[\begin{aligned}
\min_{y\in \mathcal{Y}, u\in \mathcal{U}}&amp;\; L(y, u) = \frac{1}{2}\int_0^1 \|u(x) - \bar u(x)\|^2 dx + \frac{\rho}{2}\int_0^1 y(x)^2 dx \\
\text{s.t.}&amp;\; f(y, u)=0 
\end{aligned}\]</p><p>Here <span>$f(y,u)=0$</span> is the static heat equation with the boundary conditions. </p><p class="math-container">\[c(x)u_{xx}(x) = y(x),\quad x\in (0,1), \quad u(0)=u_0, u(1)=u_1\]</p><p>where <span>$c(x)$</span> is the diffusivity coefficient, <span>$u_0$</span> and <span>$u_1$</span> are fixed boundaries. </p><p>After discretization, the optimization problem becomes</p><p class="math-container">\[\begin{aligned}
\min_{y, u}&amp;\; J(y, u) = \frac{1}{2}\|u-\bar u\|_2 + \frac{\rho}{2}\|y\|^2\\
\text{s.t.}&amp;\; F(y, u)= Ku - y = 0
\end{aligned}\tag{1}\]</p><p>where <span>$K$</span> is the stiffness matrix, taking into account of the boundary conditions, <span>$u$</span>, <span>$\bar u$</span>, and <span>$y$</span> are vectors.</p><p>In what follows, we basically apply common optimization method to the constrained optimization problem Equation 1.  </p><h2 id="Method-1:-Penalty-Method"><a class="docs-heading-anchor" href="#Method-1:-Penalty-Method">Method 1: Penalty Method</a><a id="Method-1:-Penalty-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Method-1:-Penalty-Method" title="Permalink"></a></h2><p>The simplest method for solving the unconstrained optimization problem Equation 1 is via the penalty method. Specifically, instead of solving the original constrained optimization problem, we solve </p><p class="math-container">\[\min_{y, u} \frac{1}{2}\|u-\bar u\|_2 + \frac{\rho}{2}\|y\|^2 + \lambda \|f(y, u)\|^2_2\]</p><p>where <span>$\lambda$</span> is the penalty parameter. </p><p>The penalty method is <strong>conceptually simple</strong>  and is also <strong>easy-to-implement</strong>. Additionally, it does not require solving the PDE constraint <span>$f(y,u)=0$</span> and thus the comptuational cost for each iteration can be small. However, avoid solving the PDE constraint is also a disadvantage since it means the penalty method <strong>does not eventually enforce the physical constraint</strong>. The solution from the penalty method only converges to the the true solution when <span>$\lambda\rightarrow \infty$</span>, which is <strong>not computationally feasible</strong>. Additionally, despite less cost per iteration, the total number of iterations can be huge when the PDE constraint is &quot;stiff&quot;. To gain some intuition, consider the following problem</p><p class="math-container">\[\begin{aligned}
\min_{u}&amp;\; 0\\
\text{s.t.}&amp;\;  Ku - y = 0
\end{aligned}\]</p><p>The optimal value is <span>$u = K^{-1}y$</span> and the cost by solving the linear system is usually propertional to <span>$\mathrm{cond}(K)$</span>. However, if we were to solve the problem using the penalty method </p><p class="math-container">\[\min_{u} \|Ku-y\|^2_2\]</p><p>The condition number for solving the least square problem (e.g., by solving the normal equation <span>$K^TK u = K^Ty$</span>) is usually propertional to <span>$\mathrm{cond}(K)^2$</span>. When the problem is stiff, i.e., <span>$\mathrm{cond}(K)$</span> is large, the penaty formulation can be much more <strong>ill-conditioned</strong> than the original problem. </p><h2 id="Method-2:-Primal-and-Primal-Dual-Method"><a class="docs-heading-anchor" href="#Method-2:-Primal-and-Primal-Dual-Method">Method 2: Primal and Primal-Dual Method</a><a id="Method-2:-Primal-and-Primal-Dual-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Method-2:-Primal-and-Primal-Dual-Method" title="Permalink"></a></h2><p>A classical theory regarding constrained optimization is the Karush-Kuhn-Tucker (KKT) Theorm. It states a necessary and sufficient condition for a value to be optimal under certain assumptions. To formulate the KKT condition, consider the <strong>Lagrangian function</strong> </p><p class="math-container">\[L(u, y, \lambda) = \frac{1}{2}\|u-\bar u\|_2 + \frac{\rho}{2}\|y\|^2 + \lambda^T(Ku - y)\]</p><p>where <span>$\lambda$</span> is the <strong>adjoint variable</strong>. The corresponding KKT condition is </p><p class="math-container">\[\begin{aligned}
\frac{\partial L}{\partial u} &amp;= u - \bar u + K^T\lambda = 0 \\
\frac{\partial L}{\partial y} &amp;= \rho y - \lambda = 0 \\
\frac{\partial L}{\partial \lambda} &amp;= Ku - y = 0
\end{aligned}\]</p><p>The <strong>primal-dual method</strong> solves for <span>$(u, y, \lambda)$</span> simultaneously from the linear system</p><p class="math-container">\[\begin{bmatrix} 1 &amp; 0 &amp; K^T\\ 0 &amp; \rho &amp; -1\\K &amp; -1 &amp; 0 \end{bmatrix}\begin{bmatrix}u\\ y\\ \lambda\end{bmatrix} = \begin{bmatrix}\bar u\\ 0 \\ 0\end{bmatrix}\]</p><p>In contrast, the <strong>dual method</strong> eliminates the state variables <span>$u$</span> and <span>$y$</span> and solves for <span>$\lambda$</span></p><p class="math-container">\[(1+\rho KK^T)\lambda = \rho K\bar u\]</p><p>The primal-dual and dual method have some advantages. For example, we reduce finding the minimum of a constrained optimization method to solving a nonlinear equation, where certain tools are available. For the primal-dual method, the limitation is that the system of equations can be very large and difficult to solve. The dual method requires analytical derivation and is not always obvious in practice, especially for nonlinear problems. </p><h2 id="Method-3:-Primal-Method"><a class="docs-heading-anchor" href="#Method-3:-Primal-Method">Method 3: Primal Method</a><a id="Method-3:-Primal-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Method-3:-Primal-Method" title="Permalink"></a></h2><p>The primal method reduces the constrained optimization problem to an unconstrained optimization problem by &quot;solving&quot; the numerical PDE first. In the previous example, we have <span>$u(y) = K^{-1}y$</span> and therefore we have</p><p class="math-container">\[\min_y \frac{1}{2}\|K^{-1}y-\bar u\|_2 + \frac{\rho}{2}\|y\|^2\]</p><p>The advantage is three-folds</p><ul><li>Dimension reduction. The optimization variables are reduced from <span>$(u,y)$</span> to the design variables <span>$y$</span> only. </li><li>Enforced physical constraints. The physical constraints are enforced numerically. </li><li>Unconstrained optimization. The reduced problem is a constrained optimization problem and many off-the-shelf optimizers (gradient descent, BFGS, CG, etc.) are available. </li></ul><p>However, to compute the gradients, the primal method requires deep insights into the numerical solver, which may be highly nonlinear and implicit. The usual automatic differentiation (AD) framework are in general not applicable to this type of operators (nodes in the computational graph) and we need special algorithms.</p><h3 id="Link-to-Adjoint-State-Method"><a class="docs-heading-anchor" href="#Link-to-Adjoint-State-Method">Link to Adjoint-State Method</a><a id="Link-to-Adjoint-State-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Link-to-Adjoint-State-Method" title="Permalink"></a></h3><p>The adjoint state method is a standard method for computing the gradients of the objective function with respect to design variables in PDE-constrained optimization. Consider </p><p class="math-container">\[\begin{aligned}
\min_{y, u}&amp;\; J(y, u)\\
\text{s.t.}&amp;\; F(y, u)=0 
\end{aligned}\]</p><p>Let <span>$u$</span> be the state variable and <span>$y$</span> be the design variable. Assume we solve for <span>$u=u(y)$</span> from the PDE constraint, then we have the reduced objective function </p><p class="math-container">\[\hat J(y) = J(y, u(y))\]</p><p>To conduct gradient-based optimization, we need to compute the gradient </p><p class="math-container">\[\frac{d \hat J(y)}{d y} =\nabla_y J(y, u(y)) +\nabla_u J(y, u(y))\frac{du(y)}{dy} \tag{2}\]</p><p>To compute the <span>$\frac{du(y)}{dy}$</span> we have</p><p class="math-container">\[F(y, u(y))=0 \Rightarrow \nabla_y F + \nabla_u F \frac{du}{dy} = 0 \tag{3}\]</p><p>Therefore we can use Equations 2 and 3 to evaluate the gradient of the objective function</p><p class="math-container">\[\frac{d \hat J(y)}{d y} = \nabla_y J(y, u(y)) - \nabla_u J(y, u(y)) (\nabla_u F(y,u(y)))^{-1} \nabla_y F(y, u(y))\tag{4}\]</p><h3 id="Link-to-the-Lagrange-Function"><a class="docs-heading-anchor" href="#Link-to-the-Lagrange-Function">Link to the Lagrange Function</a><a id="Link-to-the-Lagrange-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Link-to-the-Lagrange-Function" title="Permalink"></a></h3><p>There is a nice interpretation of Equations 2 and 3 using the Lagrange function. Consider the langrange function </p><p class="math-container">\[L(y, u, \lambda) = J(y, u) + \lambda^T F(y, u) \tag{5}\]</p><p>The KKT condition says</p><p class="math-container">\[\begin{aligned}
\frac{\partial L}{\partial \lambda} &amp;= F(y, u) = 0\\
\frac{\partial L}{\partial u} &amp;= \nabla_u J + \lambda^T \nabla_u F(y, u) = 0\\
\frac{\partial L}{\partial y} &amp;= \nabla_y J + \lambda^T \nabla_y F(y, u) = 0\\
\end{aligned}\]</p><p>Now we relax the third equation: given a fixed <span>$y$</span> (not necessarily optimal), we can solve for <span>$(u,\lambda)$</span> from the first two equations. We plug the solutions into the third equation and obtain (note <span>$u$</span> satisfies <span>$F(y, u)=0$</span>)</p><p class="math-container">\[\frac{\partial L}{\partial y} = \nabla_y J(y, u) - \nabla_u J(y, u) (\nabla_u F(y,u))^{-1} \nabla_y F(y, u)\]</p><p>which is the same expression as Equation 4. When <span>$y$</span> is optimal, this expression is equal to zero, i.e., all the KKT conditions are satisfied. The gradient of the unconstrained optimization problem is also zero. Both the primal system and the primal-dual system confirm the optimality. This relation also explains why we call the method above as &quot;adjoint&quot; state method. In summary, the adjoint-state method involves a three-step process</p><ul><li><p><strong>Step 1.</strong> Create the Lagrangian Equation 5.</p></li><li><p><strong>Step 2</strong>. Conduct forward computation and solve for <span>$u$</span> from </p></li></ul><p class="math-container">\[F(y, u) = 0\]</p><ul><li><strong>Step 3.</strong> Compute the adjoint variable <span>$\lambda$</span> from </li></ul><p class="math-container">\[\nabla_u J + \lambda^T \nabla_u F(y, u) = 0\]</p><ul><li><strong>Step 4.</strong> Compute the sensitivity </li></ul><p class="math-container">\[\frac{\partial \hat J}{\partial y} = \nabla_y J + \lambda^T \nabla_y F(y, u)\]</p><h3 id="Link-to-Automatic-Differentiation"><a class="docs-heading-anchor" href="#Link-to-Automatic-Differentiation">Link to Automatic Differentiation</a><a id="Link-to-Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Link-to-Automatic-Differentiation" title="Permalink"></a></h3><h4 id="Computational-Graph"><a class="docs-heading-anchor" href="#Computational-Graph">Computational Graph</a><a id="Computational-Graph-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Graph" title="Permalink"></a></h4><p>The adjoint-state method is also closely related to the reverse-mode automatic differentiation. Consider a concrete PDE-constrained optimization problem</p><p class="math-container">\[\begin{aligned}
     \min_{\mathbf{u}_1, {\theta}} &amp;\  J = f_4(\mathbf{u}_1, \mathbf{u}_2, \mathbf{u}_3, \mathbf{u}_4), \\
     \mathrm{s.t.} &amp; \ \mathbf{u}_2 = f_1(\mathbf{u}_1,  {\theta}), \\
     &amp; \ \mathbf{u}_3 = f_2(\mathbf{u}_2,  {\theta}),\\
     &amp; \  \mathbf{u}_4 = f_3(\mathbf{u}_3,  {\theta}).
\end{aligned}\]</p><p>where <span>$f_1$</span>, <span>$f_2$</span>, <span>$f_3$</span> are PDE constraints, <span>$f_4$</span> is the loss function, <span>$\mathbf{u}_1$</span> is the initial condition, and <span>$\theta$</span> is the model parameter.</p><h4 id="Adjoint-State-Method"><a class="docs-heading-anchor" href="#Adjoint-State-Method">Adjoint-State Method</a><a id="Adjoint-State-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Adjoint-State-Method" title="Permalink"></a></h4><p>The Lagrangian function is </p><p class="math-container">\[\mathcal{L}= f_4(\mathbf{u}_1, \mathbf{u}_2, \mathbf{u}_3, \mathbf{u}_4) + {\lambda}^{T}_{2}(f_1(\mathbf{u}_1,  {\theta}) - \mathbf{u}_2) + {\lambda}^T_{3}(f_2(\mathbf{u}_2,  {\theta}) - \mathbf{u}_3) + {\lambda}^T_{4}(f_3(\mathbf{u}_3,  {\theta}) - \mathbf{u}_4)\]</p><p>Upon conducting the foward computation we have all <span>$\mathbf{u}_i$</span> available. To compute the adjoint variable <span>$\lambda_i$</span>, we have </p><p class="math-container">\[\begin{aligned}
  {\lambda}_4^T &amp;= \frac{\partial f_4}{\partial \mathbf{u}_4}  \\
 {\lambda}_3^T &amp;= \frac{\partial f_4}{\partial  \mathbf{u}_3} + {\lambda}_4^T\frac{\partial f_3}{\partial  \mathbf{u}_3}  \\
  {\lambda}_2^T &amp;= \frac{\partial f_4}{\partial  \mathbf{u}_2} + {\lambda}_3^T\frac{\partial f_2}{\partial  \mathbf{u}_2} 
\end{aligned}\]</p><p>The gradient of the objective function in the constrained optimization problem is given by </p><p class="math-container">\[\frac{\partial \mathcal{L}}{\partial {\theta}} = {\lambda}_2^T\frac{\partial f_1}{\partial {\theta}} + {\lambda}_3^T\frac{\partial f_2}{\partial {\theta}} + {\lambda}_4^T\frac{\partial f_3}{\partial {\theta}}\]</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/adjoint2.png?raw=true" alt/></p><h4 id="Automatic-Differentiation"><a class="docs-heading-anchor" href="#Automatic-Differentiation">Automatic Differentiation</a><a id="Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation" title="Permalink"></a></h4><p>Now let&#39;s see how the computation is linked to automatic differentiation. As explained in the previous tutorials, when we implement the automatic differentiation operator, we need to backpropagate the &quot;top&quot; gradients to its upstreams in the computational graph. Consider the operator <span>$f_2$</span>, we need to implement two operators </p><p class="math-container">\[\begin{aligned}
\text{Forward:}&amp;\; \mathbf{u}_3 = f_2(\mathbf{u}_2, \theta)\\
\text{Backward:}&amp;\; \frac{\partial J}{\partial \mathbf{u}_2}, \frac{\partial J}{\partial \theta} = b_2\left(\frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_3}, \mathbf{u}_2, \theta\right)
\end{aligned}\]</p><p>Here <span>$\frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_3}$</span> is the &quot;total&quot; gradient <span>$\mathbf{u}_3$</span> received from the downstream in the computational graph. </p><h4 id="Relation-between-AD-and-Adjoint-State-Method"><a class="docs-heading-anchor" href="#Relation-between-AD-and-Adjoint-State-Method">Relation between AD and Adjoint-State Method</a><a id="Relation-between-AD-and-Adjoint-State-Method-1"></a><a class="docs-heading-anchor-permalink" href="#Relation-between-AD-and-Adjoint-State-Method" title="Permalink"></a></h4><p>The backward operator is implemented using the chain rule <span>$\begin{aligned} 	\frac{\partial J}{\partial \mathbf{u}_2} = \frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_3} \frac{\partial f_2}{\partial \mathbf{u}_2}\qquad 	\frac{\partial J}{\partial \theta} = \frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_3} \frac{\partial f_2}{\partial \theta} \end{aligned}$</span></p><p>The total gradient <span>$\mathbf{u}_2$</span> received is</p><p class="math-container">\[\frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_2}  = \frac{\partial f_4}{\partial \mathbf{u}_2} + \frac{\partial J}{\partial \mathbf{u}_2} = \frac{\partial f_4}{\partial \mathbf{u}_2} + \frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_3} \frac{\partial f_2}{\partial \mathbf{u}_2}\]</p><p>The dual constraint in the KKT condition <span>${\lambda}_2^T = \frac{\partial f_4}{\partial  \mathbf{u}_2} + {\lambda}_3^T\frac{\partial f_2}{\partial  \mathbf{u}_2}$</span></p><p>Now we see the important relation </p><p class="math-container">\[\boxed{{\lambda}_i^T = \frac{\partial J^{\mathrm{tot}}}{\partial \mathbf{u}_i}}\]</p><p>That means, in general, <strong>the reverse-mode AD is back-propagating the Lagrange multiplier (adjoint variables)</strong>. </p><h4 id="Dicussion-and-Physics-based-Machine-Learning"><a class="docs-heading-anchor" href="#Dicussion-and-Physics-based-Machine-Learning">Dicussion and Physics based Machine Learning</a><a id="Dicussion-and-Physics-based-Machine-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Dicussion-and-Physics-based-Machine-Learning" title="Permalink"></a></h4><p>However, although the link between AD and adjoint state methods enables us to use AD tools for PDE-constrained optimization, many standard numerical schemes, such as implicit ones, involve an iterative process (e.g., Newton-Raphson) in nature. AD is usually designed for explicit operators. To this end, we can borrow the idea from the adjoint-state methods and enhance the current AD framework to differentiate through iterative solvers or implicit schemes. This is known as <strong>physics constrained learning</strong>. For more details, see <a href="https://arxiv.org/pdf/2002.10521.pdf">the paper</a> here. </p><p>Another ongoing research is the combination of neural networks and physical modeling. One idea is to model the unknown relations in the physical system using neural networks. Those includes </p><ul><li>Koopman operator in dynamical systems</li><li>Constitutive relations in solid mechanics.</li><li>Turbulent closure relations in fluid mechanics.</li><li>......</li></ul><p>In the context of PDE-constrained optimization, there is no essential difference between learning a neural network and finding the optimal physical parameters, except that the design variables become the weights and biases of neural networks. However, the neural networks raise some questions, for example: does one optimization technique preferable than the others? How to stabilize the numerical solvers when neural networks are present? How to add physical constraints to the neural network? How to scale the algorithm? How is the well-posedness and conditioning of the optimization problem? How much data do we need? How to stabilize the training (e.g., regularization, projected gradients)? Indeed, the application of neural networks in the physics machine learning leave more problems than what have been answered here. </p><h2 id="Other-Optimization-Techniques"><a class="docs-heading-anchor" href="#Other-Optimization-Techniques">Other Optimization Techniques</a><a id="Other-Optimization-Techniques-1"></a><a class="docs-heading-anchor-permalink" href="#Other-Optimization-Techniques" title="Permalink"></a></h2><p>Besides the formulation and optimization techniques  introduced here, there are many other topics, which we have not covered here, on PDE-constrained optimization. It is worthwhile mentioning that we consider the optimize-then-discretize approach. The alternative approach, discretize-then-optimize, derives the optimal condition (KKT condition) on the continuous level and then discretize the dual PDE. In this formulation, we can use the same discretization method for both the primal and dual system, and therefore we may preserve some essential physical properties. However, the gradients derived in this way may deviate from the true gradients of the constrained optimization problem. </p><p>Another noteworthy ongoing research is to formulate the optimization as an action functional. Just like every PDE can be viewed as a minimization of an energy function, a PDE-constrained optimization problem can also be formulated as a problem of minimizing a functional. These discussions are beyond the scope of the tutorial. </p><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>PDE-constrained optimization has a wide variety of applications. Specifically, formulating the physics based machine learning as a PDE-constrained optimization problem lends us a rich toolbox for optimization, discretization, and algorithm design. The combination of neural networks and physics modeling poses a lot of opportunities as well as challenges for solving long standing problems. The gradient based optimization with automatic differentiation has the potential to consolidate the techniques in a single framework.  </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tu_basic/">« ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a><a class="docs-footer-nextpage" href="../tu_sparse/">Sparse Linear Algebra »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 4 June 2021 07:12">Friday 4 June 2021</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
