<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Newton Raphson · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li class="is-active"><a class="tocitem" href>Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Resources</a></li><li class="is-active"><a href>Newton Raphson</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Newton Raphson</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/newton_raphson.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Newton-Raphson-1"><a class="docs-heading-anchor" href="#Newton-Raphson-1">Newton Raphson</a><a class="docs-heading-anchor-permalink" href="#Newton-Raphson-1" title="Permalink"></a></h1><p>Newton-Raphson algorithm is widely used in scientific computing. In ADCME, the function for the algorithm is <a href="#ADCME.newton_raphson"><code>newton_raphson</code></a>. And the signature is</p><article class="docstring"><header><a class="docstring-binding" id="ADCME.newton_raphson" href="#ADCME.newton_raphson"><code>ADCME.newton_raphson</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">newton_raphson(func::Function, 
    u0::Union{Array,PyObject}, 
    θ::Union{Missing,PyObject, Array{&lt;:Real}}=missing,
    args::PyObject...) where T&lt;:Real</code></pre><p>Newton Raphson solver for solving a nonlinear equation.  ∘ <code>func</code> has the signature </p><ul><li><code>func(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is off)</li><li><code>func(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is on)</li></ul><p>where <code>r</code> is the residual and <code>A</code> is the Jacobian matrix; in the case where <code>linesearch</code> is on, the function value <code>fval</code> must also be supplied. ∘ <code>θ</code> are external parameters. ∘ <code>u0</code> is the initial guess for <code>u</code> ∘ <code>args</code>: additional inputs to the func function  ∘ <code>kwargs</code>: keyword arguments to <code>func</code></p><p>The solution can be configured via <code>ADCME.options.newton_raphson</code></p><ul><li><code>max_iter</code>: maximum number of iterations (default=100)</li><li><code>rtol</code>: relative tolerance for termination (default=1e-12)</li><li><code>tol</code>: absolute tolerance for termination (default=1e-12)</li><li><code>LM</code>: a float number, Levenberg-Marquardt modification <span>$x^{k+1} = x^k - (J^k + \mu^k)^{-1}g^k$</span> (default=0.0)</li><li><code>linesearch</code>: whether linesearch is used (default=false)</li></ul><p>Currently, the backtracing algorithm is implemented. The parameters for <code>linesearch</code> are supplied via <code>options.newton_raphson.linesearch_options</code></p><ul><li><code>c1</code>: stop criterion, <span>$f(x^k) &lt; f(0) + \alpha c_1  f&#39;(0)$</span></li><li><code>ρ_hi</code>: the new step size <span>$\alpha_1\leq \rho_{hi}\alpha_0$</span> </li><li><code>ρ_lo</code>: the new step size <span>$\alpha_1\geq \rho_{lo}\alpha_0$</span> </li><li><code>iterations</code>: maximum number of iterations for linesearch</li><li><code>maxstep</code>: maximum allowable steps</li><li><code>αinitial</code>: initial guess for the step size <span>$\alpha$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/e63a9f2a602a19204c4a38921c7bb422949a46f9/src/optim.jl#L347-L380">source</a></section></article><p>As an example, assume we want to solve </p><div>\[u_i^2 - 1 = 0, i=1,2,\ldots, 10\]</div><p>We first need to construct a function </p><pre><code class="language-julia">function f(θ, u)
    return u^2 - 1, 2*spdiag(u)
end</code></pre><p>Here <span>$2\texttt{spdiag}(u)$</span> is the Jacobian matrix for the equation. Then we construct a Newton Raphson solver via</p><pre><code class="language-julia">nr = newton_raphson(f, constant(rand(10)))</code></pre><p><code>nr</code> is a <code>NRResult</code> struct which is runnable and can be materialized by </p><pre><code class="language-julia">nr = run(sess, nr)</code></pre><p>The signature for <code>NRResult</code> is </p><pre><code class="language-julia">struct NRResult
    x::Union{PyObject, Array{Float64}} # final solution
    res::Union{PyObject, Array{Float64, 1}} # residual
    u::Union{PyObject, Array{Float64, 2}} # solution history
    converged::Union{PyObject, Bool} # whether it converges
    iter::Union{PyObject, Int64} # number of iterations
end</code></pre><p><code>u</code><span>$\in \mathbb{R}^{p\times n}$</span> where <code>p</code> is the solution dimension and <code>n</code> is the number of iterations. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Sometimes we want to construct <code>f</code> via some external variables <span>$\theta$</span>, e.g., when <span>$\theta$</span> is a trainable variable and embeded in the Newton-Raphson solver, we can pass this parameter to <code>newton_raphson</code> via the third parameter</p><pre><code class="language-julia">nr = newton_raphson(f, constant(rand(10)),θ)</code></pre></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>We can provide options to <code>newton_raphson</code> using <code>ADCME.options.newton_raphson</code>. For example</p><pre><code class="language-julia">ADCME.options.newton_raphson.verbose = true 
ADCME.options.newton_raphson.tol = 1e-6
nr = newton_raphson(f, constant(rand(10)), missing)</code></pre><p>This might be useful for debugging.</p></div></div><p>In the case we want to apply a linesearch step in our Newton-Raphson solver, we can turn on the <code>linesearch</code> option in <code>options</code>. However, in this case, we must provide the function value for <code>f</code> (assuming we are solving a minimization problem).  </p><pre><code class="language-julia">function f(θ, u)
    return sum(1/3*u^3-u), u^2 - 1, 2*spdiag(u)
end</code></pre><p>The corresponding driver code is</p><pre><code class="language-julia">ADCME.options.newton_raphson.verbose = false
ADCME.options.newton_raphson.linesearch = true
ADCME.options.newton_raphson.tol = 1e-12
ADCME.options.newton_raphson.linesearch_options.αinitial = 1.0
nr = newton_raphson(f, constant(rand(10)), missing</code></pre><p>Finally we consider the differentiable Newton-Raphson algorithm. Consider we want to construct a map <span>$f:x\mapsto y$</span>, which satisfies</p><div>\[y^3-x=0\]</div><p>In a later stage, we also want to evaluate <span>$\frac{dy}{dx}$</span>. To this end, we can use <a href="../api/#ADCME.newton_raphson_with_grad-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s122,N} where N where #s122&lt;:Real},Vararg{PyCall.PyObject,N} where N}} where T&lt;:Real"><code>newton_raphson_with_grad</code></a>, which provides a differentiable implementation of the Newton-Raphson&#39;s algorithm. </p><pre><code class="language-julia">function f(θ, x)
    x^3 - θ, 3spdiag(x^2)
end

θ = constant([2. .^3;3. ^3; 4. ^3])
x = newton_raphson_with_grad(f, constant(ones(3)), θ)
run(sess, x)≈[2.;3.;4.]
run(sess, gradients(sum(x), θ))≈1/3*[2. .^3;3. ^3; 4. ^3] .^(-2/3)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../exercise/">« Exercise: Inverse Modeling with ADCME</a><a class="docs-footer-nextpage" href="../parallel/">Parallel Computing »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 2 May 2020 03:44">Saturday 2 May 2020</span>. Using Julia version 1.4.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
