<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../videos_and_slides/">Video Lectures and Slides</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../optimizers/">Optimizers</a></li><li><a class="tocitem" href="../optim/">Study on Optimizers</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li><li><a class="tocitem" href="../mcmc/">Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC</a></li><li><a class="tocitem" href="../mpi/">Distributed Scientific Machine Learning using MPI</a></li><li><a class="tocitem" href="../mpi_benchmark/">MPI Benchmarks</a></li><li><a class="tocitem" href="../multithreading/">Understand the Multi-threading Model</a></li><li><a class="tocitem" href="../rbf/">Radial Basis Functions</a></li><li><a class="tocitem" href="../topopt/">Topological Optimization</a></li><li><a class="tocitem" href="../quadrature/">Numerical Integration</a></li><li><a class="tocitem" href="../sqlite3/">Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management</a></li><li><a class="tocitem" href="../hessian/">The Mathematical Structure of DNN Hessians</a></li></ul></li><li><span class="tocitem">Physics Informed Machine Learning</span><ul><li><a class="tocitem" href="../fdtd/">Finite-difference Time-domain for Electromagnetics and Seismic Inversion</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="../flow/">Normalizing Flows</a></li><li><a class="tocitem" href="../convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="../bnn/">Bayesian Neural Networks</a></li><li><a class="tocitem" href="../reinforcement_learning/">Reinforcement Learning Basics: Q-learning and SARSA</a></li></ul></li><li><span class="tocitem">Developer Guide</span><ul><li><a class="tocitem" href="../designpattern/">Design Pattern</a></li><li><a class="tocitem" href="../toolchain/">Built-in Toolchain for Third-party Libraries</a></li><li><a class="tocitem" href="../installmpi/">Configure MPI for Distributed Computing</a></li><li><a class="tocitem" href="../windows_installation/">Install ADCME on Windows</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Core-Functions"><span>Core Functions</span></a></li><li><a class="tocitem" href="#Variables"><span>Variables</span></a></li><li><a class="tocitem" href="#Random-Variables"><span>Random Variables</span></a></li><li><a class="tocitem" href="#Sparse-Matrix"><span>Sparse Matrix</span></a></li><li><a class="tocitem" href="#Operations"><span>Operations</span></a></li><li><a class="tocitem" href="#IO"><span>IO</span></a></li><li><a class="tocitem" href="#Optimization"><span>Optimization</span></a></li><li><a class="tocitem" href="#Neural-Networks"><span>Neural Networks</span></a></li><li><a class="tocitem" href="#Generative-Neural-Nets"><span>Generative Neural Nets</span></a></li><li><a class="tocitem" href="#Tools"><span>Tools</span></a></li><li><a class="tocitem" href="#ODE"><span>ODE</span></a></li><li><a class="tocitem" href="#Function-Approximators"><span>Function Approximators</span></a></li><li><a class="tocitem" href="#Optimal-Transport"><span>Optimal Transport</span></a></li><li><a class="tocitem" href="#MPI"><span>MPI</span></a></li><li><a class="tocitem" href="#Toolchain"><span>Toolchain</span></a></li><li><a class="tocitem" href="#Misc"><span>Misc</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><h2 id="Core-Functions"><a class="docs-heading-anchor" href="#Core-Functions">Core Functions</a><a id="Core-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.control_dependencies-Tuple{Any,Union{Tuple, PyCall.PyObject, Array{PyCall.PyObject,N} where N}}" href="#ADCME.control_dependencies-Tuple{Any,Union{Tuple, PyCall.PyObject, Array{PyCall.PyObject,N} where N}}"><code>ADCME.control_dependencies</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">control_dependencies(f, ops::Union{Array{PyObject}, PyObject})</code></pre><p>Executes all operations in <code>ops</code> before any operations <em>created</em> inside the block. </p><pre><code class="language-julia">op1 = tf.print(&quot;print op1&quot;)
op3 = tf.print(&quot;print op3&quot;)
control_dependencies(op1) do
    global op2 = tf.print(&quot;print op2&quot;)
end
run(sess, [op2,op3])</code></pre><p>In this example, <code>op1</code> must be executed before <code>op2</code>. But there is no guarantee when <code>op3</code> will be executed.  There are several possible outputs of the program such as</p><pre><code class="language-julia-repl">print op3
print op1
print op2</code></pre><p>or </p><pre><code class="language-none">print op1
print op3
print op2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L101-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_collection" href="#ADCME.get_collection"><code>ADCME.get_collection</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">get_collection(name::Union{String, Missing})</code></pre><p>Returns the collection with name <code>name</code>. If <code>name</code> is <code>missing</code>, returns all the trainable variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L33-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_mpi-Tuple{}" href="#ADCME.get_mpi-Tuple{}"><code>ADCME.get_mpi</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_mpi()</code></pre><p>Returns the MPI include directory and shared library.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L276-L281">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_mpirun-Tuple{}" href="#ADCME.get_mpirun-Tuple{}"><code>ADCME.get_mpirun</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_mpirun()</code></pre><p>Returns the <strong>default</strong> mpirun executable. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L301-L305">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.has_mpi" href="#ADCME.has_mpi"><code>ADCME.has_mpi</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">has_mpi(verbose::Bool = true)</code></pre><p>Determines whether MPI is installed. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L246-L250">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.if_else-Tuple{Union{Bool, PyCall.PyObject, Array},Any,Any,Vararg{Any,N} where N}" href="#ADCME.if_else-Tuple{Union{Bool, PyCall.PyObject, Array},Any,Any,Vararg{Any,N} where N}"><code>ADCME.if_else</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">if_else(condition::Union{PyObject,Array,Bool}, fn1, fn2, args...;kwargs...)</code></pre><ul><li>If <code>condition</code> is a scalar boolean, it outputs <code>fn1</code> or <code>fn2</code> (a function with no input argument or a tensor) based on whether <code>condition</code> is true or false.</li><li>If <code>condition</code> is a boolean array, if returns <code>condition .* fn1 + (1 - condition) .* fn2</code></li></ul><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>If you encounter an error like this:</p><pre><code class="language-none">tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value</code></pre><p>It&#39;s probably that your code within <code>if_else</code> is not valid. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L221-L233">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.independent-Tuple{PyCall.PyObject,Vararg{Any,N} where N}" href="#ADCME.independent-Tuple{PyCall.PyObject,Vararg{Any,N} where N}"><code>ADCME.independent</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">independent(o::PyObject, args...; kwargs...)</code></pre><p>Returns <code>o</code> but when computing the gradients, the top gradients will not be back-propagated into dependent variables of <code>o</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L334-L338">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.reset_default_graph-Tuple{}" href="#ADCME.reset_default_graph-Tuple{}"><code>ADCME.reset_default_graph</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reset_default_graph()</code></pre><p>Resets the graph by removing all the operators. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L22-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Tuple{String}" href="#ADCME.tensor-Tuple{String}"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(s::String)</code></pre><p>Returns the tensor with name <code>s</code>. See <a href="#ADCME.tensorname-Tuple{PyCall.PyObject}"><code>tensorname</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensorname-Tuple{PyCall.PyObject}" href="#ADCME.tensorname-Tuple{PyCall.PyObject}"><code>ADCME.tensorname</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensorname(o::PyObject)</code></pre><p>Returns the name of the tensor. See <a href="#ADCME.tensor-Tuple{String}"><code>tensor</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L67-L71">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.while_loop-Tuple{Union{Function, PyCall.PyObject},Function,Union{PyCall.PyObject, Array{Any,N} where N, Array{PyCall.PyObject,N} where N}}" href="#ADCME.while_loop-Tuple{Union{Function, PyCall.PyObject},Function,Union{PyCall.PyObject, Array{Any,N} where N, Array{PyCall.PyObject,N} where N}}"><code>ADCME.while_loop</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">while_loop(condition::Union{PyObject,Function}, body::Function, loop_vars::Union{PyObject, Array{Any}, Array{PyObject}};
    parallel_iterations::Int64=10, kwargs...)</code></pre><p>Loops over <code>loop_vars</code> while <code>condition</code> is true. This operator only creates one extra node to mark the loops in the computational graph.</p><p><strong>Example</strong></p><p>The following script computes </p><p class="math-container">\[\sum_{i=1}^{10} i\]</p><pre><code class="language-julia">function condition(i, ta)
    i &lt;= 10
end
function body(i, ta)
    u = read(ta, i-1)
    ta = write(ta, i, u+1)
    i+1, ta
end
ta = TensorArray(10)
ta = write(ta, 1, constant(1.0))
i = constant(2, dtype=Int32)
_, out = while_loop(condition, body, [i, ta])
summation = stack(out)[10]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L157-L185">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.bind-Tuple{PyCall.PyObject,Vararg{Any,N} where N}" href="#Base.bind-Tuple{PyCall.PyObject,Vararg{Any,N} where N}"><code>Base.bind</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bind(op::PyObject, ops...)</code></pre><p>Adding operations <code>ops</code> to the dependencies of <code>op</code>. <code>ops</code> are guaranteed to be executed <strong>before</strong> <code>op</code>. The function is useful when we want to execute <code>ops</code> but <code>ops</code> is not  in the dependency of the final output. For example, if we want to print <code>i</code> each time <code>i</code> is evaluated</p><pre><code class="language-julia">i = constant(1.0)
op = tf.print(i)
i = bind(i, op)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/core.jl#L137-L148">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Session-Tuple" href="#ADCME.Session-Tuple"><code>ADCME.Session</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Session(args...; kwargs...)</code></pre><p>Create an ADCME session. By default, ADCME will take up all the GPU resources at the start. If you want the GPU usage to grow on a need basis, before starting ADCME, you need to set the environment variable via</p><pre><code class="language-julia">ENV[&quot;TF_FORCE_GPU_ALLOW_GROWTH&quot;] = &quot;true&quot;</code></pre><p><strong>Configuration</strong></p><p>Session accepts some runtime optimization configurations </p><ul><li><code>intra</code>: Number of threads used within an individual op for parallelism</li><li><code>inter</code>: Number of threads used for parallelism between independent operations.</li><li><code>CPU</code>: Maximum number of CPUs to use. </li><li><code>GPU</code>: Maximum number of GPU devices to use</li><li><code>soft</code>: Set to True/enabled to facilitate operations to be placed on CPU instead of GPU</li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>CPU</code> limits the number of CPUs being used, not the number of cores or threads.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/run.jl#L10-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.run_profile-Tuple" href="#ADCME.run_profile-Tuple"><code>ADCME.run_profile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">run_profile(args...;kwargs...)</code></pre><p>Runs the session with tracing information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/run.jl#L92-L96">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save_profile" href="#ADCME.save_profile"><code>ADCME.save_profile</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save_profile(filename::String=&quot;default_timeline.json&quot;)</code></pre><p>Save the timeline information to file <code>filename</code>. </p><ul><li>Open Chrome and navigate to chrome://tracing</li><li>Load the timeline file</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/run.jl#L104-L110">source</a></section></article><h2 id="Variables"><a class="docs-heading-anchor" href="#Variables">Variables</a><a id="Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Variables" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.TensorArray" href="#ADCME.TensorArray"><code>ADCME.TensorArray</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">TensorArray(size_::Int64=0, args...;kwargs...)</code></pre><p>Constructs a tensor array for <a href="#ADCME.while_loop-Tuple{Union{Function, PyCall.PyObject},Function,Union{PyCall.PyObject, Array{Any,N} where N, Array{PyCall.PyObject,N} where N}}"><code>while_loop</code></a>.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L689-L693">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Variable-Tuple{Any}" href="#ADCME.Variable-Tuple{Any}"><code>ADCME.Variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Variable(initial_value;kwargs...)</code></pre><p>Constructs a trainable tensor from <code>value</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L53-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cell-Tuple{Array,Vararg{Any,N} where N}" href="#ADCME.cell-Tuple{Array,Vararg{Any,N} where N}"><code>ADCME.cell</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cell(arr::Array, args...;kwargs...)</code></pre><p>Construct a cell tensor. </p><p><strong>Example</strong></p><pre><code class="language-julia-REPL">julia&gt; r = cell([[1.],[2.,3.]])
julia&gt; run(sess, r[1])
1-element Array{Float32,1}:
 1.0
julia&gt; run(sess, r[2])
2-element Array{Float32,1}:
 2.0
 3.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L66-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.constant-Tuple{Any}" href="#ADCME.constant-Tuple{Any}"><code>ADCME.constant</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">constant(value; kwargs...)</code></pre><p>Constructs a non-trainable tensor from <code>value</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L34-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyCall.PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number" href="#ADCME.convert_to_tensor-Union{Tuple{Union{Missing, Nothing, Number, PyCall.PyObject, Array{T,N} where N}}, Tuple{T}} where T&lt;:Number"><code>ADCME.convert_to_tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">convert_to_tensor(o::Union{PyObject, Number, Array{T}, Missing, Nothing}; dtype::Union{Type, Missing}=missing) where T&lt;:Number
convert_to_tensor(os::Array, dtypes::Array)</code></pre><p>Converts the input <code>o</code> to tensor. If <code>o</code> is already a tensor and <code>dtype</code> (if provided) is the same as that of <code>o</code>, the operator does nothing. Otherwise, <code>convert_to_tensor</code> converts the numerical array to a constant tensor or casts the data type. <code>convert_to_tensor</code> also accepts multiple tensors. </p><p><strong>Example</strong></p><pre><code class="language-julia">convert_to_tensor([1.0, constant(rand(2)), rand(10)], [Float32, Float64, Float32])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L729-L741">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_variable-Tuple{Union{Number, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Number}}" href="#ADCME.get_variable-Tuple{Union{Number, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Number}}"><code>ADCME.get_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_variable(o::Union{PyObject, Bool, Array{&lt;:Number}}; 
    name::Union{String, Missing} = missing, 
    scope::String = &quot;&quot;)</code></pre><p>Creates a new variable with initial value <code>o</code>. If <code>name</code> exists, <code>get_variable</code> returns the variable instead of create a new one.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L108-L114">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_variable-Union{Tuple{Type}, Tuple{N}} where N" href="#ADCME.get_variable-Union{Tuple{Type}, Tuple{N}} where N"><code>ADCME.get_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_variable(dtype::Type;
shape::Union{Array{&lt;:Integer}, NTuple{N, &lt;:Integer}}, 
name::Union{Missing,String} = missing
scope::String = &quot;&quot;)</code></pre><p>Creates a new variable with initial value <code>o</code>. If <code>name</code> exists, <code>get_variable</code> returns the variable instead of create a new one.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L130-L137">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradient_checkpointing" href="#ADCME.gradient_checkpointing"><code>ADCME.gradient_checkpointing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gradient_checkpointing(type::String=&quot;speed&quot;)</code></pre><p>Uses checkpointing scheme for gradients. </p><ul><li>&#39;speed&#39;:  checkpoint all outputs of convolutions and matmuls. these ops are usually the most expensive,   so checkpointing them maximizes the running speed   (this is a good option if nonlinearities, concats, batchnorms, etc are taking up a lot of memory)</li><li>&#39;memory&#39;: try to minimize the memory usage   (currently using a very simple strategy that identifies a number of bottleneck tensors in the graph to checkpoint)</li><li>&#39;collection&#39;: look for a tensorflow collection named &#39;checkpoints&#39;, which holds the tensors to checkpoint</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L767-L777">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradient_magnitude-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array}}" href="#ADCME.gradient_magnitude-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array}}"><code>ADCME.gradient_magnitude</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradient_magnitude(l::PyObject, o::Union{Array, PyObject})</code></pre><p>Returns the gradient sum </p><p class="math-container">\[\sqrt{\sum_{i=1}^n \|\frac{\partial l}{\partial o_i}\|^2}\]</p><p>This function is useful for debugging the training</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L801-L809">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradients-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.gradients-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.gradients</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradients(ys::PyObject, xs::PyObject; kwargs...)</code></pre><p>Computes the gradients of <code>ys</code> w.r.t <code>xs</code>. </p><ul><li>If <code>ys</code> is a scalar, <code>gradients</code> returns the gradients with the same shape as <code>xs</code>.</li><li>If <code>ys</code> is a vector, <code>gradients</code> returns the Jacobian <span>$\frac{\partial y}{\partial x}$</span></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The second usage is not suggested since <code>ADCME</code> adopts reverse mode automatic differentiation.  Although in the case <code>ys</code> is a vector and <code>xs</code> is a scalar, <code>gradients</code> cleverly uses forward mode automatic differentiation, it requires that the second order gradients are implemented for relevant operators. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L254-L266">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradients_colocate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N},Vararg{Any,N} where N}" href="#ADCME.gradients_colocate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N},Vararg{Any,N} where N}"><code>ADCME.gradients_colocate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradients_colocate(loss::PyObject, xs::Union{PyObject, Array{PyObject}}, args...;use_locking::Bool = true, kwargs...)</code></pre><p>Computes the gradients of a <strong>scalar</strong> loss function <code>loss</code> with respect to <code>xs</code>. The gradients are colocated with respect to the forward pass.  This function is usually in distributed computing. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L359-L364">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.hessian-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.hessian-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.hessian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">hessian(ys::PyObject, xs::PyObject; kwargs...)</code></pre><p><code>hessian</code> computes the hessian of a scalar function f with respect to vector inputs xs. </p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10))
y = 0.5 * sum(x^2)
o = hessian(y, x)

sess = Session(); init(sess)
run(sess, o) # should be an identity matrix</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L399-L413">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.is_variable-Tuple{PyCall.PyObject}" href="#ADCME.is_variable-Tuple{PyCall.PyObject}"><code>ADCME.is_variable</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">is_variable(o::PyObject)</code></pre><p>Determines whether <code>o</code> is a trainable variable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L851-L855">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.jacobian-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.jacobian-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.jacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">jacobian(y::PyObject, x::PyObject)</code></pre><p>Computes the Jacobian matrix  <span>$J_{ij} = \frac{\partial y_i}{\partial x_j}$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L380-L385">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ones_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Vararg{Any,N} where N}" href="#ADCME.ones_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Vararg{Any,N} where N}"><code>ADCME.ones_like</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ones_like(o::Union{PyObject,Real, Array{&lt;:Real}}, args...; kwargs...)</code></pre><p>Returns a all-one tensor, which has the same size as <code>o</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia">a = rand(100,10)
b = ones_like(a)
@assert run(sess, b)≈ones(100,10)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L834-L845">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.placeholder-Tuple{Type}" href="#ADCME.placeholder-Tuple{Type}"><code>ADCME.placeholder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">placeholder(dtype::Type; kwargs...)</code></pre><p>Creates a placeholder of the type <code>dtype</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia">a = placeholder(Float64, shape=[20,10])
b = placeholder(Float64, shape=[]) # a scalar 
c = placeholder(Float64, shape=[nothing]) # a vector</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L158-L168">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.placeholder-Tuple{Union{Number, PyCall.PyObject, Array}}" href="#ADCME.placeholder-Tuple{Union{Number, PyCall.PyObject, Array}}"><code>ADCME.placeholder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">placeholder(o::Union{Number, Array, PyObject}; kwargs...)</code></pre><p>Creates a placeholder of the same type and size as <code>o</code>. <code>o</code> is the default value. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L178-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,1}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L639-L641">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T" href="#ADCME.tensor-Union{Tuple{Array{T,2}}, Tuple{T}} where T"><code>ADCME.tensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tensor(v::Array{T,2}; dtype=Float64, sparse=false) where T</code></pre><p>Convert a generic array <code>v</code> to a tensor. For example, </p><pre><code class="language-julia">v = [0.0 constant(1.0) 2.0
    constant(2.0) 0.0 1.0]
u = tensor(v)</code></pre><p><code>u</code> will be a <span>$2\times 3$</span> tensor. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This function is expensive. Use with caution.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L658-L670">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.zeros_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Vararg{Any,N} where N}" href="#ADCME.zeros_like-Tuple{Union{Real, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Vararg{Any,N} where N}"><code>ADCME.zeros_like</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">zeros_like(o::Union{PyObject,Real, Array{&lt;:Real}}, args...; kwargs...)</code></pre><p>Returns a all-zero tensor, which has the same size as <code>o</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia">a = rand(100,10)
b = zeros_like(a)
@assert run(sess, b)≈zeros(100,10)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L817-L828">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.copy-Tuple{PyCall.PyObject}" href="#Base.copy-Tuple{PyCall.PyObject}"><code>Base.copy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">copy(o::PyObject)</code></pre><p>Creates a tensor that has the same value that is currently stored in a variable.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The output is a graph node that will have that value when evaluated. Any time you evaluate it, it will grab the current value of <code>o</code>. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L90-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.read-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject}}" href="#Base.read-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject}}"><code>Base.read</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">read(ta::PyObject, i::Union{PyObject,Integer})</code></pre><p>Reads data from <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L709-L714">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject},PyCall.PyObject}" href="#Base.write-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject},PyCall.PyObject}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(ta::PyObject, i::Union{PyObject,Integer}, obj)</code></pre><p>Writes data <code>obj</code> to <a href="#ADCME.TensorArray"><code>TensorArray</code></a> at index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/variable.jl#L718-L723">source</a></section></article><h2 id="Random-Variables"><a class="docs-heading-anchor" href="#Random-Variables">Random Variables</a><a id="Random-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Random-Variables" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.categorical-Tuple{Union{Integer, PyCall.PyObject}}" href="#ADCME.categorical-Tuple{Union{Integer, PyCall.PyObject}}"><code>ADCME.categorical</code></a> — <span class="docstring-category">Method</span></header><section><div><p>categorical(n::Union{PyObject, Integer}; kwargs...)</p><p><code>kwargs</code> has a keyword argument <code>logits</code>, a 2-D Tensor with shape <code>[batch_size, num_classes]</code>.   Each slice <code>[i, :]</code> represents the unnormalized log-probabilities for all classes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/random.jl#L16-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.choice-Tuple{Union{PyCall.PyObject, Array},Union{Integer, PyCall.PyObject}}" href="#ADCME.choice-Tuple{Union{PyCall.PyObject, Array},Union{Integer, PyCall.PyObject}}"><code>ADCME.choice</code></a> — <span class="docstring-category">Method</span></header><section><div><p>choice(inputs::Union{PyObject, Array}, n_samples::Union{PyObject, Integer};replace::Bool=false)</p><p>Choose <code>n_samples</code> samples from <code>inputs</code> with/without replacement. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/random.jl#L41-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.logpdf-Union{Tuple{T}, Tuple{T,Any}} where T&lt;:ADCME.ADCMEDistribution" href="#ADCME.logpdf-Union{Tuple{T}, Tuple{T,Any}} where T&lt;:ADCME.ADCMEDistribution"><code>ADCME.logpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">logpdf(dist::T, x) where T&lt;:ADCMEDistribution</code></pre><p>Returns the log(prob) for a distribution <code>dist</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/random.jl#L112-L116">source</a></section></article><h2 id="Sparse-Matrix"><a class="docs-heading-anchor" href="#Sparse-Matrix">Sparse Matrix</a><a id="Sparse-Matrix-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Matrix" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor" href="#ADCME.SparseTensor"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SparseTensor</code></pre><p>A sparse matrix object. It has two fields </p><ul><li><p><code>o</code>: internal data structure </p></li><li><p><code>_diag</code>: <code>true</code> if the sparse matrix is marked as &quot;diagonal&quot;.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L8-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}" href="#ADCME.SparseTensor-Tuple{SparseArrays.SparseMatrixCSC}"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(A::SparseMatrixCSC)
SparseTensor(A::Array{Float64, 2})</code></pre><p>Creates a <code>SparseTensor</code> from numerical arrays. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L138-L143">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S},Union{Nothing, PyCall.PyObject, S}}} where S&lt;:Integer where T&lt;:Integer" href="#ADCME.SparseTensor-Union{Tuple{S}, Tuple{T}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S}}, Tuple{Union{Array{T,1}, PyCall.PyObject},Union{Array{T,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Nothing, PyCall.PyObject, S},Union{Nothing, PyCall.PyObject, S}}} where S&lt;:Integer where T&lt;:Integer"><code>ADCME.SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">SparseTensor(I::Union{PyObject,Array{T,1}}, J::Union{PyObject,Array{T,1}}, V::Union{Array{Float64,1}, PyObject}, m::Union{S, PyObject, Nothing}=nothing, n::Union{S, PyObject, Nothing}=nothing) where {T&lt;:Integer, S&lt;:Integer}</code></pre><p>Constructs a sparse tensor.  Examples:</p><pre><code class="language-none">ii = [1;2;3;4]
jj = [1;2;3;4]
vv = [1.0;1.0;1.0;1.0]
s = SparseTensor(ii, jj, vv, 4, 4)
s = SparseTensor(sprand(10,10,0.3))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L49-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Core.Array-Tuple{SparseTensor}" href="#Core.Array-Tuple{SparseTensor}"><code>Core.Array</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Array(A::SparseTensor)</code></pre><p>Converts a sparse tensor <code>A</code> to dense matrix. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L180-L184">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.RawSparseTensor-Union{Tuple{T}, Tuple{Union{Array{T,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Int64, PyCall.PyObject},Union{Int64, PyCall.PyObject}}} where T&lt;:Integer" href="#ADCME.RawSparseTensor-Union{Tuple{T}, Tuple{Union{Array{T,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Int64, PyCall.PyObject},Union{Int64, PyCall.PyObject}}} where T&lt;:Integer"><code>ADCME.RawSparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">RawSparseTensor(indices::Union{PyObject,Array{T,2}}, value::Union{PyObject,Array{Float64,1}},
    m::Union{PyObject,Int64}, n::Union{PyObject,Int64}; is_diag::Bool=false) where T&lt;:Integer</code></pre><p>A convenient wrapper for making custom operators. Here <code>indices</code> is 0-based. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L120-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.SparseAssembler" href="#ADCME.SparseAssembler"><code>ADCME.SparseAssembler</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">SparseAssembler(handle::Union{PyObject, &lt;:Integer}, n::Union{PyObject, &lt;:Integer}, tol::Union{PyObject, &lt;:Real}=0.0)</code></pre><p>Creates a SparseAssembler for accumulating <code>row</code>, <code>col</code>, <code>val</code> for sparse matrices. </p><ul><li><code>handle</code>: an integer handle for creating a sparse matrix. If the handle already exists, <code>SparseAssembler</code> return the existing sparse matrix handle. If you are creating different sparse matrices, the handles should be different. </li><li><code>n</code>: Number of rows of the sparse matrix. </li><li><code>tol</code> (optional): Tolerance. <code>SparseAssembler</code> will treats any values less than <code>tol</code> as zero. </li></ul><p><strong>Example 1</strong></p><pre><code class="language-julia">handle = SparseAssembler(100, 5, 1e-8)
op1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])
op2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])
J = assemble(5, 5, [op1;op2])</code></pre><p><code>J</code> will be a <a href="../api/#ADCME.SparseTensor"><code>SparseTensor</code></a> object. </p><p><strong>Example 2</strong></p><pre><code class="language-julia">handle = SparseAssembler(0, 5)
op1 = accumulate(handle, 1, [1;2;3], ones(3))
op2 = accumulate(handle, 1, [3], [1.])
op3 = accumulate(handle, 2, [1;3], ones(2))
J = assemble(5, 5, [op1;op2;op3]) # op1, op2, op3 are parallel
Array(run(sess, J))≈[1.0  1.0  2.0  0.0  0.0
                1.0  0.0  1.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0
                0.0  0.0  0.0  0.0  0.0]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L449-L479">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.assemble-Tuple{Union{PyCall.PyObject, #s327} where #s327&lt;:Integer,Union{PyCall.PyObject, #s326} where #s326&lt;:Integer,PyCall.PyObject}" href="#ADCME.assemble-Tuple{Union{PyCall.PyObject, #s327} where #s327&lt;:Integer,Union{PyCall.PyObject, #s326} where #s326&lt;:Integer,PyCall.PyObject}"><code>ADCME.assemble</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">assemble(m::Union{PyObject, &lt;:Integer}, n::Union{PyObject, &lt;:Integer}, ops::PyObject)</code></pre><p>Assembles the sparse matrix from the <code>ops</code> created by <a href="#Base.accumulate"><code>accumulate</code></a>. <code>ops</code> is either a single output from <code>accumulate</code>, or concated from several <code>ops</code></p><pre><code class="language-julia">op1 = accumulate(handle, 1, [1;2;3], [1.0;2.0;3.0])
op2 = accumulate(handle, 2, [1;2;3], [1.0;2.0;3.0])
op = [op1;op2] # equivalent to `vcat([op1, op2]...)`</code></pre><p><code>m</code> and <code>n</code> are rows and columns of the sparse matrix. </p><p>See <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a> for an example.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L514-L526">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.compress-Tuple{SparseTensor}" href="#ADCME.compress-Tuple{SparseTensor}"><code>ADCME.compress</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compress(A::SparseTensor)</code></pre><p>Compresses the duplicated index in <code>A</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">using ADCME
indices = [
    1 1 
    1 1
    2 2
    3 3
]
v = [1.0;1.0;1.0;1.0]
A = SparseTensor(indices[:,1], indices[:,2], v, 3, 3)
Ac = compress(A)
sess = Session(); init(sess)

run(sess, A.o.indices) # expected: [0 0;0 0;1 1;2 2]
run(sess, A.o.values) # expected: [1.0;1.0;1.0;1.0]


run(sess, Ac.o.indices) # expected: [0 0;1 1;2 2]
run(sess, Ac.o.values) # expected: [2.0;1.0;1.0]</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The indices of <code>A</code> should be sorted. <code>compress</code> does not check the validity of the input arguments.  </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L746-L775">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.find-Tuple{SparseTensor}" href="#ADCME.find-Tuple{SparseTensor}"><code>ADCME.find</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">find(s::SparseTensor)</code></pre><p>Returns the row, column and values for sparse tensor <code>s</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L88-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_add-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real" href="#ADCME.scatter_add-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{T}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real"><code>ADCME.scatter_add</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},
i1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},
i2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},
B::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S&lt;:Real,T&lt;:Real}</code></pre><p>Adds <code>B</code> to a subblock of a sparse matrix <code>A</code>. Equivalently, </p><pre><code class="language-none">A[i1, i2] += B</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L366-L376">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{S}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real" href="#ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{S}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real"><code>ADCME.scatter_update</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(A::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}},
i1::Union{Integer, Colon, UnitRange{T}, PyObject,Array{S,1}},
i2::Union{Integer, Colon, UnitRange{T}, PyObject,Array{T,1}},
B::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}})  where {S&lt;:Real,T&lt;:Real}</code></pre><p>Updates a subblock of a sparse matrix by <code>B</code>. Equivalently, </p><pre><code class="language-none">A[i1, i2] = B</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L329-L339">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.solve-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}" href="#ADCME.solve-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}"><code>ADCME.solve</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">solve(A_factorized::Tuple{SparseTensor, PyObject}, rhs::Union{Array{Float64,1}, PyObject})</code></pre><p>Solves the equation <code>A_factorized * x = rhs</code> using the factorized sparse matrix. See <a href="#LinearAlgebra.factorize"><code>factorize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L681-L685">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{Int64}" href="#ADCME.spdiag-Tuple{Int64}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(n::Int64)</code></pre><p>Constructs a sparse identity matrix of size <span>$n\times n$</span>, which is equivalent to <code>spdiag(n, 0=&gt;ones(n))</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L539-L543">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{Integer,Vararg{Pair,N} where N}" href="#ADCME.spdiag-Tuple{Integer,Vararg{Pair,N} where N}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(m::Integer, pair::Pair...)</code></pre><p>Constructs a square <span>$m\times m$</span> <a href="#ADCME.SparseTensor"><code>SparseTensor</code></a> from pairs of the form </p><pre><code class="language-none">offset =&gt; array </code></pre><p><strong>Example</strong></p><p>Suppose we want to construct a <span>$10\times 10$</span> tridiagonal matrix, where the lower off-diagonals are all -2,  the diagonals are all 2, and the upper off-diagonals are all 3, the corresponding Julia code is </p><pre><code class="language-julia">spdiag(10, -1=&gt;-2*ones(9), 0=&gt;2*ones(10), 1=&gt;3ones(9))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L617-L630">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spdiag-Tuple{PyCall.PyObject}" href="#ADCME.spdiag-Tuple{PyCall.PyObject}"><code>ADCME.spdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">spdiag(o::PyObject)</code></pre><p>Constructs a sparse diagonal matrix where the diagonal entries are <code>o</code>, which is equivalent to <code>spdiag(length(o), 0=&gt;o)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L548-L552">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.spzero" href="#ADCME.spzero"><code>ADCME.spzero</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spzero(m::Int64, n::Union{Missing, Int64}=missing)</code></pre><p>Constructs a empty sparse matrix of size <span>$m\times n$</span>. <code>n=m</code> if <code>n</code> is <code>missing</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L563-L567">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.trisolve-NTuple{4,Union{Array{Float64,1}, PyCall.PyObject}}" href="#ADCME.trisolve-NTuple{4,Union{Array{Float64,1}, PyCall.PyObject}}"><code>ADCME.trisolve</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trisolve(a::Union{PyObject, Array{Float64,1}},b::Union{PyObject, Array{Float64,1}},
    c::Union{PyObject, Array{Float64,1}},d::Union{PyObject, Array{Float64,1}})</code></pre><p>Solves a tridiagonal matrix linear system. The equation is as follows</p><p class="math-container">\[a_i x_{i-1} + b_i x_i + c_i x_{i+1} = d_i\]</p><p>In the matrix format, </p><p class="math-container">\[\begin{bmatrix}
b_1 &amp; c_1 &amp; &amp;0 \\ 
a_2 &amp; b_2 &amp; c_2 &amp; \\ 
   &amp; a_3 &amp; b_3 &amp; &amp;\\ 
   &amp;     &amp;     &amp; &amp; c_{n-1}\\ 
0 &amp; &amp; &amp;a_n &amp; b_n  
\end{bmatrix}\begin{bmatrix}
x_1\\
x_2\\
\vdots \\
x_n 
\end{bmatrix} = \begin{bmatrix}
d_1\\
d_2\\
\vdots\\
d_n\end{bmatrix}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L702-L730">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\" href="#Base.:\\"><code>Base.:\</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">\(A::SparseTensor, o::PyObject, method::String=&quot;SparseLU&quot;)</code></pre><p>Solves the linear equation  <span>$A x = o$</span></p><p><strong>Method</strong></p><p>For square matrices <span>$A$</span>, one of the following methods is available</p><ul><li><code>auto</code>: using the solver specified by <code>ADCME.options.sparse.solver</code></li><li><code>SparseLU</code></li><li><code>SparseQR</code></li><li><code>SimplicialLDLT</code></li><li><code>SimplicialLLT</code></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In the case <code>o</code> is 2 dimensional, <code>\</code> is understood as &quot;batched solve&quot;. <code>o</code> must have size <span>$n_{b} \times m$</span>, and  <span>$A$</span> has a size <span>$m\times n$</span>. It returns the solution matrix of size <span>$n_b \times n$</span></p><p class="math-container">\[s_{i,:} = A^{-1} o_{i,:}\]</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L393-L412">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}" href="#Base.:\\-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}"><code>Base.:\</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Base.:\(A_factorized::Tuple{SparseTensor, PyObject}, rhs::Union{Array{Float64,1}, PyObject})</code></pre><p>A convenient overload for <a href="#ADCME.solve-Tuple{Tuple{SparseTensor,PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject}}"><code>solve</code></a>. See <a href="#LinearAlgebra.factorize"><code>factorize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L694-L698">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.accumulate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, #s327} where #s327&lt;:Integer,Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Integer},Union{PyCall.PyObject, Array{#s263,N} where N where #s263&lt;:Real}}" href="#Base.accumulate-Tuple{PyCall.PyObject,Union{PyCall.PyObject, #s327} where #s327&lt;:Integer,Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Integer},Union{PyCall.PyObject, Array{#s263,N} where N where #s263&lt;:Real}}"><code>Base.accumulate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">accumulate(handle::PyObject, row::Union{PyObject, &lt;:Integer}, cols::Union{PyObject, Array{&lt;:Integer}}, vals::Union{PyObject, Array{&lt;:Real}})</code></pre><p>Accumulates <code>row</code>-th row. It adds the value to the sparse matrix</p><pre><code class="language-julia">for k = 1:length(cols)
    A[row, cols[k]] += vals[k]
end</code></pre><p><code>handle</code> is the handle created by <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a>. </p><p>See <a href="#ADCME.SparseAssembler"><code>SparseAssembler</code></a> for an example.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The function <code>accumulate</code> returns a <code>op::PyObject</code>. Only when <code>op</code> is executed, the nonzero values are populated into the sparse matrix. </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L489-L504">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.factorize" href="#LinearAlgebra.factorize"><code>LinearAlgebra.factorize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">factorize(A::Union{SparseTensor, SparseMatrixCSC}, max_cache_size::Int64 = 999999)</code></pre><p>Factorizes <span>$A$</span> for sparse matrix solutions. <code>max_cache_size</code> specifies the maximum cache sizes in the C++ kernels,  which determines the maximum number of factorized matrices.  The function returns the factorized matrix, which is basically <code>Tuple{SparseTensor, PyObject}</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">A = sprand(10,10,0.7)
Afac = factorize(A) # factorizing the matrix
run(sess, Afac\rand(10)) # no factorization, solving the equation
run(sess, Afac\rand(10)) # no factorization, solving the equation</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sparse.jl#L657-L670">source</a></section></article><h2 id="Operations"><a class="docs-heading-anchor" href="#Operations">Operations</a><a id="Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Operations" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.argsort-Tuple{PyCall.PyObject}" href="#ADCME.argsort-Tuple{PyCall.PyObject}"><code>ADCME.argsort</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">argsort(o::PyObject; 
stable::Bool = false, rev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)</code></pre><p>Returns the indices of a tensor that give its sorted order along an axis.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1100-L1105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.batch_matmul-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.batch_matmul-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.batch_matmul</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">batch_matmul(o1::PyObject, o2::PyObject)</code></pre><p>Computes <code>o1[i,:,:] * o2[i, :]</code> or <code>o1[i,:,:] * o2[i, :, :]</code> for each index <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L78-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.clip-Tuple{Union{Array{Any,N} where N, Array{PyCall.PyObject,N} where N},Any,Any,Vararg{Any,N} where N}" href="#ADCME.clip-Tuple{Union{Array{Any,N} where N, Array{PyCall.PyObject,N} where N},Any,Any,Vararg{Any,N} where N}"><code>ADCME.clip</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">clip(o::Union{Array{Any}, Array{PyObject}}, vmin, vmax, args...;kwargs...)</code></pre><p>Clips the values of <code>o</code> to the range [<code>vmin</code>, <code>vmax</code>]</p><p><strong>Example</strong></p><pre><code class="language-julia">a = constant(3.0)
a = clip(a, 1.0, 2.0)
b = constant(rand(3))
b = clip(b, 0.5, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L827-L839">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cvec-Tuple{PyCall.PyObject}" href="#ADCME.cvec-Tuple{PyCall.PyObject}"><code>ADCME.cvec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rvec(o::PyObject; kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> to a column vector, assuming column major.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L225-L229">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pad-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Array{Int64,2},Vararg{Any,N} where N}" href="#ADCME.pad-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Array{Int64,2},Vararg{Any,N} where N}"><code>ADCME.pad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pad(o::PyObject, paddings::Array{Int64, 2}, args...; kwargs...)</code></pre><p>Pads <code>o</code> with values on the boundary. </p><p><strong>Example</strong></p><pre><code class="language-julia">o = rand(3,3)
o = pad(o, [1 4      # first dimension
             2 3])   # second dimension
run(sess, o)</code></pre><p>Expected:</p><pre><code class="language-none">8×8 Array{Float64,2}:
 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0
 0.0  0.0  0.250457  0.666905  0.823611  0.0  0.0  0.0
 0.0  0.0  0.23456   0.625145  0.646713  0.0  0.0  0.0
 0.0  0.0  0.552415  0.226417  0.67802   0.0  0.0  0.0
 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0
 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0
 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0
 0.0  0.0  0.0       0.0       0.0       0.0  0.0  0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L430-L453">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pmap-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}" href="#ADCME.pmap-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}"><code>ADCME.pmap</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pmap(fn::Function, o::Union{Array{PyObject}, PyObject})</code></pre><p>Parallel for loop. There should be no data dependency between different iterations.</p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(ones(10))
y1 = pmap(x-&gt;2.0*x, x)
y2 = pmap(x-&gt;x[1]+x[2], [x,x])
y3 = pmap(1:10, x) do z
    i = z[1]
    xi = z[2]
    xi + cast(Float64, i)
end
run(sess, y1)
run(sess, y2)
run(sess, y3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L948-L967">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rollmean-Tuple{Any,Int64}" href="#ADCME.rollmean-Tuple{Any,Int64}"><code>ADCME.rollmean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rollmean(u, window::Int64)</code></pre><p>Returns the rolling mean given a window size <code>m</code></p><p class="math-container">\[o_k = \frac{\sum_{i=k}^{k+m-1} u_i}{m}\]</p><p><strong>Rolling functions in ADCME:</strong></p><ul><li><a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a>: rolling mean </li><li><a href="#ADCME.rollsum-Tuple{Any,Int64}"><code>rollsum</code></a>: rolling sum </li><li><a href="#ADCME.rollvar-Tuple{Any,Int64}"><code>rollvar</code></a>: rolling variance </li><li><a href="#ADCME.rollstd-Tuple{Any,Int64}"><code>rollstd</code></a>: rolling standard deviation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1284-L1296">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rollstd-Tuple{Any,Int64}" href="#ADCME.rollstd-Tuple{Any,Int64}"><code>ADCME.rollstd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rollstd(u, window::Int64)</code></pre><p>Returns the rolling standard deviation given a window size <code>m</code></p><p class="math-container">\[o_k = \sqrt{\frac{\sum_{i=k}^{k+m-1} (u_i - m_i)^2}{m-1}}\]</p><p>Here <span>$m_i$</span> is the rolling mean computed using <a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a></p><p><strong>Rolling functions in ADCME:</strong></p><ul><li><a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a>: rolling mean </li><li><a href="#ADCME.rollsum-Tuple{Any,Int64}"><code>rollsum</code></a>: rolling sum </li><li><a href="#ADCME.rollvar-Tuple{Any,Int64}"><code>rollvar</code></a>: rolling variance </li><li><a href="#ADCME.rollstd-Tuple{Any,Int64}"><code>rollstd</code></a>: rolling standard deviation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1339-L1354">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rollsum-Tuple{Any,Int64}" href="#ADCME.rollsum-Tuple{Any,Int64}"><code>ADCME.rollsum</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rollsum(u, window::Int64)</code></pre><p>Returns the rolling sum given a window size <code>m</code></p><p class="math-container">\[o_k = \sum_{i=k}^{k+m-1} u_i\]</p><p><strong>Rolling functions in ADCME:</strong></p><ul><li><a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a>: rolling mean </li><li><a href="#ADCME.rollsum-Tuple{Any,Int64}"><code>rollsum</code></a>: rolling sum </li><li><a href="#ADCME.rollvar-Tuple{Any,Int64}"><code>rollvar</code></a>: rolling variance </li><li><a href="#ADCME.rollstd-Tuple{Any,Int64}"><code>rollstd</code></a>: rolling standard deviation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1301-L1314">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rollvar-Tuple{Any,Int64}" href="#ADCME.rollvar-Tuple{Any,Int64}"><code>ADCME.rollvar</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rollvar(u, window::Int64)</code></pre><p>Returns the rolling variance given a window size <code>m</code></p><p class="math-container">\[o_k = \frac{\sum_{i=k}^{k+m-1} (u_i - m_i)^2}{m-1}\]</p><p>Here <span>$m_i$</span> is the rolling mean computed using <a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a></p><p><strong>Rolling functions in ADCME:</strong></p><ul><li><a href="#ADCME.rollmean-Tuple{Any,Int64}"><code>rollmean</code></a>: rolling mean </li><li><a href="#ADCME.rollsum-Tuple{Any,Int64}"><code>rollsum</code></a>: rolling sum </li><li><a href="#ADCME.rollvar-Tuple{Any,Int64}"><code>rollvar</code></a>: rolling variance </li><li><a href="#ADCME.rollstd-Tuple{Any,Int64}"><code>rollstd</code></a>: rolling standard deviation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1319-L1334">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rvec-Tuple{PyCall.PyObject}" href="#ADCME.rvec-Tuple{PyCall.PyObject}"><code>ADCME.rvec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rvec(o::PyObject; kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> to a row vector, assuming column major.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L207-L211">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_add</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_add(A::PyObject, 
    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><pre><code class="language-julia">A[xind, yind] += updates</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L773-L782">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_add-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_add</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_add(a::PyObject, 
    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><p>Updates array <code>add</code></p><pre><code class="language-none">a[indices] += updates</code></pre><p><strong>Example</strong></p><p>Julia:</p><pre><code class="language-julia">A[[1;2;3]] += rand(3)
A[2] += 1.0</code></pre><p>ADCME:</p><pre><code class="language-none">A = scatter_add(A, [1;2;3], rand(3))
A = scatter_add(A, 2, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L708-L730">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_sub</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_add(A::PyObject, 
    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><pre><code class="language-julia">A[xind, yind] -= updates</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L788-L797">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_sub-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_sub</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_sub(a::PyObject, 
    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><p>Updates array <code>a</code></p><pre><code class="language-none">a[indices] -= updates</code></pre><p><strong>Example</strong></p><p>Julia:</p><pre><code class="language-julia">A[[1;2;3]] -= rand(3)
A[2] -= 1.0</code></pre><p>ADCME:</p><pre><code class="language-none">A = scatter_sub(A, [1;2;3], rand(3))
A = scatter_sub(A, 2, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L680-L702">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_update</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(A::PyObject, 
    xind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    yind::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><pre><code class="language-julia">A[xind, yind] = updates</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L758-L767">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}" href="#ADCME.scatter_update-Tuple{PyCall.PyObject,Union{Colon, StepRange{Int64,Int64}, UnitRange{Int64}, Int64, BitArray{1}, Array{Bool,1}, PyCall.PyObject, Array{Int64,N} where N},Union{Real, PyCall.PyObject, Array{#s329,N} where N where #s329&lt;:Real}}"><code>ADCME.scatter_update</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">scatter_update(a::PyObject, 
    indices::Union{Colon, Int64, Array{Int64}, BitArray{1}, Array{Bool,1}, UnitRange{Int64}, StepRange{Int64, Int64}, PyObject},
    updates::Union{Array{&lt;:Real}, Real, PyObject})</code></pre><p>Updates array <code>a</code></p><pre><code class="language-none">a[indices] = updates</code></pre><p><strong>Example</strong></p><p>Julia:</p><pre><code class="language-julia">A[[1;2;3]] = rand(3)
A[2] = 1.0</code></pre><p>ADCME:</p><pre><code class="language-none">A = scatter_update(A, [1;2;3], rand(3))
A = scatter_update(A, 2, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L653-L675">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.set_shape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328&lt;:Integer}}} where N" href="#ADCME.set_shape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328&lt;:Integer}}} where N"><code>ADCME.set_shape</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">set_shape(o::PyObject, s::Union{Array{&lt;:Integer}, Tuple{Vararg{&lt;:Integer, N}}}) where N
set_shape(o::PyObject, s::Integer...)</code></pre><p>Sets the shape of <code>o</code> to <code>s</code>. <code>s</code> must be the actual shape of <code>o</code>. This function is used to convert a  tensor with unknown dimensions to a tensor with concrete dimensions. </p><p><strong>Example</strong></p><pre><code class="language-julia">a = placeholder(Float64, shape=[nothing, 10])
b = set_shape(a, 3, 10)
run(sess, b, a=&gt;rand(3,10)) # OK 
run(sess, b, a=&gt;rand(5,10)) # Error
run(sess, b, a=&gt;rand(10,3)) # Error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L259-L274">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.softmax_cross_entropy_with_logits-Tuple{Union{PyCall.PyObject, Array},Union{PyCall.PyObject, Array}}" href="#ADCME.softmax_cross_entropy_with_logits-Tuple{Union{PyCall.PyObject, Array},Union{PyCall.PyObject, Array}}"><code>ADCME.softmax_cross_entropy_with_logits</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">softmax_cross_entropy_with_logits(logits::Union{Array, PyObject}, labels::Union{Array, PyObject})</code></pre><p>Computes softmax cross entropy between <code>logits</code> and <code>labels</code></p><p><code>logits</code> is typically the output of a linear layer. For example,</p><pre><code class="language-none">logits = [
    0.124575  0.511463   0.945934
    0.538054  0.0749339  0.187802
    0.355604  0.052569   0.177009
    0.896386  0.546113   0.456832
]
labels = [2;1;2;3]</code></pre><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>The values of <code>labels</code> are from  {1,2,...,<code>num_classes</code>}. Here <code>num_classes</code> is the number of columns in <code>logits</code>.</p></div></div><p>The predicted labels associated with <code>logits</code> is </p><pre><code class="language-none">argmax(softmax(logits), dims = 2)</code></pre><p>Labels can also be one hot vectors </p><pre><code class="language-none">labels = [0 1
          1 0
          0 1
          0 1]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1359-L1391">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.solve_batch-Tuple{Union{PyCall.PyObject, Array{#s327,2} where #s327&lt;:Real},Union{PyCall.PyObject, Array{#s326,2} where #s326&lt;:Real}}" href="#ADCME.solve_batch-Tuple{Union{PyCall.PyObject, Array{#s327,2} where #s327&lt;:Real},Union{PyCall.PyObject, Array{#s326,2} where #s326&lt;:Real}}"><code>ADCME.solve_batch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">solve_batch(A::Union{PyObject, Array{&lt;:Real, 2}}, rhs::Union{PyObject, Array{&lt;:Real,2}})</code></pre><p>Solves <span>$Ax = b$</span> for a batch of right hand sides. </p><ul><li><code>A</code>: a <span>$m\times n$</span> matrix, where <span>$m\geq n$</span></li><li><code>rhs</code>: a <span>$n_b\times m$</span> matrix. Each row is a new right hand side to solve. </li></ul><p>The returned value is a <span>$n_b\times n$</span> matrix. </p><p><strong>Example</strong></p><pre><code class="language-julia">a = rand(10,5)
b = rand(100, 10)
sol = solve_batch(a, b)
@assert run(sess, sol) ≈ (a\b&#39;)&#39;</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Internally, the matrix <span>$A$</span> is factorized first and then the factorization is used to solve multiple right hand side.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L500-L520">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.stack-Tuple{PyCall.PyObject}" href="#ADCME.stack-Tuple{PyCall.PyObject}"><code>ADCME.stack</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stack(o::PyObject)</code></pre><p>Convert a <code>TensorArray</code> <code>o</code> to a normal tensor. The leading dimension is the size of the tensor array. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L598-L602">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.topk" href="#ADCME.topk"><code>ADCME.topk</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">topk(o::PyObject, k::Union{PyObject,Integer}=1;
    sorted::Bool=true, name::Union{Nothing,String}=nothing)</code></pre><p>Finds values and indices of the <code>k</code> largest entries for the last dimension. If <code>sorted=true</code> the resulting k elements will be sorted by the values in descending order.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1087-L1093">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.vector-Union{Tuple{T}, Tuple{Union{PyCall.PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Int64, PyCall.PyObject}}} where T&lt;:Integer" href="#ADCME.vector-Union{Tuple{T}, Tuple{Union{PyCall.PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Int64, PyCall.PyObject}}} where T&lt;:Integer"><code>ADCME.vector</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vector(i::Union{Array{T}, PyObject, UnitRange, StepRange}, v::Union{Array{Float64},PyObject},s::Union{Int64,PyObject})</code></pre><p>Returns a vector <code>V</code> with length <code>s</code> such that</p><pre><code class="language-none">V[i] = v</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1020-L1027">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.adjoint-Tuple{PyCall.PyObject}" href="#Base.adjoint-Tuple{PyCall.PyObject}"><code>Base.adjoint</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">adjoint(o::PyObject; kwargs...)</code></pre><p>Returns the conjugate adjoint of <code>o</code>.  When the dimension of <code>o</code> is greater than 2, only the last two dimensions are permuted, i.e., <code>permutedims(o, [1,2,...,n,n-1])</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L480-L485">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.map-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}" href="#Base.map-Tuple{Function,Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}"><code>Base.map</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">map(fn::Function, o::Union{Array{PyObject},PyObject};
kwargs...)</code></pre><p>Applies <code>fn</code> to each element of <code>o</code>. </p><ul><li><code>o</code>∈<code>Array{PyObject}</code> : returns <code>[fn(x) for x in o]</code></li><li><code>o</code>∈PyObject : splits <code>o</code> according to the first dimension and then applies <code>fn</code>. </li></ul><p><strong>Example</strong></p><pre><code class="language-julia">a = constant(rand(10,5))
b = map(x-&gt;sum(x), a) # equivalent to `sum(a, dims=2)`</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If <code>fn</code> is a multivariate function, we need to specify the output type using <code>dtype</code> keyword. For example, </p><pre><code class="language-julia">a = constant(ones(10))
b = constant(ones(10))
fn = x-&gt;x[1]+x[2]
c = map(fn, [a, b], dtype=Float64)</code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L914-L936">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.reshape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328&lt;:Integer}}} where N" href="#Base.reshape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s328,N} where N where #s328&lt;:Integer}}} where N"><code>Base.reshape</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reshape(o::PyObject, s::Union{Array{&lt;:Integer}, Tuple{Vararg{&lt;:Integer, N}}}) where N 
reshape(o::PyObject, s::Integer; kwargs...)
reshape(o::PyObject, m::Integer, n::Integer; kwargs...)
reshape(o::PyObject, ::Colon, n::Integer)
reshape(o::PyObject, n::Integer, ::Colon)</code></pre><p>Reshapes the tensor according to row major if the &quot;TensorFlow style&quot; syntax is used; otherwise  reshaping according to column major is assumed. </p><p><strong>Example</strong></p><pre><code class="language-julia">reshape(a, [10,5]) # row major 
reshape(a, 10, 5) # column major </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L168-L183">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.reverse-Tuple{PyCall.PyObject}" href="#Base.reverse-Tuple{PyCall.PyObject}"><code>Base.reverse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">reverse(o::PyObject, kwargs...)</code></pre><p>Given a tensor <code>o</code>, and an index <code>dims</code> representing the set of dimensions of tensor to reverse.</p><p><strong>Example</strong></p><pre><code class="language-julia">a = rand(10,2)
A = constant(a)
@assert run(sess, reverse(A, dims=1)) == reverse(a, dims=1)
@assert run(sess, reverse(A, dims=2)) == reverse(a, dims=2)
@assert run(sess, reverse(A, dims=-1)) == reverse(a, dims=2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1213-L1226">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.sort-Tuple{PyCall.PyObject}" href="#Base.sort-Tuple{PyCall.PyObject}"><code>Base.sort</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Base.:sort(o::PyObject; 
rev::Bool=false, dims::Integer=-1, name::Union{Nothing,String}=nothing)</code></pre><p>Sort a multidimensional array <code>o</code> along the given dimension. </p><ul><li><code>rev</code>: <code>true</code> for DESCENDING and <code>false</code> (default) for ASCENDING</li><li><code>dims</code>: <code>-1</code> for last dimension. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1069-L1076">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.split-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Integer}}" href="#Base.split-Tuple{PyCall.PyObject,Union{Integer, PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Integer}}"><code>Base.split</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">split(o::PyObject, 
    num_or_size_splits::Union{Integer, Array{&lt;:Integer}, PyObject}; kwargs...)</code></pre><p>Splits <code>o</code> according to <code>num_or_size_splits</code></p><p><strong>Example 1</strong></p><pre><code class="language-julia">a = constant(rand(10,8,6))
split(a, 5)</code></pre><p>Expected output:</p><pre><code class="language-none">5-element Array{PyCall.PyObject,1}:
 PyObject &lt;tf.Tensor &#39;split_5:0&#39; shape=(2, 8, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_5:1&#39; shape=(2, 8, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_5:2&#39; shape=(2, 8, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_5:3&#39; shape=(2, 8, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_5:4&#39; shape=(2, 8, 6) dtype=float64&gt;</code></pre><p><strong>Example 2</strong></p><pre><code class="language-julia">a = constant(rand(10,8,6))
split(a, [4,3,1], dims=2)</code></pre><p>Expected output:</p><pre><code class="language-none">3-element Array{PyCall.PyObject,1}:
 PyObject &lt;tf.Tensor &#39;split_6:0&#39; shape=(10, 4, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_6:1&#39; shape=(10, 3, 6) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_6:2&#39; shape=(10, 1, 6) dtype=float64&gt;</code></pre><p><strong>Example 3</strong></p><pre><code class="language-julia">a = constant(rand(10,8,6))
split(a, 3, dims=3)</code></pre><p>Expected output:</p><pre><code class="language-none">3-element Array{PyCall.PyObject,1}:
 PyObject &lt;tf.Tensor &#39;split_7:0&#39; shape=(10, 8, 2) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_7:1&#39; shape=(10, 8, 2) dtype=float64&gt;
 PyObject &lt;tf.Tensor &#39;split_7:2&#39; shape=(10, 8, 2) dtype=float64&gt;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L1160-L1206">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.vec-Tuple{PyCall.PyObject}" href="#Base.vec-Tuple{PyCall.PyObject}"><code>Base.vec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">vec(o::PyObject;kwargs...)</code></pre><p>Vectorizes the tensor <code>o</code> assuming column major. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L243-L247">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.svd-Tuple{PyCall.PyObject,Vararg{Any,N} where N}" href="#LinearAlgebra.svd-Tuple{PyCall.PyObject,Vararg{Any,N} where N}"><code>LinearAlgebra.svd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">svd(o::PyObject, args...; kwargs...)</code></pre><p>Returns a <code>TFSVD</code> structure which holds the following data structures</p><pre><code class="language-julia">S::PyObject
U::PyObject
V::PyObject
Vt::PyObject</code></pre><p>We have the equality <span>$o = USV&#39;$</span></p><p><strong>Example</strong></p><pre><code class="language-julia">A = rand(10,20)
r = svd(constant(A))
A2 = r.U*diagm(r.S)*r.Vt # The value of `A2` should be equal to `A`</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ops.jl#L869-L888">source</a></section></article><h2 id="IO"><a class="docs-heading-anchor" href="#IO">IO</a><a id="IO-1"></a><a class="docs-heading-anchor-permalink" href="#IO" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.Diary" href="#ADCME.Diary"><code>ADCME.Diary</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Diary(suffix::Union{String, Nothing}=nothing)</code></pre><p>Creates a diary at a temporary directory path. It returns a writer and the corresponding directory path</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L143-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.activate" href="#ADCME.activate"><code>ADCME.activate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">activate(sw::Diary, port::Int64=6006)</code></pre><p>Running <a href="#ADCME.Diary"><code>Diary</code></a> at http://localhost:port.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L173-L177">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load" href="#ADCME.load"><code>ADCME.load</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Loads the values of variables to the session <code>sess</code> from the file <code>file</code>. If <code>vars</code> is nothing, it loads values to all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L89-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load-Tuple{Diary,String}" href="#ADCME.load-Tuple{Diary,String}"><code>ADCME.load</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load(sw::Diary, dirp::String)</code></pre><p>Loads <a href="#ADCME.Diary"><code>Diary</code></a> from <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L163-L167">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.logging-Tuple{Union{Nothing, String},Vararg{PyCall.PyObject,N} where N}" href="#ADCME.logging-Tuple{Union{Nothing, String},Vararg{PyCall.PyObject,N} where N}"><code>ADCME.logging</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">logging(file::Union{Nothing,String}, o::PyObject...; summarize::Int64 = 3, sep::String = &quot; &quot;)</code></pre><p>Logging <code>o</code> to <code>file</code>. This operator must be used with <a href="#Base.bind-Tuple{PyCall.PyObject,Vararg{Any,N} where N}"><code>bind</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L217-L221">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.pload-Tuple{String}" href="#ADCME.pload-Tuple{String}"><code>ADCME.pload</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">pload(file::String)</code></pre><p>Loads a Python objection from <code>file</code>. See also <a href="#ADCME.psave-Tuple{PyCall.PyObject,String}"><code>psave</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L33-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.print_tensor" href="#ADCME.print_tensor"><code>ADCME.print_tensor</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">print_tensor(in::Union{PyObject, Array{Float64,2}})</code></pre><p>Prints the tensor <code>in</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L233-L237">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.psave-Tuple{PyCall.PyObject,String}" href="#ADCME.psave-Tuple{PyCall.PyObject,String}"><code>ADCME.psave</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">psave(o::PyObject, file::String)</code></pre><p>Saves a Python objection <code>o</code> to <code>file</code>. See also <a href="#ADCME.pload-Tuple{String}"><code>pload</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L20-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save" href="#ADCME.save"><code>ADCME.save</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">save(sess::PyObject, file::String, vars::Union{PyObject, Nothing, Array{PyObject}}=nothing, args...; kwargs...)</code></pre><p>Saves the values of <code>vars</code> in the session <code>sess</code>. The result is written into <code>file</code> as a dictionary. If <code>vars</code> is nothing, it saves all the trainable variables. See also <a href="#ADCME.save"><code>save</code></a>, <a href="#ADCME.load"><code>load</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L48-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.save-Tuple{Diary,String}" href="#ADCME.save-Tuple{Diary,String}"><code>ADCME.save</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">save(sw::Diary, dirp::String)</code></pre><p>Saves <a href="#ADCME.Diary"><code>Diary</code></a> to <code>dirp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L154-L158">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.scalar" href="#ADCME.scalar"><code>ADCME.scalar</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scalar(o::PyObject, name::String)</code></pre><p>Returns a scalar summary object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L183-L187">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}" href="#Base.write-Tuple{Diary,Int64,Union{String, Array{String,N} where N}}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">write(sw::Diary, step::Int64, cnt::Union{String, Array{String}})</code></pre><p>Writes to <a href="#ADCME.Diary"><code>Diary</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/io.jl#L195-L199">source</a></section></article><h2 id="Optimization"><a class="docs-heading-anchor" href="#Optimization">Optimization</a><a id="Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.AdadeltaOptimizer" href="#ADCME.AdadeltaOptimizer"><code>ADCME.AdadeltaOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">AdadeltaOptimizer(learning_rate=1e-3;kwargs...)</code></pre><p>See <a href="#ADCME.AdamOptimizer"><code>AdamOptimizer</code></a> for descriptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L58-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.AdagradDAOptimizer" href="#ADCME.AdagradDAOptimizer"><code>ADCME.AdagradDAOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">AdagradDAOptimizer(learning_rate=1e-3; global_step, kwargs...)</code></pre><p>See <a href="#ADCME.AdamOptimizer"><code>AdamOptimizer</code></a> for descriptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L68-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.AdagradOptimizer" href="#ADCME.AdagradOptimizer"><code>ADCME.AdagradOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">AdagradOptimizer(learning_rate=1e-3;kwargs...)</code></pre><p>See <a href="#ADCME.AdamOptimizer"><code>AdamOptimizer</code></a> for descriptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L78-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.AdamOptimizer" href="#ADCME.AdamOptimizer"><code>ADCME.AdamOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">AdamOptimizer(learning_rate=1e-3;kwargs...)</code></pre><p>Constructs an ADAM optimizer. </p><p><strong>Example</strong></p><pre><code class="language-julia">learning_rate = 1e-3
opt = AdamOptimizer(learning_rate).minimize(loss)
sess = Session(); init(sess)
for i = 1:1000
    _, l = run(sess, [opt, loss])
    @info &quot;Iteration $i, loss = $l&quot;)
end</code></pre><p><strong>Dynamical Learning Rate</strong></p><p>We can also use dynamical learning rate. For example, if we want to use a learning rate <span>$l_t = \frac{1}{1+t}$</span>, we have </p><pre><code class="language-julia">learning_rate = placeholder(1.0)
opt = AdamOptimizer(learning_rate).minimize(loss)
sess = Session(); init(sess)
for i = 1:1000
    _, l = run(sess, [opt, loss], lr = 1/(1+i))
    @info &quot;Iteration $i, loss = $l&quot;)
end</code></pre><p>The usage of other optimizers such as <a href="#ADCME.GradientDescentOptimizer"><code>GradientDescentOptimizer</code></a>, <a href="#ADCME.AdadeltaOptimizer"><code>AdadeltaOptimizer</code></a>, and so on  is similar: we can just replace <code>AdamOptimizer</code> with the corresponding ones. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L21-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, max_iter::Int64=15000; 
vars::Array{PyObject}=PyObject[], callback::Union{Function, Nothing}=nothing, method::String = &quot;L-BFGS-B&quot;, kwargs...)</code></pre><p><code>BFGS!</code> is a simplified interface for <strong>L-BFGS-B</strong> optimizer. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a>. <code>callback</code> is a callback function with signature </p><pre><code class="language-julia">callback(vs::Array, iter::Int64, loss::Float64)</code></pre><p><code>vars</code> is an array consisting of tensors and its values will be the input to <code>vs</code>.</p><p><strong>Example 1</strong></p><pre><code class="language-julia">a = Variable(1.0)
loss = (a - 10.0)^2
sess = Session(); init(sess)
BFGS!(sess, loss)</code></pre><p><strong>Example 2</strong></p><pre><code class="language-julia">θ1 = Variable(1.0)
θ2 = Variable(1.0)
loss = (θ1-1)^2 + (θ2-2)^2
cb = (vs, iter, loss)-&gt;begin 
    printstyled(&quot;[#iter $iter] θ1=$(vs[1]), θ2=$(vs[2]), loss=$loss\n&quot;, color=:green)
end
sess = Session(); init(sess)
cb(run(sess, [θ1, θ2]), 0, run(sess, loss))
BFGS!(sess, loss, 100; vars=[θ1, θ2], callback=cb)</code></pre><p><strong>Example 3</strong></p><p>Use <code>bounds</code> to specify upper and lower bound of a variable. </p><pre><code class="language-julia">x = Variable(2.0)    
loss = x^2
sess = Session(); init(sess)
BFGS!(sess, loss, bounds=Dict(x=&gt;[1.0,3.0]))</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Users can also use other scipy optimization algorithm by providing <code>method</code> keyword arguments. For example, you can use the BFGS optimizer </p><pre><code class="language-julia">BFGS!(sess, loss, method = &quot;BFGS&quot;)</code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L237-L283">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!" href="#ADCME.BFGS!"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">BFGS!(value_and_gradients_function::Function, initial_position::Union{PyObject, Array{Float64}}, max_iter::Int64=50, args...;kwargs...)</code></pre><p>Applies the BFGS optimizer to <code>value_and_gradients_function</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L331-L335">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.BFGS!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject,Union{Nothing, PyCall.PyObject, Array{T,N} where N},Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}} where T&lt;:Union{Nothing, PyCall.PyObject}" href="#ADCME.BFGS!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject,Union{Nothing, PyCall.PyObject, Array{T,N} where N},Union{PyCall.PyObject, Array{PyCall.PyObject,N} where N}}} where T&lt;:Union{Nothing, PyCall.PyObject}"><code>ADCME.BFGS!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">BFGS!(sess::PyObject, loss::PyObject, grads::Union{Array{T},Nothing,PyObject}, 
vars::Union{Array{PyObject},PyObject}; kwargs...) where T&lt;:Union{Nothing, PyObject}</code></pre><p>Running BFGS algorithm <span>$\min_{\texttt{vars}} \texttt{loss}(\texttt{vars})$</span> The gradients <code>grads</code> must be provided. Typically, <code>grads[i] = gradients(loss, vars[i])</code>.  <code>grads[i]</code> can exist on different devices (GPU or CPU). </p><p><strong>Example 1</strong></p><pre><code class="language-julia">import Optim # required
a = Variable(0.0)
loss = (a-1)^2
g = gradients(loss, a)
sess = Session(); init(sess)
BFGS!(sess, loss, g, a)</code></pre><p><strong>Example 2</strong></p><pre><code class="language-julia">import Optim # required
a = Variable(0.0)
loss = (a^2+a-1)^2
g = gradients(loss, a)
sess = Session(); init(sess)
cb = (vs, iter, loss)-&gt;begin 
    printstyled(&quot;[#iter $iter] a = $vs, loss=$loss\n&quot;, color=:green)
end
BFGS!(sess, loss, g, a; callback = cb)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L695-L726">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.CustomOptimizer-Tuple{Function}" href="#ADCME.CustomOptimizer-Tuple{Function}"><code>ADCME.CustomOptimizer</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">CustomOptimizer(opt::Function, name::String)</code></pre><p>creates a custom optimizer with struct name <code>name</code>. For example, we can integrate <code>Optim.jl</code> with <code>ADCME</code> by  constructing a new optimizer</p><pre><code class="language-julia">CustomOptimizer(&quot;Con&quot;) do f, df, c, dc, x0, x_L, x_U
    opt = Opt(:LD_MMA, length(x0))
    bd = zeros(length(x0)); bd[end-1:end] = [-Inf, 0.0]
    opt.lower_bounds = bd
    opt.xtol_rel = 1e-4
    opt.min_objective = (x,g)-&gt;(g[:]= df(x); return f(x)[1])
    inequality_constraint!(opt, (x,g)-&gt;( g[:]= dc(x);c(x)[1]), 1e-8)
    (minf,minx,ret) = NLopt.optimize(opt, x0)
    minx
end</code></pre><p>Here</p><p>∘ <code>f</code>: a function that returns <span>$f(x)$</span></p><p>∘ <code>df</code>: a function that returns <span>$\nabla f(x)$</span></p><p>∘ <code>c</code>: a function that returns the constraints <span>$c(x)$</span></p><p>∘ <code>dc</code>: a function that returns <span>$\nabla c(x)$</span></p><p>∘ <code>x0</code>: initial guess</p><p>∘ <code>nineq</code>: number of inequality constraints</p><p>∘ <code>neq</code>: number of equality constraints</p><p>∘ <code>x_L</code>: lower bounds of optimizable variables</p><p>∘ <code>x_U</code>: upper bounds of optimizable variables</p><p>Then we can create an optimizer with </p><pre><code class="language-none">opt = Con(loss, inequalities=[c1], equalities=[c2])</code></pre><p>To trigger the optimization, use</p><pre><code class="language-none">minimize(opt, sess)</code></pre><p>Note thanks to the global variable scope of Julia, <code>step_callback</code>, <code>optimizer_kwargs</code> can actually  be passed from Julia environment directly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L138-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.GradientDescentOptimizer" href="#ADCME.GradientDescentOptimizer"><code>ADCME.GradientDescentOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">GradientDescentOptimizer(learning_rate=1e-3;kwargs...)</code></pre><p>See <a href="#ADCME.AdamOptimizer"><code>AdamOptimizer</code></a> for descriptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L88-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyCall.PyObject},Union{PyCall.PyObject, Array{Float64,N} where N}}} where T&lt;:Real" href="#ADCME.NonlinearConstrainedProblem-Union{Tuple{T}, Tuple{Function,Function,Union{Array{Float64,1}, PyCall.PyObject},Union{PyCall.PyObject, Array{Float64,N} where N}}} where T&lt;:Real"><code>ADCME.NonlinearConstrainedProblem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">NonlinearConstrainedProblem(f::Function, L::Function, θ::PyObject, u0::Union{PyObject, Array{Float64}}; options::Union{Dict{String, T}, Missing}=missing) where T&lt;:Integer</code></pre><p>Computes the gradients <span>$\frac{\partial L}{\partial \theta}$</span></p><p class="math-container">\[\min \ L(u) \quad \mathrm{s.t.} \ F(\theta, u) = 0\]</p><p><code>u0</code> is the initial guess for the numerical solution <code>u</code>, see <a href="../newton_raphson/#ADCME.newton_raphson"><code>newton_raphson</code></a>.</p><p>Caveats: Assume <code>r, A = f(θ, u)</code> and <code>θ</code> are the unknown parameters, <code>gradients(r, θ)</code> must be defined (backprop works properly)</p><p>Returns: It returns a tuple (<code>L</code>: loss, <code>C</code>: constraints, and <code>Graidents</code>)</p><p class="math-container">\[\left(L(u), u, \frac{\partial L}{\partial θ}\right)\]</p><p><strong>Example</strong></p><p>We want to solve the following constrained optimization problem  <span>$\begin{aligned}\min_\theta &amp;\; L(u) = (u-1)^3\\ \text{s.t.} &amp;\; u^3 + u = \theta\end{aligned}$</span> The solution is <span>$\theta = 2$</span>. The Julia code is </p><pre><code class="language-julia">function f(θ, u)
    u^3 + u - θ, spdiag(3u^2+1) 
end
function L(u) 
    sum((u-1)^2)
end
pl = Variable(ones(1))
l, θ, dldθ = NonlinearConstrainedProblem(f, L, pl, ones(1))</code></pre><p>We can coupled it with a mathematical optimizer </p><pre><code class="language-julia">using Optim 
sess = Session(); init(sess)
BFGS!(sess, l, dldθ, pl) </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L640-L680">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Optimize!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject}, Tuple{PyCall.PyObject,PyCall.PyObject,Int64}} where T&lt;:Union{Nothing, PyCall.PyObject}" href="#ADCME.Optimize!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject}, Tuple{PyCall.PyObject,PyCall.PyObject,Int64}} where T&lt;:Union{Nothing, PyCall.PyObject}"><code>ADCME.Optimize!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Optimize!(sess::PyObject, loss::PyObject, max_iter::Int64 = 15000;
vars::Union{Array{PyObject},PyObject, Missing} = missing, 
grads::Union{Array{T},Nothing,PyObject, Missing} = missing, 
optimizer = missing,
callback::Union{Function, Missing}=missing,
x_tol::Union{Missing, Float64} = missing,
f_tol::Union{Missing, Float64} = missing,
g_tol::Union{Missing, Float64} = missing, kwargs...) where T&lt;:Union{Nothing, PyObject}</code></pre><p>An interface for using optimizers in the Optim package or custom optimizers. </p><ul><li><p><code>sess</code>: a session;</p></li><li><p><code>loss</code>: a loss function;</p></li><li><p><code>max_iter</code>: maximum number of max_iterations;</p></li><li><p><code>vars</code>, <code>grads</code>: optimizable variables and gradients </p></li><li><p><code>optimizer</code>: Optim optimizers (default: LBFGS)</p></li><li><p><code>callback</code>: callback after each linesearch completion (NOT one step in the linesearch)</p></li></ul><p>Other arguments are passed to Options in Optim optimizers. </p><p>We can also construct a custom optimizer. For example, to construct an optimizer out of Ipopt:</p><pre><code class="language-julia">import Ipopt
x = Variable(rand(2))
loss = (1-x[1])^2 + 100(x[2]-x[1]^2)^2

function opt(f, g, fg, x0, kwargs...)
    prob = createProblem(2, -100ones(2), 100ones(2), 0, Float64[], Float64[], 0, 0,
                     f, (x,g)-&gt;nothing, (x,G)-&gt;g(G, x), (x, mode, rows, cols, values)-&gt;nothing, nothing)
    prob.x = x0 
    Ipopt.addOption(prob, &quot;hessian_approximation&quot;, &quot;limited-memory&quot;)
    status = Ipopt.solveProblem(prob)
    println(Ipopt.ApplicationReturnStatus[status])
    println(prob.x)
    Ipopt.freeProblem(prob)
    nothing
end

sess = Session(); init(sess)
Optimize!(sess, loss, optimizer = opt)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L733-L782">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.RMSPropOptimizer" href="#ADCME.RMSPropOptimizer"><code>ADCME.RMSPropOptimizer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">RMSPropOptimizer(learning_rate=1e-3;kwargs...)</code></pre><p>See <a href="#ADCME.AdamOptimizer"><code>AdamOptimizer</code></a> for descriptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerInterface-Tuple{Any}" href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ADCME.ScipyOptimizerInterface</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerInterface(loss; method=&quot;L-BFGS-B&quot;, options=Dict(&quot;maxiter&quot;=&gt; 15000, &quot;ftol&quot;=&gt;1e-12, &quot;gtol&quot;=&gt;1e-12), kwargs...)</code></pre><p>A simple interface for Scipy Optimizer. See also <a href="#ADCME.ScipyOptimizerMinimize-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ScipyOptimizerMinimize</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L111-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ScipyOptimizerMinimize-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.ScipyOptimizerMinimize-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.ScipyOptimizerMinimize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ScipyOptimizerMinimize(sess::PyObject, opt::PyObject; kwargs...)</code></pre><p>Minimizes a scalar Tensor. Variables subject to optimization are updated in-place at the end of optimization.</p><p>Note that this method does not just return a minimization Op, unlike <code>minimize</code>; instead it actually performs minimization by executing commands to control a Session https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface. See also <a href="#ADCME.ScipyOptimizerInterface-Tuple{Any}"><code>ScipyOptimizerInterface</code></a> and <a href="#ADCME.BFGS!"><code>BFGS!</code></a>.</p><ul><li>feed_dict: A feed dict to be passed to calls to session.run.</li><li>fetches: A list of Tensors to fetch and supply to loss_callback as positional arguments.</li><li>step_callback: A function to be called at each optimization step; arguments are the current values of all optimization variables packed into a single vector.</li><li>loss_callback: A function to be called every time the loss and gradients are computed, with evaluated fetches supplied as positional arguments.</li><li>run_kwargs: kwargs to pass to session.run.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L119-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s237,N} where N where #s237&lt;:Real},Vararg{PyCall.PyObject,N} where N}} where T&lt;:Real" href="#ADCME.newton_raphson-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s237,N} where N where #s237&lt;:Real},Vararg{PyCall.PyObject,N} where N}} where T&lt;:Real"><code>ADCME.newton_raphson</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">newton_raphson(func::Function, 
    u0::Union{Array,PyObject}, 
    θ::Union{Missing,PyObject, Array{&lt;:Real}}=missing,
    args::PyObject...) where T&lt;:Real</code></pre><p>Newton Raphson solver for solving a nonlinear equation.  ∘ <code>func</code> has the signature </p><ul><li><code>func(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is off)</li><li><code>func(θ::Union{Missing,PyObject}, u::PyObject)-&gt;(fval::PyObject, r::PyObject, A::Union{PyObject,SparseTensor})</code> (if <code>linesearch</code> is on)</li></ul><p>where <code>r</code> is the residual and <code>A</code> is the Jacobian matrix; in the case where <code>linesearch</code> is on, the function value <code>fval</code> must also be supplied. ∘ <code>θ</code> are external parameters. ∘ <code>u0</code> is the initial guess for <code>u</code> ∘ <code>args</code>: additional inputs to the func function  ∘ <code>kwargs</code>: keyword arguments to <code>func</code></p><p>The solution can be configured via <code>ADCME.options.newton_raphson</code></p><ul><li><code>max_iter</code>: maximum number of iterations (default=100)</li><li><code>rtol</code>: relative tolerance for termination (default=1e-12)</li><li><code>tol</code>: absolute tolerance for termination (default=1e-12)</li><li><code>LM</code>: a float number, Levenberg-Marquardt modification <span>$x^{k+1} = x^k - (J^k + \mu^k)^{-1}g^k$</span> (default=0.0)</li><li><code>linesearch</code>: whether linesearch is used (default=false)</li></ul><p>Currently, the backtracing algorithm is implemented. The parameters for <code>linesearch</code> are supplied via <code>options.newton_raphson.linesearch_options</code></p><ul><li><code>c1</code>: stop criterion, <span>$f(x^k) &lt; f(0) + \alpha c_1  f&#39;(0)$</span></li><li><code>ρ_hi</code>: the new step size <span>$\alpha_1\leq \rho_{hi}\alpha_0$</span> </li><li><code>ρ_lo</code>: the new step size <span>$\alpha_1\geq \rho_{lo}\alpha_0$</span> </li><li><code>iterations</code>: maximum number of iterations for linesearch</li><li><code>maxstep</code>: maximum allowable steps</li><li><code>αinitial</code>: initial guess for the step size <span>$\alpha$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L419-L452">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.newton_raphson_with_grad-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s157,N} where N where #s157&lt;:Real},Vararg{PyCall.PyObject,N} where N}} where T&lt;:Real" href="#ADCME.newton_raphson_with_grad-Union{Tuple{T}, Tuple{Function,Union{PyCall.PyObject, Array}}, Tuple{Function,Union{PyCall.PyObject, Array},Union{Missing, PyCall.PyObject, Array{#s157,N} where N where #s157&lt;:Real},Vararg{PyCall.PyObject,N} where N}} where T&lt;:Real"><code>ADCME.newton_raphson_with_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">newton_raphson_with_grad(f::Function, 
u0::Union{Array,PyObject}, 
θ::Union{Missing,PyObject, Array{&lt;:Real}}=missing,
args::PyObject...) where T&lt;:Real</code></pre><p>Differentiable Newton-Raphson algorithm. See <a href="../newton_raphson/#ADCME.newton_raphson"><code>newton_raphson</code></a>.</p><p>Use <code>ADCME.options.newton_raphson</code> to supply options. </p><p><strong>Example</strong></p><pre><code class="language-julia">function f(θ, x)
    x^3 - θ, 3spdiag(x^2)
end

θ = constant([2. .^3;3. ^3; 4. ^3])
x = newton_raphson_with_grad(f, constant(ones(3)), θ)
run(sess, x)≈[2.;3.;4.]
run(sess, gradients(sum(x), θ))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/optim.jl#L585-L606">source</a></section></article><h2 id="Neural-Networks"><a class="docs-heading-anchor" href="#Neural-Networks">Neural Networks</a><a id="Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.BatchNormalization" href="#ADCME.BatchNormalization"><code>ADCME.BatchNormalization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">BatchNormalization(dims::Int64=2; kwargs...)</code></pre><p>Creates a batch normalization layer. </p><p><strong>Example</strong></p><pre><code class="language-julia">b = BatchNormalization(2)
x = rand(10,2)
training = placeholder(true)
y = b(x, training)
run(sess, y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L534-L547">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Conv1D" href="#ADCME.Conv1D"><code>ADCME.Conv1D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Conv1D(filters, kernel_size, strides, activation, args...;kwargs...)</code></pre><pre><code class="language-julia">c = Conv1D(32, 3, 1, &quot;relu&quot;)
x = rand(100, 6, 128) # 128-length vectors with 6 timesteps (&quot;channels&quot;)
y = c(x) # shape=(100, 4, 32)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L608-L616">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Conv2D" href="#ADCME.Conv2D"><code>ADCME.Conv2D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Conv2D(filters, kernel_size, strides, activation, args...;kwargs...)</code></pre><p>The arrangement is (samples, rows, cols, channels) (data<em>format=&#39;channels</em>last&#39;)</p><pre><code class="language-julia">Conv2D(32, 3, 1, &quot;relu&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L639-L646">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Conv3D" href="#ADCME.Conv3D"><code>ADCME.Conv3D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Conv3D(filters, kernel_size, strides, activation, args...;kwargs...)</code></pre><p>The arrangement is (samples, rows, cols, channels) (data<em>format=&#39;channels</em>last&#39;)</p><pre><code class="language-julia">c = Conv3D(32, 3, 1, &quot;relu&quot;)
x = constant(rand(100, 10, 10, 10, 16))
y = c(x)
# shape=(100, 8, 8, 8, 32)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L690-L700">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Dense" href="#ADCME.Dense"><code>ADCME.Dense</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Dense(units::Int64, activation::Union{String, Function, Nothing} = nothing,
    args...;kwargs...)</code></pre><p>Creates a callable dense neural network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L582-L587">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Resnet1D" href="#ADCME.Resnet1D"><code>ADCME.Resnet1D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Resnet1D(out_features::Int64, hidden_features::Int64;
    num_blocks::Int64=2, activation::Union{String, Function, Nothing} = &quot;relu&quot;, 
    dropout_probability::Float64 = 0.0, use_batch_norm::Bool = false, name::Union{String, Missing} = missing)</code></pre><p>Creates a 1D residual network. If <code>name</code> is not missing, <code>Resnet1D</code> does not create a new entity. </p><p><strong>Example</strong></p><pre><code class="language-julia">resnet = Resnet1D(20)
x = rand(1000,10)
y = resnet(x)</code></pre><p><strong>Example: Digit recognition</strong></p><pre><code class="language-none">using MLDatasets
using ADCME

# load data 
train_x, train_y = MNIST.traindata()
train_x = reshape(Float64.(train_x), :, size(train_x,3))&#39;|&gt;Array
test_x, test_y = MNIST.testdata()
test_x = reshape(Float64.(test_x), :, size(test_x,3))&#39;|&gt;Array

# construct loss function 
ADCME.options.training.training = placeholder(true)
x = placeholder(rand(64, 784))
l = placeholder(rand(Int64, 64))
resnet = Resnet1D(10, num_blocks=10)
y = resnet(x)
loss = mean(sparse_softmax_cross_entropy_with_logits(labels=l, logits=y))

# train the neural network 
opt = AdamOptimizer().minimize(loss)
sess = Session(); init(sess)
for i = 1:10000
    idx = rand(1:60000, 64)
    _, loss_ = run(sess, [opt, loss], feed_dict=Dict(l=&gt;train_y[idx], x=&gt;train_x[idx,:]))
    @info i, loss_
end

# test 
for i = 1:10
    idx = rand(1:10000,100)
    y0 = resnet(test_x[idx,:])
    y0 = run(sess, y0, ADCME.options.training.training=&gt;false)
    pred = [x[2]-1 for x in argmax(y0, dims=2)]
    @info &quot;Accuracy = &quot;, sum(pred .== test_y[idx])/100
end</code></pre><p><img src="https://github.com/ADCMEMarket/ADCMEImages/tree/master/ADCME/assets/resnet.png?raw=true" alt/></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L764-L815">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae" href="#ADCME.ae"><code>ADCME.ae</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae(x::PyObject, output_dims::Array{Int64}, scope::String = &quot;default&quot;;
    activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L96-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{Array{Array{Float64,N} where N,N} where N, Array{PyCall.PyObject,N} where N}}" href="#ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{Array{Array{Float64,N} where N,N} where N, Array{PyCall.PyObject,N} where N}}"><code>ADCME.ae</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae(x::Union{Array{Float64}, PyObject}, 
    output_dims::Array{Int64}, 
    θ::Union{Array{Array{Float64}}, Array{PyObject}};
    activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Constructs a neural network with given weights and biases <code>θ</code></p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = ae_init([30, 20, 20, 5])
y = ae(x, [20, 20, 5], θ) # 10×5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L187-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyCall.PyObject, Array{Float64,N} where N}}" href="#ADCME.ae-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Array{Int64,N} where N,Union{PyCall.PyObject, Array{Float64,N} where N}}"><code>ADCME.ae</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject};
activation::Union{Function,String, Nothing} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>. The weights are given by <code>θ</code></p><p><strong>Example 1: Explicitly construct weights and biases</strong></p><pre><code class="language-julia">x = constant(rand(10,2))
n = ae_num([2,20,20,20,2])
θ = Variable(randn(n)*0.001)
y = ae(x, [20,20,20,2], θ)</code></pre><p><strong>Example 2: Implicitly construct weights and biases</strong></p><pre><code class="language-julia">θ = ae_init([10,20,20,20,2]) 
x = constant(rand(10,10))
y = ae(x, [20,20,20,2], θ)</code></pre><p>See also <a href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ae_num</code></a>, <a href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ae_init</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L127-L151">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_init-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_init</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=&quot;xavier&quot;)
fc_init(output_dims::Array{Int64})</code></pre><p>Return the initial weights and bias values by TensorFlow as a vector. The neural network architecture is</p><p class="math-container">\[o_1 (\text{Input layer}) \rightarrow o_2 \rightarrow \ldots \rightarrow o_n (\text{Output layer})\]</p><p>Three types of  random initializers are provided</p><ul><li><code>xavier</code> (default). It is useful for <code>tanh</code> fully connected neural network. </li></ul><pre><code class="language-none">W^l_i \sim \mathcal{N}\left(0, \sqrt{\frac{1}{n_{l-1}}}\right)</code></pre><ul><li><code>xavier_avg</code>. A variant of <code>xavier</code></li></ul><p class="math-container">\[W^l_i \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n_l + n_{l-1}}}\right)\]</p><ul><li><code>he</code>. This is the activation aware initialization of weights and helps mitigate the problem</li></ul><p>of vanishing/exploding gradients. </p><p class="math-container">\[W^l_i \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n_{l-1}}}\right)\]</p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = fc_init([30, 20, 20, 5])
y = fc(x, [20, 20, 5], θ) # 10×5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L225-L262">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_num-Tuple{Array{Int64,N} where N}" href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ADCME.ae_num</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ae_num(output_dims::Array{Int64})
fc_num(output_dims::Array{Int64})</code></pre><p>Estimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from <a href="#ADCME.ae"><code>ae</code></a> since in <code>ae</code> the feature dimension can be inferred), and the last dimension should be the output dimension. </p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = ae_init([30, 20, 20, 5])
@assert ae_num([30, 20, 20, 5])==length(θ)
y = ae(x, [20, 20, 5], θ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L286-L301">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ae_to_code" href="#ADCME.ae_to_code"><code>ADCME.ae_to_code</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae_to_code(file::String, scope::String; activation::String = &quot;tanh&quot;)</code></pre><p>Return the code string from the feed-forward neural network data in <code>file</code>. Usually we can immediately evaluate  the code string into Julia session by </p><pre><code class="language-julia">eval(Meta.parse(s))</code></pre><p>If <code>activation</code> is not specified, <code>tanh</code> is the default. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L339-L348">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.bn-Tuple" href="#ADCME.bn-Tuple"><code>ADCME.bn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bn(args...;center = true, scale=true, kwargs...)</code></pre><p><code>bn</code> accepts a keyword parameter <code>is_training</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">bn(inputs, name=&quot;batch_norm&quot;, is_training=true)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>bn</code> should be used with <code>control_dependency</code></p><pre><code class="language-julia">update_ops = get_collection(UPDATE_OPS)
control_dependencies(update_ops) do 
    global train_step = AdamOptimizer().minimize(loss)
end </code></pre></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L394-L411">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.dense-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Int64,Vararg{Any,N} where N}" href="#ADCME.dense-Tuple{Union{PyCall.PyObject, Array{#s326,N} where N where #s326&lt;:Real},Int64,Vararg{Any,N} where N}"><code>ADCME.dense</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dense(inputs::Union{PyObject, Array{&lt;:Real}}, units::Int64, args...; 
    activation::Union{String, Function} = nothing, kwargs...)</code></pre><p>Creates a fully connected layer with the activation function specified by <code>activation</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L382-L387">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.dropout" href="#ADCME.dropout"><code>ADCME.dropout</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dropout(x::Union{PyObject, Real, Array{&lt;:Real}}, 
rate::Union{Real, PyObject}, training::Union{PyObject,Bool} = true; kwargs...)</code></pre><p>Randomly drops out entries in <code>x</code> with a rate of <code>rate</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L510-L515">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.fc" href="#ADCME.fc"><code>ADCME.fc</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae(x::PyObject, output_dims::Array{Int64}, scope::String = &quot;default&quot;;
    activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>.</p><pre><code class="language-none">ae(x::Union{Array{Float64}, PyObject}, output_dims::Array{Int64}, θ::Union{Array{Float64}, PyObject};
activation::Union{Function,String, Nothing} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Creates a neural network with intermediate numbers of neurons <code>output_dims</code>. The weights are given by <code>θ</code></p><p><strong>Example 1: Explicitly construct weights and biases</strong></p><pre><code class="language-julia">x = constant(rand(10,2))
n = ae_num([2,20,20,20,2])
θ = Variable(randn(n)*0.001)
y = ae(x, [20,20,20,2], θ)</code></pre><p><strong>Example 2: Implicitly construct weights and biases</strong></p><pre><code class="language-julia">θ = ae_init([10,20,20,20,2]) 
x = constant(rand(10,10))
y = ae(x, [20,20,20,2], θ)</code></pre><p>See also <a href="#ADCME.ae_num-Tuple{Array{Int64,N} where N}"><code>ae_num</code></a>, <a href="#ADCME.ae_init-Tuple{Array{Int64,N} where N}"><code>ae_init</code></a>.</p><pre><code class="language-none">ae(x::Union{Array{Float64}, PyObject}, 
    output_dims::Array{Int64}, 
    θ::Union{Array{Array{Float64}}, Array{PyObject}};
    activation::Union{Function,String} = &quot;tanh&quot;)</code></pre><p>Alias: <code>fc</code>, <code>ae</code></p><p>Constructs a neural network with given weights and biases <code>θ</code></p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = ae_init([30, 20, 20, 5])
y = ae(x, [20, 20, 5], θ) # 10×5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L493">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.fc_init" href="#ADCME.fc_init"><code>ADCME.fc_init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae_init(output_dims::Array{Int64}; T::Type=Float64, method::String=&quot;xavier&quot;)
fc_init(output_dims::Array{Int64})</code></pre><p>Return the initial weights and bias values by TensorFlow as a vector. The neural network architecture is</p>$<p>o<em>1 (\text{Input layer}) \rightarrow o</em>2 \rightarrow \ldots \rightarrow o_n (\text{Output layer}) $</p><p>Three types of  random initializers are provided</p><ul><li><code>xavier</code> (default). It is useful for <code>tanh</code> fully connected neural network.</li></ul><pre><code class="language-none">W^l_i \sim \mathcal{N}\left(0, \sqrt{\frac{1}{n_{l-1}}}\right)</code></pre><ul><li><code>xavier_avg</code>. A variant of <code>xavier</code></li></ul>$<p>W^l<em>i \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n</em>l + n_{l-1}}}\right) $</p><ul><li><code>he</code>. This is the activation aware initialization of weights and helps mitigate the problem</li></ul><p>of vanishing/exploding gradients. </p>$<p>W^l<em>i \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n</em>{l-1}}}\right) $</p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = fc_init([30, 20, 20, 5])
y = fc(x, [20, 20, 5], θ) # 10×5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L501">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.fc_num" href="#ADCME.fc_num"><code>ADCME.fc_num</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ae_num(output_dims::Array{Int64})
fc_num(output_dims::Array{Int64})</code></pre><p>Estimates the number of weights and biases for the neural network. Note the first dimension should be the feature dimension (this is different from <a href="#ADCME.ae"><code>ae</code></a> since in <code>ae</code> the feature dimension can be inferred), and the last dimension should be the output dimension. </p><p><strong>Example</strong></p><pre><code class="language-julia">x = constant(rand(10,30))
θ = ae_init([30, 20, 20, 5])
@assert ae_num([30, 20, 20, 5])==length(θ)
y = ae(x, [20, 20, 5], θ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L497">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.fcx-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Array{Int64,1},Union{Array{Float64,1}, PyCall.PyObject}}" href="#ADCME.fcx-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Array{Int64,1},Union{Array{Float64,1}, PyCall.PyObject}}"><code>ADCME.fcx</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fcx(x::Union{Array{Float64,2},PyObject}, output_dims::Array{Int64,1}, 
θ::Union{Array{Float64,1}, PyObject};
activation::String = &quot;tanh&quot;)</code></pre><p>Creates a fully connected neural network with output dimension <code>o</code> and inputs <span>$x\in \mathbb{R}^{m\times n}$</span>. </p><p class="math-container">\[x \rightarrow o_1 \rightarrow o_2 \rightarrow \ldots \rightarrow o_k\]</p><p><code>θ</code> is the weights and biases of the neural network, e.g., <code>θ = ae_init(output_dims)</code>.</p><p><code>fcx</code> outputs two tensors:</p><ul><li><p>the output of the neural network: <span>$u\in \mathbb{R}^{m\times o_k}$</span>.</p></li><li><p>the sensitivity of the neural network per sample: <span>$\frac{\partial u}{\partial x}\in \mathbb{R}^{m \times o_k \times n}$</span></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/layers.jl#L57-L74">source</a></section></article><h2 id="Generative-Neural-Nets"><a class="docs-heading-anchor" href="#Generative-Neural-Nets">Generative Neural Nets</a><a id="Generative-Neural-Nets-1"></a><a class="docs-heading-anchor-permalink" href="#Generative-Neural-Nets" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.GAN" href="#ADCME.GAN"><code>ADCME.GAN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GAN(dat::Union{Array,PyObject}, generator::Function, discriminator::Function,
loss::Union{Missing, Function}=missing; latent_dim::Union{Missing, Int64}=missing,
    batch_size::Int64=32)</code></pre><p>Creates a GAN instance. </p><ul><li><code>dat</code> <span>$\in \mathbb{R}^{n\times d}$</span> is the training data for the GAN, where <span>$n$</span> is the number of training data, and <span>$d$</span> is the dimension per training data.</li><li><code>generator</code><span>$:\mathbb{R}^{d&#39;} \rightarrow \mathbb{R}^d$</span> is the generator function, <span>$d&#39;$</span> is the hidden dimension.</li><li><code>discriminator</code><span>$:\mathbb{R}^{d} \rightarrow \mathbb{R}$</span> is the discriminator function. </li><li><code>loss</code> is the loss function. See <a href="#ADCME.klgan-Tuple{GAN}"><code>klgan</code></a>, <a href="#ADCME.rklgan-Tuple{GAN}"><code>rklgan</code></a>, <a href="#ADCME.wgan-Tuple{GAN}"><code>wgan</code></a>, <a href="#ADCME.lsgan-Tuple{GAN}"><code>lsgan</code></a> for examples.</li><li><code>latent_dim</code> (default=<span>$d$</span>, the same as output dimension) is the latent dimension.</li><li><code>batch_size</code> (default=32) is the batch size in training.</li></ul><p><strong>Example: Constructing a GAN</strong></p><pre><code class="language-julia">dat = rand(10000,10)
generator = (z, gan)-&gt;10*z
discriminator = (x, gan)-&gt;sum(x)
gan = GAN(dat, generator, discriminator, &quot;wgan_stable&quot;)</code></pre><p><strong>Example: Learning a Gaussian random variable</strong></p><pre><code class="language-julia">using ADCME 
using PyPlot
using Distributions
dat = randn(10000, 1) * 0.5 .+ 3.0
function gen(z, gan)
    ae(z, [20,20,20,1], &quot;generator_$(gan.ganid)&quot;, activation = &quot;relu&quot;)
end
function disc(x, gan)
    squeeze(ae(x, [20,20,20,1], &quot;discriminator_$(gan.ganid)&quot;, activation = &quot;relu&quot;))
end
gan = GAN(dat, gen, disc, g-&gt;wgan_stable(g, 0.001); latent_dim = 10)

dopt = AdamOptimizer(0.0002, beta1=0.5, beta2=0.9).minimize(gan.d_loss, var_list=gan.d_vars)
gopt = AdamOptimizer(0.0002, beta1=0.5, beta2=0.9).minimize(gan.g_loss, var_list=gan.g_vars)
sess = Session(); init(sess)
for i = 1:5000
    batch_x = rand(1:10000, 32)
    batch_z = randn(32, 10)
    for n_critic = 1:1
        global _, dl = run(sess, [dopt, gan.d_loss], 
                feed_dict=Dict(gan.ids=&gt;batch_x, gan.noise=&gt;batch_z))
    end
    _, gl, gm, dm, gp = run(sess, [gopt, gan.g_loss, 
        gan.STORAGE[&quot;g_grad_magnitude&quot;], gan.STORAGE[&quot;d_grad_magnitude&quot;], 
        gan.STORAGE[&quot;gradient_penalty&quot;]],
        feed_dict=Dict(gan.ids=&gt;batch_x, gan.noise=&gt;batch_z))
    mod(i, 100)==0 &amp;&amp; (@info i, dl, gl, gm, dm, gp)
end

hist(run(sess, squeeze(rand(gan,10000))), bins=50, density = true)
nm = Normal(3.0,0.5)
x0 = 1.0:0.01:5.0
y0 = pdf.(nm, x0)
plot(x0, y0, &quot;g&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L61-L120">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.build!-Tuple{GAN}" href="#ADCME.build!-Tuple{GAN}"><code>ADCME.build!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">build!(gan::GAN)</code></pre><p>Builds the GAN instances. This function returns <code>gan</code> for convenience.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.jsgan-Tuple{GAN}" href="#ADCME.jsgan-Tuple{GAN}"><code>ADCME.jsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">jsgan(gan::GAN)</code></pre><p>Computes the vanilla GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L199-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.klgan-Tuple{GAN}" href="#ADCME.klgan-Tuple{GAN}"><code>ADCME.klgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">klgan(gan::GAN)</code></pre><p>Computes the KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L185-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.lsgan-Tuple{GAN}" href="#ADCME.lsgan-Tuple{GAN}"><code>ADCME.lsgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">lsgan(gan::GAN)</code></pre><p>Computes the least square GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L279-L283">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.predict-Tuple{GAN,Union{PyCall.PyObject, Array}}" href="#ADCME.predict-Tuple{GAN,Union{PyCall.PyObject, Array}}"><code>ADCME.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict(gan::GAN, input::Union{PyObject, Array})</code></pre><p>Predicts the GAN <code>gan</code> output given input <code>input</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L313-L317">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rklgan-Tuple{GAN}" href="#ADCME.rklgan-Tuple{GAN}"><code>ADCME.rklgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rklgan(gan::GAN)</code></pre><p>Computes the reverse KL-divergence GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L265-L269">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.sample-Tuple{GAN,Int64}" href="#ADCME.sample-Tuple{GAN,Int64}"><code>ADCME.sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sample(gan::GAN, n::Int64)
rand(gan::GAN, n::Int64)</code></pre><p>Samples <code>n</code> instances from <code>gan</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L294-L299">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.wgan-Tuple{GAN}" href="#ADCME.wgan-Tuple{GAN}"><code>ADCME.wgan</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">wgan(gan::GAN)</code></pre><p>Computes the Wasserstein GAN loss function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L213-L217">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.wgan_stable" href="#ADCME.wgan_stable"><code>ADCME.wgan_stable</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">wgan_stable(gan::GAN, λ::Float64)</code></pre><p>Returns the discriminator and generator loss for the Wasserstein GAN loss with penalty parameter <span>$\lambda$</span></p><p>The objective function is </p><p class="math-container">\[L = E_{\tilde x\sim P_g} [D(\tilde x)] - E_{x\sim P_r} [D(x)] + \lambda E_{\hat x\sim P_{\hat x}}[(||\nabla_{\hat x}D(\hat x)||^2-1)^2]\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gan.jl#L227-L236">source</a></section></article><h2 id="Tools"><a class="docs-heading-anchor" href="#Tools">Tools</a><a id="Tools-1"></a><a class="docs-heading-anchor-permalink" href="#Tools" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.MCMCSimple" href="#ADCME.MCMCSimple"><code>ADCME.MCMCSimple</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MCMCSimple(obs::Array{Float64, 1}, h::Function, 
σ::Float64, θ0::Array{Float64,1}, lb::Float64, ub::Float64)</code></pre><p>A very simple yet useful interface for MCMC simulation in many scientific computing problems. </p><ul><li><code>obs</code>: Observations</li><li><code>h</code>: Forward computation function</li><li><code>σ</code>: Noise standard deviation for the observed data </li><li><code>ub</code>, <code>lb</code>: upper and lower bound</li><li><code>θ0</code>: Initial guess </li></ul><p>The mathematical model is </p><p class="math-container">\[y_{obs} = h(\theta)\]</p><p>and we have a hard constraint <code>lb\leq \theta \leq ub</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L862-L881">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.cmake" href="#ADCME.cmake"><code>ADCME.cmake</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">cmake(DIR::String=&quot;..&quot;; CMAKE_ARGS::Union{Array{String}, String} = &quot;&quot;)</code></pre><p>The built-in Cmake command for building C/C++ libraries. If extra Cmake arguments are needed, please specify it through <code>CMAKE_ARGS</code>.</p><p><strong>Example</strong></p><pre><code class="language-none">ADCME.cmake(CMAKE_ARGS=[&quot;SHARED=YES&quot;, &quot;STAITC=NO&quot;])</code></pre><p>The executed command might be:</p><pre><code class="language-none">/home/darve/kailaix/.julia/adcme/bin/cmake -G Ninja -DCMAKE_MAKE_PROGRAM=/home/darve/kailaix/.julia/adcme/bin/ninja -DJULIA=/home/darve/kailaix/julia-1.3.1/bin/julia -DCMAKE_C_COMPILER=/home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-gcc -DCMAKE_CXX_COMPILER=/home/darve/kailaix/.julia/adcme/bin/x86_64-conda_cos6-linux-gnu-g++ SHARED=YES STATIC=NO ..</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L36-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile-Tuple{String}" href="#ADCME.compile-Tuple{String}"><code>ADCME.compile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile(s::String; force::Bool=false)</code></pre><p>Compiles the library given by path <code>deps/s</code>. If <code>force</code> is false, <code>compile</code> first check whether  the binary product exists. If the binary product exists, return 2. Otherwise, <code>compile</code> tries to  compile the binary product, and returns 0 if successful; it return 1 otherwise. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L262-L268">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.compile-Tuple{}" href="#ADCME.compile-Tuple{}"><code>ADCME.compile</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compile()</code></pre><p>Compile a custom operator in the current directory. A <code>CMakeLists.txt</code> must be present. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L353-L357">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.customop-Tuple{}" href="#ADCME.customop-Tuple{}"><code>ADCME.customop</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">customop(;with_mpi::Bool = false)</code></pre><p>Create a new custom operator. Typically users call <code>customop</code> twice: the first call generates a <code>customop.txt</code>,  users edit the content in the file; the second all generates C++ source code, CMakeLists.txt, and gradtest.jl from <code>customop.txt</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; customop() # create an editable `customop.txt` file
[ Info: Edit custom_op.txt for custom operators
julia&gt; customop() # after editing `customop.txt`, call it again to generate interface files.</code></pre><p><strong>Options</strong></p><ul><li><code>with_mpi</code>: Whether the custom operator uses MPI</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L378-L393">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.debug" href="#ADCME.debug"><code>ADCME.debug</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">debug(libfile::String = &quot;&quot;)</code></pre><p>Loading custom operator shared library. If the loading fails, detailed error message is printed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L559-L563">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.debug-Tuple{PyCall.PyObject,PyCall.PyObject}" href="#ADCME.debug-Tuple{PyCall.PyObject,PyCall.PyObject}"><code>ADCME.debug</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">debug(sess::PyObject, o::PyObject)</code></pre><p>In the case a session run yields an error from the TensorFlow backend, this function can help print the exact error.  For example, you might encounter  <code>InvalidArgumentError()</code> with no detailed error information, and this function can be useful for debugging.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L542-L547">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.doctor-Tuple{}" href="#ADCME.doctor-Tuple{}"><code>ADCME.doctor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">doctor()</code></pre><p>Reports health of the current installed ADCME package. If some components are broken, possible fix is proposed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L578-L582">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_library_symbols-Tuple{Union{String, PyCall.PyObject}}" href="#ADCME.get_library_symbols-Tuple{Union{String, PyCall.PyObject}}"><code>ADCME.get_library_symbols</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_library_symbols(file::Union{String, PyObject})</code></pre><p>Returns the symbols in the custom op library <code>file</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L1021-L1025">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_placement-Tuple{}" href="#ADCME.get_placement-Tuple{}"><code>ADCME.get_placement</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_placement()</code></pre><p>Returns the operation placements.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L947-L951">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.install-Tuple{String}" href="#ADCME.install-Tuple{String}"><code>ADCME.install</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">install(s::String; force::Bool = false, islocal::Bool = false)</code></pre><p>Install a custom operator from a URL, a directory (when <code>islocal</code> is true), or a string. In any of the three case,  <code>install</code> copy the folder to /home/runner/work/ADCME.jl/ADCME.jl/deps/CustomOps/Plugin.  When <code>s</code> is a string, <code>s</code> is converted to </p><p>https://github.com/ADCMEMarket/&lt;s&gt;</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L443-L451">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_library-Tuple{String}" href="#ADCME.load_library-Tuple{String}"><code>ADCME.load_library</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_library(filename::String)</code></pre><p>Load custom operator libraries. If used with </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L999-L1003">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op-Tuple{Union{String, PyCall.PyObject},String}" href="#ADCME.load_op-Tuple{Union{String, PyCall.PyObject},String}"><code>ADCME.load_op</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op(oplibpath::Union{PyObject, String}, opname::String; verbose::Union{Missing, Bool} = missing)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L137-L141">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_op_and_grad-Tuple{Union{String, PyCall.PyObject},String}" href="#ADCME.load_op_and_grad-Tuple{Union{String, PyCall.PyObject},String}"><code>ADCME.load_op_and_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">load_op_and_grad(oplibpath::Union{PyObject, String}, opname::String; multiple::Bool=false)</code></pre><p>Loads the operator <code>opname</code> from library <code>oplibpath</code>; gradients are also imported.  If <code>multiple</code> is true, the operator is assumed to have multiple outputs. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L154-L159">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.load_system_op" href="#ADCME.load_system_op"><code>ADCME.load_system_op</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">load_system_op(opname::String, grad::Bool=true; multiple::Bool=false)</code></pre><p>Loads custom operator from CustomOps directory (shipped with ADCME instead of TensorFlow) For example </p><pre><code class="language-none">s = &quot;SparseOperator&quot;
oplib = &quot;libSO&quot;
grad = true</code></pre><p>this will direct Julia to find library <code>CustomOps/SparseOperator/libSO.dylib</code> on MACOSX</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L238-L249">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.make_library-Tuple{String}" href="#ADCME.make_library-Tuple{String}"><code>ADCME.make_library</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">make_library(Libdir::String)</code></pre><p>Make shared library in <code>Libdir</code>. The structure of the source codes files are </p><pre><code class="language-none">- Libdir 
  - *.cpp 
  - *.h 
  - CMakeLists
  - build (Optional)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L104-L116">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.nnuq-Tuple{Array{Float64,2},Union{Float64, Array{Float64,2}},Union{Float64, Array{Float64,2}}}" href="#ADCME.nnuq-Tuple{Array{Float64,2},Union{Float64, Array{Float64,2}},Union{Float64, Array{Float64,2}}}"><code>ADCME.nnuq</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">nnuq(H::Array{Float64,2}, invR::Union{Float64, Array{Float64,2}}, invQ::Union{Float64, Array{Float64,2}})</code></pre><p>Returns the variance matrix for the Baysian inversion. </p><p>The negative log likelihood function is</p><p class="math-container">\[l(s) =\frac{1}{2} (y-h(s))^T R^{-1} (y-h(s)) + \frac{1}{2} s^T Q^{-1} s\]</p><p>The covariance matrix is computed by first linearizing <span>$h(s)$</span></p><p class="math-container">\[h(s)\approx h(s_0) + \nabla h(s_0) (s-s_0)\]</p><p>and then computing the second order derivative</p><p class="math-container">\[V = \left(\frac{\partial^2 l}{\partial s^T\partial s}\right)^{-1} = (H^T R^{-1} H + Q^{-1})^{-1}\]</p><p>Note the result is independent of <span>$s_0$</span>, <span>$y_0$</span>, and only depends on <span>$\nabla h(s_0)$</span></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L823-L841">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.register-Tuple{Function,Function}" href="#ADCME.register-Tuple{Function,Function}"><code>ADCME.register</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">register(forward::Function, backward::Function; multiple::Bool=false)</code></pre><p>Register a function <code>forward</code> with back-propagated gradients rule <code>backward</code> to the backward.  ∘ <code>forward</code>: it takes <span>$n$</span> inputs and outputs <span>$m$</span> tensors. When <span>$m&gt;1$</span>, the keyword <code>multiple</code> must be true.  ∘ <code>backward</code>: it takes <span>$\tilde m$</span> top gradients from float/double output tensors of <code>forward</code>, <span>$m$</span> outputs of the <code>forward</code>,     and <span>$n$</span> inputs of the <code>forward</code>. <code>backward</code> outputs <span>$n$</span> gradients for each input of <code>forward</code>. When input <span>$i$</span> of    <code>forward</code> is not float/double, <code>backward</code> should return <code>nothing</code> for the corresponding gradients. </p><p><strong>Example</strong></p><pre><code class="language-julia">forward = x-&gt;log(1+exp(x))
backward = (dy, y, x)-&gt;dy*(1-1/(1+y))
f = register(forward, backward)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L499-L514">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.sleep_for-Tuple{Union{PyCall.PyObject, #s329} where #s329&lt;:Real}" href="#ADCME.sleep_for-Tuple{Union{PyCall.PyObject, #s329} where #s329&lt;:Real}"><code>ADCME.sleep_for</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sleep_for(t::Union{PyObject, &lt;:Real})</code></pre><p>Sleeps for <code>t</code> seconds. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L964-L968">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_gpu-Tuple{}" href="#ADCME.test_gpu-Tuple{}"><code>ADCME.test_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_gpu()</code></pre><p>Tests the GPU ultilities</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L804-L808">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.timestamp" href="#ADCME.timestamp"><code>ADCME.timestamp</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">timestamp(deps::Union{PyObject, &lt;:Real, Missing}=missing)</code></pre><p>These functions are usually used with <a href="#Base.bind-Tuple{PyCall.PyObject,Vararg{Any,N} where N}"><code>bind</code></a> for profiling.  Note the timing is not very accurate in a multithreaded environment.</p><ul><li><code>deps</code>: <code>deps</code> is always executed before returning the timestamp.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia">a = constant(3.0)
t0 = timestamp(a)
sleep_time = sleep_for(a)
t1 = timestamp(sleep_time)
sess = Session(); init(sess)
t0_, t1_ = run(sess, [t0, t1])
time = t1_ - t0_</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L974-L991">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.xavier_init" href="#ADCME.xavier_init"><code>ADCME.xavier_init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">xavier_init(size, dtype=Float64)</code></pre><p>Returns a matrix of size <code>size</code> and its values are from Xavier initialization. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L24-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.precompile" href="#Base.precompile"><code>Base.precompile</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">precompile(force::Bool=false)</code></pre><p>Precompile the built-in custom operators. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/extra.jl#L312-L316">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.animate-Tuple{Function,Any}" href="#ADCME.animate-Tuple{Function,Any}"><code>ADCME.animate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">animate(update::Function, frames; kwargs...)</code></pre><p>Creates an animation using update function <code>update</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia">θ = LinRange(0, 2π, 100)
x = cos.(θ)
y = sin.(θ)
pl, = plot([], [], &quot;o-&quot;)
t = title(&quot;0&quot;)
xlim(-1.2,1.2)
ylim(-1.2,1.2)
function update(i)
    t.set_text(&quot;$i&quot;)
    pl.set_data([x[1:i] y[1:i]]&#39;|&gt;Array)
end
animate(update, 1:100)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L403-L422">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gradview-Tuple{PyCall.PyObject,PyCall.PyObject,PyCall.PyObject,Any}" href="#ADCME.gradview-Tuple{PyCall.PyObject,PyCall.PyObject,PyCall.PyObject,Any}"><code>ADCME.gradview</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gradview(sess::PyObject, pl::PyObject, loss::PyObject, u0; scale::Float64 = 1.0)</code></pre><p>Visualizes the automatic differentiation and finite difference convergence converge. For correctly implemented differentiable codes, the convergence rate for AD should be 2 and for FD should be 1 (if not evaluated at stationary point).</p><ul><li><code>scale</code>: you can control the step size for perturbation. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L295-L302">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.jacview-Tuple{PyCall.PyObject,Function,Union{Missing, PyCall.PyObject, Array{Float64,N} where N},Array{Float64,N} where N,Vararg{Any,N} where N}" href="#ADCME.jacview-Tuple{PyCall.PyObject,Function,Union{Missing, PyCall.PyObject, Array{Float64,N} where N},Array{Float64,N} where N,Vararg{Any,N} where N}"><code>ADCME.jacview</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">jacview(sess::PyObject, f::Function, θ::Union{Array{Float64}, PyObject, Missing}, 
u0::Array{Float64}, args...)</code></pre><p>Performs gradient test for a vector function. <code>f</code> has the signature </p><pre><code class="language-none">f(θ, u) -&gt; r, J</code></pre><p>Here <code>θ</code> is a nuisance  parameter, <code>u</code> is the state variables (w.r.t. which the Jacobian is computed), <code>r</code> is the residual vector, and <code>J</code> is the Jacobian matrix (a dense matrix or a <a href="#ADCME.SparseTensor"><code>SparseTensor</code></a>).</p><p><strong>Example 1</strong></p><pre><code class="language-julia">u0 = rand(10)
function verify_jacobian_f(θ, u)
    r = u^3+u - u0
    r, spdiag(3u^2+1.0)
end
jacview(sess, verify_jacobian_f, missing, u0)</code></pre><p><strong>Example 2</strong></p><pre><code class="language-none">u0 = rand(10)
rs = rand(10)
function verify_jacobian_f(θ, u)
    r = [u^2;u] - [rs;rs]
    r, [spdiag(2*u); spdiag(10)]
end
jacview(sess, verify_jacobian_f, missing, u0); close(&quot;all&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L309-L340">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.lineview" href="#ADCME.lineview"><code>ADCME.lineview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">lineview(sess::PyObject, pl::PyObject, loss::PyObject, θ1, θ2=nothing; n::Integer = 10)</code></pre><p>Plots the function </p><p class="math-container">\[h(α) = f((1-α)θ_1 + αθ_2)\]</p><p><strong>Example</strong></p><pre><code class="language-julia">pl = placeholder(Float64, shape=[2])
l = sum(pl^2-pl*0.1)
sess = Session(); init(sess)
lineview(sess, pl, l, rand(2))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L120-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.saveanim-Tuple{PyCall.PyObject,String}" href="#ADCME.saveanim-Tuple{PyCall.PyObject,String}"><code>ADCME.saveanim</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">saveanim(anim::PyObject, filename::String; kwargs...)</code></pre><p>Saves the animation produced by <a href="#ADCME.animate-Tuple{Function,Any}"><code>animate</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L433-L437">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_gradients-Tuple{Function,Array{Float64,1}}" href="#ADCME.test_gradients-Tuple{Function,Array{Float64,1}}"><code>ADCME.test_gradients</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_gradients(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0, showfig::Bool = true)</code></pre><p>Testing the gradients of a vector function <code>f</code>: <code>y, J = f(x)</code> where <code>y</code> is a scalar output and <code>J</code> is the vector gradient.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L13-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_hessian-Tuple{Function,Array{Float64,1}}" href="#ADCME.test_hessian-Tuple{Function,Array{Float64,1}}"><code>ADCME.test_hessian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_hessian(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0)</code></pre><p>Testing the Hessian of a scalar function <code>f</code>: <code>g, H = f(x)</code> where <code>y</code> is a scalar output, <code>g</code> is a vector gradient output, and <code>H</code> is the Hessian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L88-L93">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.test_jacobian-Tuple{Function,Array{Float64,1}}" href="#ADCME.test_jacobian-Tuple{Function,Array{Float64,1}}"><code>ADCME.test_jacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">test_jacobian(f::Function, x0::Array{Float64, 1}; scale::Float64 = 1.0, showfig::Bool = true)</code></pre><p>Testing the gradients of a vector function <code>f</code>: <code>y, J = f(x)</code> where <code>y</code> is a vector output and <code>J</code> is the Jacobian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/kit.jl#L52-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.Database" href="#ADCME.Database"><code>ADCME.Database</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Database(filename::Union{Missing, String} = missing; 
    commit_after_execute::Bool = true)</code></pre><p>Creates a database from <code>filename</code>. If <code>filename</code> is not provided, an in-memory database is created.  If <code>commit_after_execute</code> is false, no commit operation is performed after each <a href="#ADCME.execute-Tuple{Database,String,Vararg{Any,N} where N}"><code>execute</code></a>.</p><ul><li>do block syntax:</li></ul><pre><code class="language-julia">Database() do db
    execute(db, &quot;create table mytable (a real, b real)&quot;)
end</code></pre><p>The database is automatically closed after execution. Therefore, if execute is a query operation,  users need to store the results in a global variable. </p><ul><li>Query meta information </li></ul><pre><code class="language-julia">keys(db) # all tables 
keys(db, &quot;mytable&quot;) # all column names in `db.mytable` </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sqlite.jl#L10-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.commit-Tuple{Database}" href="#ADCME.commit-Tuple{Database}"><code>ADCME.commit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">commit(db::Database)</code></pre><p>Commits changes to <code>db</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sqlite.jl#L98-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.execute-Tuple{Database,String,Vararg{Any,N} where N}" href="#ADCME.execute-Tuple{Database,String,Vararg{Any,N} where N}"><code>ADCME.execute</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">execute(db::Database, sql::String, args...)</code></pre><p>Executes the SQL statement <code>sql</code> in <code>db</code>. Users can also use the do block syntax. </p><pre><code class="language-julia">execute(db) do 
    &quot;create table mytable (a real, b real)&quot;
end</code></pre><p><code>execute</code> can also be used to insert a batch of records</p><pre><code class="language-julia">t1 = rand(10)
t2 = rand(10)
param = collect(zip(t1, t2))
execute(db, &quot;INSERT TO mytable VALUES (?,?)&quot;, param)</code></pre><p>or </p><pre><code class="language-julia">execute(db, &quot;INSERT TO mytable VALUES (?,?)&quot;, t1, t2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/sqlite.jl#L53-L74">source</a></section></article><h2 id="ODE"><a class="docs-heading-anchor" href="#ODE">ODE</a><a id="ODE-1"></a><a class="docs-heading-anchor-permalink" href="#ODE" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.ExplicitNewmark" href="#ADCME.ExplicitNewmark"><code>ADCME.ExplicitNewmark</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExplicitNewmark(M::Union{SparseTensor, SparseMatrixCSC}, Z1::Union{Missing, SparseTensor, SparseMatrixCSC}, Z2::Union{Missing, SparseTensor, SparseMatrixCSC}, Δt::Float64)</code></pre><p>An explicit Newmark integrator for </p><p class="math-container">\[M \ddot{\mathbf{d}} + Z_1 \dot{\mathbf{d}} + Z_2 \mathbf{d} + f = 0\]</p><p>The numerical scheme is </p><p class="math-container">\[\left(\frac{1}{\Delta t^2} M + \frac{1}{2\Delta t}Z_1\right)d^{n+1} = \left(\frac{2}{\Delta t^2} M - \frac{1}{2\Delta t}Z_2\right)d^n - \left(\frac{1}{\Delta t^2} M - \frac{1}{2\Delta t}Z_1\right) d^{n-1} - f\]</p><p>To use this integrator, </p><pre><code class="language-julia">en = ExplicitNewmark(M, Z1, Z2, Δt)
d2 = step(en, d0, d1, f)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L389-L406">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.TR_BDF2" href="#ADCME.TR_BDF2"><code>ADCME.TR_BDF2</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TR_BDF2(D0::Union{SparseTensor, SparseMatrixCSC}, 
    D1::Union{SparseTensor, SparseMatrixCSC}, 
    Δt::Float64)</code></pre><p>Constructs a TR-BDF2 (the Trapezoidal Rule with Second Order Backward Difference Formula) handler for  the DAE </p><p class="math-container">\[D_1 \dot y + D_0 y = f\]</p><p>The struct is a functor, which performs one step simulation </p><pre><code class="language-none">(tr::TR_BDF2)(y::Union{PyObject, Array{Float64, 1}}, 
    f1::Union{PyObject, Array{Float64, 1}}, 
    f2::Union{PyObject, Array{Float64, 1}}, 
    f3::Union{PyObject, Array{Float64, 1}})</code></pre><p>Here <code>f1</code>, <code>f2</code>, and <code>f3</code> correspond to the right hand side at time step <span>$n$</span>, <span>$n+\frac12$</span>, and <span>$n+1$</span>.</p><p>Or we can pass a batched <code>F</code> defined as a <code>(2NT+1) × DOF</code> array</p><pre><code class="language-none">(tr::TR_BDF2)(y0::Union{PyObject, Array{Float64, 1}}, 
    F::Union{PyObject, Array{Float64, 2}})</code></pre><p>The output will be the entire solution of size <code>(NT+1) × DOF</code>.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>The scheme takes the following form for n = 0, 1, ... <span>$\begin{aligned} D_1(y^{n+\frac12}-y^n) = \frac12\frac{\Delta t}{2}\left(f^{n+\frac12} + f^n - D_0 \left(y^{n+\frac12} + y^n\right)\right)\\ \left(\frac{\Delta t}{2}\right)^{-1} D_1 \left(\frac32y^{n+1} - 2y^{n+\frac12} + \frac12 y^n\right) + D_0 y^{n+1} = f^{n+1}\end{aligned}$</span></p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L256-L289">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.constant-Tuple{TR_BDF2}" href="#ADCME.constant-Tuple{TR_BDF2}"><code>ADCME.constant</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">constant(tr::TR_BDF2)</code></pre><p>Converts <code>tr</code> to a symbolic solver. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L314-L318">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ode45-Tuple" href="#ADCME.ode45-Tuple"><code>ADCME.ode45</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ode45(y::Union{PyObject, Float64, Array{Float64}}, T::Union{PyObject, Float64}, 
            NT::Union{PyObject,Int64}, f::Function, θ::Union{PyObject, Missing}=missing)</code></pre><p>Solves </p><p class="math-container">\[\frac{dy}{dt} = f(y, t, \theta)\]</p><p>with six-stage, fifth-order, Runge-Kutta method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L87-L96">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.rk4-Tuple" href="#ADCME.rk4-Tuple"><code>ADCME.rk4</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">rk4(y::Union{PyObject, Float64, Array{Float64}}, T::Union{PyObject, Float64}, 
            NT::Union{PyObject,Int64}, f::Function, θ::Union{PyObject, Missing}=missing)</code></pre><p>Solves </p><p class="math-container">\[\frac{dy}{dt} = f(y, t, \theta)\]</p><p>with Runge-Kutta (order 4) method. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L75-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.runge_kutta" href="#ADCME.runge_kutta"><code>ADCME.runge_kutta</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">runge_kutta(f::Function, T::Union{PyObject, Float64}, 
            NT::Union{PyObject,Int64}, y::Union{PyObject, Float64, Array{Float64}}, θ::Union{PyObject, Missing}=missing; method::String=&quot;rk4&quot;)</code></pre><p>Solves </p><p class="math-container">\[\frac{dy}{dt} = f(y, t, \theta)\]</p><p>with Runge-Kutta method. </p><p>For example, the default solver, <code>RK4</code>, has the following numerical scheme per time step </p><p class="math-container">\[\begin{aligned}
k_1 &amp;= \Delta t f(t_n, y_n, \theta)\\
k_2 &amp;= \Delta t f(t_n+\Delta t/2, y_n + k_1/2, \theta)\\
k_3 &amp;= \Delta t f(t_n+\Delta t/2, y_n + k_2/2, \theta)\\
k_4 &amp;= \Delta t f(t_n+\Delta t, y_n + k_3, \theta)\\
y_{n+1} &amp;= y_n + \frac{k_1}{6} +\frac{k_2}{3} +\frac{k_3}{3} +\frac{k_4}{6}
\end{aligned}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L24-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.αscheme-Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{Array{Float64,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Array{Float64,1}}" href="#ADCME.αscheme-Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{SparseTensor, SparseArrays.SparseMatrixCSC},Union{Array{Float64,2}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Array{Float64,1}}"><code>ADCME.αscheme</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">αscheme(M::Union{SparseTensor, SparseMatrixCSC}, 
    C::Union{SparseTensor, SparseMatrixCSC}, 
    K::Union{SparseTensor, SparseMatrixCSC}, 
    Force::Union{Array{Float64}, PyObject}, 
    d0::Union{Array{Float64, 1}, PyObject}, 
    v0::Union{Array{Float64, 1}, PyObject}, 
    a0::Union{Array{Float64, 1}, PyObject}, 
    Δt::Array{Float64}; 
    solve::Union{Missing, Function} = missing,
    extsolve::Union{Missing, Function} = missing, 
    ρ::Float64 = 1.0)</code></pre><p>Generalized α-scheme.  <span>$M u_{tt} + C u_{t} + K u = F$</span></p><p><code>Force</code> must be an array of size <code>n</code>×<code>p</code>, where <code>d0</code>, <code>v0</code>, and <code>a0</code> have a size <code>p</code> <code>Δt</code> is an array (variable time step). </p><p>The generalized α scheme solves the equation by the time stepping</p><p class="math-container">\[\begin{aligned}
\bf d_{n+1} &amp;= \bf d_n + h\bf v_n + h^2 \left(\left(\frac{1}{2}-\beta_2 \right)\bf a_n + \beta_2 \bf a_{n+1}  \right)\\
\bf v_{n+1} &amp;= \bf v_n + h((1-\gamma_2)\bf a_n + \gamma_2 \bf a_{n+1})\\
\bf F(t_{n+1-\alpha_{f_2}}) &amp;= M \bf a _{n+1-\alpha_{m_2}} + C \bf v_{n+1-\alpha_{f_2}} + K \bf{d}_{n+1-\alpha_{f_2}}
\end{aligned}\]</p><p>where </p><p class="math-container">\[\begin{aligned}
\bf d_{n+1-\alpha_{f_2}} &amp;= (1-\alpha_{f_2})\bf d_{n+1} + \alpha_{f_2} \bf d_n\\
\bf v_{n+1-\alpha_{f_2}} &amp;= (1-\alpha_{f_2}) \bf v_{n+1} + \alpha_{f_2} \bf v_n \\
\bf a_{n+1-\alpha_{m_2} } &amp;= (1-\alpha_{m_2}) \bf a_{n+1} + \alpha_{m_2} \bf a_n\\
t_{n+1-\alpha_{f_2}} &amp; = (1-\alpha_{f_2}) t_{n+1 + \alpha_{f_2}} + \alpha_{f_2}t_n
\end{aligned}\]</p><p>Here the parameters are computed using </p><p class="math-container">\[\begin{aligned}
\gamma_2 &amp;= \frac{1}{2} - \alpha_{m_2} + \alpha_{f_2}\\
\beta_2 &amp;= \frac{1}{4} (1-\alpha_{m_2}+\alpha_{f_2})^2 \\
\alpha_{m_2} &amp;= \frac{2\rho_\infty-1}{\rho_\infty+1}\\
\alpha_{f_2} &amp;= \frac{\rho_\infty}{\rho_\infty+1}
\end{aligned}\]</p><p>∘ <code>solve</code>: users can provide a solver function, <code>solve(A, rhs)</code> for solving <code>Ax = rhs</code> ∘ <code>extsolve</code>: similar to <code>solve</code>, but the signature has the form </p><pre><code class="language-julia">extsolve(A, rhs, i)</code></pre><p>This provides the users with more control, e.g., (time-dependent) Dirichlet boundary conditions.  See <a href="https://kailaix.github.io/ADCME.jl/dev/alphascheme/">Generalized α Scheme</a> for details.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In the case <span>$u$</span> has a nonzero essential boundary condition <span>$u_b$</span>, we let <span>$\tilde u=u-u_b$</span>, then  <span>$M \tilde u_{tt} + C \tilde u_t + K u = F - K u_b - C \dot u_b$</span></p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L100-L158">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.αscheme_time-Tuple{Array{Float64,N} where N}" href="#ADCME.αscheme_time-Tuple{Array{Float64,N} where N}"><code>ADCME.αscheme_time</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">αscheme_time(Δt::Array{Float64}; ρ::Float64 = 1.0)</code></pre><p>Returns the integration time <span>$t_{i+1-\alpha_{f_2}}$</span> between <span>$[t_i, t_{i+1}]$</span> using the alpha scheme.  If <span>$\Delta t$</span> has length <span>$n$</span>, the output will also have length <span>$n$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ode.jl#L229-L234">source</a></section></article><h2 id="Function-Approximators"><a class="docs-heading-anchor" href="#Function-Approximators">Function Approximators</a><a id="Function-Approximators-1"></a><a class="docs-heading-anchor-permalink" href="#Function-Approximators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.RBF2D" href="#ADCME.RBF2D"><code>ADCME.RBF2D</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">function RBF2D(xc::Union{PyObject, Array{Float64, 1}}, yc::Union{PyObject, Array{Float64, 1}}; 
    c::Union{PyObject, Array{Float64, 1}, Missing} = missing, 
    eps::Union{PyObject, Array{Float64, 1}, Real, Missing} = missing,
    d::Union{PyObject, Array{Float64, 1}} = zeros(0), 
    kind::Int64 = 0)</code></pre><p>Constructs a radial basis function representation on a 2D domain</p><p class="math-container">\[f(x, y) = \sum_{i=1}^N c_i \phi(r; \epsilon_i) + d_0 + d_1 x + d_2 y\]</p><p>Here <code>d</code> can be either 0, 1 (only <span>$d_0$</span> is present), or 3 (<span>$d_0$</span>, <span>$d_1$</span>, and <span>$d_2$</span> are all present).</p><p><code>kind</code> determines the type of radial basis functions </p><ul><li>0:Gaussian</li></ul><p class="math-container">\[\phi(r; \epsilon) = e^{-(\epsilon r)^2}\]</p><ul><li>1:Multiquadric</li></ul><p class="math-container">\[\phi(r; \epsilon) = \sqrt{1+(\epsilon r)^2}\]</p><ul><li>2:Inverse quadratic</li></ul><p class="math-container">\[\phi(r; \epsilon) = \frac{1}{1+(\epsilon r)^2}\]</p><ul><li>3:Inverse multiquadric</li></ul><p class="math-container">\[\phi(r; \epsilon) = \frac{1}{\sqrt{1+(\epsilon r)^2}}\]</p><p>Returns a callable struct, i.e. to evaluates the function at locations <span>$(x, y)$</span> (<code>x</code> and <code>y</code> are both vectors), run </p><pre><code class="language-julia">rbf(x, y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/rbf.jl#L3-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.interp1" href="#ADCME.interp1"><code>ADCME.interp1</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">interp1(x::Union{Array{Float64, 1}, PyObject},v::Union{Array{Float64, 1}, PyObject},xq::Union{Array{Float64, 1}, PyObject})</code></pre><p>returns interpolated values of a 1-D function at specific query points using linear interpolation.  Vector x contains the sample points, and v contains the corresponding values, v(x).  Vector xq contains the coordinates of the query points.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p><code>x</code> should be sorted in ascending order. </p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">x = sort(rand(10))
y = constant(@. x^2 + 1.0)
z = [x[1]; x[2]; rand(5) * (x[end]-x[1]) .+ x[1]; x[end]]
u = interp1(x,y,z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/rbf.jl#L77-L94">source</a></section></article><h2 id="Optimal-Transport"><a class="docs-heading-anchor" href="#Optimal-Transport">Optimal Transport</a><a id="Optimal-Transport-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Transport" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.dtw" href="#ADCME.dtw"><code>ADCME.dtw</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dtw(s::Union{PyObject, Array{Float64}}, t::Union{PyObject, Array{Float64}}, 
    use_fast::Bool = false)</code></pre><p>Computes the dynamic time wrapping (DTW) distance between two time series <code>s</code> and <code>t</code>.  Returns the distance and path. <code>use_fast</code> specifies whether fast algorithm is used. Note  fast algorithm may not be accurate.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L197-L204">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}" href="#ADCME.emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}"><code>ADCME.emd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">emd(a::Union{PyObject, Array{Float64}}, b::Union{PyObject, Array{Float64}}, M::Union{PyObject, Array{Float64}};
iter::Int64 = 1000, tol::Float64 = 1e-9, returnall::Bool=false)</code></pre><p>Computes the Earth Mover&#39;s Distance, which is defined as </p><p class="math-container">\[D(M) = \sum_{i=1}^m \sum_{j=1}^n M_{ij} d_{ij}\]</p><p>Here <span>$M \in \mathbb{R}^{m\times n}$</span> is the ground distance matrix. The algorithm solves the following optimization problem </p><p class="math-container">\[\begin{aligned}\min_{M} &amp;\ D(M)\\\text{s.t.} &amp; \ \sum_{i=1}^m M_{ij} = b_j\\ &amp;\ \sum_{j=1}^n M_{ij} = a_i \end{aligned}\]</p><p>The internal solver for the optimization problem is a netflow solver. The algorithm requires <span>$\sum_i a_i = \sum_j b_j = 1$</span>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L67-L80">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.empirical_emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}" href="#ADCME.empirical_emd-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}"><code>ADCME.empirical_emd</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">empirical_emd(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}};
    iter::Int64 = 1000, tol::Float64 = 1e-9, dist::Union{Integer,Function}=2, returnall::Bool=false)</code></pre><p>Same as <a href="#ADCME.empirical_sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}"><code>empirical_sinkhorn</code></a>, except that the Earth Mover Distance is computed. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L156-L161">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.empirical_sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}" href="#ADCME.empirical_sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N}}"><code>ADCME.empirical_sinkhorn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">empirical_sinkhorn(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}};
    reg::Union{PyObject,Float64} = 1.0, iter::Int64 = 1000, tol::Float64 = 1e-9, method::String=&quot;sinkhorn&quot;, dist::Function=dist, returnall::Bool=false)</code></pre><p>Computes the empirical Sinkhorn distance with sinkhorn algorithm. Here <span>$x$</span> and <span>$y$</span> are samples from two distributions.  </p><ul><li><code>reg</code> (default = 1.0): entropy regularization parameter </li><li><code>tol</code> (default = 1e-9), <code>iter</code> (default = 1000): tolerance and max iterations for the Sinkhorn algorithm </li><li><code>dist</code> (default = 2): Integer or Function, the distance function between two samples; if <code>dist</code> is integer, <span>$L-dist$</span> norm is used. </li><li><code>returnall</code>: returns (<code>TransportMatrix</code>, <code>Loss</code>) if true; otherwise, only <code>Loss</code> is returned. </li></ul><p>The implementation are adapted from https://github.com/rflamary/POT.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L124-L136">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ot_dist" href="#ADCME.ot_dist"><code>ADCME.ot_dist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">ot_dist(x::Union{PyObject, Array{Float64}}, y::Union{PyObject, Array{Float64}}, order::Union{Int64, PyObject}=2)</code></pre><p>Computes the distance function with norm <code>order</code>. <code>dist</code> returns a <span>$n\times m$</span> matrix, where <span>$x\in \mathbb{R}^{n\times d}$</span> and <span>$y\in \mathbb{R}^{m\times d}$</span>, and the return <span>$M\in \mathbb{R}^{n\times m}$</span></p><p class="math-container">\[M_{ij} = ||x_i - y_j||_{o}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L168-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.ot_plot1D-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2}}" href="#ADCME.ot_plot1D-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,2}}"><code>ADCME.ot_plot1D</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ot_plot1D(a::Array{Float64, 1}, b::Array{Float64, 1}, M::Array{Float64, 2})</code></pre><p>Plots the optimal transport matrix for 1D distributions. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L88-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Array{Float64,2}, PyCall.PyObject}}" href="#ADCME.sinkhorn-Tuple{Union{PyCall.PyObject, Array{Float64,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Array{Float64,2}, PyCall.PyObject}}"><code>ADCME.sinkhorn</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sinkhorn(a::Union{PyObject, Array{Float64}}, b::Union{PyObject, Array{Float64}}, M::Union{PyObject, Array{Float64}};
reg::Float64 = 1.0, iter::Int64 = 1000, tol::Float64 = 1e-9, method::String=&quot;sinkhorn&quot;)</code></pre><p>Computes the optimal transport with Sinkhorn algorithm. The mathematical formulation is </p><p class="math-container">\[\begin{aligned}
\arg\min_P &amp;\ \left(P, M\right) + \lambda \Omega(\Gamma)\\ 
\text{s.t.} &amp;\ \Gamma 1 = a\\ 
&amp;\ \Gamma^T 1 = b\\ 
&amp; \Gamma \geq 0 
\end{aligned}\]</p><p>Here <span>$\Omega$</span> is the entropic regularization. Note if <span>$\lambda$</span> is very small, the algorithm may encounter numerical instabilities. </p><p>The implementation are adapted from https://github.com/rflamary/POT.  </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/ot.jl#L4-L21">source</a></section></article><h2 id="MPI"><a class="docs-heading-anchor" href="#MPI">MPI</a><a id="MPI-1"></a><a class="docs-heading-anchor-permalink" href="#MPI" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_SparseTensor" href="#ADCME.mpi_SparseTensor"><code>ADCME.mpi_SparseTensor</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">mutable struct mpi_SparseTensor
    rows::PyObject 
    ncols::PyObject
    cols::PyObject 
    values::PyObject 
    ilower::Int64 
    iupper::Int64 
    N::Int64
    oplibpath::String
end</code></pre><p>A structure to hold local data of a sparse matrix. The global matrix is assumed to be a <span>$M\times N$</span> square matrix.  The current processor owns rows from <code>ilower</code> to <code>iupper</code> (inclusive). The data is specified by </p><ul><li><code>rows</code>: an array indicating the rows that contain nonzero values. Note <code>rows ≥ ilower</code>. </li><li><code>ncols</code>: an array indicating the number of nonzero values for each row in <code>rows</code>. </li><li><code>cols</code>: the column indices for nonzero values. Its length is <span>$\sum_{i=1}^{\mathrm{ncols}} \mathrm{ncols}_i$</span></li><li><code>vals</code>: the nonzero values corresponding to each column index in <code>cols</code></li><li><code>oplibpath</code>: the backend library (returned by <code>ADCME.load_plugin_MPITensor</code>)</li></ul><p>All data structure are 0-based. Note if we work with a linear solver, <span>$M=N$</span>.</p><p>For example, consider the sparse matrix </p><pre><code class="language-none">[  1 0 0 1  ]
[  0 1 2 1  ]</code></pre><p>We have </p><pre><code class="language-julia">rows = Int32[0;1]
ncols = Int32[2;3]
cols = Int32[0;3;1,2,3]
values = [1.;1.;1.;2.;1.]
iupper = ilower + 2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L376-L415">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_SparseTensor" href="#ADCME.mpi_SparseTensor"><code>ADCME.mpi_SparseTensor</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">mpi_SparseTensor(sp::Union{SparseTensor, SparseMatrixCSC{Float64,Int64}}, 
    ilower::Union{Int64, Missing} = missing,
    iupper::Union{Int64, Missing} = missing)</code></pre><p>Constructing <code>mpi_SparseTensor</code> from a <code>SparseTensor</code> or a sparse Array.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L472-L478">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_SparseTensor-Tuple{Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Int64,Int64,Int64}" href="#ADCME.mpi_SparseTensor-Tuple{Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Int32,1}, PyCall.PyObject},Union{Array{Float64,1}, PyCall.PyObject},Int64,Int64,Int64}"><code>ADCME.mpi_SparseTensor</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_SparseTensor(rows::Union{Array{Int32,1}, PyObject}, ncols::Union{Array{Int32,1}, PyObject}, cols::Union{Array{Int32,1}, PyObject},
    vals::Union{Array{Float64,1}, PyObject}, ilower::Int64, iupper::Int64, N::Int64)</code></pre><p>Create a <span>$N\times N$</span> distributed sparse tensor <code>A</code> for the current MPI processor. The current MPI processor owns rows with indices <code>[ilower, iupper]</code>. The submatrix is specified using the CSR format. </p><ul><li><code>rows</code>: an array indicating the rows that contain nonzero values. Note <code>rows ≥ ilower</code>. </li><li><code>ncols</code>: an array indicating the number of nonzero values for each row in <code>rows</code>. </li><li><code>cols</code>: the column indices for nonzero values. Its length is <span>$\sum_{i=1}^{\mathrm{ncols}} \mathrm{ncols}_i$</span></li><li><code>vals</code>: the nonzero values corresponding to each column index in <code>cols</code></li></ul><p>Note that by default the indices are zero-based. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L445-L458">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_bcast" href="#ADCME.mpi_bcast"><code>ADCME.mpi_bcast</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_bcast(a::Union{Array{Float64}, Float64, PyObject}, root::Int64 = 0)</code></pre><p>Broadcast <code>a</code> from processor <code>root</code> to all other processors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L151-L155">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_finalize-Tuple{}" href="#ADCME.mpi_finalize-Tuple{}"><code>ADCME.mpi_finalize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_finalize()</code></pre><p>Finalize the MPI call.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L18-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_finalized-Tuple{}" href="#ADCME.mpi_finalized-Tuple{}"><code>ADCME.mpi_finalized</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_finalized()</code></pre><p>Returns a boolean indicating whether the current MPI session is finalized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L61-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_gather" href="#ADCME.mpi_gather"><code>ADCME.mpi_gather</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_gather(u::Union{Array{Float64, 1}, PyObject}, deps::Union{Missing, PyObject} = missing)</code></pre><p>Gathers all the vectors from different processes to the root process. The function returns  a long vector which concatenates of local vectors in the order of process IDs. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L271-L276">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_halo_exchange-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}" href="#ADCME.mpi_halo_exchange-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}"><code>ADCME.mpi_halo_exchange</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_halo_exchange(u::Union{Array{Float64, 2}, PyObject},m::Int64,n::Int64; deps::Union{Missing, PyObject} = missing,
fill_value::Float64 = 0.0, tag::Union{PyObject, Int64} = 0)</code></pre><p>Perform Halo exchnage on <code>u</code> (a <span>$k \times k$</span> matrix). The output has a shape <span>$(k+2)\times (k+2)$</span></p><ul><li><code>fill_value</code>: value used for the boundaries</li><li><code>tag</code>: message tag</li><li><code>deps</code>: a <strong>scalar</strong> tensor; it can be used to serialize the MPI calls </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L507-L516">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_halo_exchange2-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}" href="#ADCME.mpi_halo_exchange2-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}"><code>ADCME.mpi_halo_exchange2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_halo_exchange2(u::Union{Array{Float64, 2}, PyObject},m::Int64,n::Int64; deps::Union{Missing, PyObject} = missing,
fill_value::Float64 = 0.0, tag::Union{PyObject, Int64} = 0)</code></pre><p>Similar to <a href="#ADCME.mpi_halo_exchange-Tuple{Union{Array{Float64,2}, PyCall.PyObject},Int64,Int64}"><code>mpi_halo_exchange</code></a>, but the reach is 2, i.e., for a <span>$N\times N$</span> matrix <span>$u$</span>, the output will be a  <span>$(N+4)\times (N+4)$</span> matrix. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L525-L531">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_init-Tuple{}" href="#ADCME.mpi_init-Tuple{}"><code>ADCME.mpi_init</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_init()</code></pre><p>Initialized the MPI session. <code>mpi_init</code> must be called before any <code>run(sess, ...)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L5-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_initialized-Tuple{}" href="#ADCME.mpi_initialized-Tuple{}"><code>ADCME.mpi_initialized</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_initialized()</code></pre><p>Returns a boolean indicating whether the current MPI session is initialized.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L71-L75">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_rank-Tuple{}" href="#ADCME.mpi_rank-Tuple{}"><code>ADCME.mpi_rank</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_rank()</code></pre><p>Returns the rank of current MPI process (rank 0 based).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_recv" href="#ADCME.mpi_recv"><code>ADCME.mpi_recv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_recv(a::Union{Array{Float64}, Float64, PyObject}, src::Int64, tag::Int64 = 0)</code></pre><p>Receives an array from processor <code>src</code>. <code>mpi_recv</code> requires an input for gradient backpropagation.  Typically we can write</p><pre><code class="language-julia">r = mpi_rank()
a = constant(Float64(r))
if r==1
    a = mpi_send(a, 0)
end
if r==0
    a = mpi_recv(a, 1)
end</code></pre><p>Then <code>a=1</code> on both processor 0 and processor 1.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L217-L235">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_send" href="#ADCME.mpi_send"><code>ADCME.mpi_send</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_send(a::Union{Array{Float64}, Float64, PyObject}, dest::Int64,root::Int64 = 0)</code></pre><p>Sends <code>a</code> to processor <code>dest</code>. <code>a</code> itself is returned so that the send action can be added to the computational graph.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L186-L190">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_sendrecv" href="#ADCME.mpi_sendrecv"><code>ADCME.mpi_sendrecv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_sendrecv(a::Union{Array{Float64}, Float64, PyObject}, dest::Int64, src::Int64, tag::Int64=0)</code></pre><p>A convenient wrapper for <code>mpi_send</code> followed by <code>mpi_recv</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L255-L259">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_size-Tuple{}" href="#ADCME.mpi_size-Tuple{}"><code>ADCME.mpi_size</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mpi_size()</code></pre><p>Returns the size of MPI world.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L39-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_sum" href="#ADCME.mpi_sum"><code>ADCME.mpi_sum</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_sum(a::Union{Array{Float64}, Float64, PyObject}, root::Int64 = 0)</code></pre><p>Sum <code>a</code> on the MPI processor <code>root</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L115-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.mpi_sync!" href="#ADCME.mpi_sync!"><code>ADCME.mpi_sync!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mpi_sync!(message::Array{Int64,1}, root::Int64 = 0)
mpi_sync!(message::Array{Float64,1}, root::Int64 = 0)</code></pre><p>Sync <code>message</code> across all MPI processors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L80-L85">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.require_mpi-Tuple{}" href="#ADCME.require_mpi-Tuple{}"><code>ADCME.require_mpi</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">require_mpi()</code></pre><p>Throws an error if <code>mpi_init()</code> has not been called. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L49-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.adjoint-Tuple{mpi_SparseTensor}" href="#Base.adjoint-Tuple{mpi_SparseTensor}"><code>Base.adjoint</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">adjoint(A::mpi_SparseTensor)</code></pre><p>Returns the adjoint of <code>A</code>, i.e., <code>A&#39;</code>. Each MPI rank owns the same number of rows.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/mpi.jl#L548-L552">source</a></section></article><h2 id="Toolchain"><a class="docs-heading-anchor" href="#Toolchain">Toolchain</a><a id="Toolchain-1"></a><a class="docs-heading-anchor-permalink" href="#Toolchain" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ADCME.change_directory" href="#ADCME.change_directory"><code>ADCME.change_directory</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">change_directory(directory::Union{Missing, AbstractString})</code></pre><p>Change the current working directory to <code>directory</code>. If <code>directory</code> does not exist, it is made. </p><p>If <code>directory</code> is missing, the default is <code>ADCME.PREFIXDIR</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L152-L158">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.copy_file-Tuple{String,String}" href="#ADCME.copy_file-Tuple{String,String}"><code>ADCME.copy_file</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">copy_file(src::String, dest::String)</code></pre><p>Copy file <code>src</code> to <code>dest</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L299-L303">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_conda-Tuple{}" href="#ADCME.get_conda-Tuple{}"><code>ADCME.get_conda</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_conda()</code></pre><p>Returns the conda executable location.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L194-L198">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_gfortran-Tuple{}" href="#ADCME.get_gfortran-Tuple{}"><code>ADCME.get_gfortran</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_gfortran()</code></pre><p>Install a gfortran compiler if it does not exist.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L111-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_library-Tuple{AbstractString}" href="#ADCME.get_library-Tuple{AbstractString}"><code>ADCME.get_library</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_library(filename::AbstractString)</code></pre><p>Returns a valid library file. For example, for <code>filename = &quot;adcme&quot;</code>, we have </p><ul><li>On MacOS, the function returns <code>libadcme.dylib</code></li><li>On Linux, the function returns <code>libadcme.so</code></li><li>On Windows, the function returns <code>adcme.dll</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L168-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_library_name-Tuple{AbstractString}" href="#ADCME.get_library_name-Tuple{AbstractString}"><code>ADCME.get_library_name</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_library_name(filename::AbstractString)</code></pre><p>Returns the OS-dependent library name </p><p><strong>Example</strong></p><pre><code class="language-none">get_library_name(&quot;mylibrary&quot;)</code></pre><ul><li>Windows: <code>mylibrary.dll</code></li><li>MacOS: <code>libmylibrary.dylib</code></li><li>Linux: <code>libmylibrary.so</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L218-L230">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_pip-Tuple{}" href="#ADCME.get_pip-Tuple{}"><code>ADCME.get_pip</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_pip()</code></pre><p>Returns the location for <code>pip</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L284-L288">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.git_repository-Tuple{AbstractString,AbstractString}" href="#ADCME.git_repository-Tuple{AbstractString,AbstractString}"><code>ADCME.git_repository</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">git_repository(url::AbstractString, file::AbstractString)</code></pre><p>Clone a repository <code>url</code> and rename it to <code>file</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L78-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.http_file-Tuple{AbstractString,AbstractString}" href="#ADCME.http_file-Tuple{AbstractString,AbstractString}"><code>ADCME.http_file</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">http_file(url::AbstractString, file::AbstractString)</code></pre><p>Download a file from <code>url</code> and rename it to <code>file</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L29-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.link_file-Tuple{AbstractString,AbstractString}" href="#ADCME.link_file-Tuple{AbstractString,AbstractString}"><code>ADCME.link_file</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">link_file(target::AbstractString, link::AbstractString)</code></pre><p>Make a symbolic link <code>link</code> -&gt; <code>target</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L126-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.make_directory-Tuple{AbstractString}" href="#ADCME.make_directory-Tuple{AbstractString}"><code>ADCME.make_directory</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">make_directory(directory::AbstractString)</code></pre><p>Make a directory if it does not exist. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L140-L144">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.read_with_env" href="#ADCME.read_with_env"><code>ADCME.read_with_env</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">read_with_env(cmd::Cmd, env::Union{Missing, Dict} = missing)</code></pre><p>Similar to <a href="#ADCME.run_with_env"><code>run_with_env</code></a>, but returns a string containing the output. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L265-L269">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.require_cmakecache" href="#ADCME.require_cmakecache"><code>ADCME.require_cmakecache</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">require_cmakecache(func::Function, DIR::String = &quot;.&quot;)</code></pre><p>Check if <code>cmake</code> has output something. If not, <code>func</code> is executed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L314-L318">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.require_file-Tuple{Function,Union{String, Array{String,N} where N}}" href="#ADCME.require_file-Tuple{Function,Union{String, Array{String,N} where N}}"><code>ADCME.require_file</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">require_file(f::Function, file::Union{String, Array{String}})</code></pre><p>If any of the files/links/directories in <code>file</code> does not exist, execute <code>f</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L91-L95">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.require_import-Tuple{Symbol}" href="#ADCME.require_import-Tuple{Symbol}"><code>ADCME.require_import</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">require_import(s::Symbol)</code></pre><p>Checks whether the package <code>s</code> is imported in the Main namespace. Returns the package handle. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L348-L352">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.require_library-Tuple{Function,AbstractString}" href="#ADCME.require_library-Tuple{Function,AbstractString}"><code>ADCME.require_library</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">require_library(func::Function, filename::AbstractString)</code></pre><p>If the library file <code>filename</code> does not exist, <code>func</code> is executed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L204-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.run_with_env" href="#ADCME.run_with_env"><code>ADCME.run_with_env</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">run_with_env(cmd::Cmd, env::Union{Missing, Dict} = missing)</code></pre><p>Running the command with the default environment and an extra environment variables <code>env</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L246-L250">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.uncompress" href="#ADCME.uncompress"><code>ADCME.uncompress</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">uncompress(zipfile::AbstractString, file::AbstractString)</code></pre><p>Uncompress a zip file <code>zipfile</code> to <code>file</code> (a directory). Note this function does not check that the  uncompressed content has the name <code>file</code>. It is used as a hint to skip <code>uncompress</code> action.</p><p>Users may use <code>mv uncompress_file file</code> to enforce the consistency.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/toolchain.jl#L42-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.get_gpu-Tuple{}" href="#ADCME.get_gpu-Tuple{}"><code>ADCME.get_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_gpu()</code></pre><p>Returns the compiler information for GPUs. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gpu.jl#L50-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.gpu_info-Tuple{}" href="#ADCME.gpu_info-Tuple{}"><code>ADCME.gpu_info</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gpu_info()</code></pre><p>Returns the CUDA and GPU information. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gpu.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ADCME.has_gpu-Tuple{}" href="#ADCME.has_gpu-Tuple{}"><code>ADCME.has_gpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">has_gpu()</code></pre><p>Check if the TensorFlow backend is using CUDA GPUs. Operators that have GPU implementations will be executed on GPU devices.  See also <a href="#ADCME.get_gpu-Tuple{}"><code>get_gpu</code></a></p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>ADCME will use GPU automatically if GPU is available. To disable GPU, set the environment variable <code>ENV[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;&quot;</code> before importing ADCME </p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kailaix/ADCME.jl/blob/943e329a3c7f267a1664def5c31f94c7c7fd5dbe/src/gpu.jl#L82-L90">source</a></section></article><h2 id="Misc"><a class="docs-heading-anchor" href="#Misc">Misc</a><a id="Misc-1"></a><a class="docs-heading-anchor-permalink" href="#Misc" title="Permalink"></a></h2></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../apps_nnfem/">« Symmetric Positive Definite Neural Networks (SPD-NN)</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 17 March 2021 00:28">Wednesday 17 March 2021</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
