<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Shared Memory Across Kernels · ADCME</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ADCME</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../videos_and_slides/">Video Lectures and Slides</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../optimizers/">Optimizers</a></li><li><a class="tocitem" href="../optim/">Study on Optimizers</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li class="is-active"><a class="tocitem" href>Shared Memory Across Kernels</a><ul class="internal"><li><a class="tocitem" href="#Introuction"><span>Introuction</span></a></li><li><a class="tocitem" href="#Solutions-for-*nix"><span>Solutions for *nix</span></a></li><li><a class="tocitem" href="#Solutions-for-Windows"><span>Solutions for Windows</span></a></li></ul></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li><li><a class="tocitem" href="../mcmc/">Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC</a></li><li><a class="tocitem" href="../mpi/">Distributed Scientific Machine Learning using MPI</a></li><li><a class="tocitem" href="../mpi_benchmark/">MPI Benchmarks</a></li><li><a class="tocitem" href="../multithreading/">Understand the Multi-threading Model</a></li><li><a class="tocitem" href="../rbf/">Radial Basis Functions</a></li><li><a class="tocitem" href="../topopt/">Topological Optimization</a></li><li><a class="tocitem" href="../quadrature/">Numerical Integration</a></li><li><a class="tocitem" href="../sqlite3/">Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management</a></li><li><a class="tocitem" href="../hessian/">The Mathematical Structure of DNN Hessians</a></li><li><a class="tocitem" href="../plotly/">Visualization with Plotly</a></li></ul></li><li><span class="tocitem">Physics Informed Machine Learning</span><ul><li><a class="tocitem" href="../fdtd/">Finite-difference Time-domain for Electromagnetics and Seismic Inversion</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="../flow/">Normalizing Flows</a></li><li><a class="tocitem" href="../convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="../bnn/">Bayesian Neural Networks</a></li><li><a class="tocitem" href="../reinforcement_learning/">Reinforcement Learning Basics: Q-learning and SARSA</a></li></ul></li><li><span class="tocitem">Developer Guide</span><ul><li><a class="tocitem" href="../designpattern/">Design Pattern</a></li><li><a class="tocitem" href="../toolchain/">Built-in Toolchain for Third-party Libraries</a></li><li><a class="tocitem" href="../installmpi/">Configure MPI for Distributed Computing</a></li><li><a class="tocitem" href="../windows_installation/">Install ADCME on Windows</a></li><li><a class="tocitem" href="../docker/">Install ADCME Docker Image</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Resources</a></li><li class="is-active"><a href>Shared Memory Across Kernels</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Shared Memory Across Kernels</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/global.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Shared-Memory-Across-Kernels"><a class="docs-heading-anchor" href="#Shared-Memory-Across-Kernels">Shared Memory Across Kernels</a><a id="Shared-Memory-Across-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Shared-Memory-Across-Kernels" title="Permalink"></a></h1><h2 id="Introuction"><a class="docs-heading-anchor" href="#Introuction">Introuction</a><a id="Introuction-1"></a><a class="docs-heading-anchor-permalink" href="#Introuction" title="Permalink"></a></h2><p>In many use cases, we want to share data across multiple kernels. For example, if we want to design several custom operators for finite element analysis (e.g., one for assembling, one for solving the linear system and one for performing Newton&#39;s iteration), we might want to share the geometric data such as nodes and element connectivity matrices. This can be done by the share memory mechanism of dynamical shared libraries. </p><p>The technique introduced here is very useful. For example, in the ADCME standard library, <a href="../api/#LinearAlgebra.factorize"><code>factorize</code></a> is implemented using this technique. <code>factorize</code> factorizes a nonsingular matrix and store the factorized form in the shared library so you can amortize the computational cost for factorization by efficiently solving many linear systems. </p><h2 id="Solutions-for-*nix"><a class="docs-heading-anchor" href="#Solutions-for-*nix">Solutions for *nix</a><a id="Solutions-for-*nix-1"></a><a class="docs-heading-anchor-permalink" href="#Solutions-for-*nix" title="Permalink"></a></h2><p>Dynamical shared libraries have the following property: in Unix-like environments, shared libries export all <code>extern</code> global variables. That is, multiple shared libraries can change the same variable as long as the variable is marked as <code>extern</code>. However, <code>extern</code> variable itself is not a definition but only a declaration. The variable should be defined in one and only one shared library. </p><p>Therefore, when we design custom operators and want to have global variables that will be reused by multiple custom kernels (each constitutes a separate dynamical shared library), we can link each of them to a &quot;data storage&quot; shared library. The &quot;data storage&quot; shared library should contain the definition of the global variable to be shared among those kernels. </p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/disk.png?raw=true" alt/></p><p>As an example, consider we want to share <code>Float64</code> vectors (with <code>String</code> keys). The data structure of the storage is given in <code>Saver.h</code></p><pre><code class="language-c">#include &lt;map&gt;
#include &lt;string&gt;
#include &lt;vector&gt;

struct DataStore
{        
    std::map&lt;std::string, std::vector&lt;double&gt;&gt; vdata;
};
extern DataStore ds;</code></pre><p>Note we include <code>extern DataStore ds;</code> for convenience: we can include <code>Saver.h</code> for our custom operator kernels so that we have access to <code>ds</code>. </p><p>Additionally, in <code>Saver.cpp</code>, we define <code>ds</code></p><pre><code class="language-c">#include &quot;Saver.h&quot;
DataStore ds;</code></pre><p>Now we can compile a dynamical shared library <code>Saver.so</code> (or <code>Saver.dylib</code>) with <code>Saver.h</code> and <code>Saver.cpp</code>. For all the other kernel implementation, we can include the header file <code>Saver.h</code> and link to <code>Saver.so</code> (or <code>Saver.dylib</code>) during compilation. </p><h3 id="Code-Examples"><a class="docs-heading-anchor" href="#Code-Examples">Code Examples</a><a id="Code-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Code-Examples" title="Permalink"></a></h3><p>We show an example for storing, querying and deleting <span>$10\times 1$</span> <code>Float64</code> vectors with this technique. The main files are (the codes can be accessed <a href="https://github.com/kailaix/ADCME.jl/tree/master/docs/src/assets/Codes/SharedMemory">here</a>)</p><ul><li><code>SaverTensor.cpp</code></li></ul><pre><code class="language-c">#include &quot;Saver.h&quot;
#include &quot;tensorflow/core/framework/op_kernel.h&quot;
#include &quot;tensorflow/core/framework/tensor_shape.h&quot;
#include &quot;tensorflow/core/platform/default/logging.h&quot;
#include &quot;tensorflow/core/framework/shape_inference.h&quot;
#include&lt;cmath&gt;
#include&lt;string&gt; 
#include&lt;eigen3/Eigen/Core&gt;
using std::string;
using namespace tensorflow;

REGISTER_OP(&quot;SaveTensor&quot;)

.Input(&quot;handle : string&quot;)
  .Input(&quot;val : double&quot;)
  .Output(&quot;out : string&quot;)
.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
    
        shape_inference::ShapeHandle handle_shape;
        TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(0), 0, &amp;handle_shape));
        shape_inference::ShapeHandle val_shape;
        TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(1), 1, &amp;val_shape));

        c-&gt;set_output(0, c-&gt;Scalar());
    return Status::OK();
  });

class SaveTensorOp : public OpKernel {
private:
  
public:
  explicit SaveTensorOp(OpKernelConstruction* context) : OpKernel(context) {

  }

  void Compute(OpKernelContext* context) override {    
    DCHECK_EQ(2, context-&gt;num_inputs());
    
    
    const Tensor&amp; handle = context-&gt;input(0);
    const Tensor&amp; val = context-&gt;input(1);
    
    
    const TensorShape&amp; val_shape = val.shape();
    
    
    DCHECK_EQ(val_shape.dims(), 1);

    // extra check
        
    // create output shape
    
    TensorShape out_shape({});
            
    // create output tensor
    
    Tensor* out = NULL;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, out_shape, &amp;out));
    
    // get the corresponding Eigen tensors for data access
    auto handle_tensor = handle.flat&lt;string&gt;().data();
    auto val_tensor = val.flat&lt;double&gt;().data();
    auto out_tensor = out-&gt;flat&lt;string&gt;().data();   

    // implement your forward function here 
    // context-&gt;tensors_[string(*handle_tensor)] = val;
    ds.vdata[string(*handle_tensor)] = std::vector&lt;double&gt;(val_tensor, val_tensor+10);
    *out_tensor = *handle_tensor;    
    printf(&quot;[Add] %s to collections.\n&quot;, string(*handle_tensor).c_str());
    printf(&quot;========Existing Keys========\n&quot;);
    for(auto &amp; kv: ds.vdata){
      printf(&quot;Key %s\n&quot;, kv.first.c_str());
    }
    printf(&quot;\n&quot;);
  }
};
REGISTER_KERNEL_BUILDER(Name(&quot;SaveTensor&quot;).Device(DEVICE_CPU), SaveTensorOp);</code></pre><ul><li><code>GetTensor.cpp</code></li></ul><pre><code class="language-c">#include &quot;Saver.h&quot;

#include &quot;tensorflow/core/framework/op_kernel.h&quot;
#include &quot;tensorflow/core/framework/tensor_shape.h&quot;
#include &quot;tensorflow/core/platform/default/logging.h&quot;
#include &quot;tensorflow/core/framework/shape_inference.h&quot;
#include&lt;cmath&gt;
#include&lt;string&gt; 
#include&lt;map&gt;
#include&lt;eigen3/Eigen/Core&gt;
using std::string;

using namespace tensorflow;

REGISTER_OP(&quot;GetTensor&quot;)
.Input(&quot;handle : string&quot;)
  .Output(&quot;val : double&quot;)
.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
    
        shape_inference::ShapeHandle handle_shape;
        TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(0), 0, &amp;handle_shape));

        c-&gt;set_output(0, c-&gt;Vector(-1));
    return Status::OK();
  });

class GetTensorOp : public OpKernel {
private:
  
public:
  explicit GetTensorOp(OpKernelConstruction* context) : OpKernel(context) {

  }

  void Compute(OpKernelContext* context) override {    
    DCHECK_EQ(1, context-&gt;num_inputs());
    
    const Tensor&amp; handle = context-&gt;input(0);    
    auto handle_tensor = handle.flat&lt;string&gt;().data();

    auto val_shape = TensorShape({10});   
    Tensor *val = nullptr;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, val_shape, &amp;val));

    if (!ds.vdata.count(string(*handle_tensor))){
        printf(&quot;[Get] Key %s does not exist.\n&quot;, string(*handle_tensor).c_str());
    }
    else{
      printf(&quot;[Get] Key %s exists.\n&quot;, string(*handle_tensor).c_str());
      auto v = ds.vdata[string(*handle_tensor)];
      for(int i=0;i&lt;10;i++){
        val-&gt;flat&lt;double&gt;().data()[i] = v[i];
      }
    }
    printf(&quot;========Existing Keys========\n&quot;);
    for(auto &amp; kv: ds.vdata){
      printf(&quot;Key %s\n&quot;, kv.first.c_str());
    }
    printf(&quot;\n&quot;);
    

  }
};
REGISTER_KERNEL_BUILDER(Name(&quot;GetTensor&quot;).Device(DEVICE_CPU), GetTensorOp);</code></pre><ul><li><code>DeleteTensor.cpp</code></li></ul><pre><code class="language-c">#include &quot;Saver.h&quot;

#include &quot;tensorflow/core/framework/op_kernel.h&quot;
#include &quot;tensorflow/core/framework/tensor_shape.h&quot;
#include &quot;tensorflow/core/platform/default/logging.h&quot;
#include &quot;tensorflow/core/framework/shape_inference.h&quot;
#include&lt;cmath&gt;
#include&lt;string&gt; 
#include&lt;map&gt;
#include&lt;eigen3/Eigen/Core&gt;
using std::string;

using namespace tensorflow;

REGISTER_OP(&quot;DeleteTensor&quot;)
.Input(&quot;handle : string&quot;)
  .Output(&quot;val : bool&quot;)
.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
    
        shape_inference::ShapeHandle handle_shape;
        TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(0), 0, &amp;handle_shape));

        c-&gt;set_output(0, c-&gt;Scalar());
    return Status::OK();
  });

class DeleteTensorOp : public OpKernel {
private:
  
public:
  explicit DeleteTensorOp(OpKernelConstruction* context) : OpKernel(context) {

  }

  void Compute(OpKernelContext* context) override {    
    DCHECK_EQ(1, context-&gt;num_inputs());
    
    const Tensor&amp; handle = context-&gt;input(0);    
    auto handle_tensor = handle.flat&lt;string&gt;().data();

    auto val_shape = TensorShape({});   
    Tensor *val = nullptr;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, val_shape, &amp;val));

    if (ds.vdata.count(string(*handle_tensor))){
      ds.vdata.erase(string(*handle_tensor));
      printf(&quot;[Delete] Erase key %s.\n&quot;, string(*handle_tensor).c_str());
      *(val-&gt;flat&lt;bool&gt;().data()) = true;
    }
    else{
      printf(&quot;[Delete] Key %s does not exist.\n&quot;, string(*handle_tensor).c_str());
      *(val-&gt;flat&lt;bool&gt;().data()) = false;
    }
    printf(&quot;========Existing Keys========\n&quot;);
    for(auto &amp; kv: ds.vdata){
      printf(&quot;Key %s\n&quot;, kv.first.c_str());
    }
    printf(&quot;\n&quot;);
  }
};
REGISTER_KERNEL_BUILDER(Name(&quot;DeleteTensor&quot;).Device(DEVICE_CPU), DeleteTensorOp);</code></pre><p>Here is part of the <a href="https://github.com/kailaix/ADCME.jl/tree/master/docs/src/assets/Codes/SharedMemory/CMakeLists.txt"><code>CMakeLists.txt</code></a> used for compilation, where we link <code>XXTensor.cpp</code> with <code>Saver</code></p><pre><code class="language-cmake">cmake_minimum_required(VERSION 3.5)
project(TF_CUSTOM_OP)
set (CMAKE_CXX_STANDARD 11)

message(&quot;JULIA=${JULIA}&quot;)
execute_process(COMMAND ${JULIA} -e &quot;import ADCME; print(ADCME.__STR__)&quot; OUTPUT_VARIABLE JL_OUT)
list(GET JL_OUT 0 BINDIR)
list(GET JL_OUT 1 LIBDIR)
list(GET JL_OUT 2 TF_INC)
list(GET JL_OUT 3 TF_ABI)
list(GET JL_OUT 4 PREFIXDIR)
list(GET JL_OUT 5 CC)
list(GET JL_OUT 6 CXX)
list(GET JL_OUT 7 CMAKE)
list(GET JL_OUT 8 MAKE)
list(GET JL_OUT 9 GIT)
list(GET JL_OUT 10 PYTHON)
list(GET JL_OUT 11 TF_LIB_FILE)


message(&quot;BINDIR=${BINDIR}&quot;)
message(&quot;LIBDIR=${LIBDIR}&quot;)
message(&quot;TF_INC=${TF_INC}&quot;)
message(&quot;TF_ABI=${TF_ABI}&quot;)
message(&quot;PREFIXDIR=${PREFIXDIR}&quot;)
message(&quot;Python path=${PYTHON}&quot;)
message(&quot;TF_LIB_FILE=${TF_LIB_FILE}&quot;)


if (CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 5.0 OR CMAKE_CXX_COMPILER_VERSION VERSION_EQUAL 5.0)
  set(CMAKE_CXX_FLAGS &quot;-D_GLIBCXX_USE_CXX11_ABI=${TF_ABI} ${CMAKE_CXX_FLAGS}&quot;)
endif()

set(CMAKE_BUILD_TYPE Release)
if(MSVC)
set(CMAKE_CXX_FLAGS_RELEASE &quot;-DNDEBUG&quot;)
else()
set(CMAKE_CXX_FLAGS_RELEASE &quot;-O3 -DNDEBUG&quot;)
endif()
include_directories(${TF_INC} ${PREFIXDIR})
link_directories(${TF_LIB})


if(MSVC)
  if(CMAKE_CXX_FLAGS MATCHES &quot;/W[0-4]&quot;)
    string(REGEX REPLACE &quot;/W[0-4]&quot; &quot;/W0&quot; CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS}&quot;)
  else()
    set(CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} /W0&quot;)
  endif()
  add_library(Saver SHARED Saver.cpp SaveTensor.cpp GetTensor.cpp DeleteTensor.cpp)
  set_property(TARGET Saver PROPERTY POSITION_INDEPENDENT_CODE ON)
  target_link_libraries(Saver ${TF_LIB_FILE})
  add_definitions(-DNOMINMAX)
else()
  add_library(Saver SHARED Saver.cpp)
  set_property(TARGET Saver PROPERTY POSITION_INDEPENDENT_CODE ON)

  add_library(SaveTensor SHARED SaveTensor.cpp)
  set_property(TARGET SaveTensor PROPERTY POSITION_INDEPENDENT_CODE ON)
  target_link_libraries(SaveTensor ${TF_LIB_FILE} Saver)

  add_library(GetTensor SHARED GetTensor.cpp)
  set_property(TARGET GetTensor PROPERTY POSITION_INDEPENDENT_CODE ON)
  target_link_libraries(GetTensor ${TF_LIB_FILE} Saver)

  add_library(DeleteTensor SHARED DeleteTensor.cpp)
  set_property(TARGET DeleteTensor PROPERTY POSITION_INDEPENDENT_CODE ON)
  target_link_libraries(DeleteTensor ${TF_LIB_FILE} Saver)
endif()</code></pre><p>Here we have separate procedure for Windows and *nix systems. </p><p>We can test our implementation with </p><pre><code class="language-julia">using ADCME

if Sys.iswindows()
    global save_tensor = load_op_and_grad(&quot;./build/Release/libSaver&quot;,&quot;save_tensor&quot;)
    global get_tensor = load_op_and_grad(&quot;./build/Release/libSaver&quot;,&quot;get_tensor&quot;)
    global delete_tensor = load_op_and_grad(&quot;./build/Release/libSaver&quot;,&quot;delete_tensor&quot;)
else 
    global save_tensor = load_op_and_grad(&quot;./build/libSaveTensor&quot;,&quot;save_tensor&quot;)
    global get_tensor = load_op_and_grad(&quot;./build/libGetTensor&quot;,&quot;get_tensor&quot;)
    global delete_tensor = load_op_and_grad(&quot;./build/libDeleteTensor&quot;,&quot;delete_tensor&quot;)
end 

val = constant(rand(10))
t1 = constant(&quot;tensor1&quot;)
t2 = constant(&quot;tensor2&quot;)
t3 = constant(&quot;tensor3&quot;)
u1 = save_tensor(t1,val)
u2 = save_tensor(t2,2*val)
u3 = save_tensor(t3,3*val)

z1 = get_tensor(t1);
z2 = get_tensor(t2);
z3 = get_tensor(t3);

d1 = delete_tensor(t1);
d2 = delete_tensor(t2);
d3 = delete_tensor(t3);
sess = Session(); 
run(sess, [u1,u2,u3]) # add all the keys

# get the keys one by one
run(sess, z1)
run(sess, z2)
run(sess, z3)

# delete 2nd key
run(sess, d2)</code></pre><p>The expected output is </p><pre><code class="language-txt">[Add] tensor3 to collections.
========Existing Keys========
Key tensor3

[Add] tensor2 to collections.
========Existing Keys========
Key tensor2
Key tensor3

[Add] tensor1 to collections.
========Existing Keys========
Key tensor1
Key tensor2
Key tensor3

[Get] Key tensor1 exists.
========Existing Keys========
Key tensor1
Key tensor2
Key tensor3

[Get] Key tensor2 exists.
========Existing Keys========
Key tensor1
Key tensor2
Key tensor3

[Get] Key tensor3 exists.
========Existing Keys========
Key tensor1
Key tensor2
Key tensor3

[Delete] Erase key tensor2.
========Existing Keys========
Key tensor1
Key tensor3</code></pre><p>For example, in <a href="../factorization/">this article</a> we use the technique introduced here to design a custom operator for direct methods for sparse matrix solutions. </p><h2 id="Solutions-for-Windows"><a class="docs-heading-anchor" href="#Solutions-for-Windows">Solutions for Windows</a><a id="Solutions-for-Windows-1"></a><a class="docs-heading-anchor-permalink" href="#Solutions-for-Windows" title="Permalink"></a></h2><p>Windows systems have special rules for creating and linking dynamic libraries. Basically you need to export symbols in the dynamic libraries so that they are visiable to application programs. To avoid many troubles that you may encounter getting the macros and configurations correct, you can instead compile all the source into a single dynamic library. The model is as follows</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/saver_win.png?raw=true" alt/></p><p>The source codes and CMakeLists.txt in the above section can be reused without any modification.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ode/">« PDE/ODE Solvers</a><a class="docs-footer-nextpage" href="../julia_customop/">Julia Custom Operators »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 19 June 2021 00:10">Saturday 19 June 2021</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
