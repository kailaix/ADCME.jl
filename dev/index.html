<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Overview · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Overview</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Optimization"><span>Optimization</span></a></li><li><a class="tocitem" href="#Machine-Learning"><span>Machine Learning</span></a></li><li><a class="tocitem" href="#Contributing"><span>Contributing</span></a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="tutorial/">Overview</a></li><li><a class="tocitem" href="videos_and_slides/">Video Lectures and Slides</a></li><li><a class="tocitem" href="tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="parallel/">Parallel Computing</a></li><li><a class="tocitem" href="optimizers/">Optimizers</a></li><li><a class="tocitem" href="optim/">Study on Optimizers</a></li><li><a class="tocitem" href="ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="nn/">Neural Networks</a></li><li><a class="tocitem" href="ot/">Optimal Transport</a></li><li><a class="tocitem" href="resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="options/">Global Options</a></li><li><a class="tocitem" href="mcmc/">Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC</a></li><li><a class="tocitem" href="mpi/">Distributed Scientific Machine Learning using MPI</a></li><li><a class="tocitem" href="mpi_benchmark/">MPI Benchmarks</a></li><li><a class="tocitem" href="multithreading/">Understand the Multi-threading Model</a></li><li><a class="tocitem" href="rbf/">Radial Basis Functions</a></li><li><a class="tocitem" href="topopt/">Topological Optimization</a></li><li><a class="tocitem" href="quadrature/">Numerical Integration</a></li></ul></li><li><span class="tocitem">Physics Informed Machine Learning</span><ul><li><a class="tocitem" href="fdtd/">Finite-difference Time-domain for Electromagnetics and Seismic Inversion</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="flow/">Normalizing Flows</a></li><li><a class="tocitem" href="convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="bnn/">Bayesian Neural Networks</a></li></ul></li><li><span class="tocitem">Developer Guide</span><ul><li><a class="tocitem" href="designpattern/">Design Pattern</a></li><li><a class="tocitem" href="toolchain/">Built-in Toolchain for Third-party Libraries</a></li><li><a class="tocitem" href="installmpi/">Configure MPI for Distributed Computing</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="apps/">Overview</a></li><li><a class="tocitem" href="apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Overview</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h1><p>ADCME is suitable for conducting inverse modeling in scientific computing; specifically, ADCME targets <strong>physics informed machine learning</strong>, which leverages machine learning techniques to solve challenging scientific computing problems. The purpose of the package is to: (1) provide differentiable programming framework for scientific computing based on TensorFlow automatic differentiation (AD) backend; (2) adapt syntax to facilitate implementing scientific computing, particularly for numerical PDE discretization schemes; (3) supply missing functionalities in the backend (TensorFlow) that are important for engineering, such as sparse linear algebra, constrained optimization, etc. Applications include</p><ul><li><p>physics informed machine learning (a.k.a., scientific machine learning, physics informed learning, etc.)</p></li><li><p>coupled hydrological and full waveform inversion</p></li><li><p>constitutive modeling in solid mechanics</p></li><li><p>learning hidden geophysical dynamics</p></li><li><p>parameter estimation in stochastic processes</p></li></ul><p>The package inherits the scalability and efficiency from the well-optimized backend TensorFlow. Meanwhile, it provides access to incorporate existing C/C++ codes via the custom operators. For example, some functionalities for sparse matrices are implemented in this way and serve as extendable &quot;plugins&quot; for ADCME. </p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/summary.png?raw=true" alt/></p><p>ADCME is open-sourced with an MIT license. You can find the source codes at </p><p><a href="https://github.com/kailaix/ADCME.jl">https://github.com/kailaix/ADCME.jl</a></p><p>Read more about methodology, philosophy, and insights about ADCME: <a href="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/Slide/ADCME.pdf?raw=true">slides</a>. Start with <a href="tutorial/">tutorial</a> to solve your own inverse modeling problems!</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>It is recommended to install ADCME via</p><pre><code class="language-julia">using Pkg
Pkg.add(&quot;ADCME&quot;)</code></pre><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>If you use Windows OS, you need to install Microsoft Visual Studio 15 (2017) first. If you do not have the compiler yet, you can download and install the compiler from <a href="https://visualstudio.microsoft.com/vs/older-downloads/">here</a>. A free community version is available. </p><p>For Windows, you also need to set an extra set of PATH environment variables. Please add the following environment variables to your system path (my user name is <code>kaila</code>; please replace it with yours!)</p><pre><code class="language-none">C:\Users\kaila\.julia\adcme\Scripts
C:\Users\kaila\.julia\adcme\Library\bin
C:\Users\kaila\.julia\adcme\</code></pre><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/windows_install.png?raw=true" alt/></p></div></div><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>In some cases, you may want to install the package and configure the environment manually. </p><p>Step 1: Install <code>ADCME</code> on a computer with Internet access and zip all files from the following paths</p><pre><code class="language-julia">julia&gt; using Pkg
julia&gt; Pkg.depots()</code></pre><p>The files will contain all the dependencies.</p><p>Step 2:  Copy the <code>deps.jl</code> file from your built ADCME and modify it for your local repository. </p><pre><code class="language-julia">using ADCME; 
print(joinpath(splitdir(pathof(ADCME))[1], &quot;deps/deps.jl&quot;))</code></pre></div></div><h2 id="Optimization"><a class="docs-heading-anchor" href="#Optimization">Optimization</a><a id="Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization" title="Permalink"></a></h2><p>ADCME is an all-in-one solver for gradient-based optimization problems. It leverages highly optimized and concurrent/parallel kernels that are implemented in C++ for both the forward computation and gradient computation. Additionally, it provides a friendly user interface to specify the mathematical optimization problem: constructing a computational graph. </p><p>Let&#39;s consider a simple problem: we want to solve the unconstrained optimization problem</p><p class="math-container">\[f(\mathbf{x}) = \sum_{i=1}^{n-1}\left[ 100(x_{i+1}-x_i^2) + (1-x_i)^2 \right]\]</p><p>where <span>$x_i\in [-10,10]$</span> and <span>$n=100$</span>. </p><p>We solve the problem using the L-BFGS-B method. </p><pre><code class="language-julia">using ADCME
n = 100
x = Variable(rand(n)) # Use `Variable` to mark the quantity that gets updated in optimization
f = sum(100((x[2:end]-x[1:end-1])^2 + (1-x[1:end-1])^2)) # Use typical Julia syntax 
sess = Session(); init(sess) # Create and initialize a session is mandatory for activating the computational graph
BFGS!(sess, f, var_to_bounds = Dict(x=&gt;[-10.,10.]))</code></pre><p>To get the value of <span>$\mathbf{x}$</span>, we use <a href="@ref"><code>run</code></a> to extract the values </p><pre><code class="language-julia">run(sess, x)</code></pre><p>The above code will return a value close to  the optimal values <span>$\mathbf{x} = [1\ 1\ \ldots\ 1]$</span>. </p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>You can also use <a href="api/#ADCME.Optimize!-Union{Tuple{T}, Tuple{PyCall.PyObject,PyCall.PyObject}, Tuple{PyCall.PyObject,PyCall.PyObject,Int64}} where T&lt;:Union{Nothing, PyCall.PyObject}"><code>Optimize!</code></a> to use other optimizers. For example, if you want to use an optimizer, such as <code>ConjugateGraidient</code> from the <code>Optim</code> package, simply replace <code>BFGS!</code> with <code>Optimize!</code> and specify the corresponding optimizer</p><pre><code class="language-julia">using Optim
Optimize!(sess, loss, optimizer = ConjugateGradient())</code></pre></div></div><h2 id="Machine-Learning"><a class="docs-heading-anchor" href="#Machine-Learning">Machine Learning</a><a id="Machine-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Machine-Learning" title="Permalink"></a></h2><p>You can also use ADCME to do typical machine learning tasks and leverage the Julia machine learning ecosystem! Here is an example of training a ResNet for digital number recognition.</p><pre><code class="language-julia">using MLDatasets
using ADCME

# load data 
train_x, train_y = MNIST.traindata()
train_x = reshape(Float64.(train_x), :, size(train_x,3))&#39;|&gt;Array
test_x, test_y = MNIST.testdata()
test_x = reshape(Float64.(test_x), :, size(test_x,3))&#39;|&gt;Array

# construct loss function 
ADCME.options.training.training = placeholder(true)
x = placeholder(rand(64, 784))
l = placeholder(rand(Int64, 64))
resnet = Resnet1D(10, num_blocks=10)
y = resnet(x)
loss = mean(sparse_softmax_cross_entropy_with_logits(labels=l, logits=y))

# train the neural network 
opt = AdamOptimizer().minimize(loss)
sess = Session(); init(sess)
for i = 1:10000
    idx = rand(1:60000, 64)
    _, loss_ = run(sess, [opt, loss], feed_dict=Dict(l=&gt;train_y[idx], x=&gt;train_x[idx,:]))
    @info i, loss_
end

# test 
for i = 1:10
    idx = rand(1:10000,100)
    y0 = resnet(test_x[idx,:])
    y0 = run(sess, y0, ADCME.options.training.training=&gt;false)
    pred = [x[2]-1 for x in argmax(y0, dims=2)]
    @info &quot;Accuracy = &quot;, sum(pred .== test_y[idx])/100
end</code></pre><h2 id="Contributing"><a class="docs-heading-anchor" href="#Contributing">Contributing</a><a id="Contributing-1"></a><a class="docs-heading-anchor-permalink" href="#Contributing" title="Permalink"></a></h2><p>Contribution and suggestions are always welcome. In addition, we are also looking for research collaborations. You can submit issues for suggestions, questions, bugs, and feature requests, or submit pull requests to contribute directly. You can also contact the authors for research collaboration. </p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorial/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 17 December 2020 21:42">Thursday 17 December 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
