<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training Deep Neural Networks with Trust-Region Methods · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../videos_and_slides/">Video Lectures and Slides</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../optimizers/">Optimizers</a></li><li><a class="tocitem" href="../optim/">Study on Optimizers</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li><li><a class="tocitem" href="../mcmc/">Uncertainty Quantification of Neural Networks in Physics Informed Learning using MCMC</a></li><li><a class="tocitem" href="../mpi/">Distributed Scientific Machine Learning using MPI</a></li><li><a class="tocitem" href="../mpi_benchmark/">MPI Benchmarks</a></li><li><a class="tocitem" href="../multithreading/">Understand the Multi-threading Model</a></li><li><a class="tocitem" href="../rbf/">Radial Basis Functions</a></li><li><a class="tocitem" href="../topopt/">Topological Optimization</a></li><li><a class="tocitem" href="../quadrature/">Numerical Integration</a></li><li><a class="tocitem" href="../sqlite3/">Introducing ADCME Database and SQL Integration: an Efficient Approach to Simulation Data Management</a></li><li><a class="tocitem" href="../hessian/">The Mathematical Structure of DNN Hessians</a></li><li><a class="tocitem" href="../plotly/">Visualization with Plotly</a></li></ul></li><li><span class="tocitem">Physics Informed Machine Learning</span><ul><li><a class="tocitem" href="../fdtd/">Finite-difference Time-domain for Electromagnetics and Seismic Inversion</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="../flow/">Normalizing Flows</a></li><li><a class="tocitem" href="../convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="../bnn/">Bayesian Neural Networks</a></li><li><a class="tocitem" href="../reinforcement_learning/">Reinforcement Learning Basics: Q-learning and SARSA</a></li></ul></li><li><span class="tocitem">Developer Guide</span><ul><li><a class="tocitem" href="../designpattern/">Design Pattern</a></li><li><a class="tocitem" href="../toolchain/">Built-in Toolchain for Third-party Libraries</a></li><li><a class="tocitem" href="../installmpi/">Configure MPI for Distributed Computing</a></li><li><a class="tocitem" href="../windows_installation/">Install ADCME on Windows</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Training Deep Neural Networks with Trust-Region Methods</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training Deep Neural Networks with Trust-Region Methods</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/second_order_optimizer.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-Deep-Neural-Networks-with-Trust-Region-Methods"><a class="docs-heading-anchor" href="#Training-Deep-Neural-Networks-with-Trust-Region-Methods">Training Deep Neural Networks with Trust-Region Methods</a><a id="Training-Deep-Neural-Networks-with-Trust-Region-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Training-Deep-Neural-Networks-with-Trust-Region-Methods" title="Permalink"></a></h1><p>Trust-region methods are a class of global optimization methods. The basic idea is to successively solve an approximated optimization problem in a small neighborhood of the current state. For example, we can approximate the local landscape of the objective function using a quadratic function, and thus can solve efficiently and accurately. The biggest advantage of trust-region methods in the context of deep neural network is that they can escape saddle points, which are demonstrated to be the dominant causes for slow convergence, with proper algorithm design. </p><p>However, the most challenging problem with trust-region methods is that we need to calculate the Hessian (curvature information) to leverage the local curvature information. Computing the Hessian can be quite expensive and challenging, especially if the forward computation involves complex procedures and has a large number of optimizable variables. Fortunately, for many deep neural network based inverse problems, the DNNs do not need to be huge for good accuracy. Therefore, calculating the Hessian is plausible. This does not mean that efficient computation is easy, and we introduce the technique is another post. In this post, we compare the trust-region method with other competing methods (L-BFGS-B, BFGS, and ADAM optimizer) for training deep neural networks that are coupled with a numerical solver. We also shed lights on why the other optimizers slow down. </p><h2 id="Trust-region-Methods"><a class="docs-heading-anchor" href="#Trust-region-Methods">Trust-region Methods</a><a id="Trust-region-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Trust-region-Methods" title="Permalink"></a></h2><p>We consider an unconstrained optimization problem </p><p class="math-container">\[\min_x f(x) \tag{1}\]</p><p>The trust-region method solves the optimization problem Eq. 1 by iteratively solving many simpler subproblems, which are good approximation to <span>$f(x_k)$</span> at the neighborhood of <span>$x_k$</span>. We model <span>$f(x_k+s)$</span> using a quadratic model </p><p class="math-container">\[m(s) = f_k + s^T g_k + \frac{1}{2}s^T H_k s \tag{2}\]</p><p>Here <span>$f_k = f(x_k)$</span>, <span>$g_k = \nabla f(x_k)$</span>, <span>$H_k = \nabla^2 f(x_k)$</span>. </p><p>Eq. 2 is essentially the Taylor expansion of <span>$f(x)$</span> at <span>$x_k$</span>. This approximation is only accurate within the neighborhood of <span>$x_k$</span>. Therefore, we constrain our subproblem to a <strong>trust region</strong> </p><p class="math-container">\[||s||\leq \Delta_k\]</p><p>The subproblem has the following form </p><p class="math-container">\[\begin{aligned}\min_{s} &amp; \; m(s) \\ \text{s.t.} &amp; \; \|s\|\leq \Delta_k\end{aligned} \tag{3}\]</p><p>In this work, we use the method proposed in [^trust-region] to solve Eq. 3 nearly exactly. </p><p>[^trust-region]: A.R. Conn, N.I. Gould, and P.L. Toint, &quot;Trust region methods&quot;, Siam, pp. 169-200, 2000.</p><h2 id="Example:-Static-Poisson&#39;s-Equation"><a class="docs-heading-anchor" href="#Example:-Static-Poisson&#39;s-Equation">Example: Static Poisson&#39;s Equation</a><a id="Example:-Static-Poisson&#39;s-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Static-Poisson&#39;s-Equation" title="Permalink"></a></h2><p>In this example, we consider the Poisson&#39;s equation </p><p class="math-container">\[\nabla \cdot (\kappa_\theta(u) \nabla u)) = f(x), \;x\in \Omega, \; x\in \partial\Omega\]</p><p>Here <span>$\kappa_\theta(u)$</span> is a deep neural network and <span>$\theta$</span> is the weights and biases. We discretize <span>$\Omega$</span> using a uniform grid. Assume we can observe the full field data <span>$u_{obs}$</span> on the grid points. We can then train the deep neural network using the residual minimization method [^residual-minimization]</p><p class="math-container">\[\min_\theta \sum_{i,j} (F_{i,j}(\theta) - f_{i,j})^2 \tag{4}\]</p><p>Here <span>$F_{i,j}(\theta)$</span> is the finite difference discretization of <span>$\nabla \cdot (\kappa_\theta(u_{obs}) \nabla u_{obs}))$</span> at the grid points. In our benchmark, we add 10% uniform random noise to <span>$f$</span> and <span>$u_{obs}$</span> to make the problem more challenging.  </p><p>[^residual-minimization]: Huang, Daniel Z., et al. &quot;Learning constitutive relations from indirect observations using deep neural networks.&quot; Journal of Computational Physics (2020): 109491.</p><p>We apply 4 optimizers to solve Eq. 4. Because the optimization results depend on the initialization of the deep neural network, we use 5 different initial guess for DNNs. The result is shown below</p><table><tr><th style="text-align: right">Case</th><th style="text-align: right">Convergence Plots</th></tr><tr><td style="text-align: right">1</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses2_static.png?raw=true" alt/></td></tr><tr><td style="text-align: right">2</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses23_static.png?raw=true" alt/></td></tr><tr><td style="text-align: right">3</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses233_static.png?raw=true" alt/></td></tr><tr><td style="text-align: right">4</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses2333_static.png?raw=true" alt/></td></tr><tr><td style="text-align: right">5</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses23333_static.png?raw=true" alt/></td></tr></table><p>We can see for all cases, the trust-region method provides a much more accurate result, and in general converges faster. The ADAM optimizer is the least competent, partially because it&#39;s a first-order optimizer and is not able to fully leverage the curvature information. The BFGS optimizers constructs an approximate Hessian that is SPD. The L-BFGS-B optimizer is an approximation to BFGS, where it uses only a limited number of previous iterates to construct the Hessian matrix. As mentioned, in the optimization problem involving deep neural networks, the slow down is mainly due to the saddle point, where the descent direction corresponds to the negative eigenvalues of the Hessian matrix. Because BFGS and L-BFGS-B ensure that the Hessian matrix is SPD, they cannot provide approximate guidance to escape the saddle point. This hypothesis is demonstrated in the following plot, where we show the distribution of Hessian eigenvalues at the last step for Case 2</p><table><tr><th style="text-align: right">Optimizer</th><th style="text-align: right">L-BFGS-B</th><th style="text-align: right">BFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right">Eigenvalue Distribution</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_lbfgs_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_bfgs_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_tr_eig.png?raw=true" alt/></td></tr></table><p>In the following, we show the eigenvalue distribution of the Hessian matrix for </p><p class="math-container">\[l(\theta) = \sum_{i=1}^n (\kappa_\theta(u_i) - \kappa_i)^2\]</p><p>We can see that the Hessian possesses some negative eigenvalues. This implies that the DNN and DNN-FEM loss functions indeed have different curvature structures at the local minimum. The structure is altered by the PDE constraint. </p><table><tr><th style="text-align: right">Optimizer</th><th style="text-align: right">L-BFGS-B</th><th style="text-align: right">BFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right">Eigenvalue Distribution</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_static_lbfgs_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_static_bfgs_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_static_tr_eig.png?raw=true" alt/></td></tr></table><p>We also show the number of <strong>negative</strong> eigenvalues for the BFGS and trust region optimizer. Here we use a threshold <span>$\epsilon=10^{-6}$</span>: for a given eigenvalue <span>$\lambda$</span>, it is treated as &quot;positive&quot; if <span>$\lambda&gt;\epsilon \lambda_{\max}$</span>, and &quot;negative&quot; if <span>$\lambda &lt; - \epsilon \lambda_{\max}$</span>, otherwise zero. Here <span>$\lambda_{\max}$</span> is the maximum eigenvalue. </p><table><tr><th style="text-align: right">BFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_positive_eigvals.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_positive_eigvals_tr.png?raw=true" alt/></td></tr></table><p>We can see that the number of positive eigenvalues stays at around 18 and 30 for BFGS and trust region methods after a sufficient number of iterations. The number of negative eigenvalues is nearly zero. This means that both optimizers converge to points with positive semidefinite Hessian matrices. Stationary points are true local minima, instead of saddle points. </p><p>We also analyze the direction of the search direction <span>$p_k$</span> in the BFGS optimizer. We consider two values</p><p class="math-container">\[\begin{aligned}\cos(\theta_1) &amp;= \frac{-p_k^T g_k}{\|p_k\|\|g_k\|} \\ \cos(\theta_2) &amp;= \frac{p_k^T q_k}{\|p_k\|\|q_k\|}\end{aligned}\]</p><p>Here <span>$q_k$</span> is the direction for the <strong>Newton&#39;s point</strong></p><p class="math-container">\[q_k = -H_k^{-1}g_k\]</p><p>The two quantities are shown in the following plots (since the trust-region method converges in around 270 iterations, <span>$\cos(\theta2)$</span> only has limited data points)</p><table><tr><th style="text-align: right"><span>$\cos(\theta_1)$</span></th><th style="text-align: right"><span>$\cos(\theta_2)$</span></th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_angles.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_angles2.png?raw=true" alt/></td></tr></table><p>There are two conclusions to draw from the plots</p><ol><li>The search direction of the BFGS optimizer deviates from the gradient descent method. </li><li>The search direction of the BFGS optimizer is not very correlated with the Newton&#39;s point direction; this indicates the search direction poorly recognizes the negative curvature directions. </li></ol><h2 id="Example:-Heat-Equation"><a class="docs-heading-anchor" href="#Example:-Heat-Equation">Example: Heat Equation</a><a id="Example:-Heat-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Heat-Equation" title="Permalink"></a></h2><p>We consider a time-dependent PDE problem: the heat equation</p><p class="math-container">\[\frac{\partial u}{\partial t} = \nabla \cdot (\kappa_\theta(x) \nabla u)) + f(x), \;x\in \Omega, \; x\in \partial\Omega\]</p><p>We assume that we can observe the full field data of <span>$u$</span> as snapshots. We again apply the residual minimization method to train the deep neural network. The following shows the convergence plots for different initial guesses of the DNNs. </p><table><tr><th style="text-align: right">Case</th><th style="text-align: right">Convergence Plots</th></tr><tr><td style="text-align: right">1</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses2_dynamic.png?raw=true" alt/></td></tr><tr><td style="text-align: right">2</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses23_dynamic.png?raw=true" alt/></td></tr><tr><td style="text-align: right">3</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses233_dynamic.png?raw=true" alt/></td></tr><tr><td style="text-align: right">4</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses2333_dynamic.png?raw=true" alt/></td></tr><tr><td style="text-align: right">5</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/losses23333_dynamic.png?raw=true" alt/></td></tr></table><p>We see that the trust-region is more competitive than the other methods. </p><p>We also show the eigenvalue distribution of the Hessian matrices for Case 3. </p><table><tr><th style="text-align: right">ADAM</th><th style="text-align: right">BFGS</th><th style="text-align: right">LBFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/dynamic_ADAM_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/dynamic_BFGS_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/dynamic_LBFGS_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/dynamic_TrustRegion_eig.png?raw=true" alt/></td></tr><tr><td style="text-align: right">50</td><td style="text-align: right">31</td><td style="text-align: right">22</td><td style="text-align: right">35</td></tr></table><p>The eigenvalues of Hessian matrices are nonnegative except for the ADAM case, where the optimizer does not converge to a satisfactory local minimum after 5000 iterations. Hence, in what follows, we omit the discussion of ADAM optimizers. </p><p>The third row show the number of positive eigenvalues using the criterion mentioned before. We again see that among all three methods–-BFGS, LBFGS, and trust region–-the smaller loss function at the last step is associated with a larger number of positive eigenvalues. </p><p>We can interpret the eigenvalues associated with zero eigenvalues as &quot;inactive directions&quot;, in the sense that given the gradient norm is small, perturbation in the direction of zero eigenvalues almost does not change the loss function values. In other words, the local minimum found by trust region methods has more active directions than BFGS and LBFGS. The active directions can also be viewed as &quot;effective degrees of freedoms (DOFs)&quot;, and thus we conclude trust region methods find a local minimum with smaller loss function due to more effective DOFs. </p><p>The readers may wonder why different local minimums have different effective DOFs. To answer this question, we show the cumulative distribution of the maginitude of weights and biases in the following plot</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/weight_dist.png?raw=true" alt/></p><p>The plot shows that BFGS and LBFGS outweight trust region methods in terms of large weights and biases (in terms of maginitudes). Because we use <span>$\tanh$</span> as activation values, for fixed intermediate activation values, large weights and biases are more likely to cause saturation of activation values, i.e., the inputs to <span>$\tanh$</span> is large or small and thus the outputs are close to 1. To illustrate the idea, consider a simple function </p><p class="math-container">\[y = w_1 \tanh(w_2 x + b_2) + b_1\]</p><p>Given a reasonable <span>$x$</span> (e.g., <span>$x\approx 0.1$</span>), if <span>$|w_2|$</span> or <span>$|b_2|$</span> is large, <span>$y \approx b_1 \pm w_1$</span>, and thus the effective DOF is 2; if <span>$w_2$</span> and <span>$b_2$</span> is close to 0, <span>$y\approx w_1 w_2 x + w_1 b_2 + b_1$</span>, perturbation of all four parameters <span>$w_1$</span>, <span>$w_2$</span>, <span>$b_1$</span>, <span>$b_2$</span> may contribute to the change of <span>$y$</span>, and thus the effective DOF is 4. In sum, trust region methods yield weights and biases with smaller magnitudes compared to BFGS/LBFGS in general, and thus achieve more effective DOFs. </p><p>This conjecture is confirmed by the following plot, which shows the histogram of the intermediate activation values. We fixed the input <span>$x = (0.5,0.5)$</span> (the midpoint of the computational domain), and collected all the outputs of the <span>$\tanh$</span> function within the DNN. The figure shows that compared to the trust region method, the activation values of ADAM, BFGS and LBFGS are more concentrated near the extreme values <span>$-1$</span> and <span>$1$</span>. </p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/activation_dist.png?raw=true" alt/></p><p>How can trust region methods manage the magnitudes of the weights and biases? The benefit is intrinsic to how the trust region method works: it only searches for &quot;optimal solution&quot; with a small neighborhood of the current state. However, BFGS and LBFGS searches for &quot;optimal solution&quot; along a direction aggressively. Given so many local minima, it is very likely that BFGS and LBFGS get trapped in a local minimum with smaller effective DOFs. In this perspective, trust region methods are useful methods for avoiding (instead of &quot;escaping&quot;) bad local minima. </p><table><tr><th style="text-align: right">ADAM</th><th style="text-align: right">BFGS</th><th style="text-align: right">LBFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_dynamic_ADAM_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_dynamic_BFGS_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_dynamic_LBFGS_eig.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/nn_dynamic_TrustRegion_eig.png?raw=true" alt/></td></tr><tr><td style="text-align: right">132</td><td style="text-align: right">34</td><td style="text-align: right">41</td><td style="text-align: right">38</td></tr></table><p>In the above plot, we show the eigenvalue distribution of the Hessian matrix for </p><p class="math-container">\[l(\theta) = \sum_{i=1}^n (\kappa_\theta(x_i) - \kappa_i)^2\]</p><p>Here <span>$\kappa_i$</span> is the true <span>$\kappa$</span> value at location <span>$x_i$</span> (<span>$x_i$</span> is the Gauss quadrature point), and <span>$\kappa_\theta(x_i)$</span> is the DNN estimate. We get rid of the PDE out of the loss function. The pattern of the eigenvalue distribution–-a few positive eigenvalues accompanied by zero eigenvalues–-still persists. The difference is that the number of positive eigenvalues are slightly larger than the loss function that couples DNNs and PDEs.This implies that PDEs restricts effective DOFs. We attribute the diminished effective DOFs to the physical constraints imposed by PDEs. </p><h2 id="Example:-FEM-for-Static-Poisson&#39;s-Equation"><a class="docs-heading-anchor" href="#Example:-FEM-for-Static-Poisson&#39;s-Equation">Example: FEM for Static Poisson&#39;s Equation</a><a id="Example:-FEM-for-Static-Poisson&#39;s-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-FEM-for-Static-Poisson&#39;s-Equation" title="Permalink"></a></h2><p>Consider the Poisson&#39;s equation again. This time, the loss function is formulated as </p><p class="math-container">\[L(\theta) = \sum_i (u_{obs}(x_i) - u_\theta(x_i))^2\]</p><p>Here <span>$u_\theta$</span> is the numerical solution to the Poisson&#39;s equation. The evaluation of <span>$\nabla^2_\theta L(\theta)$</span> requires back-propagating the Hessian matrix through various operators including the sparse solver (see <a href="https://kailaix.github.io/ADCME.jl/dev/second_order_pcl/#Example:-Developing-Second-Order-PCL-for-a-Sparse-Linear-Solver">this post</a> for how the back-propagation rule is implemented). </p><p>The following shows an example of the implementation, which is annotated for convenience. </p><pre><code class="language-julia">using AdFem 
using PyPlot 
using LinearAlgebra
using JLD2

# disable auth reordering so that the Hessian back-propagation works properly 
ADCME.options.sparse.auto_reorder = false

using Random; Random.seed!(233)
sess = Session()

function simulate(θ)

    # The first part is a standard piece of codes for doing numerical simulation in ADCME 
    global mmesh = Mesh(10,10,0.1)
    x = gauss_nodes(mmesh)
    Fsrc = eval_f_on_gauss_pts((x,y)-&gt;1.0, mmesh)
    
    global kappa = squeeze(fc(x, [20,20,20,1], θ)) + 0.5
    A_orig = compute_fem_laplace_matrix1(kappa, mmesh)
    F = compute_fem_source_term1(Fsrc, mmesh)
    global bdnode = bcnode(mmesh)
    global A, F = impose_Dirichlet_boundary_conditions(A_orig, F, bdnode, zeros(length(bdnode)))

    @load &quot;Data/fwd_data.jld2&quot; sol 
    SOL = sol 
    
    global sol = A\F

    global loss = sum((sol-SOL)^2)

    # We now calculate some extra tensors for use in Hessian back-propagation 

    # We use the TensorFlow tf.hessians (hessian in ADCME) to calculate the Hessian of DNNs. Note this algorithm is different from second order PCL 
    global H_dnn_pl, W_dnn_pl = pcl_hessian(kappa, θ, loss)
    global dsol = gradients(loss, sol)
    global dθ = gradients(loss, θ)

    # We need the indices for sparse matrices in the Hessian back-propagation 
    init(sess)
    global indices_orig = run(sess, A_orig.o.indices) .+ 1
    global indices = run(sess, A.o.indices) .+ 1

end


function calculate_hessian(θ0)
    # Retrieve intermediate values. Note in an optimized implementation, these values should already be available in the &quot;tape&quot;. However, because second order PCL is currently in development, we recalculate these values for simplicity 
    A_vals, sol_vals, dsol_vals  = run(sess, [A.o.values, sol, dsol], θ=&gt;θ0)

    # SoPCL for `loss = sum((sol-SOL)^2)`
    W = pcl_square_sum(length(sol))

    # SoPCL for `sol = A\F` 
    W = pcl_sparse_solve(indices, 
        A_vals, 
        sol_vals, 
        W, 
        dsol_vals)
        
    # SoPCL for `A, F = impose_Dirichlet_boundary_conditions(...)`
    J = pcl_impose_Dirichlet_boundary_conditions(indices_orig, bdnode, size(indices,1))
    W = pcl_linear_op(J, W)

    # SoPCL for `A_orig = compute_fem_laplace_matrix1(kappa, mmesh)`
    J = pcl_compute_fem_laplace_matrix1(mmesh)
    W = pcl_linear_op(J, W)

    # SoPCL for DNN
    run(sess, H_dnn_pl, feed_dict=Dict(W_dnn_pl=&gt;W, θ=&gt;θ0))
end

function calculate_gradient(θ0)
    run(sess, dθ, θ=&gt;θ0)
end

function calculate_loss(θ0)
    L = run(sess, loss, θ=&gt;θ0)
    @info &quot;Loss = $L&quot;
    L
end

# The optimization step
θ = placeholder(fc_init([2,20,20,20,1]))
simulate(θ)
res = opt.minimize(
    calculate_loss,
    θ0,
    method = &quot;trust-exact&quot;,
    jac = calculate_gradient,
    hess = calculate_hessian,
    tol = 1e-12,
    options = Dict(
        &quot;maxiter&quot;=&gt; 5000,
        &quot;gtol&quot;=&gt;0.0 # force the optimizer not to stop
    )
)</code></pre><p>It is very important that before we perform the optimization, we carry out the Hessian test using the <a href="../api/#ADCME.test_hessian-Tuple{Function,Array{Float64,1}}"><code>test_hessian</code></a> function.</p><pre><code class="language-julia">function test_f(θ0)
    calculate_gradient(θ0), calculate_hessian(θ0)
end
θ0 = run(sess, θ)
test_jacobian(test_f, θ0, scale=1e-3)</code></pre><p>This should give us a plot as follows:</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/hessian_test.png?raw=true" alt/></p><p>Now let us consider the inverse problem. First we generate the observation using </p><p class="math-container">\[\kappa(x) = \frac{1}{1+\|x\|_2^2}+1\]</p><p>The observation is shown as below</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/sol.png?raw=true" alt/></p><p>We use the full field data for simplicity, although our method also applies to sparse observations. The following plots shows results where the trust region method performs significantly better than the BFGS and LBFGS method. </p><p><strong>Case 1</strong></p><table><tr><th style="text-align: right">Description</th><th style="text-align: right">Result</th></tr><tr><td style="text-align: right">Loss</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/loss2.png?raw=true" alt/></td></tr><tr><td style="text-align: right">LBFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_2.png?raw=true" alt/></td></tr><tr><td style="text-align: right">BFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/bfgs_2.png?raw=true" alt/></td></tr><tr><td style="text-align: right">Trust Region</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/tr_2.png?raw=true" alt/></td></tr></table><p><strong>Case 2</strong></p><table><tr><th style="text-align: right">Description</th><th style="text-align: right">Result</th></tr><tr><td style="text-align: right">Loss</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/loss2333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">LBFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_2333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">BFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/bfgs_2333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">Trust Region</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/tr_2333.png?raw=true" alt/></td></tr></table><p><strong>Case 3</strong></p><table><tr><th style="text-align: right">Description</th><th style="text-align: right">Result</th></tr><tr><td style="text-align: right">Loss</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/loss23333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">LBFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_23333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">BFGS</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/bfgs_23333.png?raw=true" alt/></td></tr><tr><td style="text-align: right">Trust Region</td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/tr_23333.png?raw=true" alt/></td></tr></table><p>In the following plots, we show the absolute eigenvalue distributions of Hessians at the terminal point for Case 2. The red dashed line represents the level <span>$10^{-6}\lambda_{\max}$</span>, where <span>$\lambda_{\max}$</span> is the maximum eigenvalue. </p><table><tr><th style="text-align: right">LBFGS</th><th style="text-align: right">BFGS</th><th style="text-align: right">Trust Region</th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_eigs.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/bfgs_eigs.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/tr_eigs.png?raw=true" alt/></td></tr></table><p>Eigenvalues that lie below the red dashed line can be treated as zero. This means that for BFGS and the trust region method, the optimizers find local minima. In fact, we show </p><p class="math-container">\[F(\alpha) = L(x^* + \alpha v)\]</p><p>in the following plots, where <span>$x^*$</span> is the converged point for LBFGS, <span>$v$</span> is the eigenvector corresponding to either the minimum or maximum eigenvalues of the Hessian. The profile for the former case is quite flat, indicating that small perturbation along the eigenvector direction makes little change to the loss function. Thus, for LBFGS, we can also assume that a local minimum is found. </p><p>Interestingly, even though all optimizers find local minima. The final loss functions and errors are quite different. Trust methods perform much better in these cases compared to BFGS and LBFGS (in some other cases, BFGS may perform better). </p><table><tr><th style="text-align: right"><span>$\lambda_{\min}$</span></th><th style="text-align: right"><span>$\lambda_{\max}$</span></th></tr><tr><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_vmin.png?raw=true" alt/></td><td style="text-align: right"><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/second_order_optimizer/static_poisson/lbfgs_vmax.png?raw=true" alt/></td></tr></table><p>The problem itself is nonconvex and has many local minima–-different from the common belief that in deep learning, stationary points are usually saddle points if they are not the global minimum. Trust region methods do not guarantee that we can find a global  minimum, or even a &quot;good&quot; local minimum. However, because trust region methods shows faster convergence and superior accuracy in many cases, it never harms to add trust region methods into the optimization tool box. Additionally, the Hessian calculated using the second order PCL is a powerful weapon for diagnosing the convergence and provides curvature information for more sophisticated optimizers. </p><h2 id="Limitations"><a class="docs-heading-anchor" href="#Limitations">Limitations</a><a id="Limitations-1"></a><a class="docs-heading-anchor-permalink" href="#Limitations" title="Permalink"></a></h2><p>Despite many promising features of the trust region method, it is not without limitations, which we want to discuss here. The current trust-region method requires calculating the Hessian matrix. Firstly, computing the Hessian matrix can be technically difficult, especially when DNNs are coupled with a sophisticated numerical PDE solver. There are many existing techniques for computing the Hessian. The TensorFlow backend supports Hessian computation concurrently, but it requires users to implement rules for calculating &quot;gradients of gradients&quot;. Additionally, TensorFlow uses reverse-mode automatic differentiation to evaluate the Hessian. This means that TensorFlow loops over each gradient component and calculating a row of Hessian at a time. This does not leverage the symmetry of Hessians and can be quite inefficient if the number of unknowns is large. Another approach, the edge pushing algorithm, uses one backward pass to evaluate the Hessian. This approach takes advantage of the symmetry of Hessians. However, the implementation can be quite convolved and computations can be expensive in some scenarios. We will cover this topic in more details in <a href="https://kailaix.github.io/ADCME.jl/dev/second_order_pcl/#Second-Order-Physics-Constrained-Learning">another post</a>. </p><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><p>Trust-region methods are a class of global optimization techniques. They are less popular in the deep learning approach because the DNNs tend to be huge and the computation of Hessians is expensive. However, they are very suitable for many computational engineering problems, where DNNs are typically small, and convergence as well as accuracy is a critical concern. Our point of view is that although the Hessian computations are expensive, they are quite rewarding. Future researches will focus on efficient computation and automation of Hessian computations. </p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 16 May 2021 23:12">Sunday 16 May 2021</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
